@0x95bed824078b511a;

interface ReplayMemory {
  struct TransitionBatch {
    # A batch of transitions to be pushed to the replay memory

    ids @0 :List(Text);                # uuid of the transition, generated by actors
    observations @1 :Data;             # blob - picked list of numpy multiarrays
    nextObservations @2 :Data;         # blob - picked list of numpy multiarrays
    actions @3 :List(UInt8);           # discrete action of actor
    rewards @4 :List(Float32);         # reward of actor
    dones @5 :List(Bool);              # whether the episode is done
    priorities @6 :List(Float32) = [ ];      # initial estimate of the priority of the transition, generated by actors
    indices @7 :List(Int32) = [ ];           # indices of the transitions in the replay memory
    weights @8 :List(Float32) = [ ];         # weights
  }

  addTransitionBatch @0 (batch :TransitionBatch);      
  # Add a batch of transitions to the replay memory
  # Used by actors to store the transitions they generate
  # Initial priorities are calculated by actors

  sample @1 (batchSize: UInt32) -> (batch :TransitionBatch);
  # Sample a batch of transitions from the replay memory
  # Used by the learner to sample transitions for training

  updatePriorities @2 (indices :List(Int32), ids :List(Text), priorities :List(Float32));
  # Update the priorities of the transitions with the given ids
  # Used by the learner to update the priorities of transitions after training
  # on a batch of transitions

  deleteOldTransitions @3 (maxSize :UInt32);
  # Delete old transitions from the replay memory if the size exceeds maxSize
  # Used by the learner to softcap the replay memory size 

  getWeights @4 () -> (weights :Data);
  setWeights @5 (weights :Data);
  ping @6 () -> ();
}