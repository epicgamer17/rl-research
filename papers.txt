Muzero: https://arxiv.org/pdf/1911.08265.pdf
Rainbow: https://arxiv.org/pdf/1710.02298.pdf
Revisiting Rainbow: https://arxiv.org/pdf/2011.14826.pdf 
AlphaZero: https://arxiv.org/pdf/1712.01815.pdf 
    Policy Value Alignment: https://arxiv.org/pdf/2301.11857.pdf 
A Disciplined Approach to Hyperparameters Part 1: https://arxiv.org/pdf/1803.09820.pdf
High Performance Algorithms for Turn Based Games Using Deep Learning: https://www.scitepress.org/Papers/2020/89561/89561.pdf 
KataGo: https://arxiv.org/pdf/2008.10080.pdf https://github.com/lightvector/KataGo/tree/master 
Never Give Up: https://arxiv.org/pdf/2002.06038.pdf 
Agent 57: https://arxiv.org/pdf/2003.13350.pdf
MEME: https://arxiv.org/pdf/2003.13350.pdf 
GDI: https://arxiv.org/pdf/2106.06232.pdf <- not used but interesting idea
Prioritized Experience Replay: https://arxiv.org/pdf/1511.05952.pdf 
PPO: https://arxiv.org/pdf/1707.06347.pdf
What Matters in On Policy RL: https://arxiv.org/pdf/2006.05990.pdf 
Population Based Training: https://arxiv.org/pdf/1711.09846.pdf <- not used but interesting idea for the future
Neural Fictitious Self Play: https://arxiv.org/pdf/1603.01121