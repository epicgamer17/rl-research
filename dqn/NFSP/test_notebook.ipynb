{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1 2 0 2 True\n",
      "1\n",
      "2 2 0 1 True\n",
      "deque([1, 2], maxlen=2)\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "test = deque(maxlen=2)\n",
    "state = 1 \n",
    "test.append(state)\n",
    "action = 0\n",
    "done = False\n",
    "state = 2\n",
    "test.append(state)\n",
    "action = 2\n",
    "done = True\n",
    "state = 3\n",
    "for p in range(len(test)):\n",
    "    print(p)\n",
    "    print(test[p], action, 0, test[-p + 1], done)  \n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 23:22:41.627116: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-05-07 23:22:41.627144: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-07 23:22:41.627151: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-07 23:22:41.627197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-07 23:22:41.627221: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from nfsp_agent import NFSPDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default adam_epsilon: 1e-06\n",
      "Using default learning_rate: 0.01\n",
      "Using default optimizer: <class 'keras.src.optimizers.adam.Adam'>\n",
      "Using loss_function: <keras.src.losses.KLDivergence object at 0x29bc2a3d0>\n",
      "Using default training_iterations: 1\n",
      "Using default num_minibatches: 1\n",
      "Using minibatch_size: 16\n",
      "Using replay_buffer_size: 200000\n",
      "Using min_replay_buffer_size: 16\n",
      "Using training_steps: 20000\n",
      "Using activation: relu\n",
      "Using kernel_initializer: he_normal\n",
      "Using num_players: 2\n",
      "Using default adam_epsilon: 1e-06\n",
      "Using default learning_rate: 0.01\n",
      "Using default optimizer: <class 'keras.src.optimizers.adam.Adam'>\n",
      "Using loss_function: <keras.src.losses.KLDivergence object at 0x29bc2a3d0>\n",
      "Using default training_iterations: 1\n",
      "Using default num_minibatches: 1\n",
      "Using minibatch_size: 16\n",
      "Using replay_buffer_size: 200000\n",
      "Using min_replay_buffer_size: 16\n",
      "Using training_steps: 20000\n",
      "Using activation: relu\n",
      "Using kernel_initializer: he_normal\n",
      "Using default width: 128\n",
      "Using default noisy_sigma: 0.5\n",
      "Using default conv_layers: []\n",
      "Using default conv_layers_noisy: False\n",
      "Using default dense_layers: 1\n",
      "Using default dense_layers_noisy: False\n",
      "Using default value_hidden_layers: 0\n",
      "Using default advantage_hidden_layers: 0\n",
      "Using default discount_factor: 0.99\n",
      "Using default soft_update: False\n",
      "Using transfer_interval: 100\n",
      "Using default ema_beta: 0.99\n",
      "Using replay_interval: 32\n",
      "Using default per_alpha: 0.6\n",
      "Using default per_beta: 0.5\n",
      "Using per_epsilon: 0.01\n",
      "Using default n_step: 3\n",
      "Using default atom_size: 51\n",
      "Using default adam_epsilon: 1e-06\n",
      "Using default learning_rate: 0.01\n",
      "Using default optimizer: <class 'keras.src.optimizers.adam.Adam'>\n",
      "Using loss_function: <keras.src.losses.KLDivergence object at 0x29bc2a3d0>\n",
      "Using default training_iterations: 1\n",
      "Using default num_minibatches: 1\n",
      "Using minibatch_size: 16\n",
      "Using replay_buffer_size: 200000\n",
      "Using min_replay_buffer_size: 16\n",
      "Using training_steps: 20000\n",
      "Using activation: relu\n",
      "Using kernel_initializer: he_normal\n",
      "Using default width: 128\n",
      "Using default noisy_sigma: 0.5\n",
      "Using default conv_layers: []\n",
      "Using default conv_layers_noisy: False\n",
      "Using default dense_layers: 1\n",
      "Using default dense_layers_noisy: False\n",
      "Using default value_hidden_layers: 0\n",
      "Using default advantage_hidden_layers: 0\n",
      "Using default discount_factor: 0.99\n",
      "Using default soft_update: False\n",
      "Using transfer_interval: 100\n",
      "Using default ema_beta: 0.99\n",
      "Using replay_interval: 32\n",
      "Using default per_alpha: 0.6\n",
      "Using default per_beta: 0.5\n",
      "Using per_epsilon: 0.01\n",
      "Using default n_step: 3\n",
      "Using default atom_size: 51\n",
      "Using default sl_adam_epsilon: 1e-07\n",
      "Using default sl_learning_rate: 0.005\n",
      "Using default sl_optimizer: <class 'keras.src.optimizers.adam.Adam'>\n",
      "Using training_steps: 20000\n",
      "Using default sl_training_iterations: 1\n",
      "Using default sl_num_minibatches: 1\n",
      "Using sl_minibatch_size: 16\n",
      "Using sl_min_replay_buffer_size: 16\n",
      "Using sl_replay_buffer_size: 2000000\n",
      "Using sl_activation: relu\n",
      "Using sl_kernel_initializer: he_normal\n",
      "Using default sl_conv_layers: []\n",
      "Using default sl_conv_layers_noisy: False\n",
      "Using default sl_dense_layers: 1\n",
      "Using default sl_dense_layers_noisy: False\n",
      "Using default sl_width: 128\n",
      "Using default sl_adam_epsilon: 1e-07\n",
      "Using default sl_learning_rate: 0.005\n",
      "Using default sl_optimizer: <class 'keras.src.optimizers.adam.Adam'>\n",
      "Using training_steps: 20000\n",
      "Using default sl_training_iterations: 1\n",
      "Using default sl_num_minibatches: 1\n",
      "Using sl_minibatch_size: 16\n",
      "Using sl_min_replay_buffer_size: 16\n",
      "Using sl_replay_buffer_size: 2000000\n",
      "Using sl_activation: relu\n",
      "Using sl_kernel_initializer: he_normal\n",
      "Using default sl_conv_layers: []\n",
      "Using default sl_conv_layers_noisy: False\n",
      "Using default sl_dense_layers: 1\n",
      "Using default sl_dense_layers_noisy: False\n",
      "Using default sl_width: 128\n",
      "Using replay_interval: 32\n",
      "Using anticipatory_param: 0.1\n"
     ]
    }
   ],
   "source": [
    "from agent_configs import NFSPDQNConfig, RainbowConfig\n",
    "from game_configs import MississippiMarblesConfig, LeducHoldemConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config_dict = {\n",
    "    \"activation\": \"relu\",\n",
    "    \"kernel_initializer\": \"he_normal\",\n",
    "    \"loss_function\": tf.keras.losses.KLDivergence(),\n",
    "    \"per_epsilon\": 0.01,\n",
    "    \"sl_activation\": \"relu\",\n",
    "    \"sl_kernel_initializer\": \"he_normal\",\n",
    "    \"num_players\": 2,\n",
    "    \"training_steps\": 20000,\n",
    "    \"anticipatory_param\": 0.1,\n",
    "    \"min_replay_buffer_size\": 16,\n",
    "    \"sl_min_replay_buffer_size\": 16,\n",
    "    \"minibatch_size\": 16,\n",
    "    \"sl_minibatch_size\": 16,\n",
    "    \"replay_interval\": 32,\n",
    "    \"sl_replay_buffer_size\": 2000000,\n",
    "    \"replay_buffer_size\": 200000,\n",
    "    \"transfer_interval\": 100,\n",
    "    \"n_step\": 1,\n",
    "}\n",
    "# config = NFSPConfig(config_dict=config_dict, game_config=MississippiMarblesConfig(), rl_config_type=RainbowConfig)\n",
    "config = NFSPDQNConfig(config_dict=config_dict, game_config=LeducHoldemConfig(), rl_config_type=RainbowConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n",
      "observation_dimensions:  (36,)\n",
      "num_actions:  4\n"
     ]
    }
   ],
   "source": [
    "from rainbow.rainbow_agent import RainbowAgent\n",
    "import custom_gym_envs\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import rlcard\n",
    "# env = gym.make('custom_gym_envs/MississippiMarbles-v0', render_mode=\"human\", players=2)\n",
    "env = gym.make('custom_gym_envs/LeducHoldem-v0')\n",
    "agent = NFSPDQN(env, config, RainbowAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Values  [0.19670127 0.26096598 0.21420218 0.34617208]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be int8, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be int8, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.7332662, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.223592, shape=(), dtype=float32)\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.4963908, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.2262936, shape=(), dtype=float32)\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.357063, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.91884863, shape=(), dtype=float32)\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(1.1007878, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.79606843, shape=(), dtype=float32)\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.95204914, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.84860396, shape=(), dtype=float32)\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.83778703, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.5587735, shape=(), dtype=float32)\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [0.15291438 0.14113195 0.43122961 0.46269991]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.2299653  -0.178693    0.21767008  0.02009   ]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.6825988, shape=(), dtype=float32)\n",
      "RL Buffer Size  0\n",
      "Min RL Buffer Size 16\n",
      "Experience Replay for SL Agent\n",
      "RL Loss 0\n",
      "SL Loss tf.Tensor(0.5851178, shape=(), dtype=float32)\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [-0.09114787 -0.03232518  0.10117905  0.24579167]\n",
      "Selected Action  3\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.27816174 -0.03891232  0.15456206 -0.01425664]\n",
      "Selected Action  2\n",
      "True\n",
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n",
      "Q Values  [ 0.13379937 -0.06063106  0.32667211  0.27276906]\n",
      "Selected Action  2\n",
      "False\n",
      "0\n",
      "None\n",
      "Game Over!\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Q Values  [-0.28663241 -0.10636611  0.06032346  0.065293  ]\n",
      "Selected Action  3\n",
      "True\n",
      "1\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Game Over!\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Transition 0 is None\n",
      "Transition 1 is None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_80629/2197747059.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/nfsp_agent.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_players\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_players\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_players\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     action = self.nfsp_agents[p].select_action(\n\u001b[0m\u001b[1;32m    112\u001b[0m                         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                         (\n\u001b[1;32m    114\u001b[0m                             \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legal_moves\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/nfsp_agent.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, state, legal_moves)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"average_strategy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msl_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 self.sl_agent.replay_buffer.store(\n\u001b[1;32m    299\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/../rainbow/rainbow_agent.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, state, legal_moves)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q Values \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mselected_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected Action \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/../rainbow/rainbow_agent.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, state, legal_moves)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mstate_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mq_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         q_values = np.sum(np.multiply(q_distribution, np.array(self.support)), axis=2)[\n\u001b[1;32m    141\u001b[0m             \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         ]\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     )\n\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/../rainbow/rainbow_network.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_hidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_reshaped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_reduced_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;31m# print(\"Reduced Mean Advantage Shape \", advantage.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     )\n\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         with tf.GradientTape(\n\u001b[1;32m    210\u001b[0m             \u001b[0mwatch_accessed_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         ) as tape, tf.variable_creator_scope(_variable_creator):\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/rl-stuff/NFSP/../rainbow/rainbow_network.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a)\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ao\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2764\u001b[0m   \"\"\"\n\u001b[1;32m   2765\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2767\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2768\u001b[0;31m       gen_math_ops.mean(\n\u001b[0m\u001b[1;32m   2769\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m           name=name))\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6438\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6440\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6441\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6442\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6443\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6444\u001b[0m       return mean_eager_fallback(\n\u001b[1;32m   6445\u001b[0m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
