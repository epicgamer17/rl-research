{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import AtariPreprocessing, FrameStack\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "from game_configs import AtariConfig, CartPoleConfig\n",
    "from agent_configs import RainbowConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env, min_reward, max_reward):\n",
    "        super().__init__(env)\n",
    "        self.min_reward = min_reward\n",
    "        self.max_reward = max_reward\n",
    "        self.reward_range = (min_reward, max_reward)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, self.min_reward, self.max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = ClipReward(AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\n",
    "# env = FrameStack(env, 4)\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd1 = {\n",
    "  \"adam_epsilon\": 0.03125,\n",
    "  \"dense_layer_widths\": [],\n",
    "  \"value_hidden_layer_widths\": [32, 32, 32],\n",
    "  \"advantage_hidden_layer_widths\": [32, 32, 32, 32],\n",
    "  \"atom_size\": 41,\n",
    "  \"discount_factor\": 0.995,\n",
    "  \"kernel_initializer\": \"glorot_uniform\",\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"min_replay_buffer_size\": 125,\n",
    "  \"minibatch_size\": 64,\n",
    "  \"n_step\": 5,\n",
    "  \"per_alpha\": 0.2,\n",
    "  \"per_beta\": 0.6000000000000001,\n",
    "  \"per_epsilon\": 0.01,\n",
    "  \"replay_buffer_size\": 25000,\n",
    "  \"replay_interval\": 1,\n",
    "  \"training_steps\": 5000,\n",
    "  \"transfer_interval\": 1600,\n",
    "  \"width\": 32,\n",
    "}\n",
    "\n",
    "cd2 = {\n",
    "  \"adam_epsilon\": 0.3125,\n",
    "  \"dense_layers_widths\": [128,128,128],\n",
    "  \"value_hidden_layers_widths\": [128],\n",
    "  \"discount_factor\": 0.995,\n",
    "  \"kernel_initializer\": \"orthogonal\",\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"min_replay_buffer_size\": 1500,\n",
    "  \"minibatch_size\": 4,\n",
    "  \"n_step\": 2,\n",
    "  \"per_alpha\": 0.55,\n",
    "  \"per_beta\": 0.35000000000000003,\n",
    "  \"per_epsilon\": 0.001,\n",
    "  \"replay_buffer_size\": 5000,\n",
    "  \"replay_interval\": 1,\n",
    "  \"training_steps\": 5000,\n",
    "  \"transfer_interval\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_config = AtariConfig()\n",
    "# game_config.max_score = 500\n",
    "game_config = CartPoleConfig()\n",
    "config = RainbowConfig(cd2,game_config=game_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RainbowAgent(env, config, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
