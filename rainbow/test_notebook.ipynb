{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_envs\n",
    "import gymnasium as gym\n",
    "env = gym.make('gym_envs/TicTacToe-v0')\n",
    "\n",
    "state, info = env.reset()\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(0)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(4)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(3)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(6)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(2)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(1)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(7)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(8)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(5)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "env.render()\n",
    "\n",
    "\n",
    "env.reset()\n",
    "state, reward, terminated, truncated, info = env.step(0)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(3)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(7)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(4)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(2)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(6)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(1)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "print(\"Reward:\", reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeZeroToOne(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_high = self.env.observation_space.high\n",
    "        self.observation_low = self.env.observation_space.low\n",
    "\n",
    "    def observation(self, obs):\n",
    "        print(obs)\n",
    "        print((obs - self.observation_low) / (self.observation_high - self.observation_low))\n",
    "        return (obs - self.observation_low) / (self.observation_high - self.observation_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env, min_reward, max_reward):\n",
    "        super().__init__(env)\n",
    "        self.min_reward = min_reward\n",
    "        self.max_reward = max_reward\n",
    "        self.reward_range = (min_reward, max_reward)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, self.min_reward, self.max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.wrappers.AtariPreprocessing(gym.make(\"ALE/MsPacman-v5\", render_mode=\"rgb_array\"), terminal_on_life_loss=True, scale_obs=True) # as seen online with frame stackign though\n",
    "# env = gym.wrappers.AtariPreprocessing(gym.make(\"ALE/MsPacman-v5\", render_mode=\"rgb_array\"), terminal_on_life_loss=True, scale_obs=True) # as seen online\n",
    "env = ClipReward(gym.wrappers.AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\n",
    "env = gym.wrappers.FrameStack(env, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:25:19.519611: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-03-29 22:25:19.519637: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-03-29 22:25:19.519642: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-03-29 22:25:19.519683: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-29 22:25:19.519709: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from rainbow_agent import RainbowAgent\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_space():\n",
    "    search_space = {\n",
    "        \"activation\": hp.choice(\n",
    "            \"activation\",\n",
    "            [\n",
    "                \"linear\",\n",
    "                \"relu\",\n",
    "                # 'relu6',\n",
    "                \"sigmoid\",\n",
    "                \"softplus\",\n",
    "                \"soft_sign\",\n",
    "                \"silu\",\n",
    "                \"swish\",\n",
    "                \"log_sigmoid\",\n",
    "                \"hard_sigmoid\",\n",
    "                # 'hard_silu',\n",
    "                # 'hard_swish',\n",
    "                # 'hard_tanh',\n",
    "                \"elu\",\n",
    "                # 'celu',\n",
    "                \"selu\",\n",
    "                \"gelu\",\n",
    "                # 'glu'\n",
    "            ],\n",
    "        ),\n",
    "        \"kernel_initializer\": hp.choice(\n",
    "            \"kernel_initializer\",\n",
    "            [\n",
    "                \"he_uniform\",\n",
    "                \"he_normal\",\n",
    "                \"glorot_uniform\",\n",
    "                \"glorot_normal\",\n",
    "                \"lecun_uniform\",\n",
    "                \"lecun_normal\",\n",
    "                \"orthogonal\",\n",
    "                \"variance_baseline\",\n",
    "                \"variance_0.1\",\n",
    "                \"variance_0.3\",\n",
    "                \"variance_0.8\",\n",
    "                \"variance_3\",\n",
    "                \"variance_5\",\n",
    "                \"variance_10\",\n",
    "            ],\n",
    "        ),\n",
    "        \"optimizer\": hp.choice(\n",
    "            \"optimizer\", [tf.keras.optimizers.legacy.Adam]\n",
    "        ),  # NO SGD OR RMSPROP FOR NOW SINCE IT IS FOR RAINBOW DQN\n",
    "        \"learning_rate\": hp.choice(\n",
    "            \"learning_rate\", [10, 5, 2, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        ),  #\n",
    "        \"adam_epsilon\": hp.choice(\n",
    "            \"adam_epsilon\",\n",
    "            [1, 0.5, 0.3125, 0.03125, 0.003125, 0.0003125, 0.00003125, 0.000003125],\n",
    "        ),\n",
    "        \"clipnorm\": hp.choice(\"clipnorm\", [None]),\n",
    "        # NORMALIZATION?\n",
    "        \"soft_update\": hp.choice(\n",
    "            \"soft_update\", [False]\n",
    "        ),  # seems to always be false, we can try it with tru\n",
    "        \"ema_beta\": hp.uniform(\"ema_beta\", 0.95, 0.999),\n",
    "        \"transfer_interval\": hp.choice(\n",
    "            \"transfer_interval\", [10, 25, 50, 100, 200, 400, 800, 1600, 2000]\n",
    "        ),\n",
    "        \"replay_interval\": hp.choice(\"replay_interval\", [1, 2, 3, 4, 5, 8, 10, 12]),\n",
    "        \"minibatch_size\": hp.choice(\n",
    "            \"minibatch_size\", [2**i for i in range(0, 8)]\n",
    "        ),  ###########\n",
    "        \"replay_buffer_size\": hp.choice(\n",
    "            \"replay_buffer_size\", [2000, 3000, 5000, 7500, 10000, 15000, 20000, 25000, 50000]\n",
    "        ),  #############\n",
    "        \"min_replay_buffer_size\": hp.choice(\n",
    "            \"min_replay_buffer_size\", [0, 125, 250, 375, 500, 625, 750, 875, 1000, 1500, 2000]\n",
    "        ),  # 125, 250, 375, 500, 625, 750, 875, 1000, 1500, 2000\n",
    "        \"n_step\": hp.choice(\"n_step\", [1, 2, 3, 4, 5, 8, 10]),\n",
    "        \"discount_factor\": hp.choice(\n",
    "            \"discount_factor\", [0.1, 0.5, 0.9, 0.99, 0.995, 0.999]\n",
    "        ),\n",
    "        \"atom_size\": hp.choice(\"atom_size\", [11, 21, 31, 41, 51, 61, 71, 81]),  #\n",
    "        \"conv_layers\": hp.choice(\"conv_layers\", [[], [(32, 8, 4), (64, 4, 2), (64, 3, 1)]]),\n",
    "        \"conv_layers_noisy\": hp.choice(\"conv_layers_noisy\", [False]),\n",
    "        \"width\": hp.choice(\"width\", [32, 64, 128, 256, 512, 1024]),\n",
    "        \"dense_layers\": hp.choice(\"dense_layers\", [0, 1, 2, 3, 4]),\n",
    "        \"dense_layers_noisy\": hp.choice(\n",
    "            \"dense_layers_noisy\", [True]\n",
    "        ),  # i think this is always true for rainbow\n",
    "        # REWARD CLIPPING\n",
    "        \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.5]),  #\n",
    "        \"loss_function\": hp.choice(\n",
    "            \"loss_function\",\n",
    "            [tf.keras.losses.CategoricalCrossentropy(), tf.keras.losses.KLDivergence()],\n",
    "        ),\n",
    "        \"dueling\": hp.choice(\"dueling\", [True]),\n",
    "        \"advantage_hidden_layers\": hp.choice(\n",
    "            \"advantage_hidden_layers\", [0, 1, 2, 3, 4]\n",
    "        ),  #\n",
    "        \"value_hidden_layers\": hp.choice(\"value_hidden_layers\", [0, 1, 2, 3, 4]),  #\n",
    "        \"training_steps\": hp.choice(\"training_steps\", [30000]),\n",
    "        \"per_epsilon\": hp.choice(\n",
    "            \"per_epsilon\", [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "        ),\n",
    "        \"per_alpha\": hp.choice(\"per_alpha\", [0.05 * i for i in range(0, 21)]),\n",
    "        \"per_beta\": hp.choice(\"per_beta\", [0.05 * i for i in range(1, 21)]),\n",
    "        # 'per_beta_increase': hp.uniform('per_beta_increase', 0, 0.015),\n",
    "        \"v_min\": hp.choice(\"v_min\", [-500.0]),  # MIN GAME SCORE\n",
    "        \"v_max\": hp.choice(\"v_max\", [500.0]),  # MAX GAME SCORE\n",
    "        # 'search_max_depth': 5,\n",
    "        # 'search_max_time': 10,\n",
    "    }\n",
    "    initial_best_config = [\n",
    "        {\n",
    "            \"activation\": 1,\n",
    "            \"kernel_initializer\": 6,\n",
    "            \"optimizer\": 0,  # NO SGD OR RMSPROP FOR NOW SINCE IT IS FOR RAINBOW DQN\n",
    "            \"learning_rate\": 5,  #\n",
    "            \"adam_epsilon\": 5,\n",
    "            \"clipnorm\": 0,\n",
    "            # NORMALIZATION?\n",
    "            \"soft_update\": 0,  # seems to always be false, we can try it with tru\n",
    "            \"ema_beta\": 0.95,\n",
    "            \"transfer_interval\": 3,\n",
    "            \"replay_interval\": 3,\n",
    "            \"minibatch_size\": 7,\n",
    "            \"replay_buffer_size\": 8,  \n",
    "            \"min_replay_buffer_size\": 4,\n",
    "            \"n_step\": 2,\n",
    "            \"discount_factor\": 3,\n",
    "            \"atom_size\": 4,  #\n",
    "            \"conv_layers\": 0,\n",
    "            \"conv_layers_noisy\": 0,\n",
    "            \"width\": 4,\n",
    "            \"dense_layers\": 2,\n",
    "            \"dense_layers_noisy\": 0,  # i think this is always true for rainbow\n",
    "            # REWARD CLIPPING\n",
    "            \"noisy_sigma\": 0,  #\n",
    "            \"loss_function\": 0,\n",
    "            \"dueling\": 0,\n",
    "            \"advantage_hidden_layers\": 0,  #\n",
    "            \"value_hidden_layers\": 0,  #\n",
    "            \"training_steps\": 0,\n",
    "            \"per_epsilon\": 3,\n",
    "            \"per_alpha\": 10,\n",
    "            \"per_beta\": 7,\n",
    "            # 'per_beta_increase': hp.uniform('per_beta_increase', 0, 0.015),\n",
    "            \"v_min\": 0,  # MIN GAME SCORE\n",
    "            \"v_max\": 0,  # MAX GAME SCORE\n",
    "            # 'search_max_depth': 5,\n",
    "            # 'search_max_time': 10,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return search_space, initial_best_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'adam_epsilon': 0.0003125, 'advantage_hidden_layers': 0, 'atom_size': 51, 'clipnorm': None, 'conv_layers': (), 'conv_layers_noisy': False, 'dense_layers': 2, 'dense_layers_noisy': True, 'discount_factor': 0.99, 'dueling': True, 'ema_beta': 0.95, 'kernel_initializer': 'orthogonal', 'learning_rate': 0.01, 'loss_function': <keras.src.losses.CategoricalCrossentropy object at 0x29c251670>, 'min_replay_buffer_size': 500, 'minibatch_size': 128, 'n_step': 3, 'noisy_sigma': 0.5, 'optimizer': <class 'keras.src.optimizers.legacy.adam.Adam'>, 'per_alpha': 0.5, 'per_beta': 0.4, 'per_epsilon': 0.001, 'replay_buffer_size': 50000, 'replay_interval': 4, 'soft_update': False, 'training_steps': 30000, 'transfer_interval': 100, 'v_max': 500.0, 'v_min': -500.0, 'value_hidden_layers': 0, 'width': 512}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import space_eval\n",
    "\n",
    "search_sapce, initial_best_config = create_search_space()\n",
    "config = space_eval(search_sapce, initial_best_config[0])\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default training iterations: 1\n",
      "Using default number of minibatches: 1\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/rainbow/videos/RainbowDQN-CartPole-v1\n",
      "RainbowDQN-CartPole-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/rainbow/videos/RainbowDQN-CartPole-v1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "10\n",
      "./videos/RainbowDQN-CartPole-v1/10\n",
      "score:  10.0\n",
      "score:  10.0\n",
      "score:  10.0\n",
      "score:  9.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m      5\u001b[0m agent \u001b[38;5;241m=\u001b[39m RainbowAgent(env, config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRainbowDQN-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mid))\n\u001b[0;32m----> 6\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/rainbow/rainbow_agent.py:446\u001b[0m, in \u001b[0;36mRainbowAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_target_model(training_step)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m training_step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 446\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_checkpoint(\n\u001b[1;32m    455\u001b[0m     stats,\n\u001b[1;32m    456\u001b[0m     targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m     time() \u001b[38;5;241m-\u001b[39m training_time,\n\u001b[1;32m    461\u001b[0m )\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/base_agent/agent.py:107\u001b[0m, in \u001b[0;36mBaseAgent.save_checkpoint\u001b[0;34m(self, stats, targets, num_trials, training_step, frames_seen, time_taken)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(path)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# save replay buffer\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# save optimizer\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m test_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test_score)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# plot the graphs\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/base_agent/agent.py:184\u001b[0m, in \u001b[0;36mBaseAgent.test\u001b[0;34m(self, num_trials, step)\u001b[0m\n\u001b[1;32m    182\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_action(state, legal_moves)\n\u001b[1;32m    183\u001b[0m test_game_moves\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m--> 184\u001b[0m next_state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m    186\u001b[0m legal_moves \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    187\u001b[0m     info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_moves\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mhas_legal_moves \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    188\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/rainbow/rainbow_agent.py:169\u001b[0m, in \u001b[0;36mRainbowAgent.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39mstore(\u001b[38;5;241m*\u001b[39mone_step_transition)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     next_state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_state, reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/record_video.py:191\u001b[0m, in \u001b[0;36mRecordVideo.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_vector_env:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminateds \u001b[38;5;129;01mor\u001b[39;00m truncateds:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose_video_recorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m terminateds[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncateds[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_video_recorder()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/record_video.py:204\u001b[0m, in \u001b[0;36mRecordVideo.close_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_recorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:149\u001b[0m, in \u001b[0;36mVideoRecorder.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoviepy is not installed, run `pip install moviepy`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/moviepy/video/io/ImageSequenceClip.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoClip\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mImageSequenceClip\u001b[39;00m(VideoClip):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    A VideoClip made from a series of images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/moviepy/video/VideoClip.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEVNULL, string_types\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_setting\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (add_mask_if_none, apply_to_mask,\n\u001b[1;32m     20\u001b[0m                           convert_masks_to_RGB, convert_to_seconds, outplace,\n\u001b[1;32m     21\u001b[0m                           requires_duration, use_clip_fps_by_default)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (deprecated_version_of, extensions_dict, find_extension,\n\u001b[1;32m     23\u001b[0m                      is_string, subprocess_call)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/moviepy/config.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg-imageio\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_exe\n\u001b[0;32m---> 36\u001b[0m     FFMPEG_BINARY \u001b[38;5;241m=\u001b[39m \u001b[43mget_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto-detect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m try_cmd([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imageio/plugins/ffmpeg.py:173\u001b[0m, in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exe\u001b[39m():  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for imageio_ffmpeg.get_ffmpeg_exe()\"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimageio_ffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ffmpeg_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imageio_ffmpeg/_utils.py:34\u001b[0m, in \u001b[0;36mget_ffmpeg_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exe\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Nothing was found\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo ffmpeg exe could be found. Install ffmpeg on your system, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set the IMAGEIO_FFMPEG_EXE environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from configs.agent_configs.rainbow_config import RainbowConfig\n",
    "from configs.game_configs.cartpole_config import CartPoleConfig\n",
    "config = RainbowConfig(config, CartPoleConfig())\n",
    "# train\n",
    "agent = RainbowAgent(env, config, \"RainbowDQN-{}\".format(env.unwrapped.spec.id))\n",
    "agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
