{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gym\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "\n",
    "class TimeLimit(gym.Wrapper):\n",
    "    def __init__(self, env, duration):\n",
    "        super().__init__(env)\n",
    "        self._duration = duration\n",
    "        self._step = None\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self._step is not None, \"Must reset environment.\"\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self._step += 1\n",
    "        if self._step >= self._duration:\n",
    "            done = True\n",
    "            if \"discount\" not in info:\n",
    "                info[\"discount\"] = np.array(1.0).astype(np.float32)\n",
    "            self._step = None\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._step = 0\n",
    "        return self.env.reset()\n",
    "\n",
    "\n",
    "class NormalizeActions(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self._mask = np.logical_and(\n",
    "            np.isfinite(env.action_space.low), np.isfinite(env.action_space.high)\n",
    "        )\n",
    "        self._low = np.where(self._mask, env.action_space.low, -1)\n",
    "        self._high = np.where(self._mask, env.action_space.high, 1)\n",
    "        low = np.where(self._mask, -np.ones_like(self._low), self._low)\n",
    "        high = np.where(self._mask, np.ones_like(self._low), self._high)\n",
    "        self.action_space = gym.spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        original = (action + 1) / 2 * (self._high - self._low) + self._low\n",
    "        original = np.where(self._mask, original, action)\n",
    "        return self.env.step(original)\n",
    "\n",
    "\n",
    "class OneHotAction(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete)\n",
    "        super().__init__(env)\n",
    "        self._random = np.random.RandomState()\n",
    "        shape = (self.env.action_space.n,)\n",
    "        space = gym.spaces.Box(low=0, high=1, shape=shape, dtype=np.float32)\n",
    "        space.discrete = True\n",
    "        self.action_space = space\n",
    "\n",
    "    def step(self, action):\n",
    "        index = np.argmax(action).astype(int)\n",
    "        reference = np.zeros_like(action)\n",
    "        reference[index] = 1\n",
    "        if not np.allclose(reference, action):\n",
    "            raise ValueError(f\"Invalid one-hot action:\\n{action}\")\n",
    "        return self.env.step(index)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def _sample_action(self):\n",
    "        actions = self.env.action_space.n\n",
    "        index = self._random.randint(0, actions)\n",
    "        reference = np.zeros(actions, dtype=np.float32)\n",
    "        reference[index] = 1.0\n",
    "        return reference\n",
    "\n",
    "\n",
    "class RewardObs(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        spaces = self.env.observation_space.spaces\n",
    "        if \"obs_reward\" not in spaces:\n",
    "            spaces[\"obs_reward\"] = gym.spaces.Box(\n",
    "                -np.inf, np.inf, shape=(1,), dtype=np.float32\n",
    "            )\n",
    "        self.observation_space = gym.spaces.Dict(spaces)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([reward], dtype=np.float32)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([0.0], dtype=np.float32)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class SelectAction(gym.Wrapper):\n",
    "    def __init__(self, env, key):\n",
    "        super().__init__(env)\n",
    "        self._key = key\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action[self._key])\n",
    "\n",
    "\n",
    "class UUID(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "\n",
    "    def reset(self):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BettingAbstration: FCPA\n",
      "P0 Cards: 2d\n",
      "P1 Cards: 2c\n",
      "BoardCards \n",
      "Node type?: Player node for player 0\n",
      "PossibleActions (4): [ ACTION_FOLD  ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]\n",
      "Round: 0\n",
      "ACPC State: STATE:0::2d|2c\n",
      "Spent: [P0: 50  P1: 100  ]\n",
      "\n",
      "Action Sequence: dd\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pyspiel\n",
    "\n",
    "env = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "state = env.new_initial_state()\n",
    "if state.is_chance_node():\n",
    "    while state.is_chance_node():\n",
    "        state.apply_action(np.random.choice(state.legal_actions()))\n",
    "print(state)\n",
    "print(state.current_player())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Poker:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = pyspiel.load_game(\n",
    "                name,\n",
    "                {\n",
    "                    \"numPlayers\": 2,\n",
    "                    \"numSuits\": 2,\n",
    "                    \"numRanks\": 3,\n",
    "                    \"numHoleCards\": 1,\n",
    "                    \"numBoardCards\": \"0 1\",\n",
    "                    \"bettingAbstraction\": \"fcpa\",\n",
    "                    \"numRounds\": 2,\n",
    "                    \"blind\": \"50 100\",\n",
    "                },\n",
    "            )\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        print(\"agent selection\", self.agent_selection)\n",
    "        self.traverser = None\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        spaces = {}\n",
    "        obs_spec = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        for key, value in obs_spec.items():\n",
    "            if not hasattr(value, \"shape\") or len(value.shape) == 0:\n",
    "                shape = (1,)\n",
    "            else:\n",
    "                shape = value.shape\n",
    "            spaces[key] = gym.spaces.Box(-np.inf, np.inf, shape, dtype=np.float32)\n",
    "        # spaces[\"image\"] = gym.spaces.Box(0, 255, self._size + (3,), dtype=np.uint8)\n",
    "        return gym.spaces.Dict(spaces)\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = gym.spaces.Discrete(4)\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"legal actions:\", self.state.legal_actions())\n",
    "        # print(\"action:\", action)\n",
    "        if hasattr(action, \"shape\") and len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        assert np.isfinite(action).all(), action\n",
    "        if not (action in self.state.legal_actions()):\n",
    "            action = np.random.choice(self.state.legal_actions())\n",
    "        reward = 0\n",
    "        if self.state.is_chance_node():\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "\n",
    "        else:\n",
    "            # print(\"action:\", action)\n",
    "            # print(\"obs:\", self.state)\n",
    "            self.state.apply_action(action)\n",
    "            if self.state.is_chance_node():\n",
    "                while self.state.is_chance_node():\n",
    "                    self.state.apply_action(\n",
    "                        np.random.choice(self.state.legal_actions())\n",
    "                    )\n",
    "\n",
    "        if not self.state.is_terminal():\n",
    "            # store = copy.deepcopy(self.state)\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "            # print(\"3\")\n",
    "            # print(self.state.is_terminal())\n",
    "            # if self.state.is_terminal():\n",
    "            #     print(\"store:\", store)\n",
    "            # print(self.state)\n",
    "            # print(self.state.legal_actions_mask(int(self.agent_selection)))\n",
    "            # print(\"3\")\n",
    "            self.agent_selection = str(self.state.current_player())\n",
    "\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        obs[\"is_terminal\"] = False\n",
    "        obs[\"is_first\"] = True\n",
    "        reward = (\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def last(self):\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {key: [val] if len(val.shape) == 0 else val for key, val in obs.items()}\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CartPole:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = gym.make(name, render_mode=\"rgb_array\")\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        return gym.spaces.Dict(\n",
    "            {\n",
    "                \"obs\": self._env.observation_space,\n",
    "                \"image\": gym.spaces.Box(\n",
    "                    0,\n",
    "                    255,\n",
    "                    (self._env.screen_width, self._env.screen_height) + (3,),\n",
    "                    dtype=np.uint8,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = self._env.action_space\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        if len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        observation, reward, terminated, truncated, info = self._env.step(action)\n",
    "        # print(observation.shape)\n",
    "        return (\n",
    "            {\n",
    "                \"obs\": observation,\n",
    "                \"image\": self._env.render(),\n",
    "                \"is_terminal\": terminated or truncated,\n",
    "                \"is_first\": False,\n",
    "            },\n",
    "            reward,\n",
    "            terminated or truncated,\n",
    "            {},\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs, info = self._env.reset()\n",
    "        # print(obs.shape)\n",
    "        return {\n",
    "            \"obs\": obs,\n",
    "            \"image\": self._env.render(),\n",
    "            \"is_terminal\": False,\n",
    "            \"is_first\": True,\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import collections\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as torchd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def symlog(x):\n",
    "    return torch.sign(x) * torch.log(torch.abs(x) + 1.0)\n",
    "\n",
    "\n",
    "def symexp(x):\n",
    "    return torch.sign(x) * (torch.exp(torch.abs(x)) - 1.0)\n",
    "\n",
    "\n",
    "class RequiresGrad:\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._model.requires_grad_(requires_grad=True)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._model.requires_grad_(requires_grad=False)\n",
    "\n",
    "\n",
    "class TimeRecording:\n",
    "    def __init__(self, comment):\n",
    "        self._comment = comment\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._st = torch.cuda.Event(enable_timing=True)\n",
    "        self._nd = torch.cuda.Event(enable_timing=True)\n",
    "        self._st.record()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._nd.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(self._comment, self._st.elapsed_time(self._nd) / 1000)\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logdir, step):\n",
    "        self._logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=str(logdir), max_queue=1000)\n",
    "        self._last_step = None\n",
    "        self._last_time = None\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "        self.step = step\n",
    "\n",
    "    def scalar(self, name, value):\n",
    "        self._scalars[name] = float(value)\n",
    "\n",
    "    def image(self, name, value):\n",
    "        self._images[name] = np.array(value)\n",
    "\n",
    "    def video(self, name, value):\n",
    "        self._videos[name] = np.array(value)\n",
    "\n",
    "    def write(self, fps=False, step=False):\n",
    "        if not step:\n",
    "            step = self.step\n",
    "        scalars = list(self._scalars.items())\n",
    "        if fps:\n",
    "            scalars.append((\"fps\", self._compute_fps(step)))\n",
    "        print(f\"[{step}]\", \" / \".join(f\"{k} {v:.1f}\" for k, v in scalars))\n",
    "        with (self._logdir / \"metrics.jsonl\").open(\"a\") as f:\n",
    "            f.write(json.dumps({\"step\": step, **dict(scalars)}) + \"\\n\")\n",
    "        for name, value in scalars:\n",
    "            if \"/\" not in name:\n",
    "                self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "            else:\n",
    "                self._writer.add_scalar(name, value, step)\n",
    "        for name, value in self._images.items():\n",
    "            self._writer.add_image(name, value, step)\n",
    "        for name, value in self._videos.items():\n",
    "            name = name if isinstance(name, str) else name.decode(\"utf-8\")\n",
    "            if np.issubdtype(value.dtype, np.floating):\n",
    "                value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "            B, T, H, W, C = value.shape\n",
    "            value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "            self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "        self._writer.flush()\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "\n",
    "    def _compute_fps(self, step):\n",
    "        if self._last_step is None:\n",
    "            self._last_time = time.time()\n",
    "            self._last_step = step\n",
    "            return 0\n",
    "        steps = step - self._last_step\n",
    "        duration = time.time() - self._last_time\n",
    "        self._last_time += duration\n",
    "        self._last_step = step\n",
    "        return steps / duration\n",
    "\n",
    "    def offline_scalar(self, name, value, step):\n",
    "        self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "\n",
    "    def offline_video(self, name, value, step):\n",
    "        if np.issubdtype(value.dtype, np.floating):\n",
    "            value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "        B, T, H, W, C = value.shape\n",
    "        value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "        self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "\n",
    "def simulate(\n",
    "    agent,\n",
    "    envs,\n",
    "    cache,\n",
    "    directory,\n",
    "    logger,\n",
    "    is_eval=False,\n",
    "    limit=None,\n",
    "    steps=0,\n",
    "    episodes=0,\n",
    "    state=None,\n",
    "):\n",
    "    # initialize or unpack simulation state\n",
    "    if state is None:\n",
    "        step, episode = 0, 0\n",
    "        done = np.ones(len(envs), bool)\n",
    "        length = np.zeros(len(envs), np.int32)\n",
    "        obs = [None] * len(envs)\n",
    "        agent_state = None\n",
    "        reward = [0] * len(envs)\n",
    "    else:\n",
    "        step, episode, done, length, obs, agent_state, reward = state\n",
    "    while (steps and step < steps) or (episodes and episode < episodes):\n",
    "        # reset envs if necessary\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            results = [envs[i].reset() for i in indices]\n",
    "            results = [r() for r in results]\n",
    "            for index, result in zip(indices, results):\n",
    "                t = result.copy()\n",
    "                t = {k: convert(v) for k, v in t.items()}\n",
    "                # action will be added to transition in add_to_cache\n",
    "                t[\"reward\"] = 0.0\n",
    "                t[\"discount\"] = 1.0\n",
    "                # initial state should be added to cache\n",
    "                add_to_cache(cache, envs[index].id, t)\n",
    "                # replace obs with done by initial state\n",
    "                obs[index] = result\n",
    "        # step agents\n",
    "        obs = {k: np.stack([o[k] for o in obs]) for k in obs[0] if \"log_\" not in k}\n",
    "        action, agent_state = agent(obs, done, agent_state)\n",
    "        if isinstance(action, dict):\n",
    "            action = [\n",
    "                {k: np.array(action[k][i].detach().cpu()) for k in action}\n",
    "                for i in range(len(envs))\n",
    "            ]\n",
    "        else:\n",
    "            action = np.array(action)\n",
    "        assert len(action) == len(envs)\n",
    "        # step envs\n",
    "        results = [e.step(a) for e, a in zip(envs, action)]\n",
    "        results = [r() for r in results]\n",
    "        obs, reward, done = zip(*[p[:3] for p in results])\n",
    "        obs = list(obs)\n",
    "        reward = list(reward)\n",
    "        done = np.stack(done)\n",
    "        episode += int(done.sum())\n",
    "        length += 1\n",
    "        step += len(envs)\n",
    "        length *= 1 - done\n",
    "        # add to cache\n",
    "        for a, result, env in zip(action, results, envs):\n",
    "            o, r, d, info = result\n",
    "            o = {k: convert(v) for k, v in o.items()}\n",
    "            transition = o.copy()\n",
    "            if isinstance(a, dict):\n",
    "                transition.update(a)\n",
    "            else:\n",
    "                transition[\"action\"] = a\n",
    "            transition[\"reward\"] = r\n",
    "            transition[\"discount\"] = info.get(\"discount\", np.array(1 - float(d)))\n",
    "            add_to_cache(cache, env.id, transition)\n",
    "\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            # logging for done episode\n",
    "            for i in indices:\n",
    "                save_episodes(directory, {envs[i].id: cache[envs[i].id]})\n",
    "                length = len(cache[envs[i].id][\"reward\"]) - 1\n",
    "                score = float(np.array(cache[envs[i].id][\"reward\"]).sum())\n",
    "                # video = cache[envs[i].id][\"image\"]\n",
    "                # record logs given from environments\n",
    "                for key in list(cache[envs[i].id].keys()):\n",
    "                    if \"log_\" in key:\n",
    "                        logger.scalar(\n",
    "                            key, float(np.array(cache[envs[i].id][key]).sum())\n",
    "                        )\n",
    "                        # log items won't be used later\n",
    "                        cache[envs[i].id].pop(key)\n",
    "\n",
    "                if not is_eval:\n",
    "                    step_in_dataset = erase_over_episodes(cache, limit)\n",
    "                    logger.scalar(f\"dataset_size\", step_in_dataset)\n",
    "                    logger.scalar(f\"train_return\", score)\n",
    "                    logger.scalar(f\"train_length\", length)\n",
    "                    logger.scalar(f\"train_episodes\", len(cache))\n",
    "                    logger.write(step=logger.step)\n",
    "                else:\n",
    "                    if not \"eval_lengths\" in locals():\n",
    "                        eval_lengths = []\n",
    "                        eval_scores = []\n",
    "                        eval_done = False\n",
    "                    # start counting scores for evaluation\n",
    "                    eval_scores.append(score)\n",
    "                    eval_lengths.append(length)\n",
    "\n",
    "                    score = sum(eval_scores) / len(eval_scores)\n",
    "                    length = sum(eval_lengths) / len(eval_lengths)\n",
    "                    # logger.video(f\"eval_policy\", np.array(video)[None])\n",
    "\n",
    "                    if len(eval_scores) >= episodes and not eval_done:\n",
    "                        logger.scalar(f\"eval_return\", score)\n",
    "                        logger.scalar(f\"eval_length\", length)\n",
    "                        logger.scalar(f\"eval_episodes\", len(eval_scores))\n",
    "                        logger.write(step=logger.step)\n",
    "                        eval_done = True\n",
    "    if is_eval:\n",
    "        # keep only last item for saving memory. this cache is used for video_pred later\n",
    "        while len(cache) > 1:\n",
    "            # FIFO\n",
    "            cache.popitem(last=False)\n",
    "    return (step - steps, episode - episodes, done, length, obs, agent_state, reward)\n",
    "\n",
    "\n",
    "def add_to_cache(cache, id, transition):\n",
    "    if id not in cache:\n",
    "        cache[id] = dict()\n",
    "        for key, val in transition.items():\n",
    "            cache[id][key] = [convert(val)]\n",
    "    else:\n",
    "        for key, val in transition.items():\n",
    "            if key not in cache[id]:\n",
    "                # fill missing data(action, etc.) at second time\n",
    "                cache[id][key] = [convert(0 * val)]\n",
    "                cache[id][key].append(convert(val))\n",
    "            else:\n",
    "                cache[id][key].append(convert(val))\n",
    "\n",
    "\n",
    "def erase_over_episodes(cache, dataset_size):\n",
    "    step_in_dataset = 0\n",
    "    for key, ep in reversed(sorted(cache.items(), key=lambda x: x[0])):\n",
    "        if (\n",
    "            not dataset_size\n",
    "            or step_in_dataset + (len(ep[\"reward\"]) - 1) <= dataset_size\n",
    "        ):\n",
    "            step_in_dataset += len(ep[\"reward\"]) - 1\n",
    "        else:\n",
    "            del cache[key]\n",
    "    return step_in_dataset\n",
    "\n",
    "\n",
    "def convert(value, precision=32):\n",
    "    value = np.array(value)\n",
    "    if np.issubdtype(value.dtype, np.floating):\n",
    "        dtype = {16: np.float16, 32: np.float32, 64: np.float64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.signedinteger):\n",
    "        dtype = {16: np.int16, 32: np.int32, 64: np.int64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.uint8):\n",
    "        dtype = np.uint8\n",
    "    elif np.issubdtype(value.dtype, bool):\n",
    "        dtype = bool\n",
    "    else:\n",
    "        raise NotImplementedError(value.dtype)\n",
    "    return value.astype(dtype)\n",
    "\n",
    "\n",
    "def save_episodes(directory, episodes):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    for filename, episode in episodes.items():\n",
    "        length = len(episode[\"reward\"])\n",
    "        filename = directory / f\"{filename}-{length}.npz\"\n",
    "        with io.BytesIO() as f1:\n",
    "            np.savez_compressed(f1, **episode)\n",
    "            f1.seek(0)\n",
    "            with filename.open(\"wb\") as f2:\n",
    "                f2.write(f1.read())\n",
    "    return True\n",
    "\n",
    "\n",
    "def from_generator(generator, batch_size):\n",
    "    while True:\n",
    "        batch = []\n",
    "        for _ in range(batch_size):\n",
    "            batch.append(next(generator))\n",
    "        data = {}\n",
    "        for key in batch[0].keys():\n",
    "            data[key] = []\n",
    "            for i in range(batch_size):\n",
    "                data[key].append(batch[i][key])\n",
    "            data[key] = np.stack(data[key], 0)\n",
    "        yield data\n",
    "\n",
    "\n",
    "def sample_episodes(episodes, length, seed=0):\n",
    "    np_random = np.random.RandomState(seed)\n",
    "    while True:\n",
    "        size = 0\n",
    "        ret = None\n",
    "        p = np.array(\n",
    "            [len(next(iter(episode.values()))) for episode in episodes.values()]\n",
    "        )\n",
    "        p = p / np.sum(p)\n",
    "        while size < length:\n",
    "            episode = np_random.choice(list(episodes.values()), p=p)\n",
    "            total = len(next(iter(episode.values())))\n",
    "            # make sure at least one transition included\n",
    "            if total < 2:\n",
    "                continue\n",
    "            if not ret:\n",
    "                index = int(np_random.randint(0, total - 1))\n",
    "                ret = {\n",
    "                    k: v[index : min(index + length, total)].copy()\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][0] = True\n",
    "            else:\n",
    "                # 'is_first' comes after 'is_last'\n",
    "                index = 0\n",
    "                possible = length - size\n",
    "                ret = {\n",
    "                    k: np.append(\n",
    "                        ret[k], v[index : min(index + possible, total)].copy(), axis=0\n",
    "                    )\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][size] = True\n",
    "            size = len(next(iter(ret.values())))\n",
    "        yield ret\n",
    "\n",
    "\n",
    "def load_episodes(directory, limit=None, reverse=True):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    episodes = collections.OrderedDict()\n",
    "    total = 0\n",
    "    if reverse:\n",
    "        for filename in reversed(sorted(directory.glob(\"*.npz\"))):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            # extract only filename without extension\n",
    "            episodes[str(os.path.splitext(os.path.basename(filename))[0])] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    else:\n",
    "        for filename in sorted(directory.glob(\"*.npz\")):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            episodes[str(filename)] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    return episodes\n",
    "\n",
    "\n",
    "class SampleDist:\n",
    "    def __init__(self, dist, samples=100):\n",
    "        self._dist = dist\n",
    "        self._samples = samples\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"SampleDist\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def mean(self):\n",
    "        samples = self._dist.sample(self._samples)\n",
    "        return torch.mean(samples, 0)\n",
    "\n",
    "    def mode(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self._dist.log_prob(sample)\n",
    "        return sample[torch.argmax(logprob)][0]\n",
    "\n",
    "    def entropy(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self.log_prob(sample)\n",
    "        return -torch.mean(logprob, 0)\n",
    "\n",
    "\n",
    "class OneHotDist(torchd.one_hot_categorical.OneHotCategorical):\n",
    "    def __init__(self, logits=None, probs=None, unimix_ratio=0.0):\n",
    "        if logits is not None and unimix_ratio > 0.0:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs = probs * (1.0 - unimix_ratio) + unimix_ratio / probs.shape[-1]\n",
    "            logits = torch.log(probs)\n",
    "            super().__init__(logits=logits, probs=None)\n",
    "        else:\n",
    "            super().__init__(logits=logits, probs=probs)\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = F.one_hot(\n",
    "            torch.argmax(super().logits, axis=-1), super().logits.shape[-1]\n",
    "        )\n",
    "        return _mode.detach() + super().logits - super().logits.detach()\n",
    "\n",
    "    def sample(self, sample_shape=(), seed=None):\n",
    "        if seed is not None:\n",
    "            raise ValueError(\"need to check\")\n",
    "        sample = super().sample(sample_shape).detach()\n",
    "        probs = super().probs\n",
    "        while len(probs.shape) < len(sample.shape):\n",
    "            probs = probs[None]\n",
    "        sample += probs - probs.detach()\n",
    "        return sample\n",
    "\n",
    "\n",
    "class DiscDist:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logits,\n",
    "        low=-20.0,\n",
    "        high=20.0,\n",
    "        transfwd=symlog,\n",
    "        transbwd=symexp,\n",
    "        device=\"cuda\",\n",
    "    ):\n",
    "        self.logits = logits\n",
    "        self.probs = torch.softmax(logits, -1)\n",
    "        self.buckets = torch.linspace(low, high, steps=255, device=device)\n",
    "        self.width = (self.buckets[-1] - self.buckets[0]) / 255\n",
    "        self.transfwd = transfwd\n",
    "        self.transbwd = transbwd\n",
    "\n",
    "    def mean(self):\n",
    "        _mean = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mean, dim=-1, keepdim=True))\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mode, dim=-1, keepdim=True))\n",
    "\n",
    "    # Inside OneHotCategorical, log_prob is calculated using only max element in targets\n",
    "    def log_prob(self, x):\n",
    "        x = self.transfwd(x)\n",
    "        # x(time, batch, 1)\n",
    "        below = torch.sum((self.buckets <= x[..., None]).to(torch.int32), dim=-1) - 1\n",
    "        above = len(self.buckets) - torch.sum(\n",
    "            (self.buckets > x[..., None]).to(torch.int32), dim=-1\n",
    "        )\n",
    "        # this is implemented using clip at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        below = torch.clip(below, 0, len(self.buckets) - 1)\n",
    "        above = torch.clip(above, 0, len(self.buckets) - 1)\n",
    "        equal = below == above\n",
    "\n",
    "        dist_to_below = torch.where(equal, 1, torch.abs(self.buckets[below] - x))\n",
    "        dist_to_above = torch.where(equal, 1, torch.abs(self.buckets[above] - x))\n",
    "        total = dist_to_below + dist_to_above\n",
    "        weight_below = dist_to_above / total\n",
    "        weight_above = dist_to_below / total\n",
    "        target = (\n",
    "            F.one_hot(below, num_classes=len(self.buckets)) * weight_below[..., None]\n",
    "            + F.one_hot(above, num_classes=len(self.buckets)) * weight_above[..., None]\n",
    "        )\n",
    "        log_pred = self.logits - torch.logsumexp(self.logits, -1, keepdim=True)\n",
    "        target = target.squeeze(-2)\n",
    "\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "    def log_prob_target(self, target):\n",
    "        log_pred = super().logits - torch.logsumexp(super().logits, -1, keepdim=True)\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "\n",
    "class MSEDist:\n",
    "    def __init__(self, mode, agg=\"sum\"):\n",
    "        self._mode = mode\n",
    "        self._agg = agg\n",
    "\n",
    "    def mode(self):\n",
    "        return self._mode\n",
    "\n",
    "    def mean(self):\n",
    "        return self._mode\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape, (self._mode.shape, value.shape)\n",
    "        distance = (self._mode - value) ** 2\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class SymlogDist:\n",
    "    def __init__(self, mode, dist=\"mse\", agg=\"sum\", tol=1e-8):\n",
    "        self._mode = mode\n",
    "        self._dist = dist\n",
    "        self._agg = agg\n",
    "        self._tol = tol\n",
    "\n",
    "    def mode(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def mean(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape\n",
    "        if self._dist == \"mse\":\n",
    "            distance = (self._mode - symlog(value)) ** 2.0\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        elif self._dist == \"abs\":\n",
    "            distance = torch.abs(self._mode - symlog(value))\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        else:\n",
    "            raise NotImplementedError(self._dist)\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class ContDist:\n",
    "    def __init__(self, dist=None, absmax=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "        self.absmax = absmax\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        out = self._dist.mean\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        out = self._dist.rsample(sample_shape)\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return self._dist.log_prob(x)\n",
    "\n",
    "\n",
    "class Bernoulli:\n",
    "    def __init__(self, dist=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = torch.round(self._dist.mean)\n",
    "        return _mode.detach() + self._dist.mean - self._dist.mean.detach()\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        return self._dist.rsample(sample_shape)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        _logits = self._dist.base_dist.logits\n",
    "        log_probs0 = -F.softplus(_logits)\n",
    "        log_probs1 = -F.softplus(-_logits)\n",
    "\n",
    "        return torch.sum(log_probs0 * (1 - x) + log_probs1 * x, -1)\n",
    "\n",
    "\n",
    "class UnnormalizedHuber(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, threshold=1, **kwargs):\n",
    "        super().__init__(loc, scale, **kwargs)\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def log_prob(self, event):\n",
    "        return -(\n",
    "            torch.sqrt((event - self.mean) ** 2 + self._threshold**2) - self._threshold\n",
    "        )\n",
    "\n",
    "    def mode(self):\n",
    "        return self.mean\n",
    "\n",
    "\n",
    "class SafeTruncatedNormal(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, low, high, clip=1e-6, mult=1):\n",
    "        super().__init__(loc, scale)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._clip = clip\n",
    "        self._mult = mult\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        event = super().sample(sample_shape)\n",
    "        if self._clip:\n",
    "            clipped = torch.clip(event, self._low + self._clip, self._high - self._clip)\n",
    "            event = event - event.detach() + clipped.detach()\n",
    "        if self._mult:\n",
    "            event *= self._mult\n",
    "        return event\n",
    "\n",
    "\n",
    "class TanhBijector(torchd.Transform):\n",
    "    def __init__(self, validate_args=False, name=\"tanh\"):\n",
    "        super().__init__()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y = torch.where(\n",
    "            (torch.abs(y) <= 1.0), torch.clamp(y, -0.99999997, 0.99999997), y\n",
    "        )\n",
    "        y = torch.atanh(y)\n",
    "        return y\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        log2 = torch.math.log(2.0)\n",
    "        return 2.0 * (log2 - x - torch.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "def static_scan_for_lambda_return(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    indices = reversed(indices)\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        # (inputs, pcont) -> (inputs[index], pcont[index])\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            outputs = last\n",
    "            flag = False\n",
    "        else:\n",
    "            outputs = torch.cat([outputs, last], dim=-1)\n",
    "    outputs = torch.reshape(outputs, [outputs.shape[0], outputs.shape[1], 1])\n",
    "    outputs = torch.flip(outputs, [1])\n",
    "    outputs = torch.unbind(outputs, dim=0)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def lambda_return(reward, value, pcont, bootstrap, lambda_, axis):\n",
    "    # Setting lambda=1 gives a discounted Monte Carlo return.\n",
    "    # Setting lambda=0 gives a fixed 1-step return.\n",
    "    # assert reward.shape.ndims == value.shape.ndims, (reward.shape, value.shape)\n",
    "    assert len(reward.shape) == len(value.shape), (reward.shape, value.shape)\n",
    "    if isinstance(pcont, (int, float)):\n",
    "        pcont = pcont * torch.ones_like(reward)\n",
    "    dims = list(range(len(reward.shape)))\n",
    "    dims = [axis] + dims[1:axis] + [0] + dims[axis + 1 :]\n",
    "    if axis != 0:\n",
    "        reward = reward.permute(dims)\n",
    "        value = value.permute(dims)\n",
    "        pcont = pcont.permute(dims)\n",
    "    if bootstrap is None:\n",
    "        bootstrap = torch.zeros_like(value[-1])\n",
    "    next_values = torch.cat([value[1:], bootstrap[None]], 0)\n",
    "    inputs = reward + pcont * next_values * (1 - lambda_)\n",
    "    # returns = static_scan(\n",
    "    #    lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg,\n",
    "    #    (inputs, pcont), bootstrap, reverse=True)\n",
    "    # reimplement to optimize performance\n",
    "    returns = static_scan_for_lambda_return(\n",
    "        lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg, (inputs, pcont), bootstrap\n",
    "    )\n",
    "    if axis != 0:\n",
    "        returns = returns.permute(dims)\n",
    "    return returns\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        parameters,\n",
    "        lr,\n",
    "        eps=1e-4,\n",
    "        clip=None,\n",
    "        wd=None,\n",
    "        wd_pattern=r\".*\",\n",
    "        opt=\"adam\",\n",
    "        use_amp=False,\n",
    "    ):\n",
    "        assert 0 <= wd < 1\n",
    "        assert not clip or 1 <= clip\n",
    "        self._name = name\n",
    "        self._parameters = parameters\n",
    "        self._clip = clip\n",
    "        self._wd = wd\n",
    "        self._wd_pattern = wd_pattern\n",
    "        self._opt = {\n",
    "            \"adam\": lambda: torch.optim.Adam(parameters, lr=lr, eps=eps),\n",
    "            \"nadam\": lambda: NotImplemented(f\"{opt} is not implemented\"),\n",
    "            \"adamax\": lambda: torch.optim.Adamax(parameters, lr=lr, eps=eps),\n",
    "            \"sgd\": lambda: torch.optim.SGD(parameters, lr=lr),\n",
    "            \"momentum\": lambda: torch.optim.SGD(parameters, lr=lr, momentum=0.9),\n",
    "        }[opt]()\n",
    "        self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    def __call__(self, loss, params, retain_graph=True):\n",
    "        assert len(loss.shape) == 0, loss.shape\n",
    "        metrics = {}\n",
    "        metrics[f\"{self._name}_loss\"] = loss.detach().cpu().numpy()\n",
    "        self._opt.zero_grad()\n",
    "        self._scaler.scale(loss).backward(retain_graph=retain_graph)\n",
    "        self._scaler.unscale_(self._opt)\n",
    "        # loss.backward(retain_graph=retain_graph)\n",
    "        norm = torch.nn.utils.clip_grad_norm_(params, self._clip)\n",
    "        if self._wd:\n",
    "            self._apply_weight_decay(params)\n",
    "        self._scaler.step(self._opt)\n",
    "        self._scaler.update()\n",
    "        # self._opt.step()\n",
    "        self._opt.zero_grad()\n",
    "        metrics[f\"{self._name}_grad_norm\"] = to_np(norm)\n",
    "        return metrics\n",
    "\n",
    "    def _apply_weight_decay(self, varibs):\n",
    "        nontrivial = self._wd_pattern != r\".*\"\n",
    "        if nontrivial:\n",
    "            raise NotImplementedError\n",
    "        for var in varibs:\n",
    "            var.data = (1 - self._wd) * var.data\n",
    "\n",
    "\n",
    "def args_type(default):\n",
    "    def parse_string(x):\n",
    "        if default is None:\n",
    "            return x\n",
    "        if isinstance(default, bool):\n",
    "            return bool([\"False\", \"True\"].index(x))\n",
    "        if isinstance(default, int):\n",
    "            return float(x) if (\"e\" in x or \".\" in x) else int(x)\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(args_type(default[0])(y) for y in x.split(\",\"))\n",
    "        return type(default)(x)\n",
    "\n",
    "    def parse_object(x):\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(x)\n",
    "        return x\n",
    "\n",
    "    return lambda x: parse_string(x) if isinstance(x, str) else parse_object(x)\n",
    "\n",
    "\n",
    "def static_scan(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            if type(last) == type({}):\n",
    "                outputs = {\n",
    "                    key: value.clone().unsqueeze(0) for key, value in last.items()\n",
    "                }\n",
    "            else:\n",
    "                outputs = []\n",
    "                for _last in last:\n",
    "                    if type(_last) == type({}):\n",
    "                        outputs.append(\n",
    "                            {\n",
    "                                key: value.clone().unsqueeze(0)\n",
    "                                for key, value in _last.items()\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        outputs.append(_last.clone().unsqueeze(0))\n",
    "            flag = False\n",
    "        else:\n",
    "            if type(last) == type({}):\n",
    "                for key in last.keys():\n",
    "                    outputs[key] = torch.cat(\n",
    "                        [outputs[key], last[key].unsqueeze(0)], dim=0\n",
    "                    )\n",
    "            else:\n",
    "                for j in range(len(outputs)):\n",
    "                    if type(last[j]) == type({}):\n",
    "                        for key in last[j].keys():\n",
    "                            outputs[j][key] = torch.cat(\n",
    "                                [outputs[j][key], last[j][key].unsqueeze(0)], dim=0\n",
    "                            )\n",
    "                    else:\n",
    "                        outputs[j] = torch.cat(\n",
    "                            [outputs[j], last[j].unsqueeze(0)], dim=0\n",
    "                        )\n",
    "    if type(last) == type({}):\n",
    "        outputs = [outputs]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class Every:\n",
    "    def __init__(self, every):\n",
    "        self._every = every\n",
    "        self._last = None\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._every:\n",
    "            return 0\n",
    "        if self._last is None:\n",
    "            self._last = step\n",
    "            return 1\n",
    "        count = int((step - self._last) / self._every)\n",
    "        self._last += self._every * count\n",
    "        return count\n",
    "\n",
    "\n",
    "class Once:\n",
    "    def __init__(self):\n",
    "        self._once = True\n",
    "\n",
    "    def __call__(self):\n",
    "        if self._once:\n",
    "            self._once = False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Until:\n",
    "    def __init__(self, until):\n",
    "        self._until = until\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._until:\n",
    "            return True\n",
    "        return step < self._until\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        in_num = m.in_features\n",
    "        out_num = m.out_features\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        space = m.kernel_size[0] * m.kernel_size[1]\n",
    "        in_num = space * m.in_channels\n",
    "        out_num = space * m.out_channels\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def uniform_weight_init(given_scale):\n",
    "    def f(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            in_num = m.in_features\n",
    "            out_num = m.out_features\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            space = m.kernel_size[0] * m.kernel_size[1]\n",
    "            in_num = space * m.in_channels\n",
    "            out_num = space * m.out_channels\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            m.weight.data.fill_(1.0)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def tensorstats(tensor, prefix=None):\n",
    "    metrics = {\n",
    "        \"mean\": to_np(torch.mean(tensor)),\n",
    "        \"std\": to_np(torch.std(tensor)),\n",
    "        \"min\": to_np(torch.min(tensor)),\n",
    "        \"max\": to_np(torch.max(tensor)),\n",
    "    }\n",
    "    if prefix:\n",
    "        metrics = {f\"{prefix}_{k}\": v for k, v in metrics.items()}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def set_seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def enable_deterministic_run():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def recursively_collect_optim_state_dict(\n",
    "    obj, path=\"\", optimizers_state_dicts=None, visited=None\n",
    "):\n",
    "    if optimizers_state_dicts is None:\n",
    "        optimizers_state_dicts = {}\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    # avoid cyclic reference\n",
    "    if id(obj) in visited:\n",
    "        return optimizers_state_dicts\n",
    "    else:\n",
    "        visited.add(id(obj))\n",
    "    attrs = obj.__dict__\n",
    "    if isinstance(obj, torch.nn.Module):\n",
    "        attrs.update(\n",
    "            {k: attr for k, attr in obj.named_modules() if \".\" not in k and obj != attr}\n",
    "        )\n",
    "    for name, attr in attrs.items():\n",
    "        new_path = path + \".\" + name if path else name\n",
    "        if isinstance(attr, torch.optim.Optimizer):\n",
    "            optimizers_state_dicts[new_path] = attr.state_dict()\n",
    "        elif hasattr(attr, \"__dict__\"):\n",
    "            optimizers_state_dicts.update(\n",
    "                recursively_collect_optim_state_dict(\n",
    "                    attr, new_path, optimizers_state_dicts, visited\n",
    "                )\n",
    "            )\n",
    "    return optimizers_state_dicts\n",
    "\n",
    "\n",
    "def recursively_load_optim_state_dict(obj, optimizers_state_dicts):\n",
    "    for path, state_dict in optimizers_state_dicts.items():\n",
    "        keys = path.split(\".\")\n",
    "        obj_now = obj\n",
    "        for key in keys:\n",
    "            obj_now = getattr(obj_now, key)\n",
    "        obj_now.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class Random(nn.Module):\n",
    "    def __init__(self, config, act_space):\n",
    "        super(Random, self).__init__()\n",
    "        self._config = config\n",
    "        self._act_space = act_space\n",
    "\n",
    "    def actor(self, feat):\n",
    "        # if self._config.actor[\"dist\"] == \"onehot\":\n",
    "\n",
    "        return OneHotDist(\n",
    "            torch.zeros(self._config.num_actions, device=self._config.device).repeat(\n",
    "                self._config.envs, 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # else:\n",
    "    #     return torchd.independent.Independent(\n",
    "    #         torchd.uniform.Uniform(\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.low, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.high, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #         ),\n",
    "    #         1,\n",
    "    #     )\n",
    "\n",
    "    def train(self, start, context, data):\n",
    "        return None, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "import enum\n",
    "from functools import partial as bind\n",
    "\n",
    "\n",
    "class Parallel:\n",
    "    def __init__(self, ctor, strategy):\n",
    "        self.worker = Worker(bind(self._respond, ctor), strategy, state=True)\n",
    "        self.callables = {}\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name.startswith(\"_\"):\n",
    "            raise AttributeError(name)\n",
    "        try:\n",
    "            if name not in self.callables:\n",
    "                self.callables[name] = self.worker(PMessage.CALLABLE, name)()\n",
    "            if self.callables[name]:\n",
    "                return bind(self.worker, PMessage.CALL, name)\n",
    "            else:\n",
    "                return self.worker(PMessage.READ, name)()\n",
    "        except AttributeError:\n",
    "            raise ValueError(name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.worker(PMessage.CALL, \"__len__\")()\n",
    "\n",
    "    def close(self):\n",
    "        self.worker.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _respond(ctor, state, message, name, *args, **kwargs):\n",
    "        state = state or ctor\n",
    "        if message == PMessage.CALLABLE:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = callable(getattr(state, name))\n",
    "        elif message == PMessage.CALL:\n",
    "            result = getattr(state, name)(*args, **kwargs)\n",
    "        elif message == PMessage.READ:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = getattr(state, name)\n",
    "        return state, result\n",
    "\n",
    "\n",
    "class PMessage(enum.Enum):\n",
    "    CALLABLE = 2\n",
    "    CALL = 3\n",
    "    READ = 4\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    initializers = []\n",
    "\n",
    "    def __init__(self, fn, strategy=\"thread\", state=False):\n",
    "        if not state:\n",
    "            fn = lambda s, *args, fn=fn, **kwargs: (s, fn(*args, **kwargs))\n",
    "        inits = self.initializers\n",
    "        self.impl = {\n",
    "            \"process\": bind(ProcessPipeWorker, initializers=inits),\n",
    "            \"daemon\": bind(ProcessPipeWorker, initializers=inits, daemon=True),\n",
    "        }[strategy](fn)\n",
    "        self.promise = None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.promise and self.promise()  # Raise previous exception if any.\n",
    "        self.promise = self.impl(*args, **kwargs)\n",
    "        return self.promise\n",
    "\n",
    "    def wait(self):\n",
    "        return self.impl.wait()\n",
    "\n",
    "    def close(self):\n",
    "        self.impl.close()\n",
    "\n",
    "\n",
    "class ProcessPipeWorker:\n",
    "    def __init__(self, fn, initializers=(), daemon=False):\n",
    "        import multiprocessing\n",
    "        import cloudpickle\n",
    "\n",
    "        self._context = multiprocessing.get_context(\"spawn\")\n",
    "        self._pipe, pipe = self._context.Pipe()\n",
    "        fn = cloudpickle.dumps(fn)\n",
    "        initializers = cloudpickle.dumps(initializers)\n",
    "        self._process = self._context.Process(\n",
    "            target=self._loop, args=(pipe, fn, initializers), daemon=daemon\n",
    "        )\n",
    "        self._process.start()\n",
    "        self._nextid = 0\n",
    "        self._results = {}\n",
    "        assert self._submit(Message.OK)()\n",
    "        atexit.register(self.close)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self._submit(Message.RUN, (args, kwargs))\n",
    "\n",
    "    def wait(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self._pipe.send((Message.STOP, self._nextid, None))\n",
    "            self._pipe.close()\n",
    "        except (AttributeError, IOError):\n",
    "            pass  # The connection was already closed.\n",
    "        try:\n",
    "            self._process.join(0.1)\n",
    "            if self._process.exitcode is None:\n",
    "                try:\n",
    "                    os.kill(self._process.pid, 9)\n",
    "                    time.sleep(0.1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except (AttributeError, AssertionError):\n",
    "            pass\n",
    "\n",
    "    def _submit(self, message, payload=None):\n",
    "        callid = self._nextid\n",
    "        self._nextid += 1\n",
    "        self._pipe.send((message, callid, payload))\n",
    "        return Future(self._receive, callid)\n",
    "\n",
    "    def _receive(self, callid):\n",
    "        while callid not in self._results:\n",
    "            try:\n",
    "                message, callid, payload = self._pipe.recv()\n",
    "            except (OSError, EOFError):\n",
    "                raise RuntimeError(\"Lost connection to worker.\")\n",
    "            if message == Message.ERROR:\n",
    "                raise Exception(payload)\n",
    "            assert message == Message.RESULT, message\n",
    "            self._results[callid] = payload\n",
    "        return self._results.pop(callid)\n",
    "\n",
    "    @staticmethod\n",
    "    def _loop(pipe, function, initializers):\n",
    "        try:\n",
    "            callid = None\n",
    "            state = None\n",
    "            import cloudpickle\n",
    "\n",
    "            initializers = cloudpickle.loads(initializers)\n",
    "            function = cloudpickle.loads(function)\n",
    "            [fn() for fn in initializers]\n",
    "            while True:\n",
    "                if not pipe.poll(0.1):\n",
    "                    continue  # Wake up for keyboard interrupts.\n",
    "                message, callid, payload = pipe.recv()\n",
    "                if message == Message.OK:\n",
    "                    pipe.send((Message.RESULT, callid, True))\n",
    "                elif message == Message.STOP:\n",
    "                    return\n",
    "                elif message == Message.RUN:\n",
    "                    args, kwargs = payload\n",
    "                    state, result = function(state, *args, **kwargs)\n",
    "                    pipe.send((Message.RESULT, callid, result))\n",
    "                else:\n",
    "                    raise KeyError(f\"Invalid message: {message}\")\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            return\n",
    "        except Exception:\n",
    "            stacktrace = \"\".join(traceback.format_exception(*sys.exc_info()))\n",
    "            print(f\"Error inside process worker: {stacktrace}.\", flush=True)\n",
    "            pipe.send((Message.ERROR, callid, stacktrace))\n",
    "            return\n",
    "        finally:\n",
    "            try:\n",
    "                pipe.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "class Message(enum.Enum):\n",
    "    OK = 1\n",
    "    RUN = 2\n",
    "    RESULT = 3\n",
    "    STOP = 4\n",
    "    ERROR = 5\n",
    "\n",
    "\n",
    "class Future:\n",
    "    def __init__(self, receive, callid):\n",
    "        self._receive = receive\n",
    "        self._callid = callid\n",
    "        self._result = None\n",
    "        self._complete = False\n",
    "\n",
    "    def __call__(self):\n",
    "        if not self._complete:\n",
    "            self._result = self._receive(self._callid)\n",
    "            self._complete = True\n",
    "        return self._result\n",
    "\n",
    "\n",
    "class Damy:\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    def step(self, action):\n",
    "        return lambda: self._env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        return lambda: self._env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "# torch.set_default_device(\"mps\")\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def count_steps(folder):\n",
    "    return sum(int(str(n).split(\"-\")[-1][:-4]) - 1 for n in folder.glob(\"*.npz\"))\n",
    "\n",
    "\n",
    "def make_dataset(episodes, config):\n",
    "    generator = sample_episodes(episodes, config.batch_length)\n",
    "    dataset = from_generator(generator, config.batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_env(config, mode, id):\n",
    "    suite, task = config.task.split(\"_\", 1)\n",
    "    if suite == \"dmc\":\n",
    "        import envs.dmc as dmc\n",
    "\n",
    "        env = dmc.DeepMindControl(\n",
    "            task, config.action_repeat, config.size, seed=config.seed + id\n",
    "        )\n",
    "        env = NormalizeActions(env)\n",
    "    elif suite == \"cartpole\":\n",
    "        env = CartPole(\n",
    "            task,\n",
    "        )\n",
    "    elif suite == \"poker\":\n",
    "        env = Poker(\n",
    "            \"universal_poker\",\n",
    "        )\n",
    "    elif suite == \"atari\":\n",
    "        import envs.atari as atari\n",
    "\n",
    "        env = atari.Atari(\n",
    "            task,\n",
    "            config.action_repeat,\n",
    "            config.size,\n",
    "            gray=config.grayscale,\n",
    "            noops=config.noops,\n",
    "            lives=config.lives,\n",
    "            sticky=config.stickey,\n",
    "            actions=config.actions,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"dmlab\":\n",
    "        import envs.dmlab as dmlab\n",
    "\n",
    "        env = dmlab.DeepMindLabyrinth(\n",
    "            task,\n",
    "            mode if \"train\" in mode else \"test\",\n",
    "            config.action_repeat,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"memorymaze\":\n",
    "        from envs.memorymaze import MemoryMaze\n",
    "\n",
    "        env = MemoryMaze(task, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"crafter\":\n",
    "        import envs.crafter as crafter\n",
    "\n",
    "        env = crafter.Crafter(task, config.size, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"minecraft\":\n",
    "        import envs.minecraft as minecraft\n",
    "\n",
    "        env = minecraft.make_env(task, size=config.size, break_speed=config.break_speed)\n",
    "        env = OneHotAction(env)\n",
    "    else:\n",
    "        raise NotImplementedError(suite)\n",
    "    env = TimeLimit(env, config.time_limit)\n",
    "    env = SelectAction(env, key=\"action\")\n",
    "    env = UUID(env)\n",
    "    if suite == \"minecraft\":\n",
    "        env = RewardObs(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    set_seed_everywhere(config.seed)\n",
    "    if config.deterministic_run:\n",
    "        enable_deterministic_run()\n",
    "    logdir = pathlib.Path(config.logdir).expanduser()\n",
    "    config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "    config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "    config.steps //= config.action_repeat\n",
    "    config.eval_every //= config.action_repeat\n",
    "    config.log_every //= config.action_repeat\n",
    "    config.time_limit //= config.action_repeat\n",
    "\n",
    "    print(\"Logdir\", logdir)\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "    config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "    step = count_steps(config.traindir)\n",
    "    # step in logger is environmental step\n",
    "    logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "    print(\"Create envs.\")\n",
    "    if config.offline_traindir:\n",
    "        directory = config.offline_traindir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.traindir\n",
    "    train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "    if config.offline_evaldir:\n",
    "        directory = config.offline_evaldir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.evaldir\n",
    "    eval_eps = load_episodes(directory, limit=1)\n",
    "    make = lambda mode, id: make_env(config, mode, id)\n",
    "    train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "    eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "    if config.parallel:\n",
    "        train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "        eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "    else:\n",
    "        train_envs = [Damy(env) for env in train_envs]\n",
    "        eval_envs = [Damy(env) for env in eval_envs]\n",
    "    acts = train_envs[0].action_space\n",
    "    print(\"Action Space\", acts)\n",
    "    config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "    state = None\n",
    "    if not config.offline_traindir:\n",
    "        prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "        print(f\"Prefill dataset ({prefill} steps).\")\n",
    "        if hasattr(acts, \"discrete\"):\n",
    "            random_actor = OneHotDist(\n",
    "                torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "            )\n",
    "        else:\n",
    "            random_actor = torchd.independent.Independent(\n",
    "                torchd.uniform.Uniform(\n",
    "                    torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                    torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "                ),\n",
    "                1,\n",
    "            )\n",
    "\n",
    "        def random_agent(o, d, s):\n",
    "            action = random_actor.sample()\n",
    "            logprob = random_actor.log_prob(action)\n",
    "            return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "        state = simulate(\n",
    "            random_agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=prefill,\n",
    "        )\n",
    "        logger.step += prefill * config.action_repeat\n",
    "        print(f\"Logger: ({logger.step} steps).\")\n",
    "\n",
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "        logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "            eval_policy = funcpartial(agent, training=False)\n",
    "            simulate(\n",
    "                eval_policy,\n",
    "                eval_envs,\n",
    "                eval_eps,\n",
    "                config.evaldir,\n",
    "                logger,\n",
    "                is_eval=True,\n",
    "                episodes=config.eval_episode_num,\n",
    "            )\n",
    "            if config.video_pred_log:\n",
    "                video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import Loss\n",
    "import yaml\n",
    "\n",
    "from game_configs import GameConfig\n",
    "from utils import (\n",
    "    prepare_kernel_initializers,\n",
    "    prepare_activations,\n",
    ")\n",
    "\n",
    "\n",
    "class ConfigBase:\n",
    "    def parse_field(\n",
    "        self, field_name, default=None, wrapper=None, required=True, dtype=None\n",
    "    ):\n",
    "        if field_name in self.config_dict:\n",
    "            val = self.config_dict[field_name]\n",
    "            # print(\"value: \", val)\n",
    "            print(f\"Using         {field_name:30}: {val}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(val)\n",
    "            return self.config_dict[field_name]\n",
    "\n",
    "        if default is not None:\n",
    "            print(f\"Using default {field_name:30}: {default}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(default)\n",
    "            return default\n",
    "\n",
    "        if required:\n",
    "            raise ValueError(\n",
    "                f\"Missing required field without default value: {field_name}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Using         {field_name:30}: {default}\")\n",
    "\n",
    "        if field_name in self._parsed_fields:\n",
    "            print(\"warning: duplicate field: \", field_name)\n",
    "        self._parsed_fields.add(field_name)\n",
    "\n",
    "    def __init__(self, config_dict: dict):\n",
    "        self.config_dict = config_dict\n",
    "        self._parsed_fields = set()\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "\n",
    "class Config(ConfigBase):\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"], game_config=o[\"game\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict, game=self.game)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "    def __init__(self, config_dict: dict, game_config: GameConfig) -> None:\n",
    "        super().__init__(config_dict)\n",
    "        # could take in a game config and set an action space and observation shape here\n",
    "        # OR DO THAT IN BASE AGENT?\n",
    "        self.game = game_config\n",
    "\n",
    "        self._verify_game()\n",
    "\n",
    "        # not hyperparameters but utility things\n",
    "        self.save_intermediate_weights: bool = self.parse_field(\n",
    "            \"save_intermediate_weights\", False\n",
    "        )\n",
    "\n",
    "        # ADD LEARNING RATE SCHEDULES\n",
    "        self.training_steps: int = self.parse_field(\"training_steps\", 10000)\n",
    "\n",
    "        self.adam_epsilon: float = self.parse_field(\"adam_epsilon\", 1e-6)\n",
    "        self.momentum = self.parse_field(\"momentum\", 0.9)\n",
    "        self.learning_rate: float = self.parse_field(\"learning_rate\", 0.001)\n",
    "        self.clipnorm: int = self.parse_field(\"clipnorm\", 0)\n",
    "        self.optimizer: torch.optim.Optimizer = self.parse_field(\n",
    "            \"optimizer\", torch.optim.Adam\n",
    "        )\n",
    "        self.weight_decay: float = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.loss_function: Loss = self.parse_field(\"loss_function\", required=True)\n",
    "        self.activation = self.parse_field(\n",
    "            \"activation\", \"relu\", wrapper=prepare_activations\n",
    "        )\n",
    "        self.kernel_initializer = self.parse_field(\n",
    "            \"kernel_initializer\",\n",
    "            None,\n",
    "            required=False,\n",
    "            wrapper=kernel_initializer_wrapper,\n",
    "        )\n",
    "\n",
    "        self.minibatch_size: int = self.parse_field(\"minibatch_size\", 64)\n",
    "        self.replay_buffer_size: int = self.parse_field(\"replay_buffer_size\", 5000)\n",
    "        self.min_replay_buffer_size: int = self.parse_field(\n",
    "            \"min_replay_buffer_size\", self.minibatch_size\n",
    "        )\n",
    "        self.num_minibatches: int = self.parse_field(\"num_minibatches\", 1)\n",
    "        self.training_iterations: int = self.parse_field(\"training_iterations\", 1)\n",
    "        self.print_interval: int = self.parse_field(\"print_interval\", 100)\n",
    "\n",
    "    def _verify_game(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def kernel_initializer_wrapper(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    elif isinstance(x, str):\n",
    "        return prepare_kernel_initializers(x)\n",
    "    else:\n",
    "        assert callable(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.symlog_inputs = self.parse_field(\"symlog_inputs\", True)\n",
    "\n",
    "\n",
    "class DecoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.cnn_sigmoid = self.parse_field(\"cnn_sigmoid\", False)\n",
    "        self.image_dist = self.parse_field(\"image_dist\", \"mse\")\n",
    "        self.vector_dist = self.parse_field(\"vector_dist\", \"symlog_mse\")\n",
    "        self.outscale = self.parse_field(\"outscale\", 1.0)\n",
    "\n",
    "\n",
    "class HeadConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.layers = self.parse_field(\"layers\", 2)\n",
    "        self.dist = self.parse_field(\"dist\", \"symlog_disc\")\n",
    "        self.loss_scale = self.parse_field(\"loss_scale\", 1.0)\n",
    "        self.outscale = self.parse_field(\"outscale\", 0.0)\n",
    "\n",
    "\n",
    "class DreamerConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "\n",
    "        self.logdir = self.parse_field(\"logdir\", \"./logdir\")\n",
    "        self.traindir = self.parse_field(\"traindir\", \"./traindir\")\n",
    "        self.evaldir = self.parse_field(\"evaldir\", \"./evaldir\")\n",
    "        self.offline_traindir = self.parse_field(\n",
    "            \"offline_traindir\", \"./offline_traindir\"\n",
    "        )\n",
    "        self.offline_evaldir = self.parse_field(\"offline_evaldir\", \"./offline_evaldir\")\n",
    "        self.seed = self.parse_field(\"seed\", 0)\n",
    "        self.deterministic_run = self.parse_field(\"deterministic_run\", False)\n",
    "        self.steps: int = self.parse_field(\"steps\", 1000000, wrapper=float)\n",
    "        self.parallel = self.parse_field(\"parallel\", False)\n",
    "        self.eval_every = self.parse_field(\"eval_every\", 10000, wrapper=float)\n",
    "        self.eval_episode_num = self.parse_field(\"eval_episode_num\", 10)\n",
    "        self.log_every = self.parse_field(\"log_every\", 100, wrapper=float)\n",
    "        self.reset_every = self.parse_field(\"reset_every\", 1000, wrapper=float)\n",
    "        self.device = self.parse_field(\n",
    "            \"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.compile = self.parse_field(\"compile\", False)\n",
    "        self.precision = self.parse_field(\"precision\", \"fp32\")\n",
    "        self.debug = self.parse_field(\"debug\", False)\n",
    "        self.video_pred_log = self.parse_field(\"video_pred_log\", True)\n",
    "\n",
    "        self.task = self.parse_field(\"task\", \"atari_MsPacmanNoFrameskip-v4\")\n",
    "        self.size = self.parse_field(\"size\", (64, 64), wrapper=tuple)\n",
    "        self.envs = self.parse_field(\"envs\", 1)\n",
    "        self.action_repeat = self.parse_field(\"action_repeat\", 4)\n",
    "        self.noops = self.parse_field(\"noops\", 0)\n",
    "        self.lives = self.parse_field(\"lives\", \"unused\")\n",
    "        self.stickey = self.parse_field(\"stickey\", True)\n",
    "        self.actions = self.parse_field(\"actions\", \"needed\")\n",
    "        self.resize = self.parse_field(\"resize\", \"opencv\")\n",
    "        self.time_limit = self.parse_field(\"time_limit\", 1000)\n",
    "        self.grayscale = self.parse_field(\"grayscale\", True)\n",
    "        self.prefill = self.parse_field(\"prefill\", 10)\n",
    "        self.reward_EMA = self.parse_field(\"reward_EMA\", True)\n",
    "\n",
    "        self.dyn_hidden = self.parse_field(\"dyn_hidden\", 256)\n",
    "        self.dyn_deter = self.parse_field(\"dyn_deter\", 256)\n",
    "        self.dyn_stoch = self.parse_field(\"dyn_stoch\", 16)\n",
    "        self.dyn_discrete = self.parse_field(\"dyn_discrete\", 16)\n",
    "        self.dyn_rec_depth = self.parse_field(\"dyn_rec_depth\", 1)\n",
    "        self.dyn_mean_act = self.parse_field(\"dyn_mean_act\", \"none\")\n",
    "        self.dyn_std_act = self.parse_field(\"dyn_std_act\", \"sigmoid2\")\n",
    "        self.dyn_min_std = self.parse_field(\"dyn_min_std\", 0.1)\n",
    "        self.grad_heads = self.parse_field(\"grad_heads\", [\"decoder\", \"reward\", \"cont\"])\n",
    "        self.units = self.parse_field(\"units\", 256)\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.encoder = EncoderConfig(self.config_dict[\"encoder\"])\n",
    "        self.decoder = DecoderConfig(self.config_dict[\"decoder\"])\n",
    "        self.reward_head = HeadConfig(self.config_dict[\"reward_head\"])\n",
    "        self.cont_head = HeadConfig(self.config_dict[\"cont_head\"])\n",
    "        self.dyn_scale = self.parse_field(\"dyn_scale\", 0.5)\n",
    "        self.rep_scale = self.parse_field(\"rep_scale\", 0.1)\n",
    "        self.kl_free = self.parse_field(\"kl_free\", 1.0)\n",
    "        self.weight_decay = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.unimix_ratio = self.parse_field(\"unimix_ratio\", 0.01)\n",
    "        self.initial = self.parse_field(\"initial\", \"learned\")\n",
    "\n",
    "        self.batch_size = self.parse_field(\"batch_size\", 8)\n",
    "        self.batch_length = self.parse_field(\"batch_length\", 32)\n",
    "        self.train_ratio = self.parse_field(\"train_ratio\", 512)\n",
    "        self.pretrain: int = self.parse_field(\"pretrain\", 100)\n",
    "        self.model_lr = self.parse_field(\"model_lr\", 1e-4, wrapper=float)\n",
    "        self.opt_eps = self.parse_field(\"opt_eps\", 1e-8, wrapper=float)\n",
    "        self.grad_clip: int = self.parse_field(\"grad_clip\", 1000, wrapper=float)\n",
    "        self.dataset_size: int = self.parse_field(\n",
    "            \"dataset_size\", 1000000, wrapper=float\n",
    "        )\n",
    "        self.opt = self.parse_field(\"opt\", \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using         logdir                        : ./logdir\n",
      "Using         traindir                      : None\n",
      "Using         evaldir                       : None\n",
      "Using         offline_traindir              : None\n",
      "Using         offline_evaldir               : None\n",
      "Using         seed                          : 0\n",
      "Using         deterministic_run             : False\n",
      "Using         steps                         : 1e6\n",
      "Using         parallel                      : False\n",
      "Using         eval_every                    : 1e4\n",
      "Using         eval_episode_num              : 10\n",
      "Using         log_every                     : 10\n",
      "Using         reset_every                   : 0\n",
      "Using         device                        : cpu\n",
      "Using         compile                       : True\n",
      "Using         precision                     : 16\n",
      "Using         debug                         : False\n",
      "Using         video_pred_log                : False\n",
      "Using         task                          : poker_universal_poker\n",
      "Using         size                          : [64, 64]\n",
      "Using         envs                          : 1\n",
      "Using         action_repeat                 : 2\n",
      "Using default noops                         : 0\n",
      "Using default lives                         : unused\n",
      "Using default stickey                       : True\n",
      "Using default actions                       : needed\n",
      "Using default resize                        : opencv\n",
      "Using         time_limit                    : 1000\n",
      "Using         grayscale                     : False\n",
      "Using         prefill                       : 2500\n",
      "Using         reward_EMA                    : True\n",
      "Using         dyn_hidden                    : 256\n",
      "Using         dyn_deter                     : 256\n",
      "Using         dyn_stoch                     : 16\n",
      "Using         dyn_discrete                  : 16\n",
      "Using         dyn_rec_depth                 : 1\n",
      "Using         dyn_mean_act                  : none\n",
      "Using         dyn_std_act                   : sigmoid2\n",
      "Using         dyn_min_std                   : 0.1\n",
      "Using         grad_heads                    : ['decoder', 'reward', 'cont']\n",
      "Using         units                         : 256\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         symlog_inputs                 : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         cnn_sigmoid                   : False\n",
      "Using         image_dist                    : mse\n",
      "Using         vector_dist                   : symlog_mse\n",
      "Using         outscale                      : 1.0\n",
      "Using         layers                        : 2\n",
      "Using         dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 0.0\n",
      "Using         layers                        : 2\n",
      "Using default dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 1.0\n",
      "Using         dyn_scale                     : 0.5\n",
      "Using         rep_scale                     : 0.1\n",
      "Using         kl_free                       : 1.0\n",
      "Using         weight_decay                  : 0.0\n",
      "Using         unimix_ratio                  : 0.01\n",
      "Using         initial                       : learned\n",
      "Using         batch_size                    : 8\n",
      "Using         batch_length                  : 32\n",
      "Using         train_ratio                   : 512\n",
      "Using         pretrain                      : 100\n",
      "Using         model_lr                      : 1e-4\n",
      "Using         opt_eps                       : 1e-8\n",
      "Using         grad_clip                     : 1000\n",
      "Using         dataset_size                  : 1000000\n",
      "Using         opt                           : adam\n"
     ]
    }
   ],
   "source": [
    "configs = yaml.safe_load(pathlib.Path(\"./configs.yaml\").read_text())\n",
    "config_dict = configs[\"defaults\"]\n",
    "config_dict[\"logdir\"] = \"./logdir\"\n",
    "config_dict[\"offline_traindir\"] = None  # \"./offline_traindir\"\n",
    "config_dict[\"offline_evaldir\"] = None  # \"./offline_evaldir\"\n",
    "config = DreamerConfig(config_dict=config_dict)\n",
    "# config = DreamerConfig(config_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class RSSM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        stoch=30,\n",
    "        deter=200,\n",
    "        hidden=200,\n",
    "        rec_depth=1,\n",
    "        discrete=False,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        mean_act=\"none\",\n",
    "        std_act=\"softplus\",\n",
    "        min_std=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        initial=\"learned\",\n",
    "        num_actions=None,\n",
    "        embed=None,\n",
    "        device=None,\n",
    "    ):\n",
    "        super(RSSM, self).__init__()\n",
    "        self._stoch = stoch\n",
    "        self._deter = deter\n",
    "        self._hidden = hidden\n",
    "        self._min_std = min_std\n",
    "        self._rec_depth = rec_depth\n",
    "        self._discrete = discrete\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._mean_act = mean_act\n",
    "        self._std_act = std_act\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._initial = initial\n",
    "        self._num_actions = num_actions\n",
    "        self._embed = embed\n",
    "        self._device = device\n",
    "\n",
    "        inp_layers = []\n",
    "        if self._discrete:\n",
    "            inp_dim = self._stoch * self._discrete + num_actions\n",
    "        else:\n",
    "            inp_dim = self._stoch + num_actions\n",
    "        inp_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            inp_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        inp_layers.append(act())\n",
    "        self._img_in_layers = nn.Sequential(*inp_layers)\n",
    "        self._img_in_layers.apply(weight_init)\n",
    "        self._cell = GRUCell(self._hidden, self._deter, norm=norm)\n",
    "        self._cell.apply(weight_init)\n",
    "\n",
    "        img_out_layers = []\n",
    "        inp_dim = self._deter\n",
    "        img_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            img_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        img_out_layers.append(act())\n",
    "        self._img_out_layers = nn.Sequential(*img_out_layers)\n",
    "        self._img_out_layers.apply(weight_init)\n",
    "\n",
    "        obs_out_layers = []\n",
    "        inp_dim = self._deter + self._embed\n",
    "        obs_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            obs_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        obs_out_layers.append(act())\n",
    "        self._obs_out_layers = nn.Sequential(*obs_out_layers)\n",
    "        self._obs_out_layers.apply(weight_init)\n",
    "\n",
    "        if self._discrete:\n",
    "            self._imgs_stat_layer = nn.Linear(\n",
    "                self._hidden, self._stoch * self._discrete\n",
    "            )\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, self._stoch * self._discrete)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "        else:\n",
    "            self._imgs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "\n",
    "        if self._initial == \"learned\":\n",
    "            self.W = torch.nn.Parameter(\n",
    "                torch.zeros((1, self._deter), device=torch.device(self._device)),\n",
    "                requires_grad=True,\n",
    "            )\n",
    "\n",
    "    def initial(self, batch_size):\n",
    "        deter = torch.zeros(batch_size, self._deter, device=self._device)\n",
    "        if self._discrete:\n",
    "            state = dict(\n",
    "                logit=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                stoch=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                deter=deter,\n",
    "            )\n",
    "        else:\n",
    "            state = dict(\n",
    "                mean=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                std=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                stoch=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                deter=deter,\n",
    "            )\n",
    "        if self._initial == \"zeros\":\n",
    "            return state\n",
    "        elif self._initial == \"learned\":\n",
    "            state[\"deter\"] = torch.tanh(self.W).repeat(batch_size, 1)\n",
    "            state[\"stoch\"] = self.get_stoch(state[\"deter\"])\n",
    "            return state\n",
    "        else:\n",
    "            raise NotImplementedError(self._initial)\n",
    "\n",
    "    def observe(self, embed, action, is_first, state=None):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        # (batch, time, ch) -> (time, batch, ch)\n",
    "        embed, action, is_first = swap(embed), swap(action), swap(is_first)\n",
    "        # prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\n",
    "        post, prior = static_scan(\n",
    "            lambda prev_state, prev_act, embed, is_first: self.obs_step(\n",
    "                prev_state[0], prev_act, embed, is_first\n",
    "            ),\n",
    "            (action, embed, is_first),\n",
    "            (state, state),\n",
    "        )\n",
    "\n",
    "        # (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\n",
    "        post = {k: swap(v) for k, v in post.items()}\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return post, prior\n",
    "\n",
    "    def imagine_with_action(self, action, state):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        assert isinstance(state, dict), state\n",
    "        action = swap(action)\n",
    "        prior = static_scan(self.img_step, [action], state)\n",
    "        prior = prior[0]\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return prior\n",
    "\n",
    "    def get_feat(self, state):\n",
    "        stoch = state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            stoch = stoch.reshape(shape)\n",
    "        return torch.cat([stoch, state[\"deter\"]], -1)\n",
    "\n",
    "    def get_dist(self, state, dtype=None):\n",
    "        if self._discrete:\n",
    "            logit = state[\"logit\"]\n",
    "            dist = torchd.independent.Independent(\n",
    "                OneHotDist(logit, unimix_ratio=self._unimix_ratio), 1\n",
    "            )\n",
    "        else:\n",
    "            mean, std = state[\"mean\"], state[\"std\"]\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, std), 1)\n",
    "            )\n",
    "        return dist\n",
    "\n",
    "    def obs_step(self, prev_state, prev_action, embed, is_first, sample=True):\n",
    "        # initialize all prev_state\n",
    "        if prev_state == None or torch.sum(is_first) == len(is_first):\n",
    "            prev_state = self.initial(len(is_first))\n",
    "            prev_action = torch.zeros(\n",
    "                (len(is_first), self._num_actions), device=self._device\n",
    "            )\n",
    "        # overwrite the prev_state only where is_first=True\n",
    "        elif torch.sum(is_first) > 0:\n",
    "            print(is_first.shape)\n",
    "            is_first = is_first[:, None]\n",
    "            print(is_first.shape)\n",
    "            prev_action *= 1.0 - is_first\n",
    "            init_state = self.initial(len(is_first))\n",
    "            for key, val in prev_state.items():\n",
    "                is_first_r = torch.reshape(\n",
    "                    is_first,\n",
    "                    is_first.shape + (1,) * (len(val.shape) - len(is_first.shape)),\n",
    "                )\n",
    "                prev_state[key] = (\n",
    "                    val * (1.0 - is_first_r) + init_state[key] * is_first_r\n",
    "                )\n",
    "        # print(\"prev_state shape: \", prev_state[\"deter\"].shape)\n",
    "        prior = self.img_step(prev_state, prev_action)\n",
    "        # print(\"embed shape: \", embed.shape)\n",
    "        # print(\"prior shape: \", prior[\"deter\"].shape)\n",
    "        x = torch.cat([prior[\"deter\"], embed], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # print(self._deter + self._embed)\n",
    "        # print(self._hidden)\n",
    "        # (batch_size, prior_deter + embed) -> (batch_size, hidden)\n",
    "        x = self._obs_out_layers(x)\n",
    "        # (batch_size, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"obs\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        post = {\"stoch\": stoch, \"deter\": prior[\"deter\"], **stats}\n",
    "        return post, prior\n",
    "\n",
    "    def img_step(self, prev_state, prev_action, sample=True):\n",
    "        # (batch, stoch, discrete_num)\n",
    "        prev_stoch = prev_state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(prev_stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            # (batch, stoch, discrete_num) -> (batch, stoch * discrete_num)\n",
    "            prev_stoch = prev_stoch.reshape(shape)\n",
    "        # (batch, stoch * discrete_num) -> (batch, stoch * discrete_num + action)\n",
    "        x = torch.cat([prev_stoch, prev_action], -1)\n",
    "        # (batch, stoch * discrete_num + action, embed) -> (batch, hidden)\n",
    "        x = self._img_in_layers(x)\n",
    "        for _ in range(self._rec_depth):  # rec depth is not correctly implemented\n",
    "            deter = prev_state[\"deter\"]\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            # (batch, hidden), (batch, deter) -> (batch, deter), (batch, deter)\n",
    "            x, deter = self._cell(x, [deter])\n",
    "            # print(\"x shape: \", x.shape)\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            deter = deter[0]  # Keras wraps the state in a list.\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "        # (batch, deter) -> (batch, hidden)\n",
    "        x = self._img_out_layers(x)\n",
    "        # (batch, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        prior = {\"stoch\": stoch, \"deter\": deter, **stats}\n",
    "        return prior\n",
    "\n",
    "    def get_stoch(self, deter):\n",
    "        x = self._img_out_layers(deter)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        dist = self.get_dist(stats)\n",
    "        return dist.mode()\n",
    "\n",
    "    def _suff_stats_layer(self, name, x):\n",
    "        if self._discrete:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            logit = x.reshape(list(x.shape[:-1]) + [self._stoch, self._discrete])\n",
    "            return {\"logit\": logit}\n",
    "        else:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            mean, std = torch.split(x, [self._stoch] * 2, -1)\n",
    "            mean = {\n",
    "                \"none\": lambda: mean,\n",
    "                \"tanh5\": lambda: 5.0 * torch.tanh(mean / 5.0),\n",
    "            }[self._mean_act]()\n",
    "            std = {\n",
    "                \"softplus\": lambda: torch.softplus(std),\n",
    "                \"abs\": lambda: torch.abs(std + 1),\n",
    "                \"sigmoid\": lambda: torch.sigmoid(std),\n",
    "                \"sigmoid2\": lambda: 2 * torch.sigmoid(std / 2),\n",
    "            }[self._std_act]()\n",
    "            std = std + self._min_std\n",
    "            return {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    def kl_loss(self, post, prior, free, dyn_scale, rep_scale):\n",
    "        kld = torchd.kl.kl_divergence\n",
    "        dist = lambda x: self.get_dist(x)\n",
    "        sg = lambda x: {k: v.detach() for k, v in x.items()}\n",
    "\n",
    "        rep_loss = value = kld(\n",
    "            dist(post) if self._discrete else dist(post)._dist,\n",
    "            dist(sg(prior)) if self._discrete else dist(sg(prior))._dist,\n",
    "        )\n",
    "        dyn_loss = kld(\n",
    "            dist(sg(post)) if self._discrete else dist(sg(post))._dist,\n",
    "            dist(prior) if self._discrete else dist(prior)._dist,\n",
    "        )\n",
    "        # this is implemented using maximum at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        rep_loss = torch.clip(rep_loss, min=free)\n",
    "        dyn_loss = torch.clip(dyn_loss, min=free)\n",
    "        loss = dyn_scale * dyn_loss + rep_scale * rep_loss\n",
    "\n",
    "        return loss, value, dyn_loss, rep_loss\n",
    "\n",
    "\n",
    "class MultiEncoder(nn.Module):\n",
    "    def __init__(self, shapes, config):\n",
    "        super(MultiEncoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\", \"reward\")\n",
    "        shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if k not in excluded and not k.startswith(\"log_\")\n",
    "        }\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "\n",
    "        print(shapes.items())\n",
    "        print(config.mlp_keys)\n",
    "        print(config.cnn_keys)\n",
    "        for k, v in shapes.items():\n",
    "            print(\"cnn\")\n",
    "            print(len(v) == 3)\n",
    "            print(re.match(self.config.cnn_keys, k))\n",
    "            print(self.config.cnn_keys)\n",
    "            print(k)\n",
    "            print(\"mlp\")\n",
    "            print(len(v) in (1, 2))\n",
    "            print(re.match(self.config.mlp_keys, k))\n",
    "            print(self.config.mlp_keys)\n",
    "            print(k)\n",
    "\n",
    "        print(\"Encoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Encoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        self.outdim = 0\n",
    "        if self.cnn_shapes:\n",
    "            input_ch = sum([v[-1] for v in self.cnn_shapes.values()])\n",
    "            input_shape = tuple(self.cnn_shapes.values())[0][:2] + (input_ch,)\n",
    "            self._cnn = ConvEncoder(\n",
    "                input_shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "            )\n",
    "            self.outdim += self._cnn.outdim\n",
    "        if self.mlp_shapes:\n",
    "            input_size = sum([sum(v) for v in self.mlp_shapes.values()])\n",
    "            for v in self.mlp_shapes.values():\n",
    "                print(\"v: \", v)\n",
    "            print(\"input_size: \", input_size)\n",
    "            self._mlp = MLP(\n",
    "                input_size,\n",
    "                None,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                symlog_inputs=self.config.symlog_inputs,\n",
    "                name=\"Encoder\",\n",
    "            )\n",
    "            self.outdim += self.config.mlp_units\n",
    "\n",
    "    def forward(self, obs):\n",
    "        outputs = []\n",
    "        if self.cnn_shapes:\n",
    "            inputs = torch.cat([obs[k] for k in self.cnn_shapes], -1)\n",
    "            outputs.append(self._cnn(inputs))\n",
    "            # print(\"CNN output shape: \", outputs[-1].shape)\n",
    "        if self.mlp_shapes:\n",
    "            # print(\"obs\", obs)\n",
    "            inputs = torch.cat([obs[k] for k in self.mlp_shapes], -1)\n",
    "            # print(inputs.shape)\n",
    "            outputs.append(self._mlp(inputs))\n",
    "            # print(\"MLP output shape: \", outputs[-1].shape)\n",
    "        outputs = torch.cat(outputs, -1)\n",
    "        # print(\"Encoder output shape: \", outputs.shape)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MultiDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shapes,\n",
    "        config,\n",
    "    ):\n",
    "        super(MultiDecoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\")\n",
    "        shapes = {k: v for k, v in shapes.items() if k not in excluded}\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "        print(\"Decoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Decoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        if self.cnn_shapes:\n",
    "            some_shape = list(self.cnn_shapes.values())[0]\n",
    "            shape = (sum(x[-1] for x in self.cnn_shapes.values()),) + some_shape[:-1]\n",
    "            self._cnn = ConvDecoder(\n",
    "                feat_size,\n",
    "                shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "                outscale=self.config.outscale,\n",
    "                cnn_sigmoid=self.config.cnn_sigmoid,\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            self._mlp = MLP(\n",
    "                feat_size,\n",
    "                self.mlp_shapes,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.vector_dist,\n",
    "                outscale=self.config.outscale,\n",
    "                name=\"Decoder\",\n",
    "            )\n",
    "        self._image_dist = self.config.image_dist\n",
    "\n",
    "    def forward(self, features):\n",
    "        dists = {}\n",
    "        if self.cnn_shapes:\n",
    "            feat = features\n",
    "            outputs = self._cnn(feat)\n",
    "            split_sizes = [v[-1] for v in self.cnn_shapes.values()]\n",
    "            outputs = torch.split(outputs, split_sizes, -1)\n",
    "            dists.update(\n",
    "                {\n",
    "                    key: self._make_image_dist(output)\n",
    "                    for key, output in zip(self.cnn_shapes.keys(), outputs)\n",
    "                }\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            dists.update(self._mlp(features))\n",
    "        return dists\n",
    "\n",
    "    def _make_image_dist(self, mean):\n",
    "        if self._image_dist == \"normal\":\n",
    "            return ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, 1), 3)\n",
    "            )\n",
    "        if self._image_dist == \"mse\":\n",
    "            return MSEDist(mean)\n",
    "        raise NotImplementedError(self._image_dist)\n",
    "\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        depth=32,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "    ):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        h, w, input_ch = input_shape\n",
    "        stages = int(np.log2(h) - np.log2(minres))\n",
    "        in_dim = input_ch\n",
    "        out_dim = depth\n",
    "        layers = []\n",
    "        for i in range(stages):\n",
    "            layers.append(\n",
    "                Conv2dSamePad(\n",
    "                    in_channels=in_dim,\n",
    "                    out_channels=out_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=2,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim *= 2\n",
    "            h, w = h // 2, w // 2\n",
    "\n",
    "        # self.outdim = out_dim // 2 * h * w\n",
    "        # print(\"h, w: \", h, w)\n",
    "        # print(\"Encoder output shape (outdim): \", self.outdim)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # print(\"Encoder layers: \", self.layers)\n",
    "        # print(\"Encoder layers shape: \", self.layers[0].weight.shape)\n",
    "        self.layers.apply(weight_init)\n",
    "        self.outdim = self.calculate_outdim(input_shape)\n",
    "\n",
    "    def calculate_outdim(self, input_shape):\n",
    "        obs = torch.randn(1, *input_shape)\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]]).shape[-1]\n",
    "\n",
    "    def forward(self, obs):\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]])\n",
    "\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shape=(3, 64, 64),\n",
    "        depth=32,\n",
    "        act=nn.ELU,\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "        outscale=1.0,\n",
    "        cnn_sigmoid=False,\n",
    "    ):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._shape = shape\n",
    "        self._cnn_sigmoid = cnn_sigmoid\n",
    "        layer_num = int(np.log2(shape[1]) - np.log2(minres))\n",
    "        self._minres = minres\n",
    "        out_ch = minres**2 * depth * 2 ** (layer_num - 1)\n",
    "        self._embed_size = out_ch\n",
    "\n",
    "        self._linear_layer = nn.Linear(feat_size, out_ch)\n",
    "        self._linear_layer.apply(uniform_weight_init(outscale))\n",
    "        in_dim = out_ch // (minres**2)\n",
    "        out_dim = in_dim // 2\n",
    "\n",
    "        layers = []\n",
    "        h, w = minres, minres\n",
    "        for i in range(layer_num):\n",
    "            bias = False\n",
    "            if i == layer_num - 1:\n",
    "                out_dim = self._shape[0]\n",
    "                act = False\n",
    "                bias = True\n",
    "                norm = False\n",
    "\n",
    "            if i != 0:\n",
    "                in_dim = 2 ** (layer_num - (i - 1) - 2) * depth\n",
    "            pad_h, outpad_h = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            pad_w, outpad_w = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            layers.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    kernel_size,\n",
    "                    2,\n",
    "                    padding=(pad_h, pad_w),\n",
    "                    output_padding=(outpad_h, outpad_w),\n",
    "                    bias=bias,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            if act:\n",
    "                layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim //= 2\n",
    "            h, w = h * 2, w * 2\n",
    "        [m.apply(weight_init) for m in layers[:-1]]\n",
    "        layers[-1].apply(uniform_weight_init(outscale))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def calc_same_pad(self, k, s, d):\n",
    "        val = d * (k - 1) - s + 1\n",
    "        pad = math.ceil(val / 2)\n",
    "        outpad = pad * 2 - val\n",
    "        return pad, outpad\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = self._linear_layer(features)\n",
    "        # (batch, time, -1) -> (batch * time, h, w, ch)\n",
    "        x = x.reshape(\n",
    "            [-1, self._minres, self._minres, self._embed_size // self._minres**2]\n",
    "        )\n",
    "        # (batch, time, -1) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.layers(x)\n",
    "        # (batch, time, -1) -> (batch, time, ch, h, w)\n",
    "        mean = x.reshape(features.shape[:-1] + self._shape)\n",
    "        # (batch, time, ch, h, w) -> (batch, time, h, w, ch)\n",
    "        mean = mean.permute(0, 1, 3, 4, 2)\n",
    "        if self._cnn_sigmoid:\n",
    "            mean = F.sigmoid(mean)\n",
    "        else:\n",
    "            mean += 0.5\n",
    "        return mean\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim,\n",
    "        shape,\n",
    "        layers,\n",
    "        units,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        dist=\"normal\",\n",
    "        std=1.0,\n",
    "        min_std=0.1,\n",
    "        max_std=1.0,\n",
    "        absmax=None,\n",
    "        temp=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        outscale=1.0,\n",
    "        symlog_inputs=False,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        name=\"NoName\",\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self._shape = (shape,) if isinstance(shape, int) else shape\n",
    "        if self._shape is not None and len(self._shape) == 0:\n",
    "            self._shape = (1,)\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._dist = dist\n",
    "        self._std = std if isinstance(std, str) else torch.tensor((std,), device=device)\n",
    "        self._min_std = min_std\n",
    "        self._max_std = max_std\n",
    "        self._absmax = absmax\n",
    "        self._temp = temp\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._symlog_inputs = symlog_inputs\n",
    "        self._device = device\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for i in range(layers):\n",
    "            self.layers.add_module(\n",
    "                f\"{name}_linear{i}\", nn.Linear(inp_dim, units, bias=False)\n",
    "            )\n",
    "            if norm:\n",
    "                self.layers.add_module(\n",
    "                    f\"{name}_norm{i}\", nn.LayerNorm(units, eps=1e-03)\n",
    "                )\n",
    "            self.layers.add_module(f\"{name}_act{i}\", act())\n",
    "            if i == 0:\n",
    "                inp_dim = units\n",
    "        self.layers.apply(weight_init)\n",
    "\n",
    "        if isinstance(self._shape, dict):\n",
    "            self.mean_layer = nn.ModuleDict()\n",
    "            for name, shape in self._shape.items():\n",
    "                self.mean_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.ModuleDict()\n",
    "                for name, shape in self._shape.items():\n",
    "                    self.std_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "        elif self._shape is not None:\n",
    "            self.mean_layer = nn.Linear(inp_dim, np.prod(self._shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.Linear(units, np.prod(self._shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = features\n",
    "        # print(\"MLP input shape: \", x.shape)\n",
    "        if self._symlog_inputs:\n",
    "            x = symlog(x)\n",
    "            # print(\"MLP input shape after symlog: \", x.shape)\n",
    "        out = self.layers(x)\n",
    "        # print(\"MLP output shape: \", out.shape)\n",
    "        # Used for encoder output\n",
    "        if self._shape is None:\n",
    "            return out\n",
    "        if isinstance(self._shape, dict):\n",
    "            dists = {}\n",
    "            for name, shape in self._shape.items():\n",
    "                mean = self.mean_layer[name](out)\n",
    "                if self._std == \"learned\":\n",
    "                    std = self.std_layer[name](out)\n",
    "                else:\n",
    "                    std = self._std\n",
    "                dists.update({name: self.dist(self._dist, mean, std, shape)})\n",
    "            return dists\n",
    "        else:\n",
    "            mean = self.mean_layer(out)\n",
    "            if self._std == \"learned\":\n",
    "                std = self.std_layer(out)\n",
    "            else:\n",
    "                std = self._std\n",
    "            return self.dist(self._dist, mean, std, self._shape)\n",
    "\n",
    "    def dist(self, dist, mean, std, shape):\n",
    "        if dist == \"tanh_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = F.softplus(std) + self._min_std\n",
    "            dist = torchd.normal.Normal(mean, std)\n",
    "            dist = torchd.transformed_distribution.TransformedDistribution(\n",
    "                dist, TanhBijector()\n",
    "            )\n",
    "            dist = torchd.independent.Independent(dist, 1)\n",
    "            dist = SampleDist(dist)\n",
    "        elif dist == \"normal\":\n",
    "            std = (self._max_std - self._min_std) * torch.sigmoid(\n",
    "                std + 2.0\n",
    "            ) + self._min_std\n",
    "            dist = torchd.normal.Normal(torch.tanh(mean), std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"normal_std_fixed\":\n",
    "            dist = torchd.normal.Normal(mean, self._std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"trunc_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = 2 * torch.sigmoid(std / 2) + self._min_std\n",
    "            dist = SafeTruncatedNormal(mean, std, -1, 1)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"onehot\":\n",
    "            dist = OneHotDist(mean, unimix_ratio=self._unimix_ratio)\n",
    "        elif dist == \"onehot_gumble\":\n",
    "            dist = ContDist(\n",
    "                torchd.gumbel.Gumbel(mean, 1 / self._temp), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"huber\":\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(\n",
    "                    UnnormalizedHuber(mean, std, 1.0),\n",
    "                    len(shape),\n",
    "                    absmax=self._absmax,\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"binary\":\n",
    "            dist = Bernoulli(\n",
    "                torchd.independent.Independent(\n",
    "                    torchd.bernoulli.Bernoulli(logits=mean), len(shape)\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"symlog_disc\":\n",
    "            dist = DiscDist(logits=mean, device=self._device)\n",
    "        elif dist == \"symlog_mse\":\n",
    "            dist = SymlogDist(mean)\n",
    "        else:\n",
    "            raise NotImplementedError(dist)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, inp_size, size, norm=True, act=torch.tanh, update_bias=-1):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self._inp_size = inp_size\n",
    "        self._size = size\n",
    "        self._act = act\n",
    "        self._update_bias = update_bias\n",
    "        self.layers = nn.Sequential()\n",
    "        self.layers.add_module(\n",
    "            \"GRU_linear\", nn.Linear(inp_size + size, 3 * size, bias=False)\n",
    "        )\n",
    "        if norm:\n",
    "            self.layers.add_module(\"GRU_norm\", nn.LayerNorm(3 * size, eps=1e-03))\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._size\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        state = state[0]  # Keras wraps the state in a list.\n",
    "        parts = self.layers(torch.cat([inputs, state], -1))\n",
    "        reset, cand, update = torch.split(parts, [self._size] * 3, -1)\n",
    "        reset = torch.sigmoid(reset)\n",
    "        cand = self._act(reset * cand)\n",
    "        update = torch.sigmoid(update + self._update_bias)\n",
    "        output = update * cand + (1 - update) * state\n",
    "        return output, [output]\n",
    "\n",
    "\n",
    "class Conv2dSamePad(torch.nn.Conv2d):\n",
    "    def calc_same_pad(self, i, k, s, d):\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        pad_h = self.calc_same_pad(\n",
    "            i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0]\n",
    "        )\n",
    "        pad_w = self.calc_same_pad(\n",
    "            i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1]\n",
    "        )\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "\n",
    "        ret = F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "        return ret\n",
    "\n",
    "\n",
    "class ImgChLayerNorm(nn.Module):\n",
    "    def __init__(self, ch, eps=1e-03):\n",
    "        super(ImgChLayerNorm, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(ch, eps=eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class RewardEMA:\n",
    "    \"\"\"running mean and std\"\"\"\n",
    "\n",
    "    def __init__(self, device, alpha=1e-2):\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.range = torch.tensor([0.05, 0.95], device=device)\n",
    "\n",
    "    def __call__(self, x, ema_vals):\n",
    "        flat_x = torch.flatten(x.detach())\n",
    "        x_quantile = torch.quantile(input=flat_x, q=self.range)\n",
    "        # this should be in-place operation\n",
    "        ema_vals[:] = self.alpha * x_quantile + (1 - self.alpha) * ema_vals\n",
    "        scale = torch.clip(ema_vals[1] - ema_vals[0], min=1.0)\n",
    "        offset = ema_vals[0]\n",
    "        return offset.detach(), scale.detach()\n",
    "\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, step, config):\n",
    "        super(WorldModel, self).__init__()\n",
    "        self._step = step\n",
    "        self._use_amp = True if config.precision == 16 else False\n",
    "        self._config = config\n",
    "        shapes = {k: tuple(v.shape) for k, v in obs_space.spaces.items()}\n",
    "        self.encoder = MultiEncoder(shapes, config.encoder)\n",
    "        self.embed_size = self.encoder.outdim\n",
    "        self.dynamics = RSSM(\n",
    "            config.dyn_stoch,\n",
    "            config.dyn_deter,\n",
    "            config.dyn_hidden,\n",
    "            config.dyn_rec_depth,\n",
    "            config.dyn_discrete,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            config.dyn_mean_act,\n",
    "            config.dyn_std_act,\n",
    "            config.dyn_min_std,\n",
    "            config.unimix_ratio,\n",
    "            config.initial,\n",
    "            config.num_actions,\n",
    "            self.embed_size,\n",
    "            config.device,\n",
    "        )\n",
    "        self.heads = nn.ModuleDict()\n",
    "        if config.dyn_discrete:\n",
    "            feat_size = config.dyn_stoch * config.dyn_discrete + config.dyn_deter\n",
    "        else:\n",
    "            feat_size = config.dyn_stoch + config.dyn_deter\n",
    "        self.heads[\"decoder\"] = MultiDecoder(feat_size, shapes, config.decoder)\n",
    "        self.heads[\"reward\"] = MLP(\n",
    "            feat_size,\n",
    "            (255,) if config.reward_head.dist == \"symlog_disc\" else (),\n",
    "            config.reward_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=config.reward_head.dist,\n",
    "            outscale=config.reward_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Reward\",\n",
    "        )\n",
    "        self.heads[\"cont\"] = MLP(\n",
    "            feat_size,\n",
    "            (),\n",
    "            config.cont_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=\"binary\",\n",
    "            outscale=config.cont_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Cont\",\n",
    "        )\n",
    "        for name in config.grad_heads:\n",
    "            assert name in self.heads, name\n",
    "        self._model_opt = Optimizer(\n",
    "            \"model\",\n",
    "            self.parameters(),\n",
    "            config.model_lr,\n",
    "            config.opt_eps,\n",
    "            config.grad_clip,\n",
    "            config.weight_decay,\n",
    "            opt=config.opt,\n",
    "            use_amp=self._use_amp,\n",
    "        )\n",
    "        print(\n",
    "            f\"Optimizer model_opt has {sum(param.numel() for param in self.parameters())} variables.\"\n",
    "        )\n",
    "        # other losses are scaled by 1.0.\n",
    "        self._scales = dict(\n",
    "            reward=config.reward_head.loss_scale,\n",
    "            cont=config.cont_head.loss_scale,\n",
    "        )\n",
    "\n",
    "    def _train(self, data):\n",
    "        # action (batch_size, batch_length, act_dim)\n",
    "        # image (batch_size, batch_length, h, w, ch)\n",
    "        # reward (batch_size, batch_length)\n",
    "        # discount (batch_size, batch_length)\n",
    "        data = self.preprocess(data)\n",
    "\n",
    "        with RequiresGrad(self):\n",
    "            with torch.cuda.amp.autocast(self._use_amp):\n",
    "                embed = self.encoder(data)\n",
    "                post, prior = self.dynamics.observe(\n",
    "                    embed, data[\"action\"], data[\"is_first\"]\n",
    "                )\n",
    "                kl_free = self._config.kl_free\n",
    "                dyn_scale = self._config.dyn_scale\n",
    "                rep_scale = self._config.rep_scale\n",
    "                kl_loss, kl_value, dyn_loss, rep_loss = self.dynamics.kl_loss(\n",
    "                    post, prior, kl_free, dyn_scale, rep_scale\n",
    "                )\n",
    "                assert kl_loss.shape == embed.shape[:2], kl_loss.shape\n",
    "                preds = {}\n",
    "                for name, head in self.heads.items():\n",
    "                    grad_head = name in self._config.grad_heads\n",
    "                    feat = self.dynamics.get_feat(post)\n",
    "                    feat = feat if grad_head else feat.detach()\n",
    "                    pred = head(feat)\n",
    "                    if type(pred) is dict:\n",
    "                        preds.update(pred)\n",
    "                    else:\n",
    "                        preds[name] = pred\n",
    "                losses = {}\n",
    "                for name, pred in preds.items():\n",
    "                    loss = -pred.log_prob(data[name])\n",
    "                    assert loss.shape == embed.shape[:2], (name, loss.shape)\n",
    "                    losses[name] = loss\n",
    "                scaled = {\n",
    "                    key: value * self._scales.get(key, 1.0)\n",
    "                    for key, value in losses.items()\n",
    "                }\n",
    "                model_loss = sum(scaled.values()) + kl_loss\n",
    "            metrics = self._model_opt(torch.mean(model_loss), self.parameters())\n",
    "\n",
    "        metrics.update({f\"{name}_loss\": to_np(loss) for name, loss in losses.items()})\n",
    "        metrics[\"kl_free\"] = kl_free\n",
    "        metrics[\"dyn_scale\"] = dyn_scale\n",
    "        metrics[\"rep_scale\"] = rep_scale\n",
    "        metrics[\"dyn_loss\"] = to_np(dyn_loss)\n",
    "        metrics[\"rep_loss\"] = to_np(rep_loss)\n",
    "        metrics[\"kl\"] = to_np(torch.mean(kl_value))\n",
    "        with torch.cuda.amp.autocast(self._use_amp):\n",
    "            metrics[\"prior_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(prior).entropy())\n",
    "            )\n",
    "            metrics[\"post_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(post).entropy())\n",
    "            )\n",
    "            context = dict(\n",
    "                embed=embed,\n",
    "                feat=self.dynamics.get_feat(post),\n",
    "                kl=kl_value,\n",
    "                postent=self.dynamics.get_dist(post).entropy(),\n",
    "            )\n",
    "        post = {k: v.detach() for k, v in post.items()}\n",
    "        return post, context, metrics\n",
    "\n",
    "    # this function is called during both rollout and training\n",
    "    def preprocess(self, obs):\n",
    "        # print(\"WorldModel preprocess\")\n",
    "        obs = {\n",
    "            k: torch.tensor(v, device=self._config.device, dtype=torch.float32)\n",
    "            for k, v in obs.items()\n",
    "        }\n",
    "        if \"image\" in obs:\n",
    "            obs[\"image\"] = obs[\"image\"] / 255.0\n",
    "        # print(\"obs image shape: \", obs[\"image\"].shape)\n",
    "        # if \"discount\" in obs:\n",
    "        #     obs[\"discount\"] *= self._config.discount\n",
    "        #     # (batch_size, batch_length) -> (batch_size, batch_length, 1)\n",
    "        #     obs[\"discount\"] = obs[\"discount\"].unsqueeze(-1)\n",
    "        # 'is_first' is necesarry to initialize hidden state at training\n",
    "        assert \"is_first\" in obs\n",
    "        # 'is_terminal' is necesarry to train cont_head\n",
    "        assert \"is_terminal\" in obs\n",
    "        obs[\"cont\"] = (1.0 - obs[\"is_terminal\"]).unsqueeze(-1)\n",
    "        return obs\n",
    "\n",
    "    def video_pred(self, data):\n",
    "        print(\"WorldModel video_pred\")\n",
    "        data = self.preprocess(data)\n",
    "        embed = self.encoder(data)\n",
    "\n",
    "        if \"image\" not in data:\n",
    "            return None\n",
    "\n",
    "        states, _ = self.dynamics.observe(\n",
    "            embed[:6, :5], data[\"action\"][:6, :5], data[\"is_first\"][:6, :5]\n",
    "        )\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()[\n",
    "            :6\n",
    "        ]\n",
    "        reward_post = self.heads[\"reward\"](self.dynamics.get_feat(states)).mode()[:6]\n",
    "        init = {k: v[:, -1] for k, v in states.items()}\n",
    "        prior = self.dynamics.imagine_with_action(data[\"action\"][:6, 5:], init)\n",
    "        openl = self.heads[\"decoder\"](self.dynamics.get_feat(prior))[\"image\"].mode()\n",
    "        reward_prior = self.heads[\"reward\"](self.dynamics.get_feat(prior)).mode()\n",
    "        # observed image is given until 5 steps\n",
    "        model = torch.cat([recon[:, :5], openl], 1)\n",
    "        truth = data[\"image\"][:6]\n",
    "        model = model\n",
    "        error = (model - truth + 1.0) / 2.0\n",
    "\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        obs = data[\"image\"]\n",
    "        states, _ = self.dynamics.observe(embed, data[\"action\"], data[\"is_first\"])\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()\n",
    "        decoded_obs = recon\n",
    "        # rewards = reward_post\n",
    "        # predicted_rewards = reward_prior\n",
    "        batch_idx = np.random.randint(0, obs.shape[0])\n",
    "        seq_idx = np.random.randint(0, obs.shape[1] - 3)\n",
    "        grayscale = obs.shape[-1] == 1\n",
    "\n",
    "        # print(rewards.shape, predicted_rewards.shape)\n",
    "        obs = obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        decoded_obs = decoded_obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # rewards = rewards[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # predicted_rewards = predicted_rewards[batch_idx][seq_idx : seq_idx + 3]\n",
    "\n",
    "        obs = obs.cpu().detach().numpy()\n",
    "        fig, axs = plt.subplots(3, 2)\n",
    "        axs[0][0].imshow(obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][0].set_title(f\"Iteration: {self._step} -- Reward: {rewards[0]:.4f}\")\n",
    "        axs[0][0].axis(\"off\")\n",
    "        axs[0][1].imshow(decoded_obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][1].set_title(f\"Pred. Reward: {predicted_rewards[0, 0]:.4f}\")\n",
    "        axs[0][1].axis(\"off\")\n",
    "\n",
    "        axs[1][0].imshow(obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        axs[1][0].axis(\"off\")\n",
    "        # axs[1][0].set_title(f\"Reward: {rewards[1, 0]:.4f} \")\n",
    "        axs[1][1].imshow(decoded_obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[1][1].set_title(f\"Pred. Reward: {predicted_rewards[1]:.4f}\")\n",
    "        axs[1][1].axis(\"off\")\n",
    "\n",
    "        axs[2][0].imshow(obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        axs[2][0].axis(\"off\")\n",
    "        # axs[2][0].set_title(f\"Reward: {rewards[2, 0]:.4f}\")\n",
    "        axs[2][1].imshow(decoded_obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[2][1].set_title(f\"Pred. Reward: {predicted_rewards[2]:.4f}\")\n",
    "        axs[2][1].axis(\"off\")\n",
    "\n",
    "        if not os.path.exists(\"reconstructions\"):\n",
    "            os.makedirs(\"reconstructions\")\n",
    "        fig.savefig(f\"reconstructions/iteration_{step}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        return torch.cat([truth, model, error], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class Dreamer(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, config, logger, dataset):\n",
    "        super(Dreamer, self).__init__()\n",
    "        self._config = config\n",
    "        self._logger = logger\n",
    "        self._should_log = Every(config.log_every)\n",
    "        batch_steps = config.batch_size * config.batch_length\n",
    "        self._should_train = Every(batch_steps / config.train_ratio)\n",
    "        self._should_pretrain = Once()\n",
    "        self._should_reset = Every(config.reset_every)\n",
    "        # self._should_expl = Until(int(config.expl_until / config.action_repeat))\n",
    "        self._metrics = {}\n",
    "        # this is update step\n",
    "        self._step = logger.step // config.action_repeat\n",
    "        self._update_count = 0\n",
    "        self._dataset = dataset\n",
    "        self._wm = WorldModel(obs_space, act_space, self._step, config)\n",
    "        if (\n",
    "            config.compile and os.name != \"nt\"\n",
    "        ):  # compilation is not supported on windows\n",
    "            self._wm = torch.compile(self._wm)\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](f).mean()\n",
    "        self._expl_behavior = Random(config, act_space)\n",
    "\n",
    "    def __call__(self, obs, reset, state=None, training=True):\n",
    "        step = self._step\n",
    "        if training:\n",
    "            steps = (\n",
    "                self._config.pretrain\n",
    "                if self._should_pretrain()\n",
    "                else self._should_train(step)\n",
    "            )\n",
    "            for _ in range(steps):\n",
    "                print(\"iter: \", _)\n",
    "                self._train(next(self._dataset))\n",
    "                self._update_count += 1\n",
    "                self._metrics[\"update_count\"] = self._update_count\n",
    "            if self._should_log(step):\n",
    "                for name, values in self._metrics.items():\n",
    "                    self._logger.scalar(name, float(np.mean(values)))\n",
    "                    self._metrics[name] = []\n",
    "                if self._config.video_pred_log:\n",
    "                    openl = self._wm.video_pred(next(self._dataset))\n",
    "                    self._logger.video(\"train_openl\", to_np(openl))\n",
    "                self._logger.write(fps=True)\n",
    "        # policy_output, state = self._policy(obs, state, training)\n",
    "        if state is None:\n",
    "            latent = action = None\n",
    "        else:\n",
    "            latent, action = state\n",
    "        obs = self._wm.preprocess(obs)\n",
    "        embed = self._wm.encoder(obs)\n",
    "        latent, _ = self._wm.dynamics.obs_step(latent, action, embed, obs[\"is_first\"])\n",
    "        # if self._config.eval_state_mean:\n",
    "        #     latent[\"stoch\"] = latent[\"mean\"]\n",
    "        feat = self._wm.dynamics.get_feat(latent)\n",
    "        actor = self._expl_behavior.actor(feat)\n",
    "        action = actor.sample()\n",
    "        # print(\"obs action mask\", obs[\"action_mask\"])\n",
    "        print(action)\n",
    "\n",
    "        logprob = actor.log_prob(action)\n",
    "        latent = {k: v.detach() for k, v in latent.items()}\n",
    "        action = action.detach()\n",
    "        # if self._config.actor[\"dist\"] == \"onehot_gumble\":\n",
    "        # action = torch.one_hot(\n",
    "        action = torch.nn.functional.one_hot(\n",
    "            torch.argmax(action, dim=-1), self._config.num_actions\n",
    "        )\n",
    "        policy_output = {\"action\": action, \"logprob\": logprob}\n",
    "        print(policy_output[\"action\"].shape)\n",
    "        state = (latent, action)\n",
    "\n",
    "        if training:\n",
    "            self._step += len(reset)\n",
    "            self._logger.step = self._config.action_repeat * self._step\n",
    "        return policy_output, state\n",
    "\n",
    "    def _train(self, data):\n",
    "        print(\"dreamer train step:\")\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        metrics = {}\n",
    "        post, context, mets = self._wm._train(data)\n",
    "        metrics.update(mets)\n",
    "        start = post\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](\n",
    "            self._wm.dynamics.get_feat(s)\n",
    "        ).mode()\n",
    "        # metrics.update(self._task_behavior._train(start, reward)[-1])\n",
    "        for name, value in metrics.items():\n",
    "            if not name in self._metrics.keys():\n",
    "                self._metrics[name] = [value]\n",
    "            else:\n",
    "                self._metrics[name].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logdir logdir\n",
      "Create envs.\n",
      "agent selection 0\n",
      "agent selection 0\n",
      "Action Space Discrete(4)\n",
      "Prefill dataset (0 steps).\n",
      "Logger: (23292 steps).\n"
     ]
    }
   ],
   "source": [
    "set_seed_everywhere(config.seed)\n",
    "if config.deterministic_run:\n",
    "    enable_deterministic_run()\n",
    "logdir = pathlib.Path(config.logdir).expanduser()\n",
    "config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "config.steps //= config.action_repeat\n",
    "config.eval_every //= config.action_repeat\n",
    "config.log_every //= config.action_repeat\n",
    "config.time_limit //= config.action_repeat\n",
    "\n",
    "print(\"Logdir\", logdir)\n",
    "config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "step = count_steps(config.traindir)\n",
    "# step in logger is environmental step\n",
    "logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "if config.offline_evaldir:\n",
    "    directory = config.offline_evaldir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.evaldir\n",
    "eval_eps = load_episodes(directory, limit=1)\n",
    "make = lambda mode, id: make_env(config, mode, id)\n",
    "train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "if config.parallel:\n",
    "    train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "    eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "else:\n",
    "    train_envs = [Damy(env) for env in train_envs]\n",
    "    eval_envs = [Damy(env) for env in eval_envs]\n",
    "acts = train_envs[0].action_space\n",
    "print(\"Action Space\", acts)\n",
    "config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "state = None\n",
    "if not config.offline_traindir:\n",
    "    prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "    print(f\"Prefill dataset ({prefill} steps).\")\n",
    "    if hasattr(acts, \"discrete\"):\n",
    "        random_actor = OneHotDist(\n",
    "            torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "        )\n",
    "    else:\n",
    "        random_actor = torchd.independent.Independent(\n",
    "            torchd.uniform.Uniform(\n",
    "                torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def random_agent(o, d, s):\n",
    "        action = random_actor.sample()\n",
    "        logprob = random_actor.log_prob(action)\n",
    "        return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "    state = simulate(\n",
    "        random_agent,\n",
    "        train_envs,\n",
    "        train_eps,\n",
    "        config.traindir,\n",
    "        logger,\n",
    "        limit=config.dataset_size,\n",
    "        steps=prefill,\n",
    "    )\n",
    "    logger.step += prefill * config.action_repeat\n",
    "    print(f\"Logger: ({logger.step} steps).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate agent.\n",
      "dict_items([('observation', (16,))])\n",
      ".*\n",
      "$^\n",
      "cnn\n",
      "False\n",
      "None\n",
      "$^\n",
      "observation\n",
      "mlp\n",
      "True\n",
      "<re.Match object; span=(0, 11), match='observation'>\n",
      ".*\n",
      "observation\n",
      "Encoder CNN shapes: {}\n",
      "Encoder MLP shapes: {'observation': (16,)}\n",
      "v:  (16,)\n",
      "input_size:  16\n",
      "Decoder CNN shapes: {}\n",
      "Decoder MLP shapes: {'observation': (16,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_63808/3206908984.py:747: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer model_opt has 3703824 variables.\n",
      "Start evaluation.\n",
      "Start training.\n",
      "Agent step:  11646\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_63808/4161829076.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._use_amp):\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_63808/4161829076.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23292] model_loss 1.6 / model_grad_norm 4.4 / observation_loss 0.1 / reward_loss 0.1 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 2.4 / rep_loss 2.4 / kl 2.3 / prior_ent 13.6 / post_ent 11.4 / update_count 1.0 / fps 0.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[23298] dataset_size 11649.0 / train_return -100.0 / train_length 3.0 / train_episodes 4571.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[23302] dataset_size 11651.0 / train_return -100.0 / train_length 2.0 / train_episodes 4572.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "[23302] model_loss 1.6 / model_grad_norm 3.5 / observation_loss 0.1 / reward_loss 0.1 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 2.3 / rep_loss 2.3 / kl 2.2 / prior_ent 13.8 / post_ent 11.4 / update_count 11.0 / fps 1.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[23308] dataset_size 11654.0 / train_return -300.0 / train_length 3.0 / train_episodes 4573.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "[23312] model_loss 1.6 / model_grad_norm 3.6 / observation_loss 0.1 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 2.2 / rep_loss 2.2 / kl 2.1 / prior_ent 13.8 / post_ent 11.4 / update_count 21.0 / fps 1.5\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[23316] dataset_size 11658.0 / train_return -1200.0 / train_length 4.0 / train_episodes 4574.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[23320] dataset_size 11660.0 / train_return -100.0 / train_length 2.0 / train_episodes 4575.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[23322] dataset_size 11661.0 / train_return -50.0 / train_length 1.0 / train_episodes 4576.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "[23322] model_loss 1.6 / model_grad_norm 3.2 / observation_loss 0.1 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 2.2 / rep_loss 2.2 / kl 2.1 / prior_ent 13.7 / post_ent 11.3 / update_count 31.0 / fps 1.6\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(\"Number of training envs: \", len(train_envs))\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(train_envs[0].observation_space)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent step: \u001b[39m\u001b[38;5;124m\"\u001b[39m, agent\u001b[38;5;241m.\u001b[39m_step)\n\u001b[0;32m---> 41\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraindir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m items_to_save \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: agent\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptims_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: recursively_collect_optim_state_dict(agent),\n\u001b[1;32m     54\u001b[0m }\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(items_to_save, logdir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 168\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(agent, envs, cache, directory, logger, is_eval, limit, steps, episodes, state)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# step agents\u001b[39;00m\n\u001b[1;32m    167\u001b[0m obs \u001b[38;5;241m=\u001b[39m {k: np\u001b[38;5;241m.\u001b[39mstack([o[k] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obs]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k}\n\u001b[0;32m--> 168\u001b[0m action, agent_state \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    170\u001b[0m     action \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    171\u001b[0m         {k: np\u001b[38;5;241m.\u001b[39marray(action[k][i]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m action}\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(envs))\n\u001b[1;32m    173\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[13], line 56\u001b[0m, in \u001b[0;36mDreamer.__call__\u001b[0;34m(self, obs, reset, state, training)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter: \u001b[39m\u001b[38;5;124m\"\u001b[39m, _)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count\n",
      "Cell \u001b[0;32mIn[13], line 104\u001b[0m, in \u001b[0;36mDreamer._train\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# print(\"data shape: \", data[\"image\"].shape)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 104\u001b[0m post, context, mets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(mets)\n\u001b[1;32m    106\u001b[0m start \u001b[38;5;241m=\u001b[39m post\n",
      "Cell \u001b[0;32mIn[12], line 113\u001b[0m, in \u001b[0;36mWorldModel._train\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_amp):\n\u001b[1;32m    112\u001b[0m     embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(data)\n\u001b[0;32m--> 113\u001b[0m     post, prior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_first\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     kl_free \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mkl_free\n\u001b[1;32m    117\u001b[0m     dyn_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdyn_scale\n",
      "Cell \u001b[0;32mIn[11], line 130\u001b[0m, in \u001b[0;36mRSSM.observe\u001b[0;34m(self, embed, action, is_first, state)\u001b[0m\n\u001b[1;32m    128\u001b[0m embed, action, is_first \u001b[38;5;241m=\u001b[39m swap(embed), swap(action), swap(is_first)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m post, prior \u001b[38;5;241m=\u001b[39m \u001b[43mstatic_scan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m post \u001b[38;5;241m=\u001b[39m {k: swap(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m post\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[5], line 801\u001b[0m, in \u001b[0;36mstatic_scan\u001b[0;34m(fn, inputs, start)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[1;32m    800\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (_input[x] \u001b[38;5;28;01mfor\u001b[39;00m _input \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m--> 801\u001b[0m     last \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(last) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m({}):\n",
      "Cell \u001b[0;32mIn[11], line 131\u001b[0m, in \u001b[0;36mRSSM.observe.<locals>.<lambda>\u001b[0;34m(prev_state, prev_act, embed, is_first)\u001b[0m\n\u001b[1;32m    128\u001b[0m embed, action, is_first \u001b[38;5;241m=\u001b[39m swap(embed), swap(action), swap(is_first)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\u001b[39;00m\n\u001b[1;32m    130\u001b[0m post, prior \u001b[38;5;241m=\u001b[39m static_scan(\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m prev_state, prev_act, embed, is_first: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    134\u001b[0m     (action, embed, is_first),\n\u001b[1;32m    135\u001b[0m     (state, state),\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m post \u001b[38;5;241m=\u001b[39m {k: swap(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m post\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[11], line 185\u001b[0m, in \u001b[0;36mRSSM.obs_step\u001b[0;34m(self, prev_state, prev_action, embed, is_first, sample)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(is_first\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    184\u001b[0m prev_action \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m is_first\n\u001b[0;32m--> 185\u001b[0m init_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m prev_state\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    187\u001b[0m     is_first_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    188\u001b[0m         is_first,\n\u001b[1;32m    189\u001b[0m         is_first\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(val\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(is_first\u001b[38;5;241m.\u001b[39mshape)),\n\u001b[1;32m    190\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[11], line 120\u001b[0m, in \u001b[0;36mRSSM.initial\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearned\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_stoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[11], line 245\u001b[0m, in \u001b[0;36mRSSM.get_stoch\u001b[0;34m(self, deter)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, deter):\n\u001b[0;32m--> 245\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_img_out_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_suff_stats_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mims\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[1;32m    247\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dist(stats)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/functional.py:2910\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2902\u001b[0m         layer_norm,\n\u001b[1;32m   2903\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2908\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2909\u001b[0m     )\n\u001b[0;32m-> 2910\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "    #     logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "    #         eval_policy = funcpartial(agent, training=False)\n",
    "    #         simulate(\n",
    "    #             eval_policy,\n",
    "    #             eval_envs,\n",
    "    #             eval_eps,\n",
    "    #             config.evaldir,\n",
    "    #             logger,\n",
    "    #             is_eval=True,\n",
    "    #             episodes=config.eval_episode_num,\n",
    "    #         )\n",
    "            # if config.video_pred_log:\n",
    "                # video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                # video_pred = agent._wm.video_pred(next(train_dataset))\n",
    "                # logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        # print(\"Number of training envs: \", len(train_envs))\n",
    "        # print(train_envs[0].observation_space)\n",
    "        print(\"Agent step: \", agent._step)\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_save = {\n",
    "    \"agent_state_dict\": agent.state_dict(),\n",
    "    \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "}\n",
    "torch.save(items_to_save, logdir / \"latest_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent selection 0\n",
      "{'observation': array([  1.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,  50., 100.]), 'is_terminal': False, 'is_first': True}\n",
      "torch.Size([1, 512])\n",
      "recon: tensor([[ 5.9442e-01,  2.7569e-01,  1.1175e-01,  2.5689e-02,  6.1511e-01,\n",
      "          4.9627e-02,  6.7899e-02, -6.9165e-04,  2.4391e-02, -2.4351e-02,\n",
      "          5.0759e-02,  9.7485e-03,  2.4003e-02,  4.8139e-03,  6.0048e+01,\n",
      "          9.8851e+01]])\n",
      "cont: tensor([[1.]])\n",
      "rew: tensor([[-6.1989e-05]])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m feat \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_wm\u001b[38;5;241m.\u001b[39mdynamics\u001b[38;5;241m.\u001b[39mget_feat(latent)\n\u001b[1;32m     47\u001b[0m recon \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_wm\u001b[38;5;241m.\u001b[39mheads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m](feat)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmode()\n\u001b[0;32m---> 48\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcont\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m rew \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_wm\u001b[38;5;241m.\u001b[39mheads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m](feat)\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mstep(action))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/independent.py:107\u001b[0m, in \u001b[0;36mIndependent.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: _size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/distribution.py:175\u001b[0m, in \u001b[0;36mDistribution.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: _size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Generates a sample_shape shaped reparameterized sample or sample_shape\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    shaped batch of reparameterized samples if the distribution parameters\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    are batched.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = Poker(\n",
    "    \"universal_poker\",\n",
    ")\n",
    "\n",
    "obs = env.reset()\n",
    "print(obs)\n",
    "data = {}\n",
    "for key in obs.keys():\n",
    "    data[key] = []\n",
    "    data[key].append(obs[key])\n",
    "    data[key] = np.stack(data[key], 0)\n",
    "obs = data\n",
    "obs = agent._wm.preprocess(obs)\n",
    "embed = agent._wm.encoder(obs)\n",
    "# print(embed)\n",
    "print(embed.shape)\n",
    "# post, prior\n",
    "# post = new_stoch and new_deter\n",
    "latent, _ = agent._wm.dynamics.obs_step(\n",
    "    None,\n",
    "    None,\n",
    "    embed,\n",
    "    obs[\"is_first\"],\n",
    ")\n",
    "# print(latent.shape)\n",
    "\n",
    "feat = agent._wm.dynamics.get_feat(latent)\n",
    "action = torch.tensor(3)  # action from feature, which is the input to the actor\n",
    "# state = (latent, action)\n",
    "\n",
    "recon = agent._wm.heads[\"decoder\"](feat)[\"observation\"].mode()\n",
    "cont = agent._wm.heads[\"cont\"](feat).mode()\n",
    "rew = agent._wm.heads[\"reward\"](feat).mode()\n",
    "print(\"recon:\", recon)\n",
    "print(\"cont:\", cont)\n",
    "print(\"rew:\", rew)\n",
    "\n",
    "latent, _ = agent._wm.dynamics.obs_step(\n",
    "    latent,\n",
    "    action,\n",
    "    embed,\n",
    "    obs[\"is_first\"],\n",
    ")\n",
    "# print(latent)\n",
    "\n",
    "feat = agent._wm.dynamics.get_feat(latent)\n",
    "recon = agent._wm.heads[\"decoder\"](feat)[\"observation\"].mode()\n",
    "cont = agent._wm.heads[\"cont\"](feat).sample()\n",
    "rew = agent._wm.heads[\"reward\"](feat).mode()\n",
    "print(env.step(action))\n",
    "print(\"recon:\", recon)\n",
    "print(\"cont:\", cont)\n",
    "print(\"rew:\", rew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
