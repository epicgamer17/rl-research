{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c86fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/hxdspxw938n3_89qddxh_2fm0000gp/T/ipykernel_41921/4154311525.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was too old on your system - pyarrow 10.0.1 is the current minimum supported version as of this release.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pyspiel\n",
    "import open_spiel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "game = pyspiel.load_game(\"universal_poker\", {\"numPlayers\":2, \"numSuits\": 4, \"numRanks\":13, \"numHoleCards\": 2, \"numBoardCards\": \"0 3\", \"bettingAbstraction\": \"fcpa\", \"numRounds\":2})\n",
    "import copy\n",
    "class WrapperEnv:\n",
    "    def __init__(self,game):\n",
    "        self.game= game\n",
    "        self.state = game.new_initial_state()\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        self.traverser = None\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        self.state = self.game.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection =  str(self.state.current_player())\n",
    "        return self.obs()\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.state.is_chance_node():\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "\n",
    "        else:\n",
    "            self.state.apply_action(action)\n",
    "            if self.state.is_chance_node():\n",
    "                while self.state.is_chance_node():\n",
    "                    self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        \n",
    "        if self.state.is_terminal():\n",
    "            return self.obs()\n",
    "        else:\n",
    "            # store = copy.deepcopy(self.state)\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "            # print(\"3\")\n",
    "            # print(self.state.is_terminal())\n",
    "            # if self.state.is_terminal():\n",
    "            #     print(\"store:\", store)\n",
    "            # print(self.state)\n",
    "            # print(self.state.legal_actions_mask(int(self.agent_selection)))\n",
    "            # print(\"3\")\n",
    "            self.agent_selection =  str(self.state.current_player())\n",
    "\n",
    "            return self.obs()\n",
    "    \n",
    "    def last(self):\n",
    "        return self.obs()\n",
    "    \n",
    "    def obs(self):\n",
    "        return {\"observation\":self.state.observation_tensor(int(self.agent_selection)), \"action_mask\":np.stack(self.state.legal_actions_mask(int(self.agent_selection)))}, self.state.player_reward(self.traverser) if self.traverser is not None else self.state.player_return(int(self.agent_selection)), self.state.is_terminal(), False, \"OPENSPIEL\"\n",
    "\n",
    "env = WrapperEnv(game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ile-Maurice/Library/Python/3.10/lib/python/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFRConfig\n",
      "Iteration 0 done\n",
      "Nodes touched 24532\n"
     ]
    }
   ],
   "source": [
    "from pettingzoo.classic import texas_holdem_v4\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "import torch\n",
    "from cfr_network import CFRNetwork\n",
    "\n",
    "hidden_dim = 128\n",
    "input_dim = 108\n",
    "output_dim = 4\n",
    "num_players = 2\n",
    "replay_buffer_size = 4000000\n",
    "minibatch_size = 10000\n",
    "steps_per_epoch = 3000\n",
    "traversals = 3000\n",
    "training_steps = 200\n",
    "lr = 0.0001\n",
    "optimizer = None\n",
    "p_v_networks = {'input_shape':input_dim, 'output_shape':output_dim, 'hidden_size':hidden_dim, 'learning_rate':lr, 'optimizer':optimizer}\n",
    "active_player_obj = ActivePlayer(num_players)\n",
    "config = CFRConfig(\n",
    "    config_dict={'network': {'policy': p_v_networks, 'value': p_v_networks, 'num_players':num_players},\n",
    "                 'replay_buffer_size':replay_buffer_size,\n",
    "                 'minibatch_size':minibatch_size,\n",
    "                 'steps_per_epoch':steps_per_epoch,\n",
    "                 'traversals': traversals,\n",
    "                 'training_steps': training_steps,\n",
    "                 'active_player_obj': active_player_obj,\n",
    "                 },\n",
    "    game_config={'num_players':num_players,\n",
    "                 'observation_space':108,\n",
    "                 'action_space':4,},\n",
    ")\n",
    "sampling = [\"Full\"]\n",
    "for i in sampling:\n",
    "    model = CFRAgent(env=env,config=config, name=\"CFR_FHP\" + i, max_nodes=10000000)\n",
    "    model.train(sampling=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
