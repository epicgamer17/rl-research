{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ec1cbd",
   "metadata": {},
   "source": [
    "This file is to run manually a head to head evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b47e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "import torch\n",
    "from cfr_network import CFRNetwork\n",
    "from cfr_utils import evaluatebots, WrapperEnv, load_agents\n",
    "import pyspiel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fhp = pyspiel.load_game(\"universal_poker\", {\"numPlayers\":2, \"numSuits\": 4, \"numRanks\":13, \"numHoleCards\": 2, \"numBoardCards\": \"0 3\", \"bettingAbstraction\": \"fcpa\", \"numRounds\":2, \"blind\": \"50 100\"})\n",
    "leduc = pyspiel.load_game(\"universal_poker\", {\"numPlayers\":2, \"numSuits\": 2, \"numRanks\":3, \"numHoleCards\": 1, \"numBoardCards\": \"0 1\", \"bettingAbstraction\": \"fcpa\", \"numRounds\":2, \"blind\": \"50 100\"})\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = WrapperEnv(leduc)\n",
    "fhpgame = WrapperEnv(fhp)\n",
    "\n",
    "chosen_game = 'fhp'\n",
    "\n",
    "hidden_dim = 128\n",
    "input_dim = 16 if chosen_game == 'leduc' else 108\n",
    "output_dim = 4\n",
    "num_players = 2\n",
    "replay_buffer_size = 4000000\n",
    "minibatch_size = 10000\n",
    "steps_per_epoch = 3000\n",
    "traversals = 3000\n",
    "training_steps = 20000\n",
    "lr = 0.0001\n",
    "optimizer = None\n",
    "\n",
    "p_v_networks = {'input_shape':input_dim, 'output_shape':output_dim, 'hidden_size':hidden_dim, 'learning_rate':lr, 'optimizer':optimizer}\n",
    "active_player_obj = ActivePlayer(num_players)\n",
    "# path1 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/1005275/CFR_0.001LR_TEST_MC_FHP_56.pt'\n",
    "# path2 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/2006646/CFR_0.001LR_TEST_MC_FHP_112.pt'\n",
    "# path3 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/3006144/CFR_0.001LR_TEST_MC_FHP_168.pt'\n",
    "# path4 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/4014284/CFR_0.001LR_TEST_MC_FHP_224.pt'\n",
    "# path5 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/5010481/CFR_0.001LR_TEST_MC_FHP_279.pt'\n",
    "# path6 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/6001547/CFR_0.001LR_TEST_MC_FHP_332.pt'\n",
    "# path7 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/7001642/CFR_0.001LR_TEST_MC_FHP_387.pt'\n",
    "# path8 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/8016903/CFR_0.001LR_TEST_MC_FHP_439.pt'\n",
    "# path9 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/9020095/CFR_0.001LR_TEST_MC_FHP_493.pt'\n",
    "# path10 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/linear/10015290/CFR_0.001LR_TEST_MC_FHP_546.pt'\n",
    "\n",
    "\n",
    "path1 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/1005275/CFR_0.001LR_TEST_MC_FHP_56.pt'\n",
    "path2 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/2006646/CFR_0.001LR_TEST_MC_FHP_112.pt'\n",
    "path3 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/3006144/CFR_0.001LR_TEST_MC_FHP_168.pt'\n",
    "path4 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/4014284/CFR_0.001LR_TEST_MC_FHP_224.pt'\n",
    "path5 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/5010481/CFR_0.001LR_TEST_MC_FHP_279.pt'\n",
    "path6 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/6001547/CFR_0.001LR_TEST_MC_FHP_332.pt'\n",
    "path7 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/7001642/CFR_0.001LR_TEST_MC_FHP_387.pt'\n",
    "path8 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/8016903/CFR_0.001LR_TEST_MC_FHP_439.pt'\n",
    "path9 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/9020095/CFR_0.001LR_TEST_MC_FHP_493.pt'\n",
    "path10 = 'checkpoints/CFR_0.001LR_TEST_MC_FHP/policy/notlinear/10015290/CFR_0.001LR_TEST_MC_FHP_546.pt'\n",
    "\n",
    "config = CFRConfig(\n",
    "    config_dict={'network': {'policy': p_v_networks, 'value': p_v_networks, 'num_players':num_players},\n",
    "                 'replay_buffer_size':replay_buffer_size,\n",
    "                 'minibatch_size':minibatch_size,\n",
    "                 'steps_per_epoch':steps_per_epoch,\n",
    "                 'traversals': traversals,\n",
    "                 'training_steps': training_steps,\n",
    "                 'active_player_obj': active_player_obj,\n",
    "                 },\n",
    "    game_config={'num_players':num_players,\n",
    "                 'observation_space':input_dim,\n",
    "                 'action_space':4,},\n",
    ")\n",
    "\n",
    "agent1, agent2 = load_agents(path1, path2, p_v_networks, num_players)\n",
    "agent3, agent4 = load_agents(path3, path4, p_v_networks, num_players)\n",
    "agent5, agent6 = load_agents(path5, path6, p_v_networks, num_players)\n",
    "agent7, agent8 = load_agents(path7, path8, p_v_networks, num_players)\n",
    "agent9, agent10 = load_agents(path9, path10, p_v_networks, num_players)\n",
    "agents = [agent1, agent2, agent3, agent4, agent5, agent6, agent7, agent8, agent9, agent10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[0 for p in range(len(agents))] for _ in range(len(agents))]\n",
    "for i in range(len(agents)):\n",
    "    for j in range(len(agents)):\n",
    "        if results[j][i] != 0:\n",
    "            continue\n",
    "        p1, p2 = evaluatebots(agents[i], agents[j], 100000, fhpgame, config, input_dim)\n",
    "        results[i][j] = np.mean(p1)/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate halft matrix such that all of the results are on the botton, inversion of axes\n",
    "results = np.array(results)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(results, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, linewidths=.5)\n",
    "plt.title('Agent Performance Heatmap in Exploitability')\n",
    "plt.xlabel('Agent 2')\n",
    "plt.ylabel('Agent 1')\n",
    "plt.xticks(ticks=np.arange(len(agents)) + 0.5, labels=[f'Agent {i+1}' for i in range(len(agents))], rotation=45)\n",
    "plt.yticks(ticks=np.arange(len(agents)) + 0.5, labels=[f'Agent {i+1}' for i in range(len(agents))], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Save the plt to a file\n",
    "plt.savefig('NOTLINEARCFR0.001FHPMC100000.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
