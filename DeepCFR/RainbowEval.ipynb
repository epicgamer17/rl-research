{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d31d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_configs import RainbowConfig\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from utils.utils import HuberLoss\n",
    "from cfr_utils import EvalWrapper, evaluatebots, WrapperEnv, load_agents, EmptyConf\n",
    "import pyspiel\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "from cfr_network import CFRNetwork\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "\n",
    "fhp = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 4,\n",
    "        \"numRanks\": 13,\n",
    "        \"numHoleCards\": 2,\n",
    "        \"numBoardCards\": \"0 3\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leduc = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = WrapperEnv(leduc)\n",
    "fhpgame = WrapperEnv(fhp)\n",
    "chosen_game = \"leduc\"\n",
    "\n",
    "hidden_dim = 128\n",
    "input_dim = 16 if chosen_game == \"leduc\" else 108\n",
    "output_dim = 4\n",
    "num_players = 2\n",
    "replay_buffer_size = 4000000\n",
    "minibatch_size = 10000\n",
    "steps_per_epoch = 3000\n",
    "traversals = 3000\n",
    "training_steps = 20000\n",
    "lr = 0.0001\n",
    "optimizer = None\n",
    "\n",
    "p_v_networks = {\n",
    "    \"input_shape\": input_dim,\n",
    "    \"output_shape\": output_dim,\n",
    "    \"hidden_size\": hidden_dim,\n",
    "    \"learning_rate\": lr,\n",
    "    \"optimizer\": optimizer,\n",
    "}\n",
    "active_player_obj = ActivePlayer(num_players)\n",
    "\n",
    "path = \"checkpoints/V2CFR_LEDUC_Full/policy/linear/4030245/V2CFR_LEDUC_Full_190.pt\"\n",
    "config = CFRConfig(\n",
    "    config_dict={\n",
    "        \"network\": {\n",
    "            \"policy\": p_v_networks,\n",
    "            \"value\": p_v_networks,\n",
    "            \"num_players\": num_players,\n",
    "        },\n",
    "        \"replay_buffer_size\": replay_buffer_size,\n",
    "        \"minibatch_size\": minibatch_size,\n",
    "        \"steps_per_epoch\": steps_per_epoch,\n",
    "        \"traversals\": traversals,\n",
    "        \"training_steps\": training_steps,\n",
    "        \"active_player_obj\": active_player_obj,\n",
    "    },\n",
    "    game_config={\n",
    "        \"num_players\": num_players,\n",
    "        \"observation_space\": input_dim,\n",
    "        \"action_space\": 4,\n",
    "    },\n",
    ")\n",
    "\n",
    "agent1, agent2 = load_agents(path, path, p_v_networks, num_players)\n",
    "modelselect = CFRAgent(env=leducgame, config=config)\n",
    "\n",
    "leducgame = EvalWrapper(\n",
    "    game=leducgame,\n",
    "    agent=agent1,\n",
    "    in_size=input_dim,\n",
    "    out_size=output_dim,\n",
    "    select_model=modelselect,\n",
    ")\n",
    "\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [128, 128],\n",
    "    \"value_hidden_layer_widths\": [128],\n",
    "    \"advatage_hidden_layer_widths\": [128],\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"training_steps\": 1000000,\n",
    "    \"minibatch_size\": 256,\n",
    "    \"save_intermediate_weights\": True,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"min_replay_buffer_size\": 256,\n",
    "    \"transfer_interval\": 1280,\n",
    "    \"loss_function\": HuberLoss(),  # could do categorical cross entropy\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"atom_size\": 1,\n",
    "    \"replay_interval\": 64,\n",
    "    \"dueling\": True,\n",
    "    \"eg_epsilon\": 1,\n",
    "    \"eg_epsilon_final\": 0.0,\n",
    "    \"eg_epsilon_final_step\": 5000,\n",
    "    \"eg_epsilon_decay_type\": \"linear\",\n",
    "    \"num_minibatches\": 4,\n",
    "}\n",
    "gameconfig = EmptyConf()\n",
    "config = RainbowConfig(config_dict, gameconfig)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "agent = RainbowAgent(leducgame, config, name=\"Rainbow-Leduc-Test\", device=device)\n",
    "agent.checkpoint_interval = 100\n",
    "\n",
    "for param in agent.model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
