{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fc8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ile-Maurice/Library/Python/3.10/lib/python/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 22000\n",
      "Using         adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.002\n",
      "Using         clipnorm                      : 0.0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using         loss_function                 : <utils.utils.KLDivergenceLoss object at 0x1197c1120>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 32\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 32\n",
      "Using         num_minibatches               : 4\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "RainbowConfig\n",
      "Using default residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [128, 128]\n",
      "Using         value_hidden_layer_widths     : [128]\n",
      "Using default advantage_hidden_layer_widths : []\n",
      "Using default noisy_sigma                   : 0.5\n",
      "Using         eg_epsilon                    : 1\n",
      "Using         eg_epsilon_final              : 0.0\n",
      "Using         eg_epsilon_decay_type         : linear\n",
      "Using         eg_epsilon_final_step         : 2000\n",
      "Using default dueling                       : True\n",
      "Using         discount_factor               : 0.99\n",
      "Using default soft_update                   : False\n",
      "Using         transfer_interval             : 1280\n",
      "Using default ema_beta                      : 0.99\n",
      "Using         replay_interval               : 64\n",
      "Using default per_alpha                     : 0.6\n",
      "Using default per_beta                      : 0.5\n",
      "Using default per_beta_final                : 1.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default n_step                        : 3\n",
      "Using default atom_size                     : 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:11:02.358930: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for checkpoints/leduc/nfsp/0/10000000/q_network_pid0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:92\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for checkpoints/leduc/nfsp/0/10000000/q_network_pid0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 157\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[1;32m    135\u001b[0m     agent \u001b[38;5;241m=\u001b[39m open_spiel\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39malgorithms\u001b[38;5;241m.\u001b[39mnfsp\u001b[38;5;241m.\u001b[39mNFSP(\n\u001b[1;32m    136\u001b[0m         session\u001b[38;5;241m=\u001b[39msess,\n\u001b[1;32m    137\u001b[0m         player_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m         epsilon_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m     \u001b[43mLoadNFSPAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     agent\u001b[38;5;241m.\u001b[39mrestore(agent_paths[number])  \u001b[38;5;66;03m# IF YOU HAVE A NFSP AGENT PATH\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# agent.restore(path1) # IF YOU HAVE A NFSP AGENT PATH\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/rl-research-main/rl-research/DeepCFR/cfr_utils.py:424\u001b[0m, in \u001b[0;36mLoadNFSPAgent\u001b[0;34m(path, agent, pid)\u001b[0m\n\u001b[1;32m    422\u001b[0m q_network_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_network_pid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(pid)\n\u001b[1;32m    423\u001b[0m avg_network_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_network_pid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(pid)\n\u001b[0;32m--> 424\u001b[0m Qvars \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_network_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m Avars \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mlist_variables(avg_network_path)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m Qvars:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/checkpoint_utils.py:141\u001b[0m, in \u001b[0;36mlist_variables\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.list_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_variables\u001b[39m(ckpt_dir_or_file):\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Lists the checkpoint keys and shapes of variables in a checkpoint.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m  Checkpoint keys are paths in a checkpoint graph.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    List of tuples `(key, shape)`.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m   reader \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m   variable_map \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_variable_to_shape_map()\n\u001b[1;32m    143\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(variable_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/checkpoint_utils.py:80\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file or checkpoints in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ckpt_dir_or_file)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpy_checkpoint_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNewCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:96\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 96\u001b[0m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for checkpoints/leduc/nfsp/0/10000000/q_network_pid0"
     ]
    }
   ],
   "source": [
    "from agent_configs import RainbowConfig\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from utils.utils import HuberLoss\n",
    "from cfr_utils import (\n",
    "    EvalWrapper,\n",
    "    evaluatebots,\n",
    "    WrapperEnv,\n",
    "    load_agents,\n",
    "    EmptyConf,\n",
    "    NFSPWrapper,\n",
    "    NFSPEvalWrapper,\n",
    "    LoadNFSPAgent,\n",
    ")\n",
    "import pyspiel\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "from cfr_network import CFRNetwork\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import open_spiel.python.algorithms.nfsp\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "num_players = 2\n",
    "max_nodes = 10000000\n",
    "\n",
    "fhp = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 4,\n",
    "        \"numRanks\": 13,\n",
    "        \"numHoleCards\": 2,\n",
    "        \"numBoardCards\": \"0 3\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leduc = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = NFSPWrapper(leduc)\n",
    "fhpgame = NFSPWrapper(fhp)\n",
    "\n",
    "active_player_obj = ActivePlayer(2)\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [128, 128],\n",
    "    \"value_hidden_layer_widths\": [128],\n",
    "    \"advatage_hidden_layer_widths\": [128],\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"training_steps\": 22000,\n",
    "    \"minibatch_size\": 32,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"min_replay_buffer_size\": 32,\n",
    "    \"transfer_interval\": 1280,\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"replay_interval\": 64,\n",
    "    \"eg_epsilon\": 1,\n",
    "    \"eg_epsilon_final\": 0.0,\n",
    "    \"eg_epsilon_final_step\": 2000,\n",
    "    \"eg_epsilon_decay_type\": \"linear\",\n",
    "    \"num_minibatches\": 4,\n",
    "}\n",
    "gameconfig = EmptyConf()\n",
    "config = RainbowConfig(config_dict, gameconfig)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "\n",
    "mainpath1 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath2 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath3 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath4 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath5 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath6 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath7 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath8 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath9 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath10 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath11 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath12 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath13 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath14 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath15 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath16 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath17 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath18 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath19 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "mainpath20 = \"checkpoints/leduc/nfsp/0/10000000/\"\n",
    "\n",
    "leduc_agent_paths = [mainpath1, mainpath2, mainpath3, mainpath4, mainpath5, mainpath6, mainpath7, mainpath8, mainpath9, mainpath10]\n",
    "fhp_agent_paths = [mainpath11, mainpath12, mainpath13, mainpath14, mainpath15, mainpath16, mainpath17, mainpath18, mainpath19, mainpath20]\n",
    "\n",
    "nodes = 0\n",
    "games = [leducgame, fhpgame]\n",
    "for i in games:\n",
    "    if i == leducgame:\n",
    "        agent_paths = leduc_agent_paths\n",
    "        game_string = \"leduc\"\n",
    "    else:\n",
    "        agent_paths = fhp_agent_paths\n",
    "        game_string = \"fhp\"\n",
    "    for number in range(len(agent_paths)):\n",
    "        i.reset()\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            agent = open_spiel.python.algorithms.nfsp.NFSP(\n",
    "                session=sess,\n",
    "                player_id=0,\n",
    "                state_representation_size=(\n",
    "                    leducconfig[\"state_representation_size\"]\n",
    "                    if i == leducgame\n",
    "                    else fhpconfig[\"state_representation_size\"]\n",
    "                ),\n",
    "                num_actions=4,\n",
    "                hidden_layers_sizes=[1024, 512, 1024, 512],\n",
    "                reservoir_buffer_capacity=30000000,\n",
    "                anticipatory_param=0,\n",
    "                batch_size=256,\n",
    "                rl_learning_rate=0.1,\n",
    "                sl_learning_rate=0.01,\n",
    "                min_buffer_size_to_learn=1000,\n",
    "                learn_every=256,\n",
    "                optimizer_str=\"sgd\",\n",
    "                replay_buffer_capacity=600000,\n",
    "                epsilon_start=0.08,\n",
    "                epsilon_end=0,\n",
    "            )\n",
    "            LoadNFSPAgent(agent_paths[number], agent, 0)\n",
    "            agent.restore(agent_paths[number])  # IF YOU HAVE A NFSP AGENT PATH\n",
    "            # agent.restore(path1) # IF YOU HAVE A NFSP AGENT PATH\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            wrapped = NFSPEvalWrapper(i, agent, 16, 4)\n",
    "            model_name = \"Rainbow_\" + game_string + \"_agent_\" + str(number)\n",
    "            evaluator = RainbowAgent(\n",
    "                wrapped, config, name=\"Rainbow\", device=device\n",
    "            )\n",
    "            evaluator.checkpoint_interval = 200\n",
    "\n",
    "            for param in evaluator.model.parameters():\n",
    "                print(param)\n",
    "            evaluator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
