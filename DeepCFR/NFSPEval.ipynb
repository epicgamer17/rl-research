{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 5000\n",
      "Using         adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.001\n",
      "Using         clipnorm                      : 0.0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using         loss_function                 : <utils.utils.KLDivergenceLoss object at 0x3460a9e50>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 32\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 32\n",
      "Using         num_minibatches               : 4\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "RainbowConfig\n",
      "Using default residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [128, 128]\n",
      "Using         value_hidden_layer_widths     : []\n",
      "Using default advantage_hidden_layer_widths : []\n",
      "Using default noisy_sigma                   : 0.5\n",
      "Using         eg_epsilon                    : 1\n",
      "Using         eg_epsilon_final              : 0.0\n",
      "Using         eg_epsilon_decay_type         : linear\n",
      "Using         eg_epsilon_final_step         : 2000\n",
      "Using default dueling                       : True\n",
      "Using         discount_factor               : 0.99\n",
      "Using default soft_update                   : False\n",
      "Using         transfer_interval             : 1280\n",
      "Using default ema_beta                      : 0.99\n",
      "Using         replay_interval               : 64\n",
      "Using default per_alpha                     : 0.6\n",
      "Using default per_beta                      : 0.5\n",
      "Using default per_beta_final                : 1.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default n_step                        : 3\n",
      "Using default atom_size                     : 51\n",
      "('mlp/bias', [1024])\n",
      "('mlp/bias_1', [512])\n",
      "('mlp/bias_2', [1024])\n",
      "('mlp/bias_3', [512])\n",
      "('mlp/bias_4', [4])\n",
      "('mlp/weights', [16, 1024])\n",
      "('mlp/weights_1', [1024, 512])\n",
      "('mlp/weights_2', [512, 1024])\n",
      "('mlp/weights_3', [1024, 512])\n",
      "('mlp/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/avg_network_pid0\n",
      "2025-04-24 17:09:58.259396: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_2/weights_4_6/Assign' id:5668 op device:{requested: '', assigned: ''} def:{{{node mlp_2/weights_4_6/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_2/weights_4_6, zeros_119)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0281,  0.2262, -0.1738,  ..., -0.1387, -0.2191, -0.1944],\n",
      "        [-0.0747, -0.1766,  0.0440,  ..., -0.0927,  0.0012, -0.0478],\n",
      "        [-0.0387, -0.1359,  0.0175,  ..., -0.2493,  0.1532, -0.0179],\n",
      "        ...,\n",
      "        [ 0.0290, -0.2456,  0.0511,  ...,  0.0417,  0.0730, -0.0120],\n",
      "        [ 0.1875,  0.1475, -0.0028,  ...,  0.0640, -0.2442, -0.0761],\n",
      "        [-0.2430,  0.1992,  0.0115,  ...,  0.0108,  0.0751,  0.2422]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0381,  0.1271, -0.0958, -0.1034, -0.1499, -0.2244, -0.2336, -0.0080,\n",
      "        -0.0408,  0.0487,  0.0550,  0.2296,  0.2170, -0.1356, -0.1744, -0.1652,\n",
      "         0.0312,  0.1406,  0.1719,  0.0415,  0.0120,  0.2130, -0.0659,  0.1528,\n",
      "         0.1642, -0.0853, -0.1578,  0.1348,  0.1554, -0.2108,  0.1646, -0.0421,\n",
      "        -0.0303, -0.2398,  0.1997,  0.1782, -0.1369, -0.1142, -0.1975, -0.1326,\n",
      "        -0.1250,  0.0750, -0.2340, -0.1664,  0.0953,  0.0409, -0.1484, -0.1718,\n",
      "         0.0040, -0.0997, -0.2102,  0.0335, -0.1117, -0.1643,  0.2051, -0.1406,\n",
      "        -0.0771, -0.0050, -0.1535, -0.1937, -0.1877,  0.0341, -0.1887, -0.2374,\n",
      "         0.1358,  0.2105, -0.1604, -0.0592, -0.0158,  0.0652,  0.0765,  0.2098,\n",
      "        -0.1829,  0.1675,  0.0276,  0.0333,  0.0166, -0.1077,  0.1542,  0.0915,\n",
      "        -0.1601, -0.0080,  0.0293, -0.2386, -0.0041, -0.0724, -0.1601, -0.1471,\n",
      "         0.1703,  0.1572,  0.0530,  0.1756,  0.0718, -0.0889, -0.0298, -0.0149,\n",
      "        -0.2164, -0.2135, -0.2477,  0.0653,  0.1072, -0.2300, -0.1221,  0.0097,\n",
      "        -0.0553,  0.2362, -0.1764,  0.1386, -0.1166, -0.1017, -0.0297,  0.2292,\n",
      "         0.0302, -0.1923,  0.2324, -0.0923,  0.0314,  0.1389,  0.1507, -0.2047,\n",
      "        -0.2043, -0.0094,  0.2285, -0.0447, -0.0210, -0.0735,  0.0248, -0.1908],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0439,  0.0161, -0.0512,  ..., -0.0163, -0.0477,  0.0577],\n",
      "        [ 0.0716,  0.0017, -0.0370,  ...,  0.0245, -0.0308,  0.0229],\n",
      "        [ 0.0683, -0.0662,  0.0693,  ..., -0.0564, -0.0837,  0.0840],\n",
      "        ...,\n",
      "        [ 0.0449,  0.0328, -0.0445,  ...,  0.0438,  0.0448, -0.0139],\n",
      "        [-0.0286,  0.0238, -0.0401,  ...,  0.0048,  0.0224, -0.0471],\n",
      "        [-0.0374, -0.0539,  0.0675,  ...,  0.0383, -0.0769, -0.0186]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0430, -0.0400,  0.0773, -0.0745, -0.0109, -0.0253,  0.0763, -0.0499,\n",
      "         0.0590,  0.0499,  0.0070,  0.0784,  0.0472, -0.0661,  0.0086, -0.0484,\n",
      "        -0.0825,  0.0691, -0.0457,  0.0276, -0.0340, -0.0848,  0.0012, -0.0862,\n",
      "         0.0708,  0.0190, -0.0232, -0.0261, -0.0212,  0.0784,  0.0285,  0.0485,\n",
      "        -0.0139,  0.0850, -0.0236, -0.0134, -0.0621, -0.0136,  0.0766, -0.0593,\n",
      "         0.0631, -0.0605, -0.0765, -0.0427, -0.0880, -0.0227, -0.0280,  0.0186,\n",
      "         0.0829, -0.0681,  0.0516,  0.0411, -0.0361,  0.0810,  0.0826, -0.0392,\n",
      "         0.0461,  0.0610,  0.0313, -0.0028,  0.0523,  0.0368, -0.0700, -0.0149,\n",
      "         0.0507,  0.0619,  0.0247,  0.0182, -0.0553,  0.0545,  0.0382, -0.0727,\n",
      "        -0.0249,  0.0196, -0.0281,  0.0024,  0.0430,  0.0650,  0.0480, -0.0767,\n",
      "        -0.0541,  0.0627,  0.0460,  0.0454, -0.0512,  0.0828, -0.0091, -0.0357,\n",
      "        -0.0838, -0.0260, -0.0101, -0.0181, -0.0739, -0.0036,  0.0198,  0.0105,\n",
      "         0.0697, -0.0276, -0.0423, -0.0123,  0.0481,  0.0599,  0.0573,  0.0131,\n",
      "         0.0145,  0.0603,  0.0160, -0.0573,  0.0243, -0.0815, -0.0563,  0.0633,\n",
      "        -0.0374,  0.0154,  0.0320,  0.0816,  0.0112,  0.0528,  0.0657, -0.0686,\n",
      "         0.0756,  0.0092, -0.0788,  0.0522, -0.0690,  0.0524, -0.0675, -0.0123],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0622, -0.0876, -0.0416,  ...,  0.0590, -0.0848,  0.0623],\n",
      "        [ 0.0791,  0.0439,  0.0047,  ..., -0.0683, -0.0047,  0.0640],\n",
      "        [ 0.0696,  0.0834,  0.0626,  ...,  0.0709,  0.0600,  0.0133],\n",
      "        ...,\n",
      "        [ 0.0585, -0.0465,  0.0690,  ..., -0.0692, -0.0280, -0.0563],\n",
      "        [-0.0154,  0.0142,  0.0592,  ...,  0.0628, -0.0589, -0.0701],\n",
      "        [ 0.0470,  0.0684,  0.0164,  ...,  0.0032,  0.0116, -0.0209]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0422, -0.0663,  0.0161, -0.0883, -0.0219, -0.0279,  0.0434, -0.0609,\n",
      "         0.0879, -0.0296,  0.0858,  0.0023, -0.0691, -0.0773, -0.0481,  0.0623,\n",
      "         0.0853, -0.0557,  0.0425, -0.0809, -0.0706, -0.0481,  0.0820, -0.0124,\n",
      "         0.0804,  0.0172,  0.0367,  0.0269,  0.0257,  0.0566, -0.0588, -0.0406,\n",
      "        -0.0836, -0.0165,  0.0574, -0.0532, -0.0591,  0.0670,  0.0675,  0.0199,\n",
      "        -0.0562, -0.0161,  0.0115, -0.0155, -0.0488,  0.0763, -0.0506,  0.0551,\n",
      "         0.0567,  0.0753, -0.0559], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0660,  0.0219, -0.0804,  ..., -0.0190,  0.0172,  0.0539],\n",
      "        [-0.0121, -0.0550, -0.0556,  ..., -0.0401, -0.0455,  0.0757],\n",
      "        [ 0.0327,  0.0570, -0.0428,  ..., -0.0274, -0.0443,  0.0255],\n",
      "        ...,\n",
      "        [ 0.0578,  0.0030, -0.0741,  ...,  0.0362, -0.0068, -0.0285],\n",
      "        [-0.0618, -0.0148, -0.0349,  ..., -0.0158, -0.0384,  0.0816],\n",
      "        [-0.0196,  0.0858,  0.0781,  ...,  0.0004, -0.0715,  0.0391]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.9918e-02, -3.8376e-02, -8.6352e-02, -5.9604e-02,  5.7956e-02,\n",
      "        -2.4785e-02, -7.4069e-04,  6.4190e-02,  1.5782e-02, -8.5729e-02,\n",
      "        -1.5436e-02,  3.3308e-02,  6.4896e-02,  8.7000e-02,  2.8104e-02,\n",
      "         7.3742e-02,  8.4845e-03, -7.7813e-02, -5.9372e-02,  8.0911e-02,\n",
      "         2.2046e-02,  1.4237e-02, -3.8810e-02, -3.8410e-02,  2.4159e-02,\n",
      "         2.4639e-02,  5.6732e-02, -7.1971e-02,  6.1912e-02,  1.9261e-02,\n",
      "         7.4230e-02, -3.5302e-02, -7.8793e-02,  8.0674e-02,  1.5553e-02,\n",
      "        -3.4231e-02,  1.1127e-02,  8.0325e-02, -5.5414e-02, -1.6654e-02,\n",
      "         4.0672e-02, -6.0886e-03,  1.6682e-02, -1.8910e-02,  7.6269e-02,\n",
      "         7.5065e-02, -7.1690e-02,  6.8577e-02,  5.2660e-02,  3.3210e-02,\n",
      "         5.3198e-02, -1.2641e-02,  3.9886e-02,  1.1884e-02, -2.5727e-02,\n",
      "        -3.3943e-02, -2.3858e-03,  5.8619e-02,  3.2867e-02,  6.6065e-02,\n",
      "        -7.7830e-03,  8.2680e-02,  1.4778e-02, -4.0663e-02, -2.4926e-02,\n",
      "        -2.7807e-03,  1.9103e-02,  6.2080e-03, -1.0975e-03, -8.1981e-02,\n",
      "        -4.9221e-03,  3.2398e-02,  1.6162e-02,  1.2193e-02, -7.9956e-02,\n",
      "        -2.5478e-02, -5.2576e-02,  2.8681e-02,  6.1579e-03, -5.8614e-02,\n",
      "         4.5963e-02,  5.4498e-02,  7.5340e-02, -3.9421e-02,  4.0390e-02,\n",
      "         2.9355e-02,  1.9786e-02,  2.8409e-02,  7.2591e-02, -1.2912e-02,\n",
      "        -2.8678e-02, -1.6709e-02, -2.0119e-02, -7.7241e-02, -3.0682e-02,\n",
      "        -7.4036e-02, -1.5205e-02,  5.7374e-02, -8.3904e-02,  4.9610e-03,\n",
      "         2.3211e-03, -1.3404e-02, -6.3533e-02,  7.2268e-02, -8.0778e-02,\n",
      "         3.8822e-02, -8.0522e-02, -2.2585e-02,  4.4568e-02,  4.6210e-02,\n",
      "         5.5902e-03, -8.6748e-02,  8.6767e-02, -1.0725e-02,  3.3854e-02,\n",
      "        -8.6686e-02,  3.3907e-03, -2.4068e-02, -8.6657e-02, -4.6787e-02,\n",
      "        -5.4457e-03, -1.2622e-02,  3.8791e-02, -2.0392e-02, -5.2369e-02,\n",
      "        -5.9841e-02, -5.7720e-02,  8.3732e-02, -5.1932e-02,  7.9854e-02,\n",
      "         5.6945e-02, -2.1904e-02,  1.9577e-02,  1.5498e-02,  8.0481e-02,\n",
      "        -7.0495e-02,  6.3189e-02, -3.9563e-02, -7.7736e-02, -2.5660e-02,\n",
      "        -2.3581e-02, -7.4744e-02, -6.9174e-02,  8.7053e-02, -8.3515e-02,\n",
      "        -4.6212e-02,  6.8596e-02, -8.6144e-02, -9.9726e-03,  1.5387e-02,\n",
      "        -8.1873e-02, -7.0718e-02,  3.8374e-04, -1.8460e-02,  6.8237e-02,\n",
      "         4.6785e-02,  8.2277e-02, -4.0291e-02,  8.3088e-02, -6.8800e-02,\n",
      "        -6.5495e-02, -4.3658e-02, -2.2716e-02,  3.6728e-02, -6.2721e-02,\n",
      "        -8.7580e-02, -6.7370e-02,  6.3723e-02,  6.1750e-02,  7.2243e-02,\n",
      "         3.7431e-02,  1.2777e-02, -6.8667e-02, -5.2601e-02, -7.1176e-03,\n",
      "         1.5436e-05,  8.8212e-02,  1.7284e-02,  4.6749e-02,  7.2128e-02,\n",
      "         3.4257e-02,  6.7663e-02,  8.0295e-02, -9.9921e-04, -5.2220e-02,\n",
      "         7.5655e-02, -7.2207e-02, -2.6320e-02, -7.7746e-02,  6.4967e-02,\n",
      "         3.9699e-02, -3.9897e-02, -9.3250e-06, -2.1146e-02, -6.1645e-02,\n",
      "        -4.5847e-02, -7.9842e-02,  2.5713e-02, -5.0237e-02, -5.2519e-02,\n",
      "        -1.3735e-02, -4.1837e-02, -4.8209e-02,  1.2031e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 5000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/5000\n",
      "Checkpointing at 0 with score 180.0\n",
      "Training step: 101/5000\n",
      "Training step: 201/5000\n",
      "Checkpointing at 200 with score -35.67517029517831\n",
      "Training step: 301/5000\n",
      "Training step: 401/5000\n",
      "Checkpointing at 400 with score -34.962506695232996\n",
      "Training step: 501/5000\n",
      "Training step: 601/5000\n",
      "Checkpointing at 600 with score -36.439380291839306\n",
      "Training step: 701/5000\n"
     ]
    }
   ],
   "source": [
    "from agent_configs import RainbowConfig\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from utils.utils import HuberLoss\n",
    "from cfr_utils import (\n",
    "    EvalWrapper,\n",
    "    evaluatebots,\n",
    "    WrapperEnv,\n",
    "    load_agents,\n",
    "    EmptyConf,\n",
    "    NFSPWrapper,\n",
    "    NFSPEvalWrapper,\n",
    "    LoadNFSPAgent,\n",
    ")\n",
    "import pyspiel\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "from cfr_network import CFRNetwork\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import open_spiel.python.algorithms.nfsp\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "num_players = 2\n",
    "max_nodes = 10000000\n",
    "\n",
    "fhp = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 4,\n",
    "        \"numRanks\": 13,\n",
    "        \"numHoleCards\": 2,\n",
    "        \"numBoardCards\": \"0 3\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leduc = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = NFSPWrapper(leduc)\n",
    "fhpgame = NFSPWrapper(fhp)\n",
    "\n",
    "active_player_obj = ActivePlayer(2)\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [128, 128],\n",
    "    \"value_hidden_layer_widths\": [],\n",
    "    \"advatage_hidden_layer_widths\": [],\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"training_steps\": 5000,\n",
    "    \"minibatch_size\": 32,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"min_replay_buffer_size\": 32,\n",
    "    \"transfer_interval\": 1280,\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"replay_interval\": 64,\n",
    "    \"eg_epsilon\": 1,\n",
    "    \"eg_epsilon_final\": 0.0,\n",
    "    \"eg_epsilon_final_step\": 2000,\n",
    "    \"eg_epsilon_decay_type\": \"linear\",\n",
    "    \"num_minibatches\": 4,\n",
    "}\n",
    "gameconfig = EmptyConf()\n",
    "config = RainbowConfig(config_dict, gameconfig)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "\n",
    "mainpath1 = \"./checkpoints/fhp/nfsp/0/1000002/\"\n",
    "mainpath2 = \"./checkpoints/fhp/nfsp/0/4000001/\"\n",
    "mainpath3 = \"./checkpoints/fhp/nfsp/0/7000001/\"\n",
    "mainpath4 = \"./checkpoints/fhp/nfsp/0/8000000/\"\n",
    "mainpath5 = \"./checkpoints/fhp/nfsp/0/10000000/\"\n",
    "mainpath6 = \"./checkpoints/leduc/nfsp/0/1000000/\"\n",
    "mainpath7 = \"./checkpoints/leduc/nfsp/0/4000001/\"\n",
    "mainpath8 = \"./checkpoints/leduc/nfsp/0/7000001/\"\n",
    "mainpath9 = \"./checkpoints/leduc/nfsp/0/8000000/\"\n",
    "mainpath10 = \"./checkpoints/leduc/nfsp/0/10000000/\"\n",
    "\n",
    "leduc_agent_paths = [\n",
    "    mainpath6,\n",
    "    mainpath7,\n",
    "    mainpath8,\n",
    "    mainpath9,\n",
    "    mainpath10,\n",
    "]\n",
    "fhp_agent_paths = [\n",
    "    mainpath1,\n",
    "    mainpath2,\n",
    "    mainpath3,\n",
    "    mainpath4,\n",
    "    mainpath5,\n",
    "]\n",
    "\n",
    "nodes = 0\n",
    "games = [leducgame, fhpgame]\n",
    "for i in games:\n",
    "    if i == leducgame:\n",
    "        agent_paths = leduc_agent_paths\n",
    "        game_string = \"leduc\"\n",
    "    else:\n",
    "        agent_paths = fhp_agent_paths\n",
    "        game_string = \"fhp\"\n",
    "    for number in range(len(agent_paths)):\n",
    "        i.reset()\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            agent = open_spiel.python.algorithms.nfsp.NFSP(\n",
    "                session=sess,\n",
    "                player_id=0,\n",
    "                state_representation_size=(\n",
    "                    leducconfig[\"state_representation_size\"]\n",
    "                    if i == leducgame\n",
    "                    else fhpconfig[\"state_representation_size\"]\n",
    "                ),\n",
    "                num_actions=4,\n",
    "                hidden_layers_sizes=[1024, 512, 1024, 512],\n",
    "                reservoir_buffer_capacity=30000000,\n",
    "                anticipatory_param=0,\n",
    "                batch_size=256,\n",
    "                rl_learning_rate=0.1,\n",
    "                sl_learning_rate=0.01,\n",
    "                min_buffer_size_to_learn=1000,\n",
    "                learn_every=256,\n",
    "                optimizer_str=\"sgd\",\n",
    "                replay_buffer_capacity=600000,\n",
    "                epsilon_start=0.08,\n",
    "                epsilon_end=0,\n",
    "            )\n",
    "            LoadNFSPAgent(agent_paths[number], agent, 0)\n",
    "            agent.restore(agent_paths[number])  # IF YOU HAVE A NFSP AGENT PATH\n",
    "            # agent.restore(path1) # IF YOU HAVE A NFSP AGENT PATH\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            wrapped = NFSPEvalWrapper(i, agent, 16, 4)\n",
    "            model_name = \"Rainbow_\" + game_string + \"_agent_\" + str(number)\n",
    "            evaluator = RainbowAgent(wrapped, config, name=model_name, device=device)\n",
    "            evaluator.checkpoint_interval = 200\n",
    "\n",
    "            for param in evaluator.model.parameters():\n",
    "                print(param)\n",
    "            evaluator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
