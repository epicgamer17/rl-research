{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 10000\n",
      "Using         adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.002\n",
      "Using         clipnorm                      : 0.0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using         loss_function                 : <utils.utils.HuberLoss object at 0x37ca44c50>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 32\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 32\n",
      "Using         num_minibatches               : 4\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "RainbowConfig\n",
      "Using default residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [128, 128]\n",
      "Using         value_hidden_layer_widths     : []\n",
      "Using         advantage_hidden_layer_widths : []\n",
      "Using         noisy_sigma                   : 0.0\n",
      "Using         eg_epsilon                    : 1\n",
      "Using         eg_epsilon_final              : 0.0\n",
      "Using         eg_epsilon_decay_type         : linear\n",
      "Using         eg_epsilon_final_step         : 2000\n",
      "Using         dueling                       : False\n",
      "Using         discount_factor               : 0.99\n",
      "Using default soft_update                   : False\n",
      "Using         transfer_interval             : 1280\n",
      "Using default ema_beta                      : 0.99\n",
      "Using         replay_interval               : 64\n",
      "Using         per_alpha                     : 0.0\n",
      "Using         per_beta                      : 0.0\n",
      "Using         per_beta_final                : 0.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using         n_step                        : 1\n",
      "Using         atom_size                     : 1\n",
      "('mlp/bias', [1024])\n",
      "('mlp/bias_1', [512])\n",
      "('mlp/bias_2', [1024])\n",
      "('mlp/bias_3', [512])\n",
      "('mlp/bias_4', [4])\n",
      "('mlp/weights', [108, 1024])\n",
      "('mlp/weights_1', [1024, 512])\n",
      "('mlp/weights_2', [512, 1024])\n",
      "('mlp/weights_3', [1024, 512])\n",
      "('mlp/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/1000002/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/1000002/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/1000002/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/1000002/avg_network_pid0\n",
      "2025-04-25 15:25:58.999927: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_2/weights_4_12/Assign' id:11368 op device:{requested: '', assigned: ''} def:{{{node mlp_2/weights_4_12/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_2/weights_4_12, zeros_239)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0210, -0.0107,  0.0669,  ...,  0.0763,  0.0327,  0.0693],\n",
      "        [ 0.0704, -0.0636,  0.0076,  ...,  0.0831,  0.0285,  0.0331],\n",
      "        [-0.0860,  0.0805, -0.0953,  ..., -0.0751, -0.0037, -0.0065],\n",
      "        ...,\n",
      "        [ 0.0430,  0.0038, -0.0745,  ...,  0.0873, -0.0270,  0.0783],\n",
      "        [ 0.0844, -0.0118,  0.0522,  ...,  0.0861, -0.0417, -0.0047],\n",
      "        [-0.0076, -0.0014,  0.0261,  ..., -0.0094,  0.0428, -0.0741]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0459, -0.0194, -0.0500,  0.0240, -0.0906,  0.0771, -0.0713,  0.0039,\n",
      "        -0.0744, -0.0070,  0.0511, -0.0768, -0.0493,  0.0387,  0.0398,  0.0811,\n",
      "         0.0700, -0.0361, -0.0367,  0.0608,  0.0863,  0.0697,  0.0632,  0.0266,\n",
      "         0.0837,  0.0108,  0.0782,  0.0203,  0.0471, -0.0671,  0.0954, -0.0226,\n",
      "        -0.0858, -0.0335,  0.0014, -0.0392,  0.0296, -0.0697, -0.0557, -0.0221,\n",
      "        -0.0602,  0.0584,  0.0012, -0.0616, -0.0734, -0.0822, -0.0303,  0.0951,\n",
      "         0.0904,  0.0942,  0.0248, -0.0575,  0.0158,  0.0506,  0.0033, -0.0463,\n",
      "         0.0676,  0.0935,  0.0718, -0.0064, -0.0257,  0.0088,  0.0168,  0.0848,\n",
      "        -0.0604,  0.0070,  0.0621,  0.0304, -0.0618, -0.0709,  0.0033,  0.0953,\n",
      "         0.0597,  0.0647,  0.0715,  0.0190, -0.0915,  0.0129,  0.0151,  0.0793,\n",
      "        -0.0200, -0.0578, -0.0793, -0.0861,  0.0537,  0.0288,  0.0245,  0.0534,\n",
      "        -0.0890, -0.0611,  0.0041, -0.0672,  0.0242, -0.0268, -0.0442, -0.0227,\n",
      "         0.0821, -0.0345, -0.0454,  0.0451,  0.0309, -0.0332, -0.0413, -0.0649,\n",
      "        -0.0387,  0.0493, -0.0436, -0.0135, -0.0415,  0.0664,  0.0529,  0.0307,\n",
      "         0.0830, -0.0881, -0.0279, -0.0101, -0.0825, -0.0376,  0.0868, -0.0575,\n",
      "        -0.0045, -0.0565, -0.0321,  0.0616,  0.0471,  0.0652, -0.0658, -0.0377],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0550, -0.0715,  0.0547,  ...,  0.0556, -0.0359,  0.0013],\n",
      "        [-0.0613,  0.0494,  0.0081,  ..., -0.0533, -0.0573, -0.0539],\n",
      "        [-0.0259, -0.0315, -0.0122,  ...,  0.0324, -0.0070, -0.0062],\n",
      "        ...,\n",
      "        [-0.0333,  0.0618,  0.0243,  ...,  0.0636, -0.0141, -0.0859],\n",
      "        [ 0.0353,  0.0782,  0.0361,  ..., -0.0872, -0.0857, -0.0858],\n",
      "        [-0.0620,  0.0250, -0.0077,  ..., -0.0241, -0.0677, -0.0656]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0580,  0.0782, -0.0493, -0.0343, -0.0727, -0.0757, -0.0717, -0.0443,\n",
      "         0.0606,  0.0563,  0.0360,  0.0226, -0.0660,  0.0053,  0.0132, -0.0411,\n",
      "        -0.0669, -0.0565, -0.0509,  0.0651, -0.0341, -0.0559,  0.0016,  0.0182,\n",
      "         0.0180,  0.0246,  0.0146, -0.0581, -0.0786,  0.0383,  0.0323,  0.0464,\n",
      "        -0.0132, -0.0033,  0.0331,  0.0313,  0.0697,  0.0523, -0.0643,  0.0424,\n",
      "        -0.0672,  0.0596,  0.0010, -0.0763,  0.0427,  0.0141, -0.0703,  0.0181,\n",
      "        -0.0245, -0.0434, -0.0640,  0.0342, -0.0647, -0.0618, -0.0148,  0.0556,\n",
      "        -0.0478, -0.0328,  0.0114, -0.0167,  0.0180, -0.0429,  0.0732,  0.0862,\n",
      "         0.0266,  0.0502,  0.0795, -0.0737, -0.0744,  0.0612,  0.0791, -0.0585,\n",
      "        -0.0094,  0.0108, -0.0345, -0.0585,  0.0116,  0.0114, -0.0507,  0.0657,\n",
      "         0.0654,  0.0840, -0.0229,  0.0099,  0.0653,  0.0738,  0.0492,  0.0344,\n",
      "         0.0749,  0.0842, -0.0708, -0.0357, -0.0862, -0.0203,  0.0210, -0.0778,\n",
      "         0.0013,  0.0072, -0.0034,  0.0119,  0.0382,  0.0810,  0.0370,  0.0327,\n",
      "        -0.0798,  0.0048, -0.0312, -0.0108,  0.0820, -0.0028, -0.0734,  0.0763,\n",
      "        -0.0502,  0.0136, -0.0072,  0.0559, -0.0548, -0.0821, -0.0836,  0.0614,\n",
      "        -0.0209,  0.0283, -0.0368,  0.0593, -0.0393,  0.0533, -0.0266,  0.0750],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-7.4055e-02, -7.6442e-02, -8.0789e-02, -3.6211e-03,  4.0677e-02,\n",
      "         -1.7292e-02,  7.3155e-02, -3.4586e-02,  3.1620e-02,  7.7470e-02,\n",
      "          4.3625e-02, -8.5491e-02, -8.1697e-03,  7.0615e-02, -1.6800e-02,\n",
      "          1.7592e-02, -7.0918e-02,  8.5183e-02, -8.0191e-03,  2.0657e-02,\n",
      "         -3.1575e-02, -7.9004e-02,  1.8527e-02, -1.3502e-02,  1.1885e-02,\n",
      "          2.7785e-02, -6.6023e-02, -2.2503e-02,  6.7853e-02,  1.4843e-02,\n",
      "         -1.1786e-02,  5.5861e-02,  3.4989e-03,  2.5837e-02,  6.1800e-02,\n",
      "          2.7546e-02,  2.6943e-02, -4.9695e-02,  8.1304e-02,  4.4209e-02,\n",
      "         -5.0627e-02, -2.6395e-02, -1.1968e-02,  9.0499e-03,  9.5383e-03,\n",
      "          3.0516e-02, -4.0785e-02, -6.9797e-03, -2.4344e-02, -5.3895e-02,\n",
      "         -4.6481e-02, -2.5345e-02,  1.0919e-02, -5.6763e-02,  1.8196e-02,\n",
      "         -6.6282e-02,  1.2376e-03,  2.7422e-02,  7.6817e-02,  3.5434e-02,\n",
      "         -5.9283e-02, -8.2322e-02,  7.3721e-02, -6.3853e-02, -6.0254e-02,\n",
      "          1.6993e-04, -3.2569e-05, -4.7922e-02, -7.7179e-02,  3.0227e-03,\n",
      "          6.9296e-02,  2.5011e-03, -9.1705e-03, -3.3880e-02,  2.2253e-02,\n",
      "         -2.9422e-02, -5.8681e-02,  5.9382e-03, -3.1634e-02, -6.5950e-02,\n",
      "          6.0378e-02, -5.0755e-02,  6.6225e-02,  5.6735e-02,  8.3860e-02,\n",
      "         -7.9854e-02,  3.1979e-02,  5.6193e-02,  3.8273e-02,  6.2681e-02,\n",
      "          3.1041e-02,  5.7395e-02,  7.0146e-02, -1.6348e-03,  6.1603e-02,\n",
      "         -1.5814e-03, -7.6121e-02,  4.4139e-02, -3.4555e-02, -4.4687e-02,\n",
      "          9.8787e-04, -1.6189e-02, -4.0304e-02, -1.4298e-02, -2.6031e-02,\n",
      "         -4.9514e-02,  7.5262e-02, -8.2620e-02, -4.8286e-02, -3.8476e-03,\n",
      "          4.7577e-02,  7.2793e-02, -8.5135e-02,  4.0284e-02,  6.1788e-02,\n",
      "         -4.4806e-02, -1.8854e-02,  6.3060e-02, -1.4122e-02, -3.2218e-02,\n",
      "         -1.8608e-02,  6.8423e-02,  4.1111e-02, -1.2114e-02,  2.4101e-02,\n",
      "          8.7944e-02, -2.6187e-02,  3.1953e-02],\n",
      "        [-3.7125e-02,  5.2346e-02,  2.5896e-02,  5.2585e-02, -3.0873e-02,\n",
      "         -7.8907e-02,  1.7523e-02,  7.3243e-02,  1.0249e-02, -3.5977e-02,\n",
      "         -4.7185e-02,  2.4483e-02,  5.8390e-02, -2.9773e-02,  7.1787e-02,\n",
      "          4.9299e-02,  8.7295e-02,  3.8642e-02,  3.7022e-02, -5.9300e-02,\n",
      "          1.6098e-02, -8.5411e-02,  6.4922e-02,  5.9206e-02, -2.5343e-02,\n",
      "         -3.0237e-02, -5.4989e-02, -7.5926e-02, -5.1388e-02, -7.8576e-02,\n",
      "          1.0033e-02,  1.2425e-02, -4.5078e-02, -7.0210e-02, -4.8028e-02,\n",
      "         -2.5832e-02, -1.0822e-02,  2.5119e-02, -1.4152e-02,  4.5656e-03,\n",
      "         -6.8277e-02, -4.0097e-02, -2.9634e-02,  7.5660e-02,  8.2200e-02,\n",
      "         -5.9074e-03,  1.4265e-02, -7.9111e-02,  5.1700e-04, -8.5813e-02,\n",
      "         -5.8809e-02, -8.5152e-02, -3.1879e-02, -3.9118e-02,  2.9055e-02,\n",
      "          2.9944e-02, -2.1021e-02, -7.5665e-02, -2.7624e-02, -5.7717e-02,\n",
      "          3.9745e-02,  6.4870e-02,  4.4114e-02, -4.3395e-02, -2.3547e-02,\n",
      "          3.0476e-02, -3.2314e-03, -7.1612e-02, -1.2273e-02, -6.2501e-02,\n",
      "         -6.7580e-02,  8.0885e-02,  5.2441e-02,  3.6972e-02, -5.0168e-02,\n",
      "         -7.8175e-02,  4.4024e-03, -9.4540e-03,  6.8041e-02,  5.1666e-02,\n",
      "         -5.0777e-02, -6.0186e-02, -8.5988e-02, -1.8554e-04,  4.3689e-02,\n",
      "          8.7881e-02, -2.9604e-02, -7.0714e-02, -6.4928e-02,  3.0930e-02,\n",
      "          2.4402e-02, -5.8659e-02, -1.5218e-02,  8.6423e-02,  1.2163e-03,\n",
      "          4.3610e-02,  4.3935e-02,  8.5692e-02, -5.0771e-03, -2.6889e-02,\n",
      "          6.3943e-02,  8.1001e-04, -7.8506e-02,  4.0655e-02,  7.3529e-02,\n",
      "          7.9828e-03,  3.6032e-02,  8.2888e-02, -8.1393e-02,  6.2587e-02,\n",
      "         -4.3015e-02, -7.8437e-02, -5.5232e-02, -1.5404e-02, -5.6030e-02,\n",
      "          6.1124e-02, -4.3831e-02, -1.1523e-02, -6.9430e-02,  1.0920e-02,\n",
      "          8.6833e-02, -6.6154e-03,  2.7296e-02, -2.7737e-03, -3.9353e-02,\n",
      "          8.1139e-02, -5.4763e-02,  7.1987e-02],\n",
      "        [ 4.9995e-02, -8.4368e-02, -7.0296e-02,  3.6650e-02, -6.2084e-02,\n",
      "         -1.4059e-02,  6.7050e-02, -1.5970e-02, -4.3625e-02, -9.6750e-04,\n",
      "         -6.1542e-02, -6.4889e-02, -5.8637e-02, -1.5246e-03, -6.0903e-02,\n",
      "         -3.1687e-02, -2.7606e-02,  4.9899e-02, -1.0325e-02,  1.6901e-02,\n",
      "          6.1799e-02,  2.6530e-02,  5.5576e-02, -1.4135e-02, -5.8567e-02,\n",
      "          5.1530e-02, -7.0503e-02,  4.1583e-02,  1.2350e-02, -5.5423e-02,\n",
      "          1.6743e-02,  7.8998e-02,  5.7322e-02, -8.8348e-02,  2.1411e-02,\n",
      "          1.2961e-02, -8.2367e-02, -3.0569e-02, -7.7996e-02,  2.6931e-02,\n",
      "         -8.0134e-02, -6.4386e-02, -4.7494e-02, -6.2032e-02, -5.4369e-02,\n",
      "         -7.7637e-02,  3.7607e-02, -6.1080e-02, -7.1558e-02,  8.3106e-02,\n",
      "          1.8710e-03,  6.6172e-02,  5.5262e-02, -5.3432e-04, -1.4477e-02,\n",
      "         -4.5552e-02, -4.2381e-02, -4.7060e-02, -7.9698e-02,  2.7234e-02,\n",
      "         -6.5471e-03, -2.9929e-02, -2.5527e-02, -8.8202e-02, -4.5299e-02,\n",
      "          3.7290e-02,  1.5469e-04,  5.0750e-02, -7.8750e-02,  7.9808e-02,\n",
      "         -4.1187e-02,  7.2619e-02, -3.1826e-02, -5.8143e-02,  8.2942e-04,\n",
      "         -4.7290e-02,  5.7438e-02, -6.0036e-02, -6.0171e-02,  3.7841e-02,\n",
      "          3.1398e-02, -4.2543e-02, -1.2607e-02, -3.4683e-02, -7.0843e-02,\n",
      "          2.1402e-02,  4.2903e-02,  2.8859e-02, -5.9791e-03, -4.8629e-02,\n",
      "          1.7376e-02, -3.3987e-02,  2.4108e-02,  2.7550e-02, -7.1515e-03,\n",
      "         -7.4854e-02,  2.2709e-02,  5.7128e-03,  5.4481e-02,  3.2522e-02,\n",
      "          4.6601e-02, -4.9154e-02,  2.9835e-02,  1.7730e-03, -8.6433e-02,\n",
      "          6.9574e-02, -9.2964e-03,  5.6977e-02, -3.4571e-02, -4.6125e-02,\n",
      "         -7.9242e-02,  5.5130e-02,  5.4405e-02,  3.4279e-02,  4.9340e-02,\n",
      "          2.9680e-02,  1.8730e-02,  2.5057e-02,  8.4841e-02,  7.1537e-02,\n",
      "          3.3958e-02, -4.8780e-02,  1.7272e-02, -2.3971e-03,  1.6696e-02,\n",
      "          8.5245e-03, -6.9544e-02, -5.9795e-02],\n",
      "        [ 5.3005e-02,  6.1378e-02,  7.4486e-03,  4.1323e-02, -2.8586e-02,\n",
      "         -2.3281e-03, -6.5648e-02, -8.0329e-02,  7.4823e-02,  4.2763e-02,\n",
      "          6.6898e-02, -7.9059e-02,  9.3305e-03, -7.6518e-02, -7.4227e-03,\n",
      "          2.1212e-02, -1.3986e-02, -7.9934e-02,  5.4623e-02, -5.2003e-03,\n",
      "          1.1550e-03, -4.2078e-02,  8.4288e-02,  5.6003e-02, -2.3866e-02,\n",
      "         -5.3113e-02, -2.9070e-02,  5.6564e-02, -5.6096e-02,  4.2095e-02,\n",
      "          3.8993e-02, -8.6400e-02, -1.9728e-02,  5.6450e-02, -8.1845e-02,\n",
      "         -6.8002e-02, -3.3756e-02, -1.2061e-02,  3.3293e-02, -2.2240e-02,\n",
      "         -6.2522e-02,  1.4693e-02,  4.6465e-02, -6.1018e-03, -4.8979e-02,\n",
      "          3.8913e-02,  2.6811e-02,  2.0627e-02,  4.8113e-02, -4.5031e-02,\n",
      "          6.1972e-02,  8.3355e-02,  8.0173e-03, -1.7839e-02, -2.1449e-02,\n",
      "         -5.1600e-03, -2.3271e-02,  1.6160e-02, -4.6739e-03, -1.1184e-02,\n",
      "          8.8259e-02, -7.7310e-02,  6.5382e-02,  8.4780e-02, -5.0037e-03,\n",
      "         -2.5545e-02, -3.9321e-02, -2.2699e-02, -6.0135e-02,  4.3397e-02,\n",
      "          4.5447e-02,  6.4383e-02,  5.7063e-02, -2.1922e-02,  5.1619e-02,\n",
      "          6.4328e-02,  1.0213e-02,  1.5016e-02,  4.8442e-02, -8.4040e-02,\n",
      "          4.3542e-02,  8.6251e-03, -3.9783e-04,  4.4373e-02, -7.9040e-02,\n",
      "          9.9624e-03, -6.2494e-02,  6.3398e-02, -2.8514e-02,  4.7780e-02,\n",
      "          6.0661e-02, -3.2565e-02, -7.1837e-03, -2.0165e-02, -2.3286e-02,\n",
      "          3.1170e-02,  2.9007e-02, -7.8822e-03,  3.8000e-02,  4.7325e-02,\n",
      "         -6.0645e-02, -2.3057e-02,  1.2203e-02, -6.4663e-02, -5.5302e-02,\n",
      "          6.3613e-02,  5.7424e-03, -2.7772e-02, -2.4439e-02, -2.8333e-02,\n",
      "         -1.7841e-02,  9.6615e-04, -4.8622e-02,  7.0278e-02,  2.2052e-02,\n",
      "          2.1032e-02,  2.1388e-02,  1.9393e-02,  5.6988e-02, -1.6416e-02,\n",
      "         -5.8677e-02,  1.9323e-02, -1.2563e-02, -6.1832e-02, -8.6536e-02,\n",
      "         -3.0281e-02,  7.1474e-02,  3.4790e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0042,  0.0432,  0.0786, -0.0608], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score -18.29268292682927 and loss 353.821044921875\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score 37.5 and loss 463.7511413574219\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score 146.5 and loss 496.00396728515625\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score 111.5 and loss 579.7681121826172\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score 77.0 and loss 578.0150451660156\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score 105.0 and loss 569.9408630371094\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score 55.0 and loss 602.1998931884766\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score -26.0 and loss 592.4788879394531\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score -112.0 and loss 652.2033020019531\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score -108.0 and loss 762.2818603515625\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score 116.0 and loss 830.2656005859375\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score -50.5 and loss 879.494970703125\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score -30.0 and loss 740.1746948242187\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score 9.5 and loss 739.0940979003906\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score 76.0 and loss 610.7703430175782\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score 152.0 and loss 602.464077758789\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score 146.5 and loss 626.4111389160156\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score -34.5 and loss 561.7126220703125\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score 93.5 and loss 445.85448455810547\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score 79.0 and loss 483.76250915527345\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score 81.0 and loss 379.45963592529296\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score 185.5 and loss 419.18080139160156\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score -180.5 and loss 398.72855377197266\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score 154.0 and loss 634.8034454345703\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score -37.0 and loss 564.3038635253906\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score 134.5 and loss 501.3555053710937\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score 81.0 and loss 512.3031402587891\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score -26.5 and loss 565.3193588256836\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score -1.0 and loss 631.1701721191406\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score 176.5 and loss 518.1630218505859\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 145.0 and loss 539.9433837890625\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score 50.5 and loss 554.0822265625\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score 70.5 and loss 590.6066589355469\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score 197.0 and loss 476.292138671875\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score 41.0 and loss 608.1481994628906\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score 202.5 and loss 523.3970642089844\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score 69.0 and loss 548.9277587890625\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score -43.5 and loss 484.59767150878906\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score -73.0 and loss 545.9328582763671\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score -43.0 and loss 601.9069152832031\n",
      "Training step: 7901/10000\n",
      "Training step: 8001/10000\n",
      "Checkpointing at 8000 with score 100.0 and loss 498.6487976074219\n",
      "Training step: 8101/10000\n",
      "Training step: 8201/10000\n",
      "Checkpointing at 8200 with score 100.0 and loss 597.4508758544922\n",
      "Training step: 8301/10000\n",
      "Training step: 8401/10000\n",
      "Checkpointing at 8400 with score 142.5 and loss 436.7259185791016\n",
      "Training step: 8501/10000\n",
      "Training step: 8601/10000\n",
      "Checkpointing at 8600 with score -85.5 and loss 480.6096160888672\n",
      "Training step: 8701/10000\n",
      "Training step: 8801/10000\n",
      "Checkpointing at 8800 with score 122.5 and loss 518.5035217285156\n",
      "Training step: 8901/10000\n",
      "Training step: 9001/10000\n",
      "Checkpointing at 9000 with score 148.5 and loss 436.40399169921875\n",
      "Training step: 9101/10000\n",
      "Training step: 9201/10000\n",
      "Checkpointing at 9200 with score 126.5 and loss 562.8408325195312\n",
      "Training step: 9301/10000\n",
      "Training step: 9401/10000\n",
      "Checkpointing at 9400 with score 77.0 and loss 537.3698211669922\n",
      "Training step: 9501/10000\n",
      "Training step: 9601/10000\n",
      "Checkpointing at 9600 with score -44.5 and loss 437.2313865661621\n",
      "Training step: 9701/10000\n",
      "Training step: 9801/10000\n",
      "Checkpointing at 9800 with score 135.5 and loss 564.743374633789\n",
      "Training step: 9901/10000\n",
      "('mlp/bias', [1024])\n",
      "('mlp/bias_1', [512])\n",
      "('mlp/bias_2', [1024])\n",
      "('mlp/bias_3', [512])\n",
      "('mlp/bias_4', [4])\n",
      "('mlp/weights', [108, 1024])\n",
      "('mlp/weights_1', [1024, 512])\n",
      "('mlp/weights_2', [512, 1024])\n",
      "('mlp/weights_3', [1024, 512])\n",
      "('mlp/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/4000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/4000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/4000001/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/fhp/nfsp/0/4000001/avg_network_pid0\n",
      "2025-04-25 15:35:02.068903: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_2/weights_4_13/Assign' id:12318 op device:{requested: '', assigned: ''} def:{{{node mlp_2/weights_4_13/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_2/weights_4_13, zeros_259)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0945, -0.0543, -0.0041,  ...,  0.0148,  0.0190,  0.0957],\n",
      "        [ 0.0186,  0.0478, -0.0467,  ..., -0.0549,  0.0369, -0.0765],\n",
      "        [ 0.0908,  0.0347, -0.0447,  ..., -0.0317, -0.0721,  0.0171],\n",
      "        ...,\n",
      "        [-0.0881,  0.0395, -0.0657,  ..., -0.0833,  0.0429, -0.0590],\n",
      "        [ 0.0161, -0.0201, -0.0690,  ..., -0.0248, -0.0124,  0.0098],\n",
      "        [-0.0730,  0.0190, -0.0150,  ..., -0.0519, -0.0776, -0.0876]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0874,  0.0922,  0.0084,  0.0405,  0.0739, -0.0826, -0.0634,  0.0572,\n",
      "         0.0172,  0.0479, -0.0913,  0.0333,  0.0767, -0.0315,  0.0070,  0.0538,\n",
      "         0.0003, -0.0337,  0.0637,  0.0577, -0.0430, -0.0927, -0.0287,  0.0707,\n",
      "         0.0333, -0.0910, -0.0787,  0.0558, -0.0243,  0.0158, -0.0546,  0.0739,\n",
      "         0.0107, -0.0466,  0.0220,  0.0641, -0.0838, -0.0751, -0.0336,  0.0755,\n",
      "         0.0787,  0.0224, -0.0193,  0.0385, -0.0107, -0.0325,  0.0398, -0.0579,\n",
      "         0.0480, -0.0100, -0.0942,  0.0527, -0.0294,  0.0739,  0.0246,  0.0011,\n",
      "         0.0301,  0.0927, -0.0647,  0.0759, -0.0823,  0.0309, -0.0355, -0.0674,\n",
      "        -0.0019, -0.0604, -0.0283, -0.0766, -0.0444,  0.0259, -0.0836, -0.0615,\n",
      "         0.0772, -0.0072, -0.0333, -0.0434,  0.0316, -0.0139, -0.0350,  0.0742,\n",
      "        -0.0347,  0.0797,  0.0525, -0.0823, -0.0543,  0.0147, -0.0489, -0.0314,\n",
      "        -0.0398,  0.0101, -0.0125, -0.0687,  0.0645, -0.0315, -0.0660,  0.0109,\n",
      "        -0.0396, -0.0025,  0.0100, -0.0462,  0.0676,  0.0508, -0.0521,  0.0123,\n",
      "         0.0677, -0.0861, -0.0095,  0.0134, -0.0875,  0.0799, -0.0751, -0.0873,\n",
      "         0.0668, -0.0081, -0.0622,  0.0958,  0.0096, -0.0081, -0.0111, -0.0484,\n",
      "         0.0693, -0.0633, -0.0330, -0.0920, -0.0055, -0.0890,  0.0867,  0.0012],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0067, -0.0667,  0.0327,  ...,  0.0652,  0.0405, -0.0557],\n",
      "        [-0.0268,  0.0124, -0.0124,  ..., -0.0686, -0.0384, -0.0213],\n",
      "        [-0.0246,  0.0341, -0.0243,  ...,  0.0879, -0.0669, -0.0301],\n",
      "        ...,\n",
      "        [-0.0878,  0.0386, -0.0440,  ...,  0.0011,  0.0843, -0.0341],\n",
      "        [-0.0606,  0.0036, -0.0206,  ...,  0.0154, -0.0413,  0.0670],\n",
      "        [-0.0372, -0.0396,  0.0637,  ..., -0.0287, -0.0653,  0.0528]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0673,  0.0240,  0.0587,  0.0056, -0.0359,  0.0189, -0.0269,  0.0053,\n",
      "         0.0832, -0.0303,  0.0374,  0.0609,  0.0685,  0.0382,  0.0700, -0.0829,\n",
      "        -0.0466,  0.0056,  0.0749,  0.0252,  0.0670,  0.0184, -0.0339,  0.0286,\n",
      "         0.0338,  0.0367, -0.0742,  0.0622,  0.0543, -0.0562, -0.0228, -0.0060,\n",
      "         0.0417,  0.0070, -0.0339, -0.0508, -0.0861,  0.0180, -0.0676,  0.0771,\n",
      "         0.0589,  0.0695,  0.0432,  0.0868, -0.0457,  0.0594, -0.0423,  0.0503,\n",
      "         0.0667,  0.0780, -0.0371,  0.0687,  0.0756, -0.0053, -0.0179,  0.0129,\n",
      "         0.0531, -0.0180,  0.0196,  0.0807,  0.0379, -0.0744, -0.0380, -0.0463,\n",
      "         0.0793,  0.0556, -0.0084, -0.0325,  0.0155,  0.0818,  0.0158, -0.0034,\n",
      "        -0.0438,  0.0049,  0.0438,  0.0279,  0.0688, -0.0777, -0.0760,  0.0002,\n",
      "        -0.0206,  0.0431,  0.0305, -0.0799, -0.0746,  0.0694, -0.0711, -0.0282,\n",
      "        -0.0482,  0.0766, -0.0337, -0.0385,  0.0149, -0.0031, -0.0818, -0.0066,\n",
      "         0.0585,  0.0056, -0.0744, -0.0818,  0.0348, -0.0693, -0.0821,  0.0120,\n",
      "        -0.0634, -0.0867,  0.0743,  0.0642,  0.0020,  0.0093, -0.0748, -0.0534,\n",
      "        -0.0528, -0.0301, -0.0028,  0.0570,  0.0662, -0.0050,  0.0587,  0.0217,\n",
      "        -0.0618,  0.0541, -0.0189, -0.0441,  0.0860,  0.0387,  0.0461,  0.0409],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0119,  0.0831, -0.0043,  0.0614, -0.0477,  0.0179, -0.0100, -0.0056,\n",
      "         -0.0694, -0.0700, -0.0687, -0.0623,  0.0014,  0.0104,  0.0818, -0.0543,\n",
      "          0.0665,  0.0297,  0.0752,  0.0068, -0.0402, -0.0778,  0.0050,  0.0282,\n",
      "          0.0090,  0.0609,  0.0262,  0.0151, -0.0876, -0.0553, -0.0846, -0.0240,\n",
      "         -0.0505,  0.0549,  0.0480,  0.0548,  0.0583, -0.0746, -0.0155,  0.0420,\n",
      "          0.0562,  0.0503,  0.0159,  0.0419, -0.0573,  0.0067,  0.0692, -0.0500,\n",
      "          0.0018,  0.0621, -0.0205, -0.0654,  0.0578,  0.0840,  0.0138,  0.0022,\n",
      "         -0.0386, -0.0389,  0.0024,  0.0147,  0.0737, -0.0185,  0.0837, -0.0478,\n",
      "          0.0130,  0.0816, -0.0118,  0.0151,  0.0041,  0.0858, -0.0372, -0.0353,\n",
      "         -0.0003, -0.0222, -0.0542, -0.0340, -0.0408, -0.0280, -0.0207, -0.0342,\n",
      "         -0.0533, -0.0437,  0.0415, -0.0753,  0.0277,  0.0478, -0.0842, -0.0416,\n",
      "         -0.0576,  0.0034,  0.0218, -0.0777, -0.0466,  0.0469,  0.0881, -0.0353,\n",
      "         -0.0762,  0.0855, -0.0585,  0.0839,  0.0706, -0.0717,  0.0677,  0.0873,\n",
      "          0.0685,  0.0372, -0.0406, -0.0641, -0.0539, -0.0247,  0.0880,  0.0242,\n",
      "          0.0777, -0.0360,  0.0269, -0.0728,  0.0162,  0.0197,  0.0600, -0.0276,\n",
      "         -0.0222, -0.0369, -0.0404, -0.0532, -0.0126,  0.0489, -0.0192,  0.0574],\n",
      "        [ 0.0256,  0.0788, -0.0392, -0.0384, -0.0764, -0.0056, -0.0628,  0.0453,\n",
      "          0.0449, -0.0140, -0.0701,  0.0142,  0.0776,  0.0720,  0.0073,  0.0750,\n",
      "         -0.0364, -0.0726, -0.0384, -0.0777,  0.0754,  0.0003, -0.0472,  0.0504,\n",
      "         -0.0260, -0.0545,  0.0773,  0.0438, -0.0616,  0.0192,  0.0743, -0.0333,\n",
      "          0.0795,  0.0284,  0.0049,  0.0144,  0.0505, -0.0209,  0.0326,  0.0482,\n",
      "         -0.0562, -0.0585,  0.0007,  0.0392,  0.0329,  0.0555,  0.0429, -0.0058,\n",
      "          0.0816, -0.0026, -0.0374, -0.0707, -0.0742,  0.0714,  0.0255,  0.0388,\n",
      "         -0.0249,  0.0704, -0.0074, -0.0685, -0.0682,  0.0828,  0.0868, -0.0592,\n",
      "         -0.0149, -0.0236, -0.0643, -0.0217, -0.0861, -0.0801, -0.0299,  0.0700,\n",
      "          0.0446, -0.0734,  0.0483, -0.0148,  0.0354,  0.0746,  0.0104, -0.0053,\n",
      "         -0.0154,  0.0402,  0.0483, -0.0557, -0.0292, -0.0075,  0.0575,  0.0687,\n",
      "          0.0634,  0.0633,  0.0813, -0.0627,  0.0697,  0.0172,  0.0181, -0.0428,\n",
      "         -0.0657, -0.0241, -0.0095,  0.0869,  0.0341, -0.0092, -0.0478, -0.0071,\n",
      "         -0.0439,  0.0355, -0.0459,  0.0365, -0.0201,  0.0313,  0.0486, -0.0450,\n",
      "          0.0724,  0.0009, -0.0648, -0.0272, -0.0578, -0.0002, -0.0716,  0.0703,\n",
      "         -0.0388,  0.0100,  0.0812, -0.0637,  0.0111, -0.0809,  0.0676,  0.0847],\n",
      "        [ 0.0335, -0.0043, -0.0373,  0.0847, -0.0539, -0.0603, -0.0130,  0.0755,\n",
      "         -0.0843, -0.0488,  0.0349,  0.0670, -0.0331, -0.0586,  0.0875, -0.0287,\n",
      "          0.0707,  0.0116,  0.0145, -0.0729,  0.0711,  0.0143,  0.0245, -0.0223,\n",
      "         -0.0408, -0.0049,  0.0252,  0.0312,  0.0447,  0.0867, -0.0182, -0.0398,\n",
      "          0.0071, -0.0496, -0.0345, -0.0371, -0.0117, -0.0455,  0.0053,  0.0110,\n",
      "         -0.0599, -0.0018, -0.0586, -0.0235, -0.0496, -0.0769,  0.0451, -0.0058,\n",
      "          0.0255,  0.0810,  0.0161, -0.0807, -0.0009, -0.0224, -0.0048, -0.0744,\n",
      "          0.0276, -0.0120,  0.0234, -0.0321, -0.0130, -0.0050,  0.0735, -0.0460,\n",
      "         -0.0161, -0.0104,  0.0026,  0.0543,  0.0624,  0.0631, -0.0185,  0.0636,\n",
      "         -0.0318,  0.0643, -0.0439,  0.0213,  0.0399,  0.0302,  0.0810,  0.0699,\n",
      "         -0.0058, -0.0875,  0.0829, -0.0460,  0.0213, -0.0276,  0.0266, -0.0130,\n",
      "          0.0312,  0.0055,  0.0222,  0.0816,  0.0848, -0.0340, -0.0815, -0.0337,\n",
      "         -0.0716, -0.0331,  0.0550, -0.0180, -0.0487, -0.0463,  0.0266, -0.0449,\n",
      "         -0.0255, -0.0571,  0.0684, -0.0326,  0.0433,  0.0301, -0.0563,  0.0747,\n",
      "         -0.0434, -0.0147,  0.0493, -0.0456,  0.0729, -0.0519,  0.0456,  0.0607,\n",
      "         -0.0048, -0.0264, -0.0110, -0.0070,  0.0604, -0.0124, -0.0855,  0.0537],\n",
      "        [ 0.0099,  0.0882, -0.0812, -0.0070,  0.0399,  0.0544,  0.0716,  0.0645,\n",
      "         -0.0229,  0.0152, -0.0263, -0.0396, -0.0471, -0.0037, -0.0724,  0.0078,\n",
      "         -0.0803,  0.0834, -0.0232, -0.0392, -0.0688,  0.0360,  0.0429, -0.0183,\n",
      "          0.0809, -0.0013,  0.0648, -0.0672,  0.0793, -0.0421, -0.0840,  0.0041,\n",
      "          0.0553, -0.0549, -0.0346, -0.0712, -0.0575,  0.0263,  0.0045, -0.0588,\n",
      "         -0.0072, -0.0567, -0.0561, -0.0523, -0.0515, -0.0719, -0.0533,  0.0847,\n",
      "         -0.0573,  0.0313, -0.0791,  0.0256,  0.0012, -0.0059, -0.0346, -0.0805,\n",
      "         -0.0193,  0.0559, -0.0247,  0.0534,  0.0495,  0.0308, -0.0522,  0.0309,\n",
      "         -0.0211,  0.0305,  0.0282,  0.0242,  0.0680, -0.0250,  0.0731, -0.0186,\n",
      "         -0.0689,  0.0779,  0.0295, -0.0374, -0.0600, -0.0790,  0.0197,  0.0731,\n",
      "         -0.0690,  0.0621, -0.0312, -0.0468, -0.0409, -0.0418, -0.0098, -0.0772,\n",
      "         -0.0315,  0.0373,  0.0405, -0.0717, -0.0665,  0.0543, -0.0333, -0.0512,\n",
      "          0.0089,  0.0226, -0.0752, -0.0543, -0.0078,  0.0644, -0.0556,  0.0656,\n",
      "          0.0773, -0.0698, -0.0520, -0.0046, -0.0546, -0.0768, -0.0703,  0.0607,\n",
      "          0.0210,  0.0778, -0.0666, -0.0198, -0.0013, -0.0598,  0.0873, -0.0026,\n",
      "         -0.0358, -0.0318,  0.0708, -0.0167,  0.0199,  0.0567, -0.0618, -0.0468]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0508, -0.0550,  0.0873,  0.0216], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score 37.5 and loss 400.28550720214844\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score -243.0 and loss 405.88096313476564\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score -119.5 and loss 377.9640396118164\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score -129.5 and loss 405.63710632324216\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score 39.5 and loss 415.52940063476564\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score 54.5 and loss 366.66412963867185\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score 118.0 and loss 510.6642730712891\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score -258.5 and loss 564.0667724609375\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score 92.0 and loss 580.2746459960938\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score 19.0 and loss 601.1499877929688\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score -67.5 and loss 661.5470764160157\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score 71.0 and loss 649.3909790039063\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score -52.0 and loss 711.8709411621094\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score 87.0 and loss 762.7718078613282\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score 3.0 and loss 719.8994384765625\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score 13.5 and loss 714.8437927246093\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score -13.0 and loss 632.6567657470703\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score 103.0 and loss 633.0223022460938\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score -153.5 and loss 531.1764526367188\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score -188.0 and loss 622.001611328125\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score -119.0 and loss 486.40680541992185\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score -35.5 and loss 582.3288604736329\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score 218.0 and loss 596.4288696289062\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score -104.5 and loss 535.7352600097656\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score -16.0 and loss 649.2133819580079\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score -75.0 and loss 600.0300018310547\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score 31.5 and loss 668.7498474121094\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score 62.0 and loss 573.7436279296875\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score -22.0 and loss 545.5584991455078\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score 56.5 and loss 486.60158386230466\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 86.0 and loss 390.7286575317383\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score 74.5 and loss 461.9899169921875\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score -140.5 and loss 426.14352264404295\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score -268.5 and loss 366.4648178100586\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score -62.5 and loss 328.4848861694336\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score -151.0 and loss 379.0925003051758\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score 134.5 and loss 374.15884857177736\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score -244.5 and loss 513.5614013671875\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score -87.5 and loss 474.51129760742185\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score -203.5 and loss 416.43934020996096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 190\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(param)\n\u001b[0;32m--> 190\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/../dqn/rainbow/rainbow_agent.py:434\u001b[0m, in \u001b[0;36mRainbowAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m action \u001b[38;5;241m=\u001b[39m epsilon_greedy_policy(\n\u001b[1;32m    424\u001b[0m     values,\n\u001b[1;32m    425\u001b[0m     info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m     )\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# print(\"Action\", action)\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# print(\"Epislon Greedy Epsilon\", self.eg_epsilon)\u001b[39;00m\n\u001b[1;32m    433\u001b[0m next_state, reward, terminated, truncated, next_info \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m )\n\u001b[1;32m    436\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# print(\"State\", state)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/cfr_utils.py:547\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    545\u001b[0m         obs_mask, rew, terminal, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    548\u001b[0m             obs_mask[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    549\u001b[0m             reward,\n\u001b[1;32m    550\u001b[0m             terminal,\n\u001b[1;32m    551\u001b[0m             truncated,\n\u001b[1;32m    552\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_moves\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlegal_actions()},\n\u001b[1;32m    553\u001b[0m         )\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mis_terminal():\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_player \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/cfr_utils.py:133\u001b[0m, in \u001b[0;36mNFSPWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mapply_action(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlegal_actions()))\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcurrent_player())\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/cfr_utils.py:148\u001b[0m, in \u001b[0;36mNFSPWrapper.obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mis_terminal():\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo_state\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcurrent_player()] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mobservation_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcurrent_player())\n\u001b[1;32m    147\u001b[0m     )\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcurrent_player()] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegal_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_player\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# not_current_player = 1 - self.state.current_player()\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# self.observations[\"info_state\"][not_current_player] = self.state.observation_tensor(not_current_player)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# self.observations[\"legal_actions\"][not_current_player] = np.stack(self.state.legal_actions_mask(not_current_player))\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mis_chance_node():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/shape_base.py:443\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_stack_dispatcher)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Join a sequence of arrays along a new axis.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from agent_configs import RainbowConfig\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from utils.utils import HuberLoss\n",
    "from cfr_utils import (\n",
    "    EvalWrapper,\n",
    "    evaluatebots,\n",
    "    WrapperEnv,\n",
    "    load_agents,\n",
    "    EmptyConf,\n",
    "    NFSPWrapper,\n",
    "    NFSPEvalWrapper,\n",
    "    LoadNFSPAgent,\n",
    ")\n",
    "import pyspiel\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "from cfr_network import CFRNetwork\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import open_spiel.python.algorithms.nfsp\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "num_players = 2\n",
    "max_nodes = 10000000\n",
    "\n",
    "fhp = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 4,\n",
    "        \"numRanks\": 13,\n",
    "        \"numHoleCards\": 2,\n",
    "        \"numBoardCards\": \"0 3\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leduc = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = NFSPWrapper(leduc)\n",
    "fhpgame = NFSPWrapper(fhp)\n",
    "\n",
    "active_player_obj = ActivePlayer(2)\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [128, 256, 256, 128],\n",
    "    \"value_hidden_layer_widths\": [128, 128],\n",
    "    \"advantage_hidden_layer_widths\": [128, 128],\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"training_steps\": 20000,\n",
    "    \"per_epsilon\": 0.001,\n",
    "    \"per_alpha\": 0,\n",
    "    \"per_beta\": 0,\n",
    "    \"per_beta_final\": 0.5,\n",
    "    \"minibatch_size\": 256,\n",
    "    \"replay_buffer_size\": 1000000,\n",
    "    \"min_replay_buffer_size\": 256,\n",
    "    \"transfer_interval\": 1024,\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"replay_interval\": 64,\n",
    "    \"eg_epsilon\": 1,\n",
    "    \"eg_epsilon_final\": 0.0,\n",
    "    \"eg_epsilon_final_step\": 5000,\n",
    "    \"eg_epsilon_decay_type\": \"linear\",\n",
    "    \"num_minibatches\": 4,\n",
    "}\n",
    "gameconfig = EmptyConf()\n",
    "config = RainbowConfig(config_dict, gameconfig)\n",
    "config.v_min = -1200\n",
    "config.v_max = 1200\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "\n",
    "mainpath1 = \"./checkpoints/fhp/nfsp/0/1000002/\"\n",
    "mainpath2 = \"./checkpoints/fhp/nfsp/0/4000001/\"\n",
    "mainpath3 = \"./checkpoints/fhp/nfsp/0/7000001/\"\n",
    "mainpath4 = \"./checkpoints/fhp/nfsp/0/8000000/\"\n",
    "mainpath5 = \"./checkpoints/fhp/nfsp/0/10000000/\"\n",
    "mainpath6 = \"./checkpoints/leduc/nfsp/0/1000000/\"\n",
    "mainpath7 = \"./checkpoints/leduc/nfsp/0/4000001/\"\n",
    "mainpath8 = \"./checkpoints/leduc/nfsp/0/7000001/\"\n",
    "mainpath9 = \"./checkpoints/leduc/nfsp/0/8000000/\"\n",
    "mainpath10 = \"./checkpoints/leduc/nfsp/0/10000000/\"\n",
    "\n",
    "leduc_agent_paths = [\n",
    "    mainpath6,\n",
    "    mainpath7,\n",
    "    mainpath8,\n",
    "    mainpath9,\n",
    "    mainpath10,\n",
    "]\n",
    "fhp_agent_paths = [\n",
    "    mainpath1,\n",
    "    mainpath2,\n",
    "    mainpath3,\n",
    "    mainpath4,\n",
    "    mainpath5,\n",
    "]\n",
    "\n",
    "nodes = 0\n",
    "games = [fhpgame, leducgame]\n",
    "for i in games:\n",
    "    if i == leducgame:\n",
    "        agent_paths = leduc_agent_paths\n",
    "        game_string = \"leduc\"\n",
    "    else:\n",
    "        agent_paths = fhp_agent_paths\n",
    "        game_string = \"fhp\"\n",
    "    for number in range(len(agent_paths)):\n",
    "        i.reset()\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            agent = open_spiel.python.algorithms.nfsp.NFSP(\n",
    "                session=sess,\n",
    "                player_id=0,\n",
    "                state_representation_size=(\n",
    "                    leducconfig[\"state_representation_size\"]\n",
    "                    if i == leducgame\n",
    "                    else fhpconfig[\"state_representation_size\"]\n",
    "                ),\n",
    "                num_actions=4,\n",
    "                hidden_layers_sizes=[1024, 512, 1024, 512],\n",
    "                reservoir_buffer_capacity=30000000,\n",
    "                anticipatory_param=0,\n",
    "                batch_size=256,\n",
    "                rl_learning_rate=0.1,\n",
    "                sl_learning_rate=0.01,\n",
    "                min_buffer_size_to_learn=1000,\n",
    "                learn_every=256,\n",
    "                optimizer_str=\"sgd\",\n",
    "                replay_buffer_capacity=600000,\n",
    "                epsilon_start=0.08,\n",
    "                epsilon_end=0,\n",
    "            )\n",
    "            LoadNFSPAgent(agent_paths[number], agent, 0)\n",
    "            agent.restore(agent_paths[number])  # IF YOU HAVE A NFSP AGENT PATH\n",
    "            # agent.restore(path1) # IF YOU HAVE A NFSP AGENT PATH\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            wrapped = NFSPEvalWrapper(\n",
    "                i,\n",
    "                agent,\n",
    "                (\n",
    "                    leducconfig[\"state_representation_size\"]\n",
    "                    if i == leducgame\n",
    "                    else fhpconfig[\"state_representation_size\"]\n",
    "                ),\n",
    "                4,\n",
    "            )\n",
    "            model_name = \"Rainbow2_\" + game_string + \"_agent_\" + str(number)\n",
    "            evaluator = RainbowAgent(wrapped, config, name=model_name, device=device)\n",
    "            evaluator.checkpoint_interval = 200\n",
    "\n",
    "            for param in evaluator.model.parameters():\n",
    "                print(param)\n",
    "            evaluator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
