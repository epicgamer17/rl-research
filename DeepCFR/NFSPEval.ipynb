{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 10000\n",
      "Using         adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.001\n",
      "Using         clipnorm                      : 0.0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using         loss_function                 : <utils.utils.KLDivergenceLoss object at 0x348a20da0>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 32\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 32\n",
      "Using         num_minibatches               : 4\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "RainbowConfig\n",
      "Using default residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [128, 128]\n",
      "Using         value_hidden_layer_widths     : []\n",
      "Using default advantage_hidden_layer_widths : []\n",
      "Using default noisy_sigma                   : 0.5\n",
      "Using         eg_epsilon                    : 1\n",
      "Using         eg_epsilon_final              : 0.0\n",
      "Using         eg_epsilon_decay_type         : linear\n",
      "Using         eg_epsilon_final_step         : 2000\n",
      "Using default dueling                       : True\n",
      "Using         discount_factor               : 0.99\n",
      "Using default soft_update                   : False\n",
      "Using         transfer_interval             : 1280\n",
      "Using default ema_beta                      : 0.99\n",
      "Using         replay_interval               : 64\n",
      "Using default per_alpha                     : 0.6\n",
      "Using default per_beta                      : 0.5\n",
      "Using default per_beta_final                : 1.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default n_step                        : 3\n",
      "Using default atom_size                     : 51\n",
      "('mlp/bias', [1024])\n",
      "('mlp/bias_1', [512])\n",
      "('mlp/bias_2', [1024])\n",
      "('mlp/bias_3', [512])\n",
      "('mlp/bias_4', [4])\n",
      "('mlp/weights', [16, 1024])\n",
      "('mlp/weights_1', [1024, 512])\n",
      "('mlp/weights_2', [512, 1024])\n",
      "('mlp/weights_3', [1024, 512])\n",
      "('mlp/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/1000000/avg_network_pid0\n",
      "2025-04-24 18:30:24.246099: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_2/weights_4_5/Assign' id:5477 op device:{requested: '', assigned: ''} def:{{{node mlp_2/weights_4_5/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_2/weights_4_5, zeros_99)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0387,  0.1424,  0.1356,  ..., -0.1193,  0.2109, -0.2149],\n",
      "        [-0.0606,  0.0378,  0.0511,  ..., -0.2193, -0.0842, -0.1617],\n",
      "        [-0.2293,  0.1946, -0.1496,  ...,  0.1164,  0.2161, -0.0674],\n",
      "        ...,\n",
      "        [-0.1260, -0.0601,  0.0103,  ...,  0.1794,  0.1275,  0.1623],\n",
      "        [ 0.0858, -0.1984,  0.0916,  ...,  0.2449, -0.1395,  0.2120],\n",
      "        [ 0.1745, -0.2096, -0.0616,  ..., -0.1356,  0.2044,  0.1124]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1880, -0.0411,  0.0980,  0.1710,  0.0469,  0.1676,  0.0136,  0.0639,\n",
      "        -0.1890, -0.0132, -0.0459,  0.1067, -0.0220,  0.1031, -0.0249,  0.0972,\n",
      "        -0.0956,  0.1260, -0.1369,  0.2037, -0.0744,  0.0498,  0.0003, -0.1738,\n",
      "         0.2442,  0.1502,  0.0110, -0.2337, -0.1094, -0.1409,  0.0730, -0.1916,\n",
      "        -0.1829, -0.1310, -0.0220, -0.1460,  0.1371, -0.2102,  0.0709,  0.2422,\n",
      "         0.0678, -0.2173, -0.2424, -0.1234, -0.0184,  0.1385, -0.0651,  0.0567,\n",
      "        -0.0296,  0.1477, -0.1270, -0.0838,  0.1461,  0.0896,  0.2483, -0.2285,\n",
      "         0.0386, -0.1386, -0.1707,  0.1541,  0.2348, -0.0480,  0.1578,  0.2063,\n",
      "         0.2214, -0.1359,  0.0439, -0.2079,  0.2313,  0.0431,  0.1728, -0.1892,\n",
      "         0.1732,  0.0483,  0.1200, -0.0453, -0.1896,  0.1847,  0.0436, -0.0660,\n",
      "        -0.2296,  0.0778, -0.0524,  0.1651,  0.2318,  0.0792,  0.1320,  0.0636,\n",
      "        -0.0700, -0.0532,  0.1155, -0.2013,  0.1507,  0.0102,  0.1544, -0.0253,\n",
      "         0.0369,  0.1143, -0.1593, -0.1833, -0.1705,  0.1286, -0.1340,  0.0805,\n",
      "        -0.0710,  0.1322, -0.1516, -0.1585,  0.2302,  0.1499,  0.0992,  0.2199,\n",
      "        -0.2400,  0.1001,  0.1126,  0.1513, -0.0958,  0.0811,  0.0486, -0.0929,\n",
      "        -0.2131,  0.0382, -0.1466, -0.2349,  0.0757,  0.1050,  0.1503,  0.1680],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0097,  0.0259,  0.0297,  ..., -0.0434,  0.0780, -0.0561],\n",
      "        [ 0.0572,  0.0450, -0.0545,  ..., -0.0721,  0.0317,  0.0227],\n",
      "        [ 0.0701,  0.0440, -0.0804,  ..., -0.0864, -0.0207,  0.0521],\n",
      "        ...,\n",
      "        [-0.0258,  0.0435, -0.0873,  ..., -0.0091, -0.0485, -0.0367],\n",
      "        [ 0.0441,  0.0415, -0.0811,  ..., -0.0179, -0.0361,  0.0805],\n",
      "        [-0.0739, -0.0467,  0.0564,  ...,  0.0281,  0.0815,  0.0291]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0477,  0.0698, -0.0707, -0.0223, -0.0699, -0.0206,  0.0042,  0.0042,\n",
      "        -0.0037, -0.0220, -0.0807,  0.0397,  0.0785,  0.0801,  0.0197,  0.0221,\n",
      "        -0.0011,  0.0850,  0.0740, -0.0013, -0.0066,  0.0047,  0.0043,  0.0031,\n",
      "        -0.0288, -0.0756, -0.0258, -0.0172,  0.0133, -0.0402,  0.0491,  0.0033,\n",
      "         0.0129,  0.0555,  0.0513, -0.0511, -0.0392, -0.0726, -0.0264, -0.0085,\n",
      "         0.0442,  0.0813,  0.0799, -0.0098,  0.0515,  0.0138,  0.0619, -0.0616,\n",
      "         0.0650, -0.0396, -0.0879,  0.0276,  0.0088, -0.0263,  0.0615,  0.0820,\n",
      "        -0.0371,  0.0202, -0.0492, -0.0824,  0.0194, -0.0656, -0.0038, -0.0578,\n",
      "         0.0755, -0.0397,  0.0498,  0.0539,  0.0759, -0.0168, -0.0314, -0.0781,\n",
      "        -0.0181, -0.0060,  0.0630,  0.0795, -0.0733, -0.0363, -0.0672,  0.0582,\n",
      "        -0.0737, -0.0696, -0.0670,  0.0855, -0.0288, -0.0360,  0.0317, -0.0659,\n",
      "        -0.0120,  0.0227,  0.0603,  0.0683,  0.0749, -0.0740, -0.0294,  0.0368,\n",
      "        -0.0667,  0.0881, -0.0073, -0.0651,  0.0737,  0.0684,  0.0663, -0.0742,\n",
      "        -0.0520,  0.0404,  0.0788, -0.0403, -0.0768,  0.0306, -0.0120,  0.0620,\n",
      "         0.0570, -0.0143, -0.0798, -0.0130,  0.0567,  0.0310,  0.0230,  0.0003,\n",
      "        -0.0597,  0.0388,  0.0317, -0.0624, -0.0522, -0.0650,  0.0032,  0.0478],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0723, -0.0030, -0.0882,  ...,  0.0531,  0.0314,  0.0543],\n",
      "        [-0.0732, -0.0535,  0.0868,  ...,  0.0622, -0.0405,  0.0525],\n",
      "        [ 0.0492,  0.0801,  0.0882,  ...,  0.0294, -0.0007, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0211,  0.0406,  0.0479,  ...,  0.0172, -0.0254, -0.0543],\n",
      "        [-0.0733,  0.0287,  0.0870,  ..., -0.0437,  0.0685,  0.0683],\n",
      "        [-0.0131,  0.0213,  0.0169,  ..., -0.0466,  0.0483, -0.0700]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0410,  0.0534,  0.0728,  0.0454,  0.0284, -0.0317,  0.0246, -0.0659,\n",
      "         0.0320, -0.0245, -0.0381,  0.0224, -0.0711, -0.0763, -0.0100,  0.0014,\n",
      "        -0.0635, -0.0024, -0.0713, -0.0231,  0.0883,  0.0194, -0.0755,  0.0283,\n",
      "         0.0238,  0.0236,  0.0529,  0.0465,  0.0334, -0.0232,  0.0706, -0.0723,\n",
      "         0.0545, -0.0671, -0.0704, -0.0215, -0.0241,  0.0618,  0.0643,  0.0159,\n",
      "         0.0738, -0.0755,  0.0375,  0.0264, -0.0823,  0.0560,  0.0180,  0.0264,\n",
      "        -0.0474,  0.0511,  0.0833], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0245, -0.0465,  0.0434,  ...,  0.0040,  0.0158,  0.0107],\n",
      "        [ 0.0522, -0.0327,  0.0044,  ..., -0.0471, -0.0354, -0.0611],\n",
      "        [-0.0354, -0.0150, -0.0084,  ..., -0.0226, -0.0290, -0.0383],\n",
      "        ...,\n",
      "        [-0.0598,  0.0313,  0.0583,  ..., -0.0060,  0.0532, -0.0224],\n",
      "        [-0.0404,  0.0400,  0.0297,  ...,  0.0407, -0.0784, -0.0594],\n",
      "        [ 0.0713,  0.0792, -0.0257,  ..., -0.0700, -0.0253,  0.0556]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0258,  0.0790,  0.0564,  0.0128,  0.0016, -0.0177,  0.0265,  0.0503,\n",
      "         0.0534,  0.0829,  0.0668, -0.0465,  0.0340, -0.0219, -0.0213,  0.0646,\n",
      "        -0.0557, -0.0205, -0.0154, -0.0874, -0.0230, -0.0876, -0.0391, -0.0539,\n",
      "         0.0245,  0.0220, -0.0054, -0.0405,  0.0580, -0.0461,  0.0112, -0.0234,\n",
      "        -0.0181,  0.0775,  0.0576, -0.0117, -0.0344,  0.0372,  0.0497,  0.0351,\n",
      "         0.0255, -0.0131,  0.0454,  0.0763, -0.0130, -0.0382,  0.0433, -0.0104,\n",
      "         0.0090, -0.0747,  0.0788,  0.0708,  0.0621, -0.0852, -0.0881, -0.0526,\n",
      "        -0.0217, -0.0188,  0.0275, -0.0253, -0.0079, -0.0409, -0.0740, -0.0785,\n",
      "        -0.0522, -0.0101,  0.0180, -0.0469, -0.0213, -0.0283,  0.0755, -0.0834,\n",
      "        -0.0002,  0.0853,  0.0007, -0.0687, -0.0280, -0.0180,  0.0169, -0.0063,\n",
      "         0.0512,  0.0845,  0.0440, -0.0700, -0.0585,  0.0085,  0.0392,  0.0790,\n",
      "         0.0838, -0.0445,  0.0597, -0.0581,  0.0670,  0.0062, -0.0192, -0.0045,\n",
      "         0.0504, -0.0090,  0.0865,  0.0174,  0.0558,  0.0167,  0.0166,  0.0877,\n",
      "         0.0841,  0.0464, -0.0191, -0.0743, -0.0240, -0.0748, -0.0438,  0.0227,\n",
      "         0.0616,  0.0076, -0.0521,  0.0569, -0.0839, -0.0160, -0.0883,  0.0579,\n",
      "        -0.0526,  0.0694,  0.0360,  0.0450,  0.0337, -0.0389,  0.0878, -0.0511,\n",
      "        -0.0346,  0.0694, -0.0108,  0.0165, -0.0863,  0.0434,  0.0410, -0.0867,\n",
      "         0.0163, -0.0075,  0.0044, -0.0007, -0.0657, -0.0320, -0.0147, -0.0461,\n",
      "        -0.0281,  0.0741, -0.0674, -0.0022, -0.0158,  0.0526,  0.0692,  0.0443,\n",
      "        -0.0553,  0.0375, -0.0024,  0.0854, -0.0372, -0.0818,  0.0012,  0.0232,\n",
      "         0.0172,  0.0041,  0.0884, -0.0218, -0.0112, -0.0575,  0.0490,  0.0580,\n",
      "        -0.0455, -0.0515,  0.0351, -0.0319,  0.0243, -0.0771,  0.0316,  0.0776,\n",
      "         0.0332,  0.0702,  0.0098, -0.0026,  0.0319,  0.0261, -0.0093,  0.0501,\n",
      "         0.0134, -0.0107,  0.0225,  0.0494, -0.0301,  0.0819, -0.0710, -0.0680,\n",
      "         0.0302, -0.0329, -0.0099, -0.0090,  0.0358,  0.0811,  0.0460, -0.0182,\n",
      "         0.0393,  0.0502, -0.0329, -0.0700], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score 68.51851851851852 and loss 7.1483460664749146\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score 75.0 and loss 0.004772076290100813\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score 65.0 and loss 7.817890436854214e-05\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score 92.0 and loss 8.83766684296461e-06\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score 82.5 and loss 7.367694720983309e-08\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score 132.0 and loss 2.1176990100402192e-08\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score 79.5 and loss 2.4138187298623628e-15\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score 61.5 and loss 1.397256901979281e-16\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score 79.5 and loss 4.202028089343368e-19\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score 109.5 and loss 8.494978090576533e-20\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score 112.5 and loss 1.9912804317505007e-21\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score 122.5 and loss 2.364288595196366e-27\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score 133.0 and loss 8.971333479247508e-27\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score 75.0 and loss 1.1163593654523609e-28\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score 93.0 and loss 2.4321213652022328e-29\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score 100.5 and loss 3.1334061739119058e-27\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score 157.5 and loss 1.9941447474696565e-31\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score 80.5 and loss 9.581191940253902e-32\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score 144.0 and loss 9.197177162773787e-24\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score 127.0 and loss 1.1504263113126707e-27\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score 80.0 and loss 6.249510727849884e-22\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score 54.5 and loss 1.562653049803351e-29\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score 111.0 and loss 2.1107344123909125e-38\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score 152.0 and loss 4.300486896120361e-41\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score 59.0 and loss 1.5975983346499324e-35\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score 112.5 and loss 5.17913366100447e-33\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score 40.0 and loss 9.592153112949875e-35\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score 18.0 and loss 4.755208320452095e-25\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score 84.5 and loss 0.0\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score 112.0 and loss 0.0\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 80.5 and loss 0.0\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score 60.5 and loss 0.0\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score 40.0 and loss 0.0\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score 81.5 and loss 0.0\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score 122.0 and loss 0.0\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score 109.5 and loss 0.0\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score 83.5 and loss 0.0\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score 98.5 and loss 0.0\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score 52.5 and loss 0.0\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score 65.0 and loss 0.0\n",
      "Training step: 7901/10000\n",
      "Training step: 8001/10000\n",
      "Checkpointing at 8000 with score 66.5 and loss 0.0\n",
      "Training step: 8101/10000\n",
      "Training step: 8201/10000\n",
      "Checkpointing at 8200 with score 22.0 and loss 0.0\n",
      "Training step: 8301/10000\n",
      "Training step: 8401/10000\n",
      "Checkpointing at 8400 with score 130.5 and loss 0.0\n",
      "Training step: 8501/10000\n",
      "Training step: 8601/10000\n",
      "Checkpointing at 8600 with score 84.5 and loss 0.0\n",
      "Training step: 8701/10000\n",
      "Training step: 8801/10000\n",
      "Checkpointing at 8800 with score 68.5 and loss 0.0\n",
      "Training step: 8901/10000\n",
      "Training step: 9001/10000\n",
      "Checkpointing at 9000 with score 127.5 and loss 0.0\n",
      "Training step: 9101/10000\n",
      "Training step: 9201/10000\n",
      "Checkpointing at 9200 with score 112.5 and loss 0.0\n",
      "Training step: 9301/10000\n",
      "Training step: 9401/10000\n",
      "Checkpointing at 9400 with score 150.5 and loss 0.0\n",
      "Training step: 9501/10000\n",
      "Training step: 9601/10000\n",
      "Checkpointing at 9600 with score 179.0 and loss 0.0\n",
      "Training step: 9701/10000\n",
      "Training step: 9801/10000\n",
      "Checkpointing at 9800 with score 56.0 and loss 0.0\n",
      "Training step: 9901/10000\n",
      "('mlp/bias', [1024])\n",
      "('mlp/bias_1', [512])\n",
      "('mlp/bias_2', [1024])\n",
      "('mlp/bias_3', [512])\n",
      "('mlp/bias_4', [4])\n",
      "('mlp/weights', [16, 1024])\n",
      "('mlp/weights_1', [1024, 512])\n",
      "('mlp/weights_2', [512, 1024])\n",
      "('mlp/weights_3', [1024, 512])\n",
      "('mlp/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/4000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/4000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/4000001/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/4000001/avg_network_pid0\n",
      "2025-04-24 18:51:30.346162: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_2/weights_4_6/Assign' id:6427 op device:{requested: '', assigned: ''} def:{{{node mlp_2/weights_4_6/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_2/weights_4_6, zeros_119)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.2132, -0.1325,  0.1449,  ..., -0.0294,  0.1902, -0.2222],\n",
      "        [ 0.0034, -0.0749, -0.1597,  ..., -0.2124, -0.0075,  0.0055],\n",
      "        [ 0.0130, -0.0592,  0.0318,  ...,  0.0541,  0.1074,  0.1347],\n",
      "        ...,\n",
      "        [-0.1521,  0.1424, -0.1522,  ..., -0.1665,  0.2450, -0.2215],\n",
      "        [ 0.1710,  0.0053, -0.1334,  ...,  0.0572, -0.1827, -0.0751],\n",
      "        [-0.1107,  0.0891,  0.0266,  ...,  0.1177, -0.1204, -0.2183]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0252, -0.2462, -0.0497,  0.0934, -0.1560, -0.2140, -0.0830,  0.1631,\n",
      "         0.1032,  0.1507, -0.0824, -0.1976,  0.0821,  0.1545,  0.0780,  0.0410,\n",
      "         0.0711, -0.1231,  0.1287,  0.0073, -0.0799,  0.0576, -0.2069, -0.1292,\n",
      "         0.2219, -0.2071,  0.1547,  0.1445,  0.1229, -0.1508,  0.1940, -0.1018,\n",
      "        -0.0966,  0.0466, -0.1051,  0.1142,  0.1587,  0.1226, -0.1285, -0.2333,\n",
      "         0.1399, -0.1974,  0.0960, -0.2285,  0.1359, -0.1114, -0.0815,  0.2066,\n",
      "         0.1954, -0.1434, -0.2033, -0.1802, -0.0927, -0.0545, -0.0121,  0.0790,\n",
      "         0.0244,  0.2232, -0.0855,  0.1220, -0.1457, -0.1860, -0.1573, -0.0493,\n",
      "         0.1602, -0.2386, -0.1629, -0.0972, -0.0197, -0.2493, -0.0315, -0.1841,\n",
      "         0.1413, -0.0575,  0.0505,  0.1155,  0.1324,  0.0121,  0.2441, -0.0051,\n",
      "         0.1311, -0.2120,  0.1711,  0.1748, -0.0712, -0.0470,  0.1056, -0.1485,\n",
      "         0.1389, -0.1254,  0.1023,  0.1722,  0.2053, -0.2258,  0.0354, -0.2002,\n",
      "         0.0439,  0.2352,  0.0578, -0.0399, -0.1515,  0.2277,  0.0230,  0.1503,\n",
      "        -0.0522,  0.2252,  0.0859,  0.1546,  0.1969,  0.2010,  0.0414,  0.0412,\n",
      "         0.0393,  0.2029,  0.0559,  0.1791, -0.0808, -0.1023,  0.0095, -0.2142,\n",
      "        -0.1639, -0.1318, -0.0061, -0.1520, -0.2081,  0.0300,  0.1125,  0.1318],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0204, -0.0184,  0.0036,  ...,  0.0514, -0.0818, -0.0879],\n",
      "        [-0.0851,  0.0410,  0.0484,  ..., -0.0626,  0.0805,  0.0544],\n",
      "        [ 0.0563, -0.0844,  0.0127,  ...,  0.0534,  0.0286, -0.0676],\n",
      "        ...,\n",
      "        [-0.0774, -0.0117,  0.0371,  ...,  0.0638, -0.0465, -0.0207],\n",
      "        [ 0.0329,  0.0081, -0.0322,  ...,  0.0386,  0.0621,  0.0382],\n",
      "        [ 0.0807,  0.0860, -0.0008,  ...,  0.0362,  0.0655,  0.0106]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0639,  0.0154,  0.0477,  0.0168,  0.0265, -0.0214,  0.0353,  0.0696,\n",
      "         0.0013,  0.0572, -0.0007,  0.0364, -0.0694, -0.0680,  0.0551,  0.0735,\n",
      "        -0.0142,  0.0685,  0.0749,  0.0664,  0.0565, -0.0347,  0.0704, -0.0627,\n",
      "        -0.0481,  0.0813,  0.0663,  0.0177,  0.0201, -0.0393, -0.0606, -0.0700,\n",
      "        -0.0305,  0.0681, -0.0625, -0.0172, -0.0118, -0.0252,  0.0647, -0.0100,\n",
      "        -0.0220,  0.0818, -0.0384,  0.0383,  0.0397, -0.0817, -0.0693, -0.0818,\n",
      "         0.0206,  0.0878,  0.0136,  0.0543,  0.0774, -0.0699,  0.0599, -0.0451,\n",
      "        -0.0407, -0.0363, -0.0390, -0.0242,  0.0445, -0.0798, -0.0656,  0.0139,\n",
      "        -0.0088,  0.0548, -0.0269, -0.0727,  0.0376, -0.0039,  0.0761, -0.0305,\n",
      "        -0.0203,  0.0504, -0.0834,  0.0189, -0.0729,  0.0046,  0.0108, -0.0475,\n",
      "        -0.0847, -0.0761, -0.0483, -0.0136,  0.0333,  0.0298,  0.0595,  0.0288,\n",
      "         0.0425,  0.0378,  0.0691,  0.0363,  0.0257, -0.0465, -0.0077, -0.0517,\n",
      "        -0.0605, -0.0012,  0.0582, -0.0140,  0.0771, -0.0664, -0.0632, -0.0090,\n",
      "        -0.0621, -0.0640,  0.0268, -0.0116, -0.0767,  0.0878, -0.0115, -0.0645,\n",
      "        -0.0487, -0.0109,  0.0271,  0.0774, -0.0651, -0.0452,  0.0684, -0.0840,\n",
      "         0.0756,  0.0387, -0.0416, -0.0204,  0.0429,  0.0319,  0.0195, -0.0717],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0692,  0.0159, -0.0800,  ..., -0.0095,  0.0347, -0.0697],\n",
      "        [ 0.0877,  0.0515,  0.0582,  ...,  0.0030,  0.0341,  0.0003],\n",
      "        [-0.0159,  0.0720, -0.0861,  ...,  0.0866, -0.0822, -0.0434],\n",
      "        ...,\n",
      "        [ 0.0336,  0.0135,  0.0268,  ...,  0.0749, -0.0134, -0.0448],\n",
      "        [-0.0701, -0.0310,  0.0528,  ..., -0.0602,  0.0868, -0.0249],\n",
      "        [ 0.0518, -0.0035,  0.0416,  ..., -0.0491,  0.0343, -0.0580]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0546, -0.0792,  0.0572,  0.0594,  0.0645, -0.0552, -0.0492, -0.0196,\n",
      "         0.0717, -0.0414, -0.0380, -0.0068, -0.0592, -0.0089,  0.0427, -0.0674,\n",
      "        -0.0351, -0.0283, -0.0157,  0.0022, -0.0601, -0.0144,  0.0279, -0.0541,\n",
      "         0.0230, -0.0010, -0.0855, -0.0641,  0.0374, -0.0454,  0.0645, -0.0018,\n",
      "        -0.0048,  0.0084,  0.0728,  0.0358, -0.0241,  0.0370, -0.0016,  0.0829,\n",
      "         0.0879,  0.0649,  0.0023, -0.0429,  0.0451,  0.0018,  0.0743,  0.0728,\n",
      "        -0.0524, -0.0040,  0.0862], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0306, -0.0668,  0.0013,  ...,  0.0020,  0.0087, -0.0456],\n",
      "        [-0.0101, -0.0355,  0.0526,  ..., -0.0274,  0.0092, -0.0621],\n",
      "        [-0.0008, -0.0540, -0.0175,  ...,  0.0677, -0.0089,  0.0144],\n",
      "        ...,\n",
      "        [ 0.0031, -0.0657,  0.0006,  ..., -0.0288,  0.0003, -0.0232],\n",
      "        [ 0.0258, -0.0159,  0.0161,  ..., -0.0326,  0.0271, -0.0505],\n",
      "        [ 0.0272,  0.0120,  0.0019,  ..., -0.0287, -0.0336, -0.0346]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0380,  0.0181,  0.0691,  0.0214,  0.0188,  0.0257,  0.0616, -0.0197,\n",
      "         0.0822, -0.0216,  0.0667, -0.0412,  0.0223,  0.0780, -0.0202, -0.0870,\n",
      "        -0.0473,  0.0814, -0.0064,  0.0552, -0.0730,  0.0622, -0.0432, -0.0310,\n",
      "         0.0614, -0.0696, -0.0313, -0.0764, -0.0574, -0.0195, -0.0476, -0.0068,\n",
      "         0.0735,  0.0545,  0.0255,  0.0219,  0.0055,  0.0382,  0.0304,  0.0285,\n",
      "         0.0811,  0.0630,  0.0479,  0.0637, -0.0392, -0.0802, -0.0793, -0.0450,\n",
      "        -0.0787, -0.0150, -0.0843, -0.0395, -0.0079, -0.0497,  0.0067, -0.0735,\n",
      "         0.0501, -0.0820,  0.0501, -0.0319,  0.0427,  0.0572, -0.0050, -0.0612,\n",
      "        -0.0719,  0.0127, -0.0136,  0.0816, -0.0390,  0.0031, -0.0598, -0.0743,\n",
      "        -0.0784,  0.0305, -0.0854, -0.0763,  0.0249,  0.0234,  0.0598, -0.0864,\n",
      "        -0.0123,  0.0029, -0.0784, -0.0053, -0.0242,  0.0239, -0.0823,  0.0744,\n",
      "        -0.0728, -0.0452,  0.0316, -0.0223, -0.0427,  0.0281, -0.0642, -0.0032,\n",
      "        -0.0438,  0.0805, -0.0475,  0.0643, -0.0466, -0.0107,  0.0759,  0.0294,\n",
      "        -0.0533,  0.0858,  0.0601, -0.0881, -0.0155, -0.0168,  0.0724,  0.0786,\n",
      "        -0.0056, -0.0712, -0.0577,  0.0339, -0.0734,  0.0799,  0.0215,  0.0242,\n",
      "        -0.0820, -0.0825, -0.0059,  0.0859,  0.0502,  0.0315, -0.0231,  0.0407,\n",
      "        -0.0479, -0.0300, -0.0717,  0.0368, -0.0039,  0.0009, -0.0062,  0.0715,\n",
      "         0.0390,  0.0177, -0.0575, -0.0429, -0.0766,  0.0623, -0.0690,  0.0360,\n",
      "         0.0159,  0.0502, -0.0188, -0.0365, -0.0388, -0.0321, -0.0379, -0.0251,\n",
      "         0.0661,  0.0679,  0.0162, -0.0088, -0.0883,  0.0049, -0.0736,  0.0861,\n",
      "         0.0122, -0.0408,  0.0403,  0.0373, -0.0067,  0.0094, -0.0419,  0.0244,\n",
      "         0.0607, -0.0875, -0.0844,  0.0717,  0.0840, -0.0354, -0.0108, -0.0236,\n",
      "         0.0140, -0.0765,  0.0039,  0.0589,  0.0656,  0.0772, -0.0374, -0.0029,\n",
      "         0.0616, -0.0165, -0.0132, -0.0424, -0.0418, -0.0015,  0.0225, -0.0457,\n",
      "         0.0452,  0.0493, -0.0366, -0.0413, -0.0065,  0.0742, -0.0251,  0.0207,\n",
      "        -0.0839,  0.0645, -0.0850,  0.0467], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score 103.0 and loss 8.513774394989014\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score -26.0 and loss 0.00015110892927623355\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score -21.5 and loss 5.346225961488927e-07\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score -53.0 and loss 4.098275584452082e-08\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score 10.5 and loss 1.6913082045988403e-11\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score 68.5 and loss 5.69854473421707e-13\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score 23.5 and loss 1.504660186825898e-15\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score 21.0 and loss 3.749977279836435e-17\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score 48.5 and loss 1.7713022047524269e-19\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score -21.5 and loss 2.174398260189944e-20\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score -26.5 and loss 1.3688027195743835e-24\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score 117.5 and loss 4.6640781324157614e-20\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score 29.5 and loss 4.286756347820507e-26\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score 45.5 and loss 5.445318677757891e-30\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score 19.5 and loss 9.859588349116129e-32\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score 35.0 and loss 1.0693051769763965e-32\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score 97.0 and loss 7.152651352845148e-33\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score -14.5 and loss 2.6901130866224503e-37\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score -3.0 and loss 2.2522654591968267e-38\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score 129.5 and loss 2.7154221511839875e-41\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score 49.0 and loss 5.0446744715693416e-45\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score -28.0 and loss 0.0\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score 65.0 and loss 0.0\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score 81.0 and loss 5.885453550164232e-45\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score 10.0 and loss 1.4012984643248171e-46\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score -15.0 and loss 0.0\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score 3.5 and loss 0.0\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score -2.0 and loss 0.0\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score 39.0 and loss 0.0\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score 76.5 and loss 0.0\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 9.5 and loss 0.0\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score -37.5 and loss 0.0\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score 18.0 and loss 0.0\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score 2.0 and loss 0.0\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score 31.0 and loss 0.0\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score 11.0 and loss 0.0\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score 25.5 and loss 0.0\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score -30.0 and loss 0.0\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score 33.0 and loss 0.0\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score 2.0 and loss 0.0\n",
      "Training step: 7901/10000\n",
      "Training step: 8001/10000\n",
      "Checkpointing at 8000 with score -25.0 and loss 0.0\n",
      "Training step: 8101/10000\n",
      "Training step: 8201/10000\n",
      "Checkpointing at 8200 with score 28.5 and loss 0.0\n",
      "Training step: 8301/10000\n",
      "Training step: 8401/10000\n",
      "Checkpointing at 8400 with score 40.0 and loss 0.0\n",
      "Training step: 8501/10000\n",
      "Training step: 8601/10000\n",
      "Checkpointing at 8600 with score 23.0 and loss 0.0\n",
      "Training step: 8701/10000\n",
      "Training step: 8801/10000\n",
      "Checkpointing at 8800 with score -19.5 and loss 0.0\n",
      "Training step: 8901/10000\n",
      "Training step: 9001/10000\n",
      "Checkpointing at 9000 with score 34.5 and loss 0.0\n",
      "Training step: 9101/10000\n",
      "Training step: 9201/10000\n",
      "Checkpointing at 9200 with score 24.0 and loss 0.0\n",
      "Training step: 9301/10000\n",
      "Training step: 9401/10000\n",
      "Checkpointing at 9400 with score 27.5 and loss 0.0\n",
      "Training step: 9501/10000\n",
      "Training step: 9601/10000\n",
      "Checkpointing at 9600 with score -14.0 and loss 0.0\n",
      "Training step: 9701/10000\n",
      "Training step: 9801/10000\n",
      "Checkpointing at 9800 with score 46.0 and loss 0.0\n",
      "Training step: 9901/10000\n",
      "('mlp_6/bias', [1024])\n",
      "('mlp_6/bias_1', [512])\n",
      "('mlp_6/bias_2', [1024])\n",
      "('mlp_6/bias_3', [512])\n",
      "('mlp_6/bias_4', [4])\n",
      "('mlp_6/weights', [16, 1024])\n",
      "('mlp_6/weights_1', [1024, 512])\n",
      "('mlp_6/weights_2', [512, 1024])\n",
      "('mlp_6/weights_3', [1024, 512])\n",
      "('mlp_6/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/7000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/7000001/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/7000001/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/7000001/avg_network_pid0\n",
      "2025-04-24 19:16:27.728938: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_8/weights_4_1/Assign' id:7377 op device:{requested: '', assigned: ''} def:{{{node mlp_8/weights_4_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_8/weights_4_1, zeros_139)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0093,  0.1627,  0.0237,  ...,  0.0605, -0.0526, -0.1078],\n",
      "        [-0.1705,  0.2001,  0.1729,  ..., -0.0298,  0.1511, -0.1159],\n",
      "        [ 0.1146, -0.1420, -0.0291,  ...,  0.2271, -0.1694, -0.2072],\n",
      "        ...,\n",
      "        [-0.0321,  0.1457, -0.1098,  ..., -0.2221, -0.0109,  0.1575],\n",
      "        [-0.0883, -0.2151,  0.1374,  ...,  0.1975, -0.1479,  0.2131],\n",
      "        [ 0.1497,  0.2183, -0.0608,  ...,  0.1889, -0.0342, -0.0183]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0169,  0.0817, -0.2469, -0.1942, -0.1492,  0.0476, -0.1169,  0.1017,\n",
      "         0.2039, -0.0155, -0.2149, -0.0350, -0.0811, -0.1097,  0.1572,  0.2490,\n",
      "        -0.0774,  0.1543, -0.0018,  0.1320,  0.1909, -0.0176, -0.0146, -0.0313,\n",
      "        -0.0931, -0.1441, -0.1653, -0.0435,  0.0861,  0.2277, -0.0777, -0.2094,\n",
      "         0.0457,  0.1207,  0.2479,  0.1128,  0.0983,  0.0440,  0.1491, -0.0733,\n",
      "         0.1387,  0.2240, -0.2358,  0.0462, -0.1059, -0.0960,  0.0367,  0.1306,\n",
      "        -0.0429, -0.2487, -0.1824, -0.0880,  0.1126,  0.1934,  0.1212, -0.0839,\n",
      "        -0.0997, -0.1737, -0.1517, -0.0078,  0.1086, -0.0488,  0.0059,  0.2367,\n",
      "        -0.1972, -0.2028,  0.1394,  0.0665, -0.0347, -0.1874, -0.0338,  0.1501,\n",
      "        -0.1288,  0.0801, -0.0635, -0.1534, -0.0552,  0.0155, -0.1011,  0.0125,\n",
      "         0.1100,  0.1050, -0.0345, -0.0608, -0.2111, -0.0521, -0.1521,  0.1165,\n",
      "         0.2431, -0.1953, -0.1866, -0.0392, -0.0093,  0.0630, -0.0262,  0.0425,\n",
      "         0.2335, -0.0073,  0.0893,  0.0551, -0.0682, -0.0005,  0.2027, -0.0450,\n",
      "         0.1845, -0.1649, -0.0600, -0.2091,  0.0538, -0.0897,  0.2206, -0.1061,\n",
      "        -0.0655, -0.0573, -0.0413,  0.2430, -0.2293,  0.1713,  0.0040, -0.0287,\n",
      "        -0.0916, -0.2350,  0.1366, -0.2472,  0.2202, -0.2083, -0.1378, -0.0843],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0311,  0.0527,  0.0004,  ...,  0.0183, -0.0420, -0.0107],\n",
      "        [ 0.0611,  0.0199, -0.0309,  ...,  0.0235,  0.0474,  0.0250],\n",
      "        [ 0.0326,  0.0882, -0.0019,  ..., -0.0518,  0.0825,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0626,  0.0219,  0.0468,  ..., -0.0181, -0.0462, -0.0642],\n",
      "        [-0.0721, -0.0411,  0.0421,  ...,  0.0759, -0.0857,  0.0760],\n",
      "        [ 0.0225, -0.0408,  0.0364,  ..., -0.0866, -0.0192, -0.0374]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0712,  0.0516, -0.0015,  0.0578, -0.0666, -0.0720,  0.0457,  0.0060,\n",
      "        -0.0158, -0.0758,  0.0762,  0.0617, -0.0266, -0.0434, -0.0731, -0.0015,\n",
      "         0.0867,  0.0593, -0.0016, -0.0662, -0.0747, -0.0057, -0.0858,  0.0629,\n",
      "        -0.0301, -0.0659, -0.0195, -0.0346, -0.0278, -0.0072, -0.0371, -0.0448,\n",
      "        -0.0032, -0.0873,  0.0192,  0.0065, -0.0712, -0.0778,  0.0655,  0.0080,\n",
      "        -0.0230,  0.0392, -0.0250,  0.0745, -0.0439,  0.0345,  0.0700,  0.0280,\n",
      "         0.0418, -0.0287,  0.0416, -0.0780,  0.0689,  0.0312, -0.0351, -0.0048,\n",
      "        -0.0295,  0.0069, -0.0765, -0.0492,  0.0184, -0.0308,  0.0348, -0.0610,\n",
      "        -0.0882, -0.0560, -0.0776, -0.0007,  0.0417, -0.0412,  0.0782, -0.0010,\n",
      "         0.0156, -0.0848, -0.0258,  0.0659,  0.0570, -0.0585,  0.0568,  0.0795,\n",
      "         0.0376,  0.0232, -0.0360,  0.0246,  0.0579, -0.0786,  0.0176,  0.0373,\n",
      "        -0.0653,  0.0331, -0.0070, -0.0509, -0.0714, -0.0672, -0.0222, -0.0303,\n",
      "         0.0787,  0.0786,  0.0627,  0.0593,  0.0069,  0.0148,  0.0148,  0.0492,\n",
      "        -0.0038, -0.0334, -0.0548,  0.0075, -0.0684,  0.0229, -0.0691, -0.0466,\n",
      "        -0.0597, -0.0049,  0.0838, -0.0097,  0.0621, -0.0246, -0.0854, -0.0215,\n",
      "         0.0090, -0.0043, -0.0639, -0.0347,  0.0600,  0.0211, -0.0130,  0.0244],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0193, -0.0816,  0.0358,  ...,  0.0394,  0.0300,  0.0488],\n",
      "        [ 0.0087,  0.0452,  0.0540,  ...,  0.0117, -0.0215,  0.0563],\n",
      "        [-0.0482,  0.0579,  0.0458,  ...,  0.0015,  0.0745,  0.0116],\n",
      "        ...,\n",
      "        [ 0.0725, -0.0031, -0.0147,  ..., -0.0107,  0.0772, -0.0171],\n",
      "        [ 0.0508,  0.0189,  0.0785,  ...,  0.0421,  0.0145,  0.0226],\n",
      "        [-0.0129, -0.0293,  0.0154,  ..., -0.0179, -0.0249,  0.0214]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0833, -0.0444,  0.0121,  0.0480, -0.0133, -0.0159, -0.0474, -0.0681,\n",
      "        -0.0609,  0.0290, -0.0197,  0.0265, -0.0519, -0.0613, -0.0471,  0.0167,\n",
      "         0.0881,  0.0346,  0.0517, -0.0420, -0.0548,  0.0739,  0.0463,  0.0554,\n",
      "         0.0648,  0.0090,  0.0499, -0.0760, -0.0229, -0.0653, -0.0361,  0.0119,\n",
      "        -0.0314,  0.0795,  0.0328,  0.0669,  0.0832, -0.0532, -0.0860,  0.0299,\n",
      "        -0.0411, -0.0639,  0.0283, -0.0666, -0.0558,  0.0825,  0.0298, -0.0060,\n",
      "        -0.0250, -0.0463, -0.0019], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0082, -0.0347, -0.0059,  ...,  0.0797, -0.0413, -0.0226],\n",
      "        [ 0.0194,  0.0236, -0.0804,  ...,  0.0329, -0.0228,  0.0401],\n",
      "        [ 0.0558, -0.0442,  0.0724,  ...,  0.0758,  0.0091,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0707, -0.0264, -0.0059,  ..., -0.0835,  0.0870, -0.0762],\n",
      "        [ 0.0343,  0.0626, -0.0065,  ..., -0.0845,  0.0206,  0.0348],\n",
      "        [ 0.0147,  0.0509, -0.0570,  ..., -0.0128, -0.0242, -0.0675]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0114, -0.0409, -0.0422, -0.0008, -0.0552, -0.0698, -0.0108,  0.0679,\n",
      "        -0.0081, -0.0032, -0.0476,  0.0431,  0.0078, -0.0420, -0.0759, -0.0023,\n",
      "        -0.0685,  0.0846, -0.0340,  0.0660, -0.0545, -0.0596, -0.0809,  0.0492,\n",
      "         0.0152, -0.0354,  0.0191,  0.0026,  0.0151,  0.0774,  0.0010,  0.0535,\n",
      "         0.0084,  0.0192,  0.0769,  0.0520,  0.0411,  0.0686, -0.0425,  0.0314,\n",
      "         0.0864, -0.0320,  0.0153,  0.0379, -0.0501,  0.0108,  0.0081, -0.0133,\n",
      "         0.0792,  0.0063,  0.0607,  0.0435, -0.0664,  0.0270,  0.0339, -0.0172,\n",
      "         0.0086,  0.0636,  0.0337,  0.0624,  0.0270, -0.0181,  0.0660, -0.0309,\n",
      "         0.0809, -0.0011, -0.0148, -0.0253, -0.0348, -0.0512, -0.0194,  0.0506,\n",
      "         0.0204,  0.0688, -0.0732, -0.0211, -0.0614, -0.0516, -0.0757,  0.0121,\n",
      "         0.0673, -0.0735,  0.0614, -0.0308,  0.0291,  0.0617, -0.0772, -0.0634,\n",
      "         0.0395, -0.0797,  0.0330, -0.0499,  0.0254, -0.0143, -0.0662, -0.0566,\n",
      "         0.0713,  0.0118,  0.0429, -0.0122, -0.0531, -0.0089, -0.0768,  0.0740,\n",
      "         0.0239, -0.0632, -0.0695, -0.0463, -0.0795,  0.0436, -0.0508,  0.0193,\n",
      "        -0.0651, -0.0717,  0.0355, -0.0385, -0.0162,  0.0281,  0.0504, -0.0775,\n",
      "         0.0388,  0.0375, -0.0630,  0.0595,  0.0431,  0.0058, -0.0820,  0.0058,\n",
      "         0.0278,  0.0340,  0.0863, -0.0479, -0.0244,  0.0590,  0.0165, -0.0462,\n",
      "        -0.0583, -0.0193, -0.0034,  0.0020,  0.0578,  0.0430,  0.0792, -0.0229,\n",
      "        -0.0158,  0.0574, -0.0212,  0.0375, -0.0644,  0.0466,  0.0393,  0.0873,\n",
      "         0.0517, -0.0405,  0.0607, -0.0097, -0.0787,  0.0177,  0.0861, -0.0090,\n",
      "        -0.0444, -0.0504, -0.0774, -0.0851, -0.0739, -0.0470,  0.0697,  0.0833,\n",
      "         0.0505, -0.0751, -0.0747, -0.0052,  0.0535, -0.0048, -0.0472,  0.0554,\n",
      "         0.0092,  0.0679, -0.0570,  0.0760, -0.0041, -0.0162,  0.0489, -0.0079,\n",
      "        -0.0627, -0.0567, -0.0699,  0.0883, -0.0179, -0.0492, -0.0273,  0.0326,\n",
      "         0.0489, -0.0127,  0.0443,  0.0513, -0.0116, -0.0205, -0.0135, -0.0860,\n",
      "        -0.0559, -0.0320, -0.0607,  0.0445], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score 18.6046511627907 and loss 9.32323968410492\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score -32.5 and loss 0.0002033001626841724\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score -67.5 and loss 4.0674829335785036e-07\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score -15.5 and loss 9.476491480420179e-10\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score 23.5 and loss 1.2819916070556937e-11\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score -61.0 and loss 2.6654072503554587e-08\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score 160.0 and loss 5.856189516538579e-15\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score -48.5 and loss 9.734681815733656e-18\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score 208.0 and loss 1.3400063626476974e-20\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score -35.5 and loss 3.0303209912462408e-24\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score -118.5 and loss 5.074259934175986e-21\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score 66.0 and loss 5.217863695689329e-29\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score -198.0 and loss 9.760870339989464e-32\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score -138.0 and loss 2.920151332175698e-35\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score 117.5 and loss 1.1493642772614096e-36\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score 100.0 and loss 1.3700807855520973e-38\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score -131.0 and loss 1.2625699163566601e-43\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score -24.0 and loss 1.0593816390295616e-43\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score 12.5 and loss 0.0\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score 82.0 and loss 2.1839236566502274e-42\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score 20.5 and loss 0.0\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score 23.5 and loss 0.0\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score -160.0 and loss 0.0\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score 120.0 and loss 0.0\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score -63.0 and loss 0.0\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score 97.0 and loss 0.0\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score -111.0 and loss 0.0\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score 58.0 and loss 0.0\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score -130.5 and loss 0.0\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score -27.5 and loss 0.0\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 116.0 and loss 0.0\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score -74.0 and loss 0.0\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score -201.0 and loss 0.0\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score -46.0 and loss 0.0\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score 49.0 and loss 0.0\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score -49.5 and loss 0.0\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score 30.5 and loss 0.0\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score -63.0 and loss 0.0\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score 4.5 and loss 0.0\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score -12.0 and loss 0.0\n",
      "Training step: 7901/10000\n",
      "Training step: 8001/10000\n",
      "Checkpointing at 8000 with score -310.0 and loss 0.0\n",
      "Training step: 8101/10000\n",
      "Training step: 8201/10000\n",
      "Checkpointing at 8200 with score 116.0 and loss 0.0\n",
      "Training step: 8301/10000\n",
      "Training step: 8401/10000\n",
      "Checkpointing at 8400 with score -54.5 and loss 0.0\n",
      "Training step: 8501/10000\n",
      "Training step: 8601/10000\n",
      "Checkpointing at 8600 with score -6.0 and loss 0.0\n",
      "Training step: 8701/10000\n",
      "Training step: 8801/10000\n",
      "Checkpointing at 8800 with score 141.0 and loss 0.0\n",
      "Training step: 8901/10000\n",
      "Training step: 9001/10000\n",
      "Checkpointing at 9000 with score 73.5 and loss 0.0\n",
      "Training step: 9101/10000\n",
      "Training step: 9201/10000\n",
      "Checkpointing at 9200 with score 120.0 and loss 0.0\n",
      "Training step: 9301/10000\n",
      "Training step: 9401/10000\n",
      "Checkpointing at 9400 with score -168.5 and loss 0.0\n",
      "Training step: 9501/10000\n",
      "Training step: 9601/10000\n",
      "Checkpointing at 9600 with score -45.0 and loss 0.0\n",
      "Training step: 9701/10000\n",
      "Training step: 9801/10000\n",
      "Checkpointing at 9800 with score -110.5 and loss 0.0\n",
      "Training step: 9901/10000\n",
      "('mlp_6/bias', [1024])\n",
      "('mlp_6/bias_1', [512])\n",
      "('mlp_6/bias_2', [1024])\n",
      "('mlp_6/bias_3', [512])\n",
      "('mlp_6/bias_4', [4])\n",
      "('mlp_6/weights', [16, 1024])\n",
      "('mlp_6/weights_1', [1024, 512])\n",
      "('mlp_6/weights_2', [512, 1024])\n",
      "('mlp_6/weights_3', [1024, 512])\n",
      "('mlp_6/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/8000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/8000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/8000000/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/8000000/avg_network_pid0\n",
      "2025-04-24 19:39:57.282081: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_8/weights_4_2/Assign' id:8327 op device:{requested: '', assigned: ''} def:{{{node mlp_8/weights_4_2/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_8/weights_4_2, zeros_159)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[ 0.2378, -0.1560, -0.1265,  ..., -0.1625,  0.1329,  0.0983],\n",
      "        [ 0.0424,  0.0147,  0.0789,  ..., -0.0644,  0.0989,  0.1075],\n",
      "        [-0.0654, -0.0124, -0.1924,  ...,  0.0647, -0.1127, -0.1819],\n",
      "        ...,\n",
      "        [-0.0032, -0.1908, -0.2493,  ..., -0.0293, -0.0832,  0.1655],\n",
      "        [-0.0493, -0.0238,  0.0421,  ...,  0.1483, -0.0109, -0.2024],\n",
      "        [-0.1611,  0.1256, -0.0718,  ...,  0.2049,  0.0277, -0.2087]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1208, -0.0940, -0.1084,  0.2140,  0.0978, -0.0271,  0.0342,  0.1060,\n",
      "         0.1384, -0.0145, -0.0780, -0.0462,  0.0457,  0.1052, -0.1517,  0.2412,\n",
      "        -0.1619,  0.0810, -0.1473, -0.2193, -0.1114,  0.2093,  0.0372,  0.1101,\n",
      "        -0.2108, -0.2025,  0.0710,  0.2287,  0.1044,  0.1861,  0.2328, -0.0963,\n",
      "        -0.2212, -0.0811,  0.0174,  0.1176, -0.0343, -0.0339,  0.2300, -0.0032,\n",
      "         0.2104, -0.1951, -0.0939, -0.0315, -0.0444, -0.2255,  0.1608, -0.0362,\n",
      "         0.1539, -0.0952,  0.0626, -0.0436, -0.0982, -0.1162,  0.1714, -0.0276,\n",
      "         0.1149, -0.1289, -0.1825, -0.0530,  0.1664, -0.0050,  0.2022,  0.1547,\n",
      "        -0.1695, -0.0850, -0.0814,  0.0776, -0.1956,  0.1134,  0.2148,  0.0352,\n",
      "        -0.2024,  0.1610,  0.1688,  0.2376,  0.0080,  0.2234, -0.0306,  0.0077,\n",
      "        -0.1053,  0.2345, -0.0742, -0.0080, -0.1162, -0.1200,  0.0794,  0.2114,\n",
      "         0.0106, -0.0228,  0.0393,  0.1273, -0.1342, -0.0961, -0.0557, -0.2282,\n",
      "        -0.1171,  0.1661, -0.1572, -0.2187,  0.0269,  0.0750,  0.0747, -0.1371,\n",
      "         0.2461,  0.0097,  0.2107, -0.2128,  0.1758, -0.1347,  0.0595,  0.0318,\n",
      "        -0.1665,  0.1372, -0.1714,  0.0610, -0.2314, -0.0461,  0.2220, -0.0418,\n",
      "         0.0487, -0.0278,  0.1100, -0.0469, -0.1205, -0.0742,  0.2398, -0.1089],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0416,  0.0777, -0.0334,  ..., -0.0441,  0.0805, -0.0451],\n",
      "        [-0.0359, -0.0685, -0.0743,  ..., -0.0447,  0.0091, -0.0728],\n",
      "        [-0.0449, -0.0546,  0.0447,  ...,  0.0059,  0.0021,  0.0086],\n",
      "        ...,\n",
      "        [-0.0284,  0.0287, -0.0511,  ...,  0.0819,  0.0776, -0.0708],\n",
      "        [-0.0379,  0.0510,  0.0486,  ...,  0.0616,  0.0596, -0.0738],\n",
      "        [-0.0631, -0.0702,  0.0178,  ..., -0.0619, -0.0500, -0.0343]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0031,  0.0335, -0.0818,  0.0505, -0.0306,  0.0249,  0.0535, -0.0134,\n",
      "         0.0228,  0.0311,  0.0183,  0.0325,  0.0500, -0.0240, -0.0501, -0.0036,\n",
      "        -0.0178, -0.0869, -0.0386, -0.0517,  0.0399, -0.0247, -0.0721, -0.0471,\n",
      "         0.0149,  0.0035,  0.0211,  0.0235,  0.0412, -0.0231, -0.0252, -0.0757,\n",
      "        -0.0374,  0.0670, -0.0218,  0.0242,  0.0750, -0.0488, -0.0543,  0.0661,\n",
      "         0.0577, -0.0038,  0.0409, -0.0359,  0.0357,  0.0119,  0.0660, -0.0842,\n",
      "        -0.0524,  0.0845,  0.0734, -0.0048, -0.0431,  0.0491,  0.0570,  0.0374,\n",
      "        -0.0479, -0.0263,  0.0741,  0.0601, -0.0028, -0.0372,  0.0113,  0.0402,\n",
      "        -0.0574,  0.0240, -0.0719,  0.0281,  0.0606,  0.0393,  0.0812,  0.0429,\n",
      "         0.0305,  0.0026,  0.0655, -0.0177,  0.0657,  0.0620, -0.0881, -0.0014,\n",
      "        -0.0084, -0.0227,  0.0716, -0.0358, -0.0730,  0.0259,  0.0625,  0.0506,\n",
      "         0.0283, -0.0725,  0.0390,  0.0060,  0.0758,  0.0796,  0.0611, -0.0628,\n",
      "        -0.0327,  0.0276,  0.0353, -0.0022,  0.0576,  0.0858, -0.0619,  0.0478,\n",
      "         0.0307,  0.0385, -0.0520, -0.0136,  0.0422,  0.0809, -0.0303,  0.0846,\n",
      "         0.0635, -0.0331,  0.0854,  0.0023, -0.0148, -0.0165, -0.0280, -0.0663,\n",
      "        -0.0486,  0.0543, -0.0661,  0.0009,  0.0429,  0.0785, -0.0652, -0.0581],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0386,  0.0568, -0.0069,  ..., -0.0560, -0.0135,  0.0072],\n",
      "        [ 0.0516,  0.0739, -0.0577,  ..., -0.0863, -0.0006,  0.0868],\n",
      "        [-0.0249,  0.0345,  0.0571,  ...,  0.0303,  0.0757, -0.0482],\n",
      "        ...,\n",
      "        [-0.0715,  0.0262,  0.0866,  ...,  0.0531,  0.0829, -0.0816],\n",
      "        [-0.0877,  0.0377, -0.0592,  ..., -0.0413,  0.0163,  0.0339],\n",
      "        [ 0.0755,  0.0529, -0.0173,  ..., -0.0410, -0.0623,  0.0428]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0024, -0.0691,  0.0310,  0.0396,  0.0242, -0.0502,  0.0693, -0.0797,\n",
      "        -0.0190, -0.0291,  0.0378,  0.0202,  0.0470, -0.0108, -0.0230,  0.0367,\n",
      "        -0.0754,  0.0575, -0.0579, -0.0090, -0.0141, -0.0830, -0.0818,  0.0505,\n",
      "        -0.0214,  0.0876, -0.0877, -0.0519,  0.0019,  0.0767, -0.0839,  0.0738,\n",
      "         0.0809,  0.0136, -0.0486, -0.0280, -0.0612,  0.0803, -0.0579,  0.0558,\n",
      "        -0.0538, -0.0432,  0.0300, -0.0053,  0.0082,  0.0340,  0.0510,  0.0004,\n",
      "        -0.0794, -0.0015, -0.0619], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0224,  0.0297,  0.0498,  ...,  0.0413, -0.0618, -0.0469],\n",
      "        [ 0.0165,  0.0451, -0.0002,  ...,  0.0292,  0.0638, -0.0460],\n",
      "        [ 0.0591,  0.0496, -0.0569,  ..., -0.0385, -0.0588, -0.0459],\n",
      "        ...,\n",
      "        [-0.0598, -0.0325, -0.0728,  ..., -0.0282, -0.0269, -0.0546],\n",
      "        [ 0.0682, -0.0455,  0.0358,  ...,  0.0182, -0.0872,  0.0694],\n",
      "        [-0.0749,  0.0827, -0.0504,  ..., -0.0350,  0.0044,  0.0369]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.0518e-02,  8.1609e-02,  4.8019e-02,  4.4493e-02, -4.3806e-02,\n",
      "         7.6661e-02,  6.0492e-02, -6.5910e-02, -2.2581e-02,  2.6376e-02,\n",
      "         1.8998e-02,  5.8124e-02,  3.8295e-02,  1.6141e-02, -4.6676e-02,\n",
      "        -8.1708e-02, -7.9666e-02, -8.7832e-02, -4.0297e-02, -8.5322e-02,\n",
      "        -7.3194e-02,  6.1021e-02, -3.0478e-02,  2.2155e-02, -3.8133e-02,\n",
      "         4.4218e-02, -5.3490e-02, -2.8121e-02,  7.2047e-02,  6.2746e-02,\n",
      "         1.6859e-02,  3.3044e-02, -2.9257e-02, -2.5783e-05, -6.6366e-02,\n",
      "        -7.9298e-02, -2.4006e-02, -3.7616e-02, -2.3228e-02,  3.4441e-02,\n",
      "        -7.3219e-02,  2.8176e-02, -8.0865e-02, -9.0127e-03,  7.7425e-02,\n",
      "         4.1607e-02, -3.4291e-02, -8.3591e-02,  6.6903e-02,  2.2856e-02,\n",
      "        -2.0376e-02, -9.1204e-04,  6.0010e-02,  8.0774e-02, -3.1648e-04,\n",
      "        -5.8777e-02,  3.2791e-02,  8.7242e-02,  3.5147e-02, -6.0414e-02,\n",
      "        -6.2700e-02,  2.6392e-02,  6.2892e-02, -9.8635e-03, -5.9816e-02,\n",
      "         5.6158e-02,  3.7877e-02, -4.1574e-02,  3.7392e-02, -7.5583e-02,\n",
      "        -3.4517e-02,  6.3843e-02, -2.9568e-02,  5.9414e-02, -4.8502e-02,\n",
      "         8.0827e-02, -1.2195e-02, -6.7785e-02,  5.9295e-02,  5.0399e-02,\n",
      "        -6.3203e-02,  4.9566e-02,  6.3981e-02,  3.1204e-02, -8.0358e-02,\n",
      "         3.4923e-02, -2.9684e-02,  7.9337e-02, -5.3399e-02,  6.7537e-02,\n",
      "        -7.2458e-02, -3.7368e-02,  1.6801e-02, -2.9239e-03, -3.5789e-02,\n",
      "         3.6783e-02,  2.2690e-02,  4.5413e-02,  2.8164e-02, -8.6262e-02,\n",
      "        -6.3297e-02, -5.2168e-02, -7.6049e-02,  6.0978e-02, -1.0246e-02,\n",
      "         6.5047e-02,  7.6155e-02, -3.5519e-04,  6.2067e-02, -3.3854e-03,\n",
      "        -7.3282e-02, -5.9088e-02, -1.9227e-02,  5.2139e-02,  4.6869e-02,\n",
      "         5.1036e-02,  3.3052e-02,  6.6184e-02, -2.6073e-02,  1.7272e-03,\n",
      "         5.7407e-03,  3.4702e-02,  6.9457e-02, -4.1590e-02,  4.4177e-02,\n",
      "         6.9965e-04, -3.3329e-02,  8.0203e-02,  1.8963e-02, -3.9565e-02,\n",
      "        -1.6027e-02,  8.0597e-02, -5.4348e-02, -5.1981e-02, -7.6922e-02,\n",
      "        -1.3941e-02,  7.3286e-02,  2.2612e-02, -5.7702e-02,  5.1539e-02,\n",
      "        -8.1036e-02,  2.0068e-02,  2.1903e-02,  7.2034e-02, -3.6236e-02,\n",
      "         8.7042e-02, -7.9138e-02,  7.4927e-02, -4.7418e-02, -4.4646e-02,\n",
      "        -4.3421e-02,  9.4523e-03,  4.9901e-02, -5.9358e-02,  6.8324e-02,\n",
      "         8.1712e-02, -5.0612e-02,  8.6117e-02, -3.2849e-02, -5.8742e-02,\n",
      "        -7.2183e-02,  1.2496e-02,  2.1092e-02,  6.5948e-02,  5.5307e-02,\n",
      "        -5.7260e-02, -2.7265e-02,  2.6917e-02,  6.0389e-02, -2.9852e-02,\n",
      "         7.2763e-02, -4.3545e-02,  1.8030e-02,  4.0081e-02, -7.0287e-02,\n",
      "         7.4531e-02,  6.1188e-03,  6.2758e-02, -6.2605e-02,  2.6679e-02,\n",
      "        -4.1723e-02, -2.4914e-02,  1.6587e-02,  5.4610e-02, -1.3773e-02,\n",
      "         3.4096e-02,  6.9009e-02, -3.2784e-04,  5.7445e-02,  1.4549e-03,\n",
      "        -4.1207e-02,  2.2576e-02,  7.5919e-02,  2.6952e-02,  3.4298e-02,\n",
      "        -3.1122e-02,  3.1382e-02,  3.1220e-02,  2.3624e-02,  2.2484e-02,\n",
      "        -1.9562e-02,  2.5620e-02, -1.7155e-02,  6.8485e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score -46.15384615384615 and loss 8.424067616462708\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score -23.5 and loss 0.00013835619101882913\n",
      "Training step: 301/10000\n",
      "Training step: 401/10000\n",
      "Checkpointing at 400 with score -88.0 and loss 4.102011871509603e-07\n",
      "Training step: 501/10000\n",
      "Training step: 601/10000\n",
      "Checkpointing at 600 with score -37.0 and loss 1.34137492557862e-08\n",
      "Training step: 701/10000\n",
      "Training step: 801/10000\n",
      "Checkpointing at 800 with score -142.0 and loss 4.624885728294476e-12\n",
      "Training step: 901/10000\n",
      "Training step: 1001/10000\n",
      "Checkpointing at 1000 with score -131.5 and loss 4.843335781534123e-14\n",
      "Training step: 1101/10000\n",
      "Training step: 1201/10000\n",
      "Checkpointing at 1200 with score -105.5 and loss 1.2781968679737353e-13\n",
      "Training step: 1301/10000\n",
      "Training step: 1401/10000\n",
      "Checkpointing at 1400 with score -161.5 and loss 6.367457922623063e-17\n",
      "Training step: 1501/10000\n",
      "Training step: 1601/10000\n",
      "Checkpointing at 1600 with score -23.0 and loss 2.7834719360088103e-21\n",
      "Training step: 1701/10000\n",
      "Training step: 1801/10000\n",
      "Checkpointing at 1800 with score 32.5 and loss 2.8036022361841156e-23\n",
      "Training step: 1901/10000\n",
      "Training step: 2001/10000\n",
      "Checkpointing at 2000 with score -81.5 and loss 8.394240165777618e-22\n",
      "Training step: 2101/10000\n",
      "Training step: 2201/10000\n",
      "Checkpointing at 2200 with score 26.0 and loss 2.28150199064812e-22\n",
      "Training step: 2301/10000\n",
      "Training step: 2401/10000\n",
      "Checkpointing at 2400 with score -181.5 and loss 4.601996712362239e-28\n",
      "Training step: 2501/10000\n",
      "Training step: 2601/10000\n",
      "Checkpointing at 2600 with score -67.5 and loss 1.3292712026960323e-27\n",
      "Training step: 2701/10000\n",
      "Training step: 2801/10000\n",
      "Checkpointing at 2800 with score -87.0 and loss 3.316236984083958e-35\n",
      "Training step: 2901/10000\n",
      "Training step: 3001/10000\n",
      "Checkpointing at 3000 with score -18.5 and loss 1.068402030825445e-29\n",
      "Training step: 3101/10000\n",
      "Training step: 3201/10000\n",
      "Checkpointing at 3200 with score -148.5 and loss 4.154707720523199e-31\n",
      "Training step: 3301/10000\n",
      "Training step: 3401/10000\n",
      "Checkpointing at 3400 with score -76.5 and loss 1.5806716742507153e-40\n",
      "Training step: 3501/10000\n",
      "Training step: 3601/10000\n",
      "Checkpointing at 3600 with score -13.0 and loss 7.309312919764679e-42\n",
      "Training step: 3701/10000\n",
      "Training step: 3801/10000\n",
      "Checkpointing at 3800 with score 13.0 and loss 4.5124052628802027e-41\n",
      "Training step: 3901/10000\n",
      "Training step: 4001/10000\n",
      "Checkpointing at 4000 with score -86.0 and loss 0.0\n",
      "Training step: 4101/10000\n",
      "Training step: 4201/10000\n",
      "Checkpointing at 4200 with score -72.5 and loss 0.0\n",
      "Training step: 4301/10000\n",
      "Training step: 4401/10000\n",
      "Checkpointing at 4400 with score -19.5 and loss 0.0\n",
      "Training step: 4501/10000\n",
      "Training step: 4601/10000\n",
      "Checkpointing at 4600 with score 4.0 and loss 0.0\n",
      "Training step: 4701/10000\n",
      "Training step: 4801/10000\n",
      "Checkpointing at 4800 with score -9.0 and loss 0.0\n",
      "Training step: 4901/10000\n",
      "Training step: 5001/10000\n",
      "Checkpointing at 5000 with score -55.0 and loss 0.0\n",
      "Training step: 5101/10000\n",
      "Training step: 5201/10000\n",
      "Checkpointing at 5200 with score -63.0 and loss 0.0\n",
      "Training step: 5301/10000\n",
      "Training step: 5401/10000\n",
      "Checkpointing at 5400 with score 27.0 and loss 0.0\n",
      "Training step: 5501/10000\n",
      "Training step: 5601/10000\n",
      "Checkpointing at 5600 with score 29.5 and loss 0.0\n",
      "Training step: 5701/10000\n",
      "Training step: 5801/10000\n",
      "Checkpointing at 5800 with score -61.0 and loss 0.0\n",
      "Training step: 5901/10000\n",
      "Training step: 6001/10000\n",
      "Checkpointing at 6000 with score 31.0 and loss 0.0\n",
      "Training step: 6101/10000\n",
      "Training step: 6201/10000\n",
      "Checkpointing at 6200 with score 17.5 and loss 0.0\n",
      "Training step: 6301/10000\n",
      "Training step: 6401/10000\n",
      "Checkpointing at 6400 with score 5.0 and loss 0.0\n",
      "Training step: 6501/10000\n",
      "Training step: 6601/10000\n",
      "Checkpointing at 6600 with score -67.5 and loss 0.0\n",
      "Training step: 6701/10000\n",
      "Training step: 6801/10000\n",
      "Checkpointing at 6800 with score -14.5 and loss 0.0\n",
      "Training step: 6901/10000\n",
      "Training step: 7001/10000\n",
      "Checkpointing at 7000 with score -99.5 and loss 0.0\n",
      "Training step: 7101/10000\n",
      "Training step: 7201/10000\n",
      "Checkpointing at 7200 with score -148.5 and loss 0.0\n",
      "Training step: 7301/10000\n",
      "Training step: 7401/10000\n",
      "Checkpointing at 7400 with score -118.5 and loss 0.0\n",
      "Training step: 7501/10000\n",
      "Training step: 7601/10000\n",
      "Checkpointing at 7600 with score -24.5 and loss 0.0\n",
      "Training step: 7701/10000\n",
      "Training step: 7801/10000\n",
      "Checkpointing at 7800 with score -77.0 and loss 0.0\n",
      "Training step: 7901/10000\n",
      "Training step: 8001/10000\n",
      "Checkpointing at 8000 with score -39.0 and loss 0.0\n",
      "Training step: 8101/10000\n",
      "Training step: 8201/10000\n",
      "Checkpointing at 8200 with score -70.0 and loss 0.0\n",
      "Training step: 8301/10000\n",
      "Training step: 8401/10000\n",
      "Checkpointing at 8400 with score -20.5 and loss 0.0\n",
      "Training step: 8501/10000\n",
      "Training step: 8601/10000\n",
      "Checkpointing at 8600 with score -146.5 and loss 0.0\n",
      "Training step: 8701/10000\n",
      "Training step: 8801/10000\n",
      "Checkpointing at 8800 with score -20.5 and loss 0.0\n",
      "Training step: 8901/10000\n",
      "Training step: 9001/10000\n",
      "Checkpointing at 9000 with score -122.0 and loss 0.0\n",
      "Training step: 9101/10000\n",
      "Training step: 9201/10000\n",
      "Checkpointing at 9200 with score -134.5 and loss 0.0\n",
      "Training step: 9301/10000\n",
      "Training step: 9401/10000\n",
      "Checkpointing at 9400 with score -39.5 and loss 0.0\n",
      "Training step: 9501/10000\n",
      "Training step: 9601/10000\n",
      "Checkpointing at 9600 with score 21.0 and loss 0.0\n",
      "Training step: 9701/10000\n",
      "Training step: 9801/10000\n",
      "Checkpointing at 9800 with score -26.0 and loss 0.0\n",
      "Training step: 9901/10000\n",
      "('mlp_6/bias', [1024])\n",
      "('mlp_6/bias_1', [512])\n",
      "('mlp_6/bias_2', [1024])\n",
      "('mlp_6/bias_3', [512])\n",
      "('mlp_6/bias_4', [4])\n",
      "('mlp_6/weights', [16, 1024])\n",
      "('mlp_6/weights_1', [1024, 512])\n",
      "('mlp_6/weights_2', [512, 1024])\n",
      "('mlp_6/weights_3', [1024, 512])\n",
      "('mlp_6/weights_4', [512, 4])\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/10000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/10000000/q_network_pid0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/10000000/avg_network_pid0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/leduc/nfsp/0/10000000/avg_network_pid0\n",
      "2025-04-24 19:58:15.265930: W tensorflow/c/c_api.cc:305] Operation '{name:'mlp_8/weights_4_3/Assign' id:9277 op device:{requested: '', assigned: ''} def:{{{node mlp_8/weights_4_3/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mlp_8/weights_4_3, zeros_179)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_actions:  4\n",
      "float32\n",
      "Parameter containing:\n",
      "tensor([[-0.0061,  0.1451,  0.1814,  ...,  0.2017, -0.1751,  0.0222],\n",
      "        [ 0.1377, -0.1481,  0.1134,  ...,  0.0544, -0.0025, -0.0751],\n",
      "        [ 0.0740, -0.0122, -0.0627,  ..., -0.1409, -0.1177, -0.1074],\n",
      "        ...,\n",
      "        [-0.2233, -0.2277, -0.0231,  ..., -0.0606, -0.1158,  0.2097],\n",
      "        [ 0.1082,  0.1162, -0.1571,  ..., -0.0555, -0.0650,  0.2107],\n",
      "        [ 0.1305, -0.2376, -0.0251,  ..., -0.0503, -0.1969,  0.2250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1546, -0.0836, -0.0927,  0.0264,  0.1944, -0.0382,  0.1115,  0.2015,\n",
      "        -0.0966, -0.0894, -0.0092, -0.2234, -0.0172,  0.1385, -0.1843,  0.1694,\n",
      "         0.0210, -0.1780, -0.1889,  0.2150,  0.1350, -0.2427,  0.1788,  0.0236,\n",
      "         0.0785,  0.1105, -0.0559, -0.0889, -0.2432,  0.2020,  0.1387,  0.0326,\n",
      "         0.1941, -0.0332,  0.2218, -0.0347,  0.2221, -0.1545, -0.1655,  0.1417,\n",
      "        -0.1012,  0.1012,  0.0219,  0.1126,  0.1963, -0.0359,  0.1889, -0.2277,\n",
      "        -0.0110,  0.2437,  0.1416, -0.2149,  0.0146,  0.2343,  0.1668,  0.0467,\n",
      "         0.1310,  0.2039,  0.1170, -0.1891,  0.0374, -0.1756,  0.1901, -0.1620,\n",
      "         0.0864,  0.2283, -0.1085, -0.1298, -0.0269, -0.0925,  0.0290,  0.1872,\n",
      "         0.1898,  0.0755, -0.0083,  0.0735,  0.0981, -0.0257,  0.1275,  0.1022,\n",
      "        -0.0221,  0.1439, -0.2357,  0.0835,  0.1701, -0.2348,  0.1877,  0.1665,\n",
      "        -0.1889, -0.1599,  0.1210, -0.2426,  0.0460, -0.2059,  0.1172,  0.2401,\n",
      "        -0.0546,  0.1090, -0.1705,  0.1600, -0.2422, -0.0523,  0.2460,  0.0659,\n",
      "        -0.0854, -0.1777,  0.0299,  0.0063, -0.0945,  0.0092, -0.2040,  0.1894,\n",
      "         0.1824, -0.2451, -0.0121,  0.0890,  0.1354,  0.0096, -0.0860, -0.2487,\n",
      "        -0.2039,  0.2067, -0.1563, -0.2114,  0.2006,  0.0831,  0.0938,  0.2391],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.1250, 0.1250], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0315, -0.0425, -0.0658,  ..., -0.0100,  0.0786,  0.0386],\n",
      "        [-0.0226, -0.0464,  0.0884,  ...,  0.0279, -0.0483,  0.0780],\n",
      "        [ 0.0802, -0.0051, -0.0413,  ...,  0.0376, -0.0750,  0.0048],\n",
      "        ...,\n",
      "        [-0.0181, -0.0544, -0.0134,  ...,  0.0272, -0.0332, -0.0808],\n",
      "        [-0.0231, -0.0002,  0.0058,  ..., -0.0488,  0.0860,  0.0356],\n",
      "        [ 0.0552, -0.0400,  0.0377,  ..., -0.0337,  0.0232,  0.0707]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0058, -0.0417, -0.0797, -0.0431, -0.0397, -0.0471, -0.0576, -0.0074,\n",
      "        -0.0499,  0.0404, -0.0848, -0.0751, -0.0683,  0.0398,  0.0608,  0.0336,\n",
      "        -0.0194, -0.0492,  0.0493,  0.0542,  0.0403,  0.0034, -0.0473, -0.0845,\n",
      "        -0.0512,  0.0243,  0.0304, -0.0653, -0.0728,  0.0837, -0.0061,  0.0050,\n",
      "        -0.0262, -0.0041,  0.0562, -0.0213, -0.0229, -0.0240,  0.0340,  0.0848,\n",
      "         0.0065,  0.0662, -0.0408,  0.0875, -0.0782,  0.0838, -0.0291, -0.0450,\n",
      "         0.0638, -0.0578,  0.0372,  0.0013, -0.0196,  0.0193,  0.0801,  0.0584,\n",
      "         0.0663, -0.0796,  0.0125,  0.0631, -0.0884,  0.0873,  0.0558, -0.0408,\n",
      "         0.0648, -0.0428, -0.0382,  0.0142, -0.0246, -0.0181,  0.0215,  0.0111,\n",
      "        -0.0683,  0.0038, -0.0047, -0.0748, -0.0242,  0.0175,  0.0604,  0.0824,\n",
      "        -0.0709,  0.0879, -0.0272, -0.0502, -0.0465,  0.0533,  0.0391, -0.0790,\n",
      "        -0.0791,  0.0026,  0.0130,  0.0180, -0.0528,  0.0072, -0.0277, -0.0501,\n",
      "        -0.0732, -0.0208,  0.0133, -0.0745, -0.0434,  0.0700,  0.0465,  0.0121,\n",
      "         0.0475,  0.0341, -0.0554, -0.0807, -0.0561, -0.0433,  0.0285,  0.0450,\n",
      "        -0.0249, -0.0133,  0.0024,  0.0856, -0.0040, -0.0347, -0.0157, -0.0778,\n",
      "        -0.0279,  0.0162, -0.0388, -0.0485,  0.0861,  0.0416, -0.0702, -0.0501],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0321,  0.0781,  0.0141,  ..., -0.0709,  0.0548, -0.0137],\n",
      "        [-0.0474,  0.0697, -0.0089,  ...,  0.0449,  0.0626,  0.0352],\n",
      "        [-0.0036, -0.0655,  0.0267,  ..., -0.0507, -0.0064, -0.0520],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0532, -0.0141,  ..., -0.0352,  0.0602,  0.0370],\n",
      "        [-0.0465, -0.0180,  0.0453,  ...,  0.0529,  0.0045,  0.0223],\n",
      "        [-0.0020,  0.0227,  0.0486,  ..., -0.0055,  0.0222,  0.0096]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0053,  0.0081,  0.0476,  0.0273,  0.0470, -0.0781,  0.0788, -0.0559,\n",
      "         0.0762,  0.0104,  0.0121,  0.0778, -0.0590, -0.0289,  0.0613,  0.0164,\n",
      "         0.0295, -0.0616,  0.0069,  0.0045,  0.0748, -0.0481, -0.0025,  0.0691,\n",
      "        -0.0005, -0.0576,  0.0373, -0.0434, -0.0822,  0.0330,  0.0592,  0.0755,\n",
      "         0.0355, -0.0592,  0.0407,  0.0416,  0.0211, -0.0562, -0.0432, -0.0067,\n",
      "        -0.0786,  0.0081, -0.0181, -0.0350,  0.0504,  0.0832,  0.0797, -0.0785,\n",
      "         0.0021, -0.0714, -0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0831,  0.0247, -0.0319,  ..., -0.0808, -0.0417,  0.0714],\n",
      "        [-0.0610,  0.0602, -0.0881,  ..., -0.0627, -0.0138,  0.0363],\n",
      "        [-0.0374,  0.0332,  0.0851,  ...,  0.0305, -0.0364,  0.0003],\n",
      "        ...,\n",
      "        [ 0.0828,  0.0021,  0.0863,  ..., -0.0255,  0.0587,  0.0089],\n",
      "        [-0.0749,  0.0445,  0.0008,  ..., -0.0818, -0.0237, -0.0549],\n",
      "        [-0.0436,  0.0206,  0.0146,  ..., -0.0763,  0.0219, -0.0329]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        ...,\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442],\n",
      "        [0.0442, 0.0442, 0.0442,  ..., 0.0442, 0.0442, 0.0442]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0273, -0.0255,  0.0118, -0.0597, -0.0188,  0.0204, -0.0406,  0.0617,\n",
      "        -0.0028,  0.0465,  0.0540,  0.0707, -0.0378, -0.0376,  0.0758, -0.0746,\n",
      "        -0.0491, -0.0789, -0.0195,  0.0169,  0.0733,  0.0756, -0.0245, -0.0064,\n",
      "        -0.0051, -0.0721, -0.0678,  0.0474,  0.0368, -0.0334,  0.0370, -0.0801,\n",
      "        -0.0154,  0.0856,  0.0120,  0.0129, -0.0715, -0.0398,  0.0719,  0.0356,\n",
      "         0.0355,  0.0594, -0.0834,  0.0513, -0.0861, -0.0346,  0.0039,  0.0482,\n",
      "         0.0618,  0.0341,  0.0119,  0.0181, -0.0830,  0.0754,  0.0853,  0.0300,\n",
      "        -0.0161, -0.0214,  0.0757, -0.0336,  0.0367,  0.0142,  0.0628, -0.0122,\n",
      "        -0.0101,  0.0852, -0.0726,  0.0038,  0.0049, -0.0498,  0.0379, -0.0792,\n",
      "        -0.0575, -0.0757,  0.0099,  0.0829, -0.0252, -0.0239, -0.0349, -0.0281,\n",
      "         0.0304,  0.0553,  0.0015,  0.0641, -0.0320,  0.0127,  0.0578,  0.0249,\n",
      "        -0.0027,  0.0610,  0.0344, -0.0174,  0.0627, -0.0019, -0.0874, -0.0333,\n",
      "         0.0790,  0.0688,  0.0495, -0.0159,  0.0550,  0.0099, -0.0794,  0.0616,\n",
      "         0.0281, -0.0478,  0.0426, -0.0344,  0.0424, -0.0359, -0.0763,  0.0341,\n",
      "         0.0519, -0.0226,  0.0189,  0.0290,  0.0817,  0.0795,  0.0383,  0.0477,\n",
      "         0.0288, -0.0095, -0.0613,  0.0506, -0.0742, -0.0020, -0.0772,  0.0661,\n",
      "         0.0008,  0.0270,  0.0580, -0.0275, -0.0382, -0.0061,  0.0182,  0.0008,\n",
      "        -0.0829,  0.0174, -0.0323,  0.0543,  0.0203, -0.0816, -0.0574, -0.0016,\n",
      "        -0.0454,  0.0696,  0.0615,  0.0063, -0.0491, -0.0857, -0.0661,  0.0435,\n",
      "         0.0744, -0.0245, -0.0256,  0.0623, -0.0843,  0.0821, -0.0303,  0.0282,\n",
      "        -0.0181, -0.0474,  0.0638, -0.0293, -0.0180,  0.0271,  0.0370, -0.0382,\n",
      "         0.0516,  0.0691,  0.0215, -0.0384, -0.0736, -0.0731, -0.0571,  0.0544,\n",
      "        -0.0174, -0.0056,  0.0673, -0.0509, -0.0545, -0.0207,  0.0675,  0.0749,\n",
      "         0.0369, -0.0507,  0.0226,  0.0872,  0.0102, -0.0648, -0.0687, -0.0861,\n",
      "         0.0604,  0.0511, -0.0464,  0.0420,  0.0808,  0.0176, -0.0172, -0.0677,\n",
      "        -0.0387,  0.0240, -0.0616, -0.0057], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442], requires_grad=True)\n",
      "Resuming training at step 1 / 10000\n",
      "replay buffer size: 0\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 0 / (32)\n",
      "filling replay buffer: 1 / (32)\n",
      "filling replay buffer: 2 / (32)\n",
      "filling replay buffer: 3 / (32)\n",
      "filling replay buffer: 4 / (32)\n",
      "filling replay buffer: 5 / (32)\n",
      "filling replay buffer: 6 / (32)\n",
      "filling replay buffer: 7 / (32)\n",
      "filling replay buffer: 8 / (32)\n",
      "filling replay buffer: 9 / (32)\n",
      "filling replay buffer: 10 / (32)\n",
      "filling replay buffer: 11 / (32)\n",
      "filling replay buffer: 12 / (32)\n",
      "filling replay buffer: 13 / (32)\n",
      "filling replay buffer: 14 / (32)\n",
      "filling replay buffer: 15 / (32)\n",
      "filling replay buffer: 16 / (32)\n",
      "filling replay buffer: 17 / (32)\n",
      "filling replay buffer: 18 / (32)\n",
      "filling replay buffer: 19 / (32)\n",
      "filling replay buffer: 20 / (32)\n",
      "filling replay buffer: 21 / (32)\n",
      "filling replay buffer: 22 / (32)\n",
      "filling replay buffer: 23 / (32)\n",
      "filling replay buffer: 24 / (32)\n",
      "filling replay buffer: 25 / (32)\n",
      "filling replay buffer: 26 / (32)\n",
      "filling replay buffer: 27 / (32)\n",
      "filling replay buffer: 28 / (32)\n",
      "filling replay buffer: 29 / (32)\n",
      "filling replay buffer: 30 / (32)\n",
      "filling replay buffer: 31 / (32)\n",
      "Training step: 1/10000\n",
      "Checkpointing at 0 with score -32.857142857142854 and loss 8.95740520954132\n",
      "Training step: 101/10000\n",
      "Training step: 201/10000\n",
      "Checkpointing at 200 with score -125.5 and loss 0.000176244429894723\n",
      "Training step: 301/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 173\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mprint\u001b[39m(param)\n\u001b[0;32m--> 173\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/../dqn/rainbow/rainbow_agent.py:434\u001b[0m, in \u001b[0;36mRainbowAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m action \u001b[38;5;241m=\u001b[39m epsilon_greedy_policy(\n\u001b[1;32m    424\u001b[0m     values,\n\u001b[1;32m    425\u001b[0m     info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m     )\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# print(\"Action\", action)\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# print(\"Epislon Greedy Epsilon\", self.eg_epsilon)\u001b[39;00m\n\u001b[1;32m    433\u001b[0m next_state, reward, terminated, truncated, next_info \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m )\n\u001b[1;32m    436\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# print(\"State\", state)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/DeepCFR/cfr_utils.py:545\u001b[0m, in \u001b[0;36mNFSPEvalWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mis_terminal() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminal:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcurrent_player() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplayer_id:\n\u001b[0;32m--> 545\u001b[0m         construct \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m         action, probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mstep(construct, is_evaluation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    547\u001b[0m         obs_mask, rew, terminal, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/copy.py:261\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    259\u001b[0m     state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 261\u001b[0m     \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from agent_configs import RainbowConfig\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from utils.utils import HuberLoss\n",
    "from cfr_utils import (\n",
    "    EvalWrapper,\n",
    "    evaluatebots,\n",
    "    WrapperEnv,\n",
    "    load_agents,\n",
    "    EmptyConf,\n",
    "    NFSPWrapper,\n",
    "    NFSPEvalWrapper,\n",
    "    LoadNFSPAgent,\n",
    ")\n",
    "import pyspiel\n",
    "import copy\n",
    "from agent_configs.cfr_config import CFRConfig\n",
    "from active_player import ActivePlayer\n",
    "from cfr_agent import CFRAgent\n",
    "from cfr_network import CFRNetwork\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import open_spiel.python.algorithms.nfsp\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "num_players = 2\n",
    "max_nodes = 10000000\n",
    "\n",
    "fhp = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 4,\n",
    "        \"numRanks\": 13,\n",
    "        \"numHoleCards\": 2,\n",
    "        \"numBoardCards\": \"0 3\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leduc = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "leducconfig = {\"state_representation_size\": 16}\n",
    "fhpconfig = {\"state_representation_size\": 108}\n",
    "leducgame = NFSPWrapper(leduc)\n",
    "fhpgame = NFSPWrapper(fhp)\n",
    "\n",
    "active_player_obj = ActivePlayer(2)\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [128, 128],\n",
    "    \"value_hidden_layer_widths\": [128],\n",
    "    \"advantage_hidden_layer_widths\": [128],\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"training_steps\": 10000,\n",
    "    \"minibatch_size\": 32,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"min_replay_buffer_size\": 32,\n",
    "    \"transfer_interval\": 1280,\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"replay_interval\": 64,\n",
    "    \"eg_epsilon\": 1,\n",
    "    \"eg_epsilon_final\": 0.0,\n",
    "    \"eg_epsilon_final_step\": 2000,\n",
    "    \"eg_epsilon_decay_type\": \"linear\",\n",
    "    \"num_minibatches\": 4,\n",
    "    \"atom_size\": 1,\n",
    "    \"noisy_sigma\": 0.0,\n",
    "    \"per_beta\": 0.0,\n",
    "    \"per_alpha\": 0.0,\n",
    "    \"per_beta_final\": 0.0,\n",
    "    \"n_step\": 1,\n",
    "}\n",
    "gameconfig = EmptyConf()\n",
    "config = RainbowConfig(config_dict, gameconfig)\n",
    "config.v_min = -1200\n",
    "config.v_max = 1200\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "\n",
    "mainpath1 = \"./checkpoints/fhp/nfsp/0/1000002/\"\n",
    "mainpath2 = \"./checkpoints/fhp/nfsp/0/4000001/\"\n",
    "mainpath3 = \"./checkpoints/fhp/nfsp/0/7000001/\"\n",
    "mainpath4 = \"./checkpoints/fhp/nfsp/0/8000000/\"\n",
    "mainpath5 = \"./checkpoints/fhp/nfsp/0/10000000/\"\n",
    "mainpath6 = \"./checkpoints/leduc/nfsp/0/1000000/\"\n",
    "mainpath7 = \"./checkpoints/leduc/nfsp/0/4000001/\"\n",
    "mainpath8 = \"./checkpoints/leduc/nfsp/0/7000001/\"\n",
    "mainpath9 = \"./checkpoints/leduc/nfsp/0/8000000/\"\n",
    "mainpath10 = \"./checkpoints/leduc/nfsp/0/10000000/\"\n",
    "\n",
    "leduc_agent_paths = [\n",
    "    mainpath6,\n",
    "    mainpath7,\n",
    "    mainpath8,\n",
    "    mainpath9,\n",
    "    mainpath10,\n",
    "]\n",
    "fhp_agent_paths = [\n",
    "    mainpath1,\n",
    "    mainpath2,\n",
    "    mainpath3,\n",
    "    mainpath4,\n",
    "    mainpath5,\n",
    "]\n",
    "\n",
    "nodes = 0\n",
    "games = [leducgame, fhpgame]\n",
    "for i in games:\n",
    "    if i == leducgame:\n",
    "        agent_paths = leduc_agent_paths\n",
    "        game_string = \"leduc\"\n",
    "    else:\n",
    "        agent_paths = fhp_agent_paths\n",
    "        game_string = \"fhp\"\n",
    "    for number in range(len(agent_paths)):\n",
    "        i.reset()\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            agent = open_spiel.python.algorithms.nfsp.NFSP(\n",
    "                session=sess,\n",
    "                player_id=0,\n",
    "                state_representation_size=(\n",
    "                    leducconfig[\"state_representation_size\"]\n",
    "                    if i == leducgame\n",
    "                    else fhpconfig[\"state_representation_size\"]\n",
    "                ),\n",
    "                num_actions=4,\n",
    "                hidden_layers_sizes=[1024, 512, 1024, 512],\n",
    "                reservoir_buffer_capacity=30000000,\n",
    "                anticipatory_param=0,\n",
    "                batch_size=256,\n",
    "                rl_learning_rate=0.1,\n",
    "                sl_learning_rate=0.01,\n",
    "                min_buffer_size_to_learn=1000,\n",
    "                learn_every=256,\n",
    "                optimizer_str=\"sgd\",\n",
    "                replay_buffer_capacity=600000,\n",
    "                epsilon_start=0.08,\n",
    "                epsilon_end=0,\n",
    "            )\n",
    "            LoadNFSPAgent(agent_paths[number], agent, 0)\n",
    "            agent.restore(agent_paths[number])  # IF YOU HAVE A NFSP AGENT PATH\n",
    "            # agent.restore(path1) # IF YOU HAVE A NFSP AGENT PATH\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            wrapped = NFSPEvalWrapper(i, agent, 16, 4)\n",
    "            model_name = \"Deuling_\" + game_string + \"_agent_\" + str(number)\n",
    "            evaluator = RainbowAgent(wrapped, config, name=model_name, device=device)\n",
    "            evaluator.checkpoint_interval = 200\n",
    "\n",
    "            for param in evaluator.model.parameters():\n",
    "                print(param)\n",
    "            evaluator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
