{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "init_setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "\n",
                "sys.path.append(\"../../\")\n",
                "import time\n",
                "import torch\n",
                "from losses.basic_losses import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
                "from agents.random import RandomAgent\n",
                "from agents.muzero import MuZeroAgent\n",
                "from agent_configs.muzero_config import MuZeroConfig\n",
                "from game_configs.tictactoe_config import TicTacToeConfig\n",
                "from agents.tictactoe_expert import TicTacToeBestAgent\n",
                "from modules.world_models.muzero_world_model import MuzeroWorldModel\n",
                "\n",
                "# Ensure we use CPU for fairness/comparibility or GPU if available\n",
                "device = \"cpu\"  # or \"cuda\" if available\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "muzero_benchmark",
            "metadata": {},
            "source": [
                "# MuZero Benchmark (Iterative vs Batched)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "09299485",
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"num_simulations\": 25,\n",
                "    \"per_alpha\": 0.0,\n",
                "    \"per_beta\": 0.0,\n",
                "    \"per_beta_final\": 0.0,\n",
                "    \"n_step\": 10,\n",
                "    \"root_dirichlet_alpha\": 0.25,\n",
                "    \"residual_layers\": [(24, 3, 1)],\n",
                "    \"reward_dense_layer_widths\": [],\n",
                "    \"reward_conv_layers\": [(16, 1, 1)],\n",
                "    \"actor_dense_layer_widths\": [],\n",
                "    \"actor_conv_layers\": [(16, 1, 1)],\n",
                "    \"critic_dense_layer_widths\": [],\n",
                "    \"critic_conv_layers\": [(16, 1, 1)],\n",
                "    \"to_play_dense_layer_widths\": [],\n",
                "    \"to_play_conv_layers\": [(16, 1, 1)],\n",
                "    \"known_bounds\": [-1, 1],\n",
                "    \"support_range\": None,\n",
                "    \"minibatch_size\": 8,\n",
                "    \"replay_buffer_size\": 100000,\n",
                "    \"gumbel\": False,\n",
                "    \"gumbel_m\": 16,\n",
                "    \"policy_loss_function\": CategoricalCrossentropyLoss(),\n",
                "    \"training_steps\": 20000,  # Reduced for benchmark speed\n",
                "    \"transfer_interval\": 1,\n",
                "    \"num_workers\": 4,\n",
                "    \"world_model_cls\": MuzeroWorldModel,\n",
                "    \"search_batch_size\": 0,  # Iterative\n",
                "    \"use_virtual_mean\": False,\n",
                "    \"virtual_loss\": 3.0,\n",
                "    \"use_torch_compile\": True,\n",
                "    \"use_mixed_precision\": True,\n",
                "    \"use_quantization\": False,\n",
                "}\n",
                "\n",
                "game_config = TicTacToeConfig()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a8cbfbda",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Running MuZero Batched Search Max Fast ---\n",
                        "Using default save_intermediate_weights     : False\n",
                        "Using         training_steps                : 20000\n",
                        "Using default adam_epsilon                  : 1e-08\n",
                        "Using default momentum                      : 0.9\n",
                        "Using default learning_rate                 : 0.001\n",
                        "Using default clipnorm                      : 0\n",
                        "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
                        "Using default weight_decay                  : 0.0\n",
                        "Using default num_minibatches               : 1\n",
                        "Using default training_iterations           : 1\n",
                        "Using default lr_schedule_type              : none\n",
                        "Using default lr_schedule_steps             : []\n",
                        "Using default lr_schedule_steps             : []\n",
                        "Using default lr_schedule_values            : []\n",
                        "Using         use_mixed_precision           : False\n",
                        "Using         use_torch_compile             : True\n",
                        "Using default compile_mode                  : reduce-overhead\n",
                        "Using         minibatch_size                : 8\n",
                        "Using         replay_buffer_size            : 100000\n",
                        "Using default min_replay_buffer_size        : 8\n",
                        "Using         n_step                        : 10\n",
                        "Using default discount_factor               : 0.99\n",
                        "Using         per_alpha                     : 0.0\n",
                        "Using         per_beta                      : 0.0\n",
                        "Using         per_beta_final                : 0.0\n",
                        "Using default per_epsilon                   : 1e-06\n",
                        "Using default per_use_batch_weights         : False\n",
                        "Using default per_use_initial_max_priority  : True\n",
                        "Using default loss_function                 : <class 'losses.basic_losses.MSELoss'>\n",
                        "Using default activation                    : relu\n",
                        "Using         kernel_initializer            : None\n",
                        "Using         prob_layer_initializer        : None\n",
                        "Using default norm_type                     : none\n",
                        "Using default soft_update                   : False\n",
                        "Using default min_max_epsilon               : 0.01\n",
                        "Using         world_model_cls               : <class 'modules.world_models.muzero_world_model.MuzeroWorldModel'>\n",
                        "Using         known_bounds                  : [-1, 1]\n",
                        "Using         residual_layers               : [(24, 3, 1)]\n",
                        "Using default conv_layers                   : []\n",
                        "Using default dense_layer_widths            : []\n",
                        "Using default representation_residual_layers: [(24, 3, 1)]\n",
                        "Using default representation_conv_layers    : []\n",
                        "Using default representation_dense_layer_widths: []\n",
                        "Using default dynamics_residual_layers      : [(24, 3, 1)]\n",
                        "Using default dynamics_conv_layers          : []\n",
                        "Using default dynamics_dense_layer_widths   : []\n",
                        "Using         reward_conv_layers            : [(16, 1, 1)]\n",
                        "Using         reward_dense_layer_widths     : []\n",
                        "Using         to_play_conv_layers           : [(16, 1, 1)]\n",
                        "Using         to_play_dense_layer_widths    : []\n",
                        "Using         critic_conv_layers            : [(16, 1, 1)]\n",
                        "Using         critic_dense_layer_widths     : []\n",
                        "Using         actor_conv_layers             : [(16, 1, 1)]\n",
                        "Using         actor_dense_layer_widths      : []\n",
                        "Using default noisy_sigma                   : 0.0\n",
                        "Using default games_per_generation          : 100\n",
                        "Using default value_loss_factor             : 1.0\n",
                        "Using default to_play_loss_factor           : 1.0\n",
                        "Using         num_simulations               : 25\n",
                        "Using         search_batch_size             : 5\n",
                        "Using         use_virtual_mean              : True\n",
                        "Using         virtual_loss                  : 3.0\n",
                        "Using         root_dirichlet_alpha          : 0.25\n",
                        "Using default root_exploration_fraction     : 0.25\n",
                        "Using default root_dirichlet_alpha_adaptive : False\n",
                        "Using         gumbel                        : False\n",
                        "Using         gumbel_m                      : 16\n",
                        "Using default gumbel_cvisit                 : 50\n",
                        "Using default gumbel_cscale                 : 1.0\n",
                        "Using default pb_c_base                     : 19652\n",
                        "Using default pb_c_init                     : 1.25\n",
                        "Using default temperatures                  : [1.0, 0.0]\n",
                        "Using default temperature_updates           : [5]\n",
                        "Using default temperature_with_training_steps: False\n",
                        "Using default clip_low_prob                 : 0.0\n",
                        "Using default value_loss_function           : <losses.basic_losses.MSELoss object at 0x375427700>\n",
                        "Using default reward_loss_function          : <losses.basic_losses.MSELoss object at 0x375427cd0>\n",
                        "Using         policy_loss_function          : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x3754265c0>\n",
                        "Using default to_play_loss_function         : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x375427d00>\n",
                        "Using default unroll_steps                  : 5\n",
                        "Using default atom_size                     : 1\n",
                        "Using         support_range                 : None\n",
                        "Using default multi_process                 : True\n",
                        "Using         num_workers                   : 4\n",
                        "Using default lr_ratio                      : inf\n",
                        "Using         transfer_interval             : 100\n",
                        "Using default reanalyze_ratio               : 0.0\n",
                        "Using         use_quantization              : True\n",
                        "Using default reanalyze_method              : mcts\n",
                        "Using default reanalyze_tau                 : 0.3\n",
                        "Using default injection_frac                : 0.0\n",
                        "Using default reanalyze_noise               : False\n",
                        "Using default reanalyze_update_priorities   : False\n",
                        "Using default consistency_loss_factor       : 0.0\n",
                        "Using default projector_output_dim          : 128\n",
                        "Using default projector_hidden_dim          : 128\n",
                        "Using default predictor_output_dim          : 128\n",
                        "Using default predictor_hidden_dim          : 64\n",
                        "Using default mask_absorbing                : True\n",
                        "Using default value_prefix                  : False\n",
                        "Using default lstm_horizon_len              : 5\n",
                        "Using default lstm_hidden_size              : 64\n",
                        "Using default q_estimation_method           : v_mix\n",
                        "Using default stochastic                    : False\n",
                        "Using default use_true_chance_codes         : False\n",
                        "Using default num_chance                    : 32\n",
                        "Using default sigma_loss                    : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x375427ee0>\n",
                        "Using default afterstate_residual_layers    : [(24, 3, 1)]\n",
                        "Using default afterstate_conv_layers        : []\n",
                        "Using default afterstate_dense_layer_widths : []\n",
                        "Using default chance_conv_layers            : [(32, 3, 1)]\n",
                        "Using default chance_dense_layer_widths     : [256]\n",
                        "Using default vqvae_commitment_cost_factor  : 1.0\n",
                        "Using default action_embedding_dim          : 32\n",
                        "Using default single_action_plane           : False\n",
                        "Using default latent_viz_method             : umap\n",
                        "Using default latent_viz_interval           : 10\n",
                        "[muzero_batched_bench_fast] Using device: cpu\n",
                        "Observation dimensions: torch.Size([9, 3, 3])\n",
                        "Num actions: 9 (Discrete: True)\n",
                        "Making test env...\n",
                        "Test env configured for video recording.\n",
                        "MARL Agent 'muzero_batched_bench_fast' initialized. Test agents: ['random', 'tictactoe_expert']\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "Max size: 100000\n",
                        "Initializing stat 'score' with subkeys None\n",
                        "Initializing stat 'policy_loss' with subkeys None\n",
                        "Initializing stat 'value_loss' with subkeys None\n",
                        "Initializing stat 'reward_loss' with subkeys None\n",
                        "Initializing stat 'to_play_loss' with subkeys None\n",
                        "Initializing stat 'cons_loss' with subkeys None\n",
                        "Initializing stat 'loss' with subkeys None\n",
                        "Initializing stat 'test_score' with subkeys ['score', 'max_score', 'min_score']\n",
                        "Initializing stat 'episode_length' with subkeys None\n",
                        "Initializing stat 'policy_entropy' with subkeys None\n",
                        "Initializing stat 'value_diff' with subkeys None\n",
                        "Initializing stat 'policy_improvement' with subkeys ['network', 'search']\n",
                        "Initializing stat 'root_children_values' with subkeys None\n",
                        "Initializing stat 'test_score_vs_random' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
                        "Initializing stat 'test_score_vs_tictactoe_expert' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
                        "Compiling models in train()...\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "[Worker 1] Starting self-play...\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "Hidden state shape: (8, 24, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "encoder input shape (8, 18, 3, 3)\n",
                        "[Worker 0] Starting self-play...\n",
                        "[Worker 3] Starting self-play...\n",
                        "[Worker 2] Starting self-play...\n",
                        "Started recording episode 0 to ./videos/muzero_batched_bench_fast/3/episode_000000.mp4Started recording episode 0 to ./videos/muzero_batched_bench_fast/2/episode_000000.mp4\n",
                        "\n",
                        "Started recording episode 0 to ./videos/muzero_batched_bench_fast/0/episode_000000.mp4Started recording episode 0 to ./videos/muzero_batched_bench_fast/1/episode_000000.mp4\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 368, in worker_fn\n",
                        "    score, num_steps = self.play_game(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 1057, in play_game\n",
                        "    prediction = self.predict(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 997, in predict\n",
                        "    self.search.run(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../search/modular_search.py\", line 70, in run\n",
                        "    outputs = inference_fns[\"initial\"](state, model=inference_model)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 926, in predict_initial_inference\n",
                        "    values, policies, hidden_states = model.initial_inference(state_inputs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 284, in initial_inference\n",
                        "    value, policy = self.prediction(hidden_state)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 62, in forward\n",
                        "    return self.head(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 40, in forward\n",
                        "    return self.critic(S), self.actor(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/critic.py\", line 32, in forward\n",
                        "    return self.head(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/heads.py\", line 99, in forward\n",
                        "    x = self.output_layer(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/dense.py\", line 20, in forward\n",
                        "    return self.layer(inputs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py\", line 58, in forward\n",
                        "    Y = torch.ops.quantized.linear_dynamic(\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/_ops.py\", line 1255, in __call__\n",
                        "    return self._op(*args, **kwargs)\n",
                        "RuntimeError: Quantize only works on Float Tensor, got BFloat16\n",
                        "\n",
                        "Stopped recording episode 0. Recorded 1 frames.\n",
                        "Stopped recording episode 0. Recorded 1 frames.\n",
                        "Stopped recording episode 0. Recorded 1 frames.\n",
                        "Stopped recording episode 0. Recorded 1 frames.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[W127 10:57:33.539002000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
                        "[W127 10:57:33.539117000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
                        "[W127 10:57:33.539518000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
                        "[W127 10:57:33.539764000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
                        "Process Process-4:\n",
                        "Process Process-2:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Process Process-3:\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 368, in worker_fn\n",
                        "    score, num_steps = self.play_game(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 1057, in play_game\n",
                        "    prediction = self.predict(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 997, in predict\n",
                        "    self.search.run(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../search/modular_search.py\", line 70, in run\n",
                        "    outputs = inference_fns[\"initial\"](state, model=inference_model)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 926, in predict_initial_inference\n",
                        "    values, policies, hidden_states = model.initial_inference(state_inputs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 284, in initial_inference\n",
                        "    value, policy = self.prediction(hidden_state)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 62, in forward\n",
                        "    return self.head(S)\n",
                        "Process Process-1:\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 40, in forward\n",
                        "    return self.critic(S), self.actor(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/critic.py\", line 32, in forward\n",
                        "    return self.head(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/heads.py\", line 99, in forward\n",
                        "    x = self.output_layer(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/dense.py\", line 20, in forward\n",
                        "    return self.layer(inputs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py\", line 58, in forward\n",
                        "    Y = torch.ops.quantized.linear_dynamic(\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/_ops.py\", line 1255, in __call__\n",
                        "    return self._op(*args, **kwargs)\n",
                        "RuntimeError: Quantize only works on Float Tensor, got BFloat16\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 368, in worker_fn\n",
                        "    score, num_steps = self.play_game(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 1057, in play_game\n",
                        "    prediction = self.predict(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 997, in predict\n",
                        "    self.search.run(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../search/modular_search.py\", line 70, in run\n",
                        "    outputs = inference_fns[\"initial\"](state, model=inference_model)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 926, in predict_initial_inference\n",
                        "    values, policies, hidden_states = model.initial_inference(state_inputs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 284, in initial_inference\n",
                        "    value, policy = self.prediction(hidden_state)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 62, in forward\n",
                        "    return self.head(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 40, in forward\n",
                        "    return self.critic(S), self.actor(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/critic.py\", line 32, in forward\n",
                        "    return self.head(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/heads.py\", line 99, in forward\n",
                        "    x = self.output_layer(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/dense.py\", line 20, in forward\n",
                        "    return self.layer(inputs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py\", line 58, in forward\n",
                        "    Y = torch.ops.quantized.linear_dynamic(\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/_ops.py\", line 1255, in __call__\n",
                        "    return self._op(*args, **kwargs)\n",
                        "RuntimeError: Quantize only works on Float Tensor, got BFloat16\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 368, in worker_fn\n",
                        "    score, num_steps = self.play_game(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 1057, in play_game\n",
                        "    prediction = self.predict(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 997, in predict\n",
                        "    self.search.run(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../search/modular_search.py\", line 70, in run\n",
                        "    outputs = inference_fns[\"initial\"](state, model=inference_model)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 926, in predict_initial_inference\n",
                        "    values, policies, hidden_states = model.initial_inference(state_inputs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 284, in initial_inference\n",
                        "    value, policy = self.prediction(hidden_state)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 62, in forward\n",
                        "    return self.head(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 40, in forward\n",
                        "    return self.critic(S), self.actor(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/critic.py\", line 32, in forward\n",
                        "    return self.head(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/heads.py\", line 99, in forward\n",
                        "    x = self.output_layer(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/dense.py\", line 20, in forward\n",
                        "    return self.layer(inputs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py\", line 58, in forward\n",
                        "    Y = torch.ops.quantized.linear_dynamic(\n",
                        "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/_ops.py\", line 1255, in __call__\n",
                        "    return self._op(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 368, in worker_fn\n",
                        "    score, num_steps = self.play_game(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 1057, in play_game\n",
                        "    prediction = self.predict(\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 997, in predict\n",
                        "    self.search.run(\n",
                        "RuntimeError: Quantize only works on Float Tensor, got BFloat16\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../search/modular_search.py\", line 70, in run\n",
                        "    outputs = inference_fns[\"initial\"](state, model=inference_model)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py\", line 926, in predict_initial_inference\n",
                        "    values, policies, hidden_states = model.initial_inference(state_inputs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 284, in initial_inference\n",
                        "    value, policy = self.prediction(hidden_state)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 62, in forward\n",
                        "    return self.head(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/agent_nets/muzero.py\", line 40, in forward\n",
                        "    return self.critic(S), self.actor(S)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/critic.py\", line 32, in forward\n",
                        "    return self.head(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/heads.py\", line 99, in forward\n",
                        "    x = self.output_layer(x)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/dense.py\", line 20, in forward\n",
                        "    return self.layer(inputs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
                        "    return self._call_impl(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
                        "    return forward_call(*args, **kwargs)\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py\", line 58, in forward\n",
                        "    Y = torch.ops.quantized.linear_dynamic(\n",
                        "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/_ops.py\", line 1255, in __call__\n",
                        "    return self._op(*args, **kwargs)\n",
                        "RuntimeError: Quantize only works on Float Tensor, got BFloat16\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "Quantize only works on Float Tensor, got BFloat16",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m agent_batch\u001b[38;5;241m.\u001b[39mtest_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     27\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 28\u001b[0m \u001b[43magent_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMuZero Batched Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../agents/muzero.py:451\u001b[0m, in \u001b[0;36mMuZeroAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;66;03m# Re-raise the *exact same* exception type with traceback\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tb))  \u001b[38;5;66;03m# optional: print worker traceback\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mdrain_queue()\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_process:\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Quantize only works on Float Tensor, got BFloat16"
                    ]
                }
            ],
            "source": [
                "print(\"--- Running MuZero Batched Search Max Fast ---\")\n",
                "params_batched = params.copy()\n",
                "params_batched[\"num_workers\"] = 4\n",
                "params_batched[\"search_batch_size\"] = 5\n",
                "params_batched[\"use_virtual_mean\"] = True\n",
                "params_batched[\"use_mixed_precision\"] = False\n",
                "params_batched[\"use_torch_compile\"] = True\n",
                "params_batched[\"use_quantization\"] = True\n",
                "params_batched[\"transfer_interval\"] = 100\n",
                "\n",
                "# params_batched[\"num_envs_per_worker\"] = 4\n",
                "\n",
                "env_batch = TicTacToeConfig().make_env()\n",
                "config_batch = MuZeroConfig(config_dict=params_batched, game_config=game_config)\n",
                "\n",
                "agent_batch = MuZeroAgent(\n",
                "    env=env_batch,\n",
                "    config=config_batch,\n",
                "    name=\"muzero_batched_bench_fast\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_batch.checkpoint_interval = 100\n",
                "agent_batch.test_interval = 1000\n",
                "agent_batch.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_batch.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Batched Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "muzero_iterative_run",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running MuZero Iterative Search (Batch=0) ---\")\n",
                "env_iter = TicTacToeConfig().make_env()\n",
                "config_iter = MuZeroConfig(config_dict=params, game_config=game_config)\n",
                "config_iter.search_batch_size = 0  # Explicitly set\n",
                "\n",
                "agent_iter = MuZeroAgent(\n",
                "    env=env_iter,\n",
                "    config=config_iter,\n",
                "    name=\"muzero_iterative_bench\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_iter.checkpoint_interval = 100\n",
                "agent_iter.test_interval = 1000\n",
                "agent_iter.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_iter.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Iterative Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1fe0b3c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running MuZero Iterative Search (Batch=1) ---\")\n",
                "env_iter = TicTacToeConfig().make_env()\n",
                "config_iter = MuZeroConfig(config_dict=params, game_config=game_config)\n",
                "config_iter.search_batch_size = 1  # Explicitly set\n",
                "\n",
                "agent_iter = MuZeroAgent(\n",
                "    env=env_iter,\n",
                "    config=config_iter,\n",
                "    name=\"muzero_iterative_bench\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_iter.checkpoint_interval = 100\n",
                "agent_iter.test_interval = 1000\n",
                "agent_iter.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_iter.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Iterative Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "muzero_batched_run",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running MuZero Batched Search (Batch=5) ---\")\n",
                "params_batched = params.copy()\n",
                "params_batched[\"search_batch_size\"] = 5\n",
                "\n",
                "env_batch = TicTacToeConfig().make_env()\n",
                "config_batch = MuZeroConfig(config_dict=params_batched, game_config=game_config)\n",
                "config_batch.search_batch_size = 5  # Explicitly set\n",
                "\n",
                "agent_batch = MuZeroAgent(\n",
                "    env=env_batch,\n",
                "    config=config_batch,\n",
                "    name=\"muzero_batched_bench_size_5\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_batch.checkpoint_interval = 100\n",
                "agent_batch.test_interval = 1000\n",
                "agent_batch.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_batch.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Batched Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e22fc8c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running MuZero Batched Search (Batch=5) ---\")\n",
                "params_batched = params.copy()\n",
                "params_batched[\"search_batch_size\"] = 5\n",
                "\n",
                "env_batch = TicTacToeConfig().make_env()\n",
                "config_batch = MuZeroConfig(config_dict=params_batched, game_config=game_config)\n",
                "config_batch.search_batch_size = 5  # Explicitly set\n",
                "\n",
                "agent_batch = MuZeroAgent(\n",
                "    env=env_batch,\n",
                "    config=config_batch,\n",
                "    name=\"muzero_batched_bench_size_5\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_batch.checkpoint_interval = 100\n",
                "agent_batch.test_interval = 1000\n",
                "agent_batch.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_batch.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Batched Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f52b0d54",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running MuZero Batched Search (Batch=5) Virtual Mean ---\")\n",
                "params_batched = params.copy()\n",
                "params_batched[\"search_batch_size\"] = 5\n",
                "params_batched[\"use_virtual_mean\"] = True\n",
                "\n",
                "env_batch = TicTacToeConfig().make_env()\n",
                "config_batch = MuZeroConfig(config_dict=params_batched, game_config=game_config)\n",
                "config_batch.search_batch_size = 5  # Explicitly set\n",
                "\n",
                "agent_batch = MuZeroAgent(\n",
                "    env=env_batch,\n",
                "    config=config_batch,\n",
                "    name=\"muzero_batched_bench_size_5_virtual_mean_1\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_batch.checkpoint_interval = 100\n",
                "agent_batch.test_interval = 1000\n",
                "agent_batch.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_batch.train()\n",
                "end_time = time.time()\n",
                "print(f\"MuZero Batched Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "gumbel_benchmark",
            "metadata": {},
            "source": [
                "# Gumbel MuZero Benchmark (Iterative vs Batched)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "695b2ba9",
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"num_simulations\": 25,\n",
                "    \"per_alpha\": 0.0,\n",
                "    \"per_beta\": 0.0,\n",
                "    \"per_beta_final\": 0.0,\n",
                "    \"n_step\": 10,\n",
                "    \"root_dirichlet_alpha\": 0.25,\n",
                "    \"residual_layers\": [(24, 3, 1)],\n",
                "    \"reward_dense_layer_widths\": [],\n",
                "    \"reward_conv_layers\": [(16, 1, 1)],\n",
                "    \"actor_dense_layer_widths\": [],\n",
                "    \"actor_conv_layers\": [(16, 1, 1)],\n",
                "    \"critic_dense_layer_widths\": [],\n",
                "    \"critic_conv_layers\": [(16, 1, 1)],\n",
                "    \"to_play_dense_layer_widths\": [],\n",
                "    \"to_play_conv_layers\": [(16, 1, 1)],\n",
                "    \"known_bounds\": [-1, 1],\n",
                "    \"support_range\": None,\n",
                "    \"minibatch_size\": 8,\n",
                "    \"replay_buffer_size\": 100000,\n",
                "    \"gumbel\": True,\n",
                "    \"gumbel_m\": 4,\n",
                "    \"policy_loss_function\": KLDivergenceLoss(),\n",
                "    \"training_steps\": 20000,  # Reduced for benchmark speed\n",
                "    \"transfer_interval\": 1,\n",
                "    \"num_workers\": 4,\n",
                "    \"world_model_cls\": MuzeroWorldModel,\n",
                "    \"search_batch_size\": 0,  # Iterative\n",
                "    \"use_virtual_mean\": False,\n",
                "    \"virtual_loss\": 3.0,\n",
                "}\n",
                "\n",
                "game_config = TicTacToeConfig()\n",
                "\n",
                "params_gumbel = params.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gumbel_iterative_run",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running Gumbel MuZero Iterative Search (Batch=1) ---\")\n",
                "params_gumbel[\"search_batch_size\"] = 0\n",
                "\n",
                "env_gumbel = TicTacToeConfig().make_env()\n",
                "config_gumbel = MuZeroConfig(config_dict=params_gumbel, game_config=game_config)\n",
                "\n",
                "agent_gumbel = MuZeroAgent(\n",
                "    env=env_gumbel,\n",
                "    config=config_gumbel,\n",
                "    name=\"gumbel_iterative_bench\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_gumbel.checkpoint_interval = 100\n",
                "agent_gumbel.test_interval = 1000\n",
                "agent_gumbel.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_gumbel.train()\n",
                "end_time = time.time()\n",
                "print(f\"Gumbel Iterative Time: {end_time - start_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gumbel_batched_run",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Running Gumbel MuZero Batched Search (Batch=5) ---\")\n",
                "params_gumbel_batch = params_gumbel.copy()\n",
                "params_gumbel_batch[\"search_batch_size\"] = 5\n",
                "params_gumbel_batch[\"use_virtual_mean\"] = True\n",
                "\n",
                "env_gumbel_batch = TicTacToeConfig().make_env()\n",
                "config_gumbel_batch = MuZeroConfig(\n",
                "    config_dict=params_gumbel_batch, game_config=game_config\n",
                ")\n",
                "\n",
                "agent_gumbel_batch = MuZeroAgent(\n",
                "    env=env_gumbel_batch,\n",
                "    config=config_gumbel_batch,\n",
                "    name=\"gumbel_batched_bench\",\n",
                "    device=\"cpu\",\n",
                "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
                ")\n",
                "agent_gumbel_batch.checkpoint_interval = 100\n",
                "agent_gumbel_batch.test_interval = 1000\n",
                "agent_gumbel_batch.test_trials = 100\n",
                "\n",
                "start_time = time.time()\n",
                "agent_gumbel_batch.train()\n",
                "end_time = time.time()\n",
                "print(f\"Gumbel Batched Time: {end_time - start_time:.2f}s\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
