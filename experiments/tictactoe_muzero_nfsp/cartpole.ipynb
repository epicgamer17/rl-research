{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204362f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 20000\n",
      "Using default adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.001\n",
      "Using default clipnorm                      : 0\n",
      "Using         optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using default loss_function                 : <class 'utils.utils.MSELoss'>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 32\n",
      "Using         replay_buffer_size            : 1000\n",
      "Using default min_replay_buffer_size        : 32\n",
      "Using default num_minibatches               : 1\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "Using         known_bounds                  : [1, 500]\n",
      "Using         residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [512]\n",
      "Using default representation_residual_layers: []\n",
      "Using default representation_conv_layers    : []\n",
      "Using default representation_dense_layer_widths: [512]\n",
      "Using default dynamics_residual_layers      : []\n",
      "Using default dynamics_conv_layers          : []\n",
      "Using default dynamics_dense_layer_widths   : [512]\n",
      "Using         reward_conv_layers            : []\n",
      "Using         reward_dense_layer_widths     : [32]\n",
      "Using         to_play_conv_layers           : []\n",
      "Using         to_play_dense_layer_widths    : []\n",
      "Using         critic_conv_layers            : []\n",
      "Using         critic_dense_layer_widths     : [32]\n",
      "Using         actor_conv_layers             : []\n",
      "Using         actor_dense_layer_widths      : [32]\n",
      "Using default noisy_sigma                   : 0.0\n",
      "Using default games_per_generation          : 100\n",
      "Using         value_loss_factor             : 1.0\n",
      "Using default to_play_loss_factor           : 1.0\n",
      "Using default weight_decay                  : 0.0001\n",
      "Using         root_dirichlet_alpha          : 0.25\n",
      "Using default root_exploration_fraction     : 0.25\n",
      "Using         num_simulations               : 50\n",
      "Using         temperatures                  : [3, 2, 1, 0.5, 0.25, 0.125, 0.075, 0.01, 0.0]\n",
      "Using         temperature_updates           : [100, 200, 300, 400, 500, 600, 700, 800]\n",
      "Using         temperature_with_training_steps: True\n",
      "Using default clip_low_prob                 : 0.0\n",
      "Using default pb_c_base                     : 19652\n",
      "Using default pb_c_init                     : 1.25\n",
      "Using         value_loss_function           : <utils.utils.CategoricalCrossentropyLoss object at 0x3244c7820>\n",
      "Using         reward_loss_function          : <utils.utils.CategoricalCrossentropyLoss object at 0x113032e30>\n",
      "Using         policy_loss_function          : <utils.utils.CategoricalCrossentropyLoss object at 0x113059720>\n",
      "Using default to_play_loss_function         : <utils.utils.CategoricalCrossentropyLoss object at 0x3244c7940>\n",
      "Using         n_step                        : 10\n",
      "Using         discount_factor               : 0.997\n",
      "Using         unroll_steps                  : 5\n",
      "Using         per_alpha                     : 0.0\n",
      "Using         per_beta                      : 0.0\n",
      "Using         per_beta_final                : 0.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default per_use_batch_weights         : False\n",
      "Using default per_initial_priority_max      : False\n",
      "Using         support_range                 : 31\n",
      "Using default multi_process                 : True\n",
      "Using         num_workers                   : 4\n",
      "Using default lr_ratio                      : inf\n",
      "Using         transfer_interval             : 100\n",
      "Using         reanalyze_ratio               : 0.1\n",
      "Using default reanalyze_method              : mcts\n",
      "Using default reanalyze_tau                 : 0.3\n",
      "Using         injection_frac                : 0.1\n",
      "Using default reanalyze_noise               : False\n",
      "Using default reanalyze_update_priorities   : False\n",
      "Using         gumbel                        : True\n",
      "Using         gumbel_m                      : 2\n",
      "Using default gumbel_cvisit                 : 50\n",
      "Using default gumbel_cscale                 : 1.0\n",
      "Using         consistency_loss_factor       : 2.0\n",
      "Using default projector_output_dim          : 128\n",
      "Using default projector_hidden_dim          : 128\n",
      "Using default predictor_output_dim          : 128\n",
      "Using default predictor_hidden_dim          : 64\n",
      "Using default mask_absorbing                : True\n",
      "Using         value_prefix                  : True\n",
      "Using default lstm_horizon_len              : 5\n",
      "Using default lstm_hidden_size              : 64\n",
      "Using default q_estimation_method           : v_mix\n",
      "Using default stochastic                    : False\n",
      "Using default num_chance                    : 32\n",
      "Using default sigma_loss                    : <utils.utils.CategoricalCrossentropyLoss object at 0x3244c7970>\n",
      "Using default afterstate_residual_layers    : []\n",
      "Using default afterstate_conv_layers        : []\n",
      "Using default afterstate_dense_layer_widths : [512]\n",
      "Using default chance_conv_layers            : [(32, 3, 1)]\n",
      "Using default chance_dense_layer_widths     : [256]\n",
      "Using default vqvae_commitment_cost_factor  : 1.0\n",
      "Using device: cpu\n",
      "making test env\n",
      "Warning: test_env will not record videos as render_mode is not 'rgb_array'\n",
      "Test env: <TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>>\n",
      "<class 'gymnasium.spaces.box.Box'>\n",
      "Observation dimensions: (4,)\n",
      "Observation dtype: float32\n",
      "num_actions:  2 <class 'int'>\n",
      "Test agents: []\n",
      "Hidden state shape: (32, 512)\n",
      "dynamics input shape (32, 512)\n",
      "Hidden state shape: (32, 512)\n",
      "dynamics input shape (32, 512)\n",
      "Warning: for board games it is recommnded to have n_step >= game length\n",
      "Max size: 1000\n",
      "Initializing stat 'score' with subkeys None\n",
      "Initializing stat 'policy_loss' with subkeys None\n",
      "Initializing stat 'value_loss' with subkeys None\n",
      "Initializing stat 'reward_loss' with subkeys None\n",
      "Initializing stat 'to_play_loss' with subkeys None\n",
      "Initializing stat 'cons_loss' with subkeys None\n",
      "Initializing stat 'q_loss' with subkeys None\n",
      "Initializing stat 'sigma_loss' with subkeys None\n",
      "Initializing stat 'vqvae_commitment_cost' with subkeys None\n",
      "Initializing stat 'loss' with subkeys None\n",
      "Initializing stat 'test_score' with subkeys ['score', 'max_score', 'min_score']\n",
      "Initializing stat 'episode_length' with subkeys None\n",
      "Initializing stat 'num_codes' with subkeys None\n",
      "[Worker 1] Starting self-play...\n",
      "[Worker 3] Starting self-play...\n",
      "[Worker 2] Starting self-play...\n",
      "[Worker 0] Starting self-play...\n",
      "Buffer size: 12\n",
      "Buffer size: 38\n",
      "Buffer size: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:572: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n",
      "  actions[i]: float(logits[actions[i]]) for i in top_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 68\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 82\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 104\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 116\n",
      "Buffer size: 133\n",
      "learned\n",
      "learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:572: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n",
      "  actions[i]: float(logits[actions[i]]) for i in top_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 169\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 189\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 199\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 215\n",
      "learned\n",
      "learned\n",
      "Buffer size: 226\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 266\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 289\n",
      "learned\n",
      "learned\n",
      "Buffer size: 302\n",
      "Buffer size: 330\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 352\n",
      "learned\n",
      "Buffer size: 374\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 406\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 418\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 444\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "Buffer size: 463\n",
      "Buffer size: 479\n",
      "Buffer size: 494\n",
      "Buffer size: 505\n",
      "Buffer size: 518\n",
      "learned\n",
      "Buffer size: 530\n",
      "learned\n",
      "learned\n",
      "Buffer size: 548\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 576\n",
      "Buffer size: 599\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 619\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 656\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 724\n",
      "learned\n",
      "Buffer size: 739\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 750\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 764\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 779\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 808\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 829\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "Buffer size: 845\n",
      "Buffer size: 859\n",
      "learned\n",
      "learned\n",
      "Buffer size: 899\n",
      "Buffer size: 913\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 932\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "Buffer size: 969\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:572: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n",
      "  actions[i]: float(logits[actions[i]]) for i in top_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:572: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n",
      "  actions[i]: float(logits[actions[i]]) for i in top_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "score:  106.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  53.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "score:  108.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  55.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  13.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  34.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  18.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  58.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  55.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  42.0\n",
      "Test score {'score': 54.2, 'max_score': 108.0, 'min_score': 13.0}\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  137.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  285.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  165.0\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  94.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  83.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  151.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "score:  56.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  92.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  29.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  110.0\n",
      "Test score {'score': 120.2, 'max_score': 285.0, 'min_score': 29.0}\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  151.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  177.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  145.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  150.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  153.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  76.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  96.0\n",
      "score:  26.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learnedscore:  23.0\n",
      "\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  118.0\n",
      "Test score {'score': 111.5, 'max_score': 177.0, 'min_score': 23.0}\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  129.0\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  51.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  40.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  30.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  91.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  54.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  69.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  63.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  57.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  40.0\n",
      "Test score {'score': 62.4, 'max_score': 129.0, 'min_score': 30.0}\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  16.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  42.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  87.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  64.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  86.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  95.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  57.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "score:  122.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  56.0\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "score:  117.0\n",
      "Test score {'score': 74.2, 'max_score': 122.0, 'min_score': 16.0}\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n",
      "learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 308, in worker_fn\n",
      "    score, num_steps = self.play_game(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 1644, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 1585, in predict\n",
      "    value, policy, target_policy, best_action = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 633, in monte_carlo_tree_search\n",
      "    best_action = self.sequential_halving(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 726, in sequential_halving\n",
      "    self._run_single_simulation(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 833, in _run_single_simulation\n",
      "    reward = support_to_scalar(reward, self.config.support_range).item()\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/utils.py\", line 39, in support_to_scalar\n",
      "    z = torch.sum(\n",
      "KeyboardInterrupt\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 306, in worker_fn\n",
      "    self.reanalyze_game(inference_model=self.target_model)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 1758, in reanalyze_game\n",
      "    root_value, _, new_policy, best_action = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 633, in monte_carlo_tree_search\n",
      "    best_action = self.sequential_halving(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 726, in sequential_halving\n",
      "    self._run_single_simulation(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 798, in _run_single_simulation\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 282, in select_child\n",
      "    pi0 = self.get_gumbel_improved_policy(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 382, in get_gumbel_improved_policy\n",
      "    completedQ = self.get_completed_q(min_max_stats)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 365, in get_completed_q\n",
      "    v_mix = self.get_v_mix()\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line -1, in get_v_mix\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 306, in worker_fn\n",
      "    self.reanalyze_game(inference_model=self.target_model)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 1758, in reanalyze_game\n",
      "    root_value, _, new_policy, best_action = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 633, in monte_carlo_tree_search\n",
      "    best_action = self.sequential_halving(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 726, in sequential_halving\n",
      "    self._run_single_simulation(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 798, in _run_single_simulation\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 282, in select_child\n",
      "    pi0 = self.get_gumbel_improved_policy(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 382, in get_gumbel_improved_policy\n",
      "    completedQ = self.get_completed_q(min_max_stats)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line -1, in get_completed_q\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 306, in worker_fn\n",
      "    self.reanalyze_game(inference_model=self.target_model)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 1758, in reanalyze_game\n",
      "    root_value, _, new_policy, best_action = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 633, in monte_carlo_tree_search\n",
      "    best_action = self.sequential_halving(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 726, in sequential_halving\n",
      "    self._run_single_simulation(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 798, in _run_single_simulation\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 282, in select_child\n",
      "    pi0 = self.get_gumbel_improved_policy(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 382, in get_gumbel_improved_policy\n",
      "    completedQ = self.get_completed_q(min_max_stats)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 365, in get_completed_q\n",
      "    v_mix = self.get_v_mix()\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 349, in get_v_mix\n",
      "    q_vals[action] = self.get_child_q_from_parent(child)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 418, in get_child_q_from_parent\n",
      "    v = float(child.value())\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 229, in value\n",
      "    def value(self):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     86\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:413\u001b[0m, in \u001b[0;36mMuZeroAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmin_replay_buffer_size:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m minibatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_minibatches):\n\u001b[1;32m    403\u001b[0m         (\n\u001b[1;32m    404\u001b[0m             value_loss,\n\u001b[1;32m    405\u001b[0m             policy_loss,\n\u001b[1;32m    406\u001b[0m             reward_loss,\n\u001b[1;32m    407\u001b[0m             to_play_loss,\n\u001b[1;32m    408\u001b[0m             cons_loss,\n\u001b[1;32m    409\u001b[0m             q_loss,\n\u001b[1;32m    410\u001b[0m             sigma_loss,\n\u001b[1;32m    411\u001b[0m             vqvae_commitment_cost,\n\u001b[1;32m    412\u001b[0m             loss,\n\u001b[0;32m--> 413\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, value_loss)\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, policy_loss)\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:1017\u001b[0m, in \u001b[0;36mMuZeroAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# infos = samples[\"infos\"].to(self.device)\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(observations)\n\u001b[1;32m   1013\u001b[0m (\n\u001b[1;32m   1014\u001b[0m     initial_values,\n\u001b[1;32m   1015\u001b[0m     initial_policies,\n\u001b[1;32m   1016\u001b[0m     hidden_states,\n\u001b[0;32m-> 1017\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_initial_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# This list will capture predicted latent states s_{t}, s_{t+1}, ..., s_{t+K}\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;66;03m# `hidden_state` at this point is s_t (from initial inference)\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m reward_h_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mminibatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlstm_hidden_size\n\u001b[1;32m   1023\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:1517\u001b[0m, in \u001b[0;36mMuZeroAgent.predict_initial_inference\u001b[0;34m(self, states, model)\u001b[0m\n\u001b[1;32m   1515\u001b[0m state_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(states)\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# print(\"state input shape\", state_input.shape)\u001b[39;00m\n\u001b[0;32m-> 1517\u001b[0m values, policies, hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;66;03m# should we action mask the priors?\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;66;03m# legal_moves = get_legal_moves(info)\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;66;03m# policy = action_mask(policy, legal_moves, device=self.device)\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;66;03m# policy = policy / torch.sum(policy)  # Normalize policy\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# print(\"policy shape\", policy.shape)\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values, policies, hidden_states\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_network.py:1507\u001b[0m, in \u001b[0;36mNetwork.initial_inference\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitial_inference\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m   1506\u001b[0m     \u001b[38;5;66;03m# print(\"Initial inference\")\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m     hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1508\u001b[0m     value, policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction(hidden_state)\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;66;03m# print(\"Hidden state:\", hidden_state.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_network.py:144\u001b[0m, in \u001b[0;36mRepresentation.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# normalize inputs as per paper\u001b[39;00m\n\u001b[1;32m    143\u001b[0m min_hidden_state \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 144\u001b[0m max_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    145\u001b[0m scale_hidden_state \u001b[38;5;241m=\u001b[39m max_hidden_state \u001b[38;5;241m-\u001b[39m min_hidden_state\n\u001b[1;32m    146\u001b[0m scale_hidden_state[scale_hidden_state \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-5\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from agents.random import RandomAgent\n",
    "from hyperparameter_optimization.hyperopt import (\n",
    "    marl_objective,\n",
    "    set_marl_config,\n",
    "    MarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import atpe, tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from game_configs import CartPoleConfig, TicTacToeConfig\n",
    "from agents.tictactoe_expert import TicTacToeBestAgent\n",
    "from muzero.action_functions import action_as_onehot, action_as_plane\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "env = CartPoleConfig().make_env()\n",
    "# env = FrameStackWrapper(env, 4)\n",
    "params = {\n",
    "    \"num_simulations\": 50,\n",
    "    \"per_alpha\": 0.0,\n",
    "    \"per_beta\": 0.0,\n",
    "    \"per_beta_final\": 0.0,\n",
    "    \"root_dirichlet_alpha\": 0.25,\n",
    "    \"dense_layer_widths\": [512],\n",
    "    \"residual_layers\": [],\n",
    "    \"reward_dense_layer_widths\": [32],\n",
    "    \"reward_conv_layers\": [],\n",
    "    \"actor_dense_layer_widths\": [32],\n",
    "    \"actor_conv_layers\": [],\n",
    "    \"critic_dense_layer_widths\": [32],\n",
    "    \"critic_conv_layers\": [],\n",
    "    \"to_play_dense_layer_widths\": [],\n",
    "    \"to_play_conv_layers\": [],\n",
    "    \"known_bounds\": [1, 500],\n",
    "    \"support_range\": 31,\n",
    "    \"minibatch_size\": 32,\n",
    "    \"replay_buffer_size\": 1000,\n",
    "    \"gumbel\": True,\n",
    "    \"gumbel_m\": 2,\n",
    "    \"policy_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"reward_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"value_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"training_steps\": 20000,\n",
    "    \"transfer_interval\": 100,\n",
    "    \"num_workers\": 4,\n",
    "    \"discount_factor\": 0.997,\n",
    "    \"unroll_steps\": 5,\n",
    "    \"n_step\": 10,\n",
    "    \"temperatures\": [3, 2, 1, 0.5, 0.25, 0.125, 0.075, 0.01, 0.0],\n",
    "    # \"temperatures\": [1, 0.5, 0.25],\n",
    "    # \"temperature_updates\": [100, 125, 150, 175, 200, 225, 250],\n",
    "    \"temperature_updates\": [100, 200, 300, 400, 500, 600, 700, 800],\n",
    "    # \"temperature_updates\": [\n",
    "    #     500,\n",
    "    #     750,\n",
    "    # ],\n",
    "    \"temperature_with_training_steps\": True,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": Adam,\n",
    "    \"value_loss_factor\": 0.25,\n",
    "    \"reanalyze_ratio\": 0.1,\n",
    "    \"injection_frac\": 0.1,\n",
    "    \"value_prefix\": True,\n",
    "    \"consistency_loss_factor\": 2.0,\n",
    "}\n",
    "game_config = CartPoleConfig()\n",
    "config = MuZeroConfig(config_dict=params, game_config=game_config)\n",
    "\n",
    "agent = MuZeroAgent(\n",
    "    env=env,\n",
    "    config=config,\n",
    "    name=\"cartpole_test_5\",\n",
    "    device=\"cpu\",\n",
    "    test_agents=[],\n",
    ")\n",
    "agent.checkpoint_interval = 100\n",
    "agent.test_interval = 1000\n",
    "agent.test_trials = 10\n",
    "\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_onehot as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[0, 500]]),\n",
    "    \"residual_filters\": hp.choice(\"residual_filters\", [[]]),\n",
    "    \"residual_stacks\": hp.choice(\"residual_stacks\", [[]]),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"actor_and_critic_conv_filters\": hp.choice(\"actor_and_critic_conv_filters\", [[]]),\n",
    "    \"reward_conv_layers\": hp.choice(\"reward_conv_layers\", [[]]),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[32], []]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[32], []]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[32], []]),\n",
    "    \"to_play_dense_layer_widths\": hp.choice(\"to_play_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\n",
    "        \"dense_layer_widths\", [[32], [32, 32], [32, 32, 32]]\n",
    "    ),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": hp.quniform(\n",
    "        \"root_dirichlet_alpha\", 0.1, 1.0, 0.1\n",
    "    ),  # hp.choice(\"root_dirichlet_alpha\", [0.3, 1.0, 2.0]),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(150), 25)\n",
    "    ),\n",
    "    # \"temperature_updates\": hp.choice(\"temperature_updates\", [[15000, 30000]]),\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.5, 0.25]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [True]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\n",
    "        \"value_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"reward_loss_function\": hp.choice(\n",
    "        \"reward_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(hp.quniform(\"training_steps\", 10000, 10100, 1000)),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 7, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(1100), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 3, 6, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [10, 500]),\n",
    "    \"clipnorm\": hp.choice(\n",
    "        \"clipnorm\",\n",
    "        [0.0, scope.int(10 ** (hp.quniform(\"clip_val\", 0, 2, 1)))],\n",
    "        # \"clipnorm\",\n",
    "        # [0.0],\n",
    "    ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 5, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "    \"support_range\": scope.int(hp.quniform(\"support_range\", 601, 601 + 1e-8, 1)),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_params(params):\n",
    "    params[\"residual_layers\"] = []\n",
    "    params[\"actor_conv_layers\"] = []\n",
    "    params[\"critic_conv_layers\"] = []\n",
    "    params[\"to_play_conv_layers\"] = []\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    # if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "    #     params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "    #     params[\"optimizer\"] = Adam\n",
    "    # elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "    #     params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "    #     params[\"optimizer\"] = SGD\n",
    "    params[\"temperature_updates\"] = [\n",
    "        params[\"training_steps\"] / 2,\n",
    "        3 * params[\"training_steps\"] / 4,\n",
    "    ]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0235f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.random import RandomAgent\n",
    "from hyperparameter_optimization.hyperopt import (\n",
    "    sarl_objective,\n",
    "    set_sarl_config,\n",
    "    SarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import atpe, tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from game_configs import CartPoleConfig\n",
    "\n",
    "search_space_path, initial_best_config_path = (\n",
    "    \"search_space.pkl\",\n",
    "    \"best_config.pkl\",\n",
    ")\n",
    "# search_space = pickle.load(open(search_space_path, \"rb\"))\n",
    "# initial_best_config = pickle.load(open(initial_best_config_path, \"rb\"))\n",
    "file_name = \"cartpole_muzero\"\n",
    "max_trials = 128\n",
    "trials_step = 128  # how many additional trials to do after loading the last ones\n",
    "\n",
    "set_sarl_config(\n",
    "    SarlHyperoptConfig(\n",
    "        file_name=file_name,\n",
    "        eval_method=\"rolling_average\",\n",
    "        make_env=CartPoleConfig().make_env,\n",
    "        prep_params=prep_params,\n",
    "        agent_class=MuZeroAgent,\n",
    "        agent_config=MuZeroConfig,\n",
    "        game_config=CartPoleConfig,\n",
    "        checkpoint_interval=50,\n",
    "        test_interval=100,\n",
    "        test_trials=25,\n",
    "        last_n_rolling_avg=3,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "try:  # try to load an already saved trials object, and increase the max\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading...\")\n",
    "    max_trials = len(trials.trials) + trials_step\n",
    "    print(\n",
    "        \"Rerunning from {} trials to {} (+{}) trials\".format(\n",
    "            len(trials.trials), max_trials, trials_step\n",
    "        )\n",
    "    )\n",
    "except:  # create a new trials object and start searching\n",
    "    print(\"No saved Trials! Starting from scratch.\")\n",
    "    trials = None\n",
    "\n",
    "best = fmin(\n",
    "    fn=sarl_objective,  # Objective Function to optimize\n",
    "    space=search_space,  # Hyperparameter's Search Space\n",
    "    algo=atpe.suggest,  # Optimization algorithm (representative TPE)\n",
    "    max_evals=max_trials,  # Number of optimization attempts\n",
    "    trials=trials,  # Record the results\n",
    "    # early_stop_fn=no_progress_loss(5, 1),\n",
    "    trials_save_file=f\"./{file_name}_trials.p\",\n",
    "    points_to_evaluate=initial_best_config,\n",
    "    show_progressbar=False,\n",
    ")\n",
    "print(best)\n",
    "best_trial = space_eval(search_space, best)\n",
    "# gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
