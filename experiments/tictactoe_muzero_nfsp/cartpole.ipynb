{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_onehot as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": hp.qloguniform(\n",
    "                #     \"adam_epsilon\", np.log(1e-8), np.log(0.5), 1e-8\n",
    "                # ),\n",
    "                \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 1, 8, 1)),\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": \"sgd\",\n",
    "                \"momentum\": hp.quniform(\"momentum\", 0, 0.9, 0.1),\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 1, 4, 1)),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[0, 500]]),\n",
    "    \"residual_filters\": hp.choice(\"residual_filters\", [[]]),\n",
    "    \"residual_stacks\": hp.choice(\"residual_stacks\", [[]]),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"actor_and_critic_conv_filters\": hp.choice(\"actor_and_critic_conv_filters\", [[]]),\n",
    "    \"reward_conv_layers\": hp.choice(\"reward_conv_layers\", [[]]),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\n",
    "        \"actor_dense_layer_widths\", [[512], [256], [128], []]\n",
    "    ),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\n",
    "        \"critic_dense_layer_widths\", [[512], [256], [128], []]\n",
    "    ),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\n",
    "        \"reward_dense_layer_widths\", [[512], [256], [128], []]\n",
    "    ),\n",
    "    \"dense_layer_widths\": hp.choice(\n",
    "        \"dense_layer_widths\", [[512, 64], [256, 64], [128, 64]]\n",
    "    ),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": hp.quniform(\n",
    "        \"root_dirichlet_alpha\", 0.1, 5.0, 0.1\n",
    "    ),  # hp.choice(\"root_dirichlet_alpha\", [0.3, 1.0, 2.0]),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(50), 25)\n",
    "    ),\n",
    "    # \"temperature_updates\": hp.choice(\"temperature_updates\", [[15000, 30000]]),\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.5, 0.25]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [True]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\n",
    "        \"value_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"reward_loss_function\": hp.choice(\n",
    "        \"reward_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(hp.quniform(\"training_steps\", 15000, 45000, 15000)),\n",
    "    # \"minibatch_size\": scope.int(\n",
    "    #     hp.qloguniform(\"minibatch_size\", np.log(8), np.log(64), 8)\n",
    "    # ),\n",
    "    # \"min_replay_buffer_size\": scope.int(\n",
    "    #     hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "    # ),\n",
    "    # \"replay_buffer_size\": scope.int(\n",
    "    #     hp.qloguniform(\"replay_buffer_size\", np.log(10000), np.log(200000), 10000)\n",
    "    # ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 7, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(20000), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 6, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [10]),\n",
    "    \"clipnorm\": scope.int(hp.quniform(\"clipnorm\", 0, 10.0, 1)),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "    \"support_range\": scope.int(hp.quniform(\"support_range\", 5, 15, 5)),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_params(params):\n",
    "    params[\"residual_layers\"] = []\n",
    "    params[\"actor_conv_layers\"] = []\n",
    "    params[\"critic_conv_layers\"] = []\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "        params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "        params[\"optimizer\"] = Adam\n",
    "    elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "        params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "        params[\"optimizer\"] = SGD\n",
    "    params[\"temperature_updates\"] = [\n",
    "        params[\"training_steps\"] / 3,\n",
    "        2 * params[\"training_steps\"] / 3,\n",
    "    ]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0235f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.random import RandomAgent\n",
    "from hyperparameter_optimization.hyperopt import (\n",
    "    sarl_objective,\n",
    "    set_sarl_config,\n",
    "    SarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import atpe, tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from game_configs import CartPoleConfig\n",
    "\n",
    "search_space_path, initial_best_config_path = (\n",
    "    \"search_space.pkl\",\n",
    "    \"best_config.pkl\",\n",
    ")\n",
    "# search_space = pickle.load(open(search_space_path, \"rb\"))\n",
    "# initial_best_config = pickle.load(open(initial_best_config_path, \"rb\"))\n",
    "file_name = \"cartpole_muzero\"\n",
    "max_trials = 1\n",
    "trials_step = 24  # how many additional trials to do after loading the last ones\n",
    "\n",
    "set_sarl_config(\n",
    "    SarlHyperoptConfig(\n",
    "        file_name=file_name,\n",
    "        eval_method=\"rolling_average\",\n",
    "        make_env=CartPoleConfig().make_env,\n",
    "        prep_params=prep_params,\n",
    "        agent_class=MuZeroAgent,\n",
    "        agent_config=MuZeroConfig,\n",
    "        game_config=CartPoleConfig,\n",
    "        checkpoint_interval=50,\n",
    "        test_interval=100,\n",
    "        test_trials=25,\n",
    "        last_n_rolling_avg=10,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "try:  # try to load an already saved trials object, and increase the max\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading...\")\n",
    "    max_trials = len(trials.trials) + trials_step\n",
    "    print(\n",
    "        \"Rerunning from {} trials to {} (+{}) trials\".format(\n",
    "            len(trials.trials), max_trials, trials_step\n",
    "        )\n",
    "    )\n",
    "except:  # create a new trials object and start searching\n",
    "    print(\"No saved Trials! Starting from scratch.\")\n",
    "    trials = None\n",
    "\n",
    "best = fmin(\n",
    "    fn=sarl_objective,  # Objective Function to optimize\n",
    "    space=search_space,  # Hyperparameter's Search Space\n",
    "    algo=atpe.suggest,  # Optimization algorithm (representative TPE)\n",
    "    max_evals=max_trials,  # Number of optimization attempts\n",
    "    trials=trials,  # Record the results\n",
    "    # early_stop_fn=no_progress_loss(5, 1),\n",
    "    trials_save_file=f\"./{file_name}_trials.p\",\n",
    "    points_to_evaluate=initial_best_config,\n",
    "    show_progressbar=False,\n",
    ")\n",
    "print(best)\n",
    "best_trial = space_eval(search_space, best)\n",
    "# gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
