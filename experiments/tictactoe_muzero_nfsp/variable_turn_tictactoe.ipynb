{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab5455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import torch\n",
    "from losses.basic_losses import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "from agents.random import RandomAgent\n",
    "from agents.muzero import MuZeroAgent\n",
    "from agent_configs.muzero_config import MuZeroConfig\n",
    "from game_configs.variable_turn_tictactoe_config import VariableTurnTicTacToeConfig\n",
    "from agents.tictactoe_expert import TicTacToeBestAgent\n",
    "from modules.world_models.muzero_world_model import MuzeroWorldModel\n",
    "\n",
    "# Ensure we use CPU for fairness/comparibility or GPU if available\n",
    "device = \"cpu\" # or \"cuda\" if available\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1d9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"num_simulations\": 25,\n",
    "    \"per_alpha\": 0.0,\n",
    "    \"per_beta\": 0.0,\n",
    "    \"per_beta_final\": 0.0,\n",
    "    \"n_step\": 10,\n",
    "    \"root_dirichlet_alpha\": 0.25,\n",
    "    \"residual_layers\": [(24, 3, 1)],\n",
    "    \"reward_dense_layer_widths\": [],\n",
    "    \"reward_conv_layers\": [(16, 1, 1)],\n",
    "    \"actor_dense_layer_widths\": [],\n",
    "    \"actor_conv_layers\": [(16, 1, 1)],\n",
    "    \"critic_dense_layer_widths\": [],\n",
    "    \"critic_conv_layers\": [(16, 1, 1)],\n",
    "    \"to_play_dense_layer_widths\": [],\n",
    "    \"to_play_conv_layers\": [(16, 1, 1)],\n",
    "    \"known_bounds\": [-1, 1],\n",
    "    \"support_range\": None,\n",
    "    \"minibatch_size\": 8,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"gumbel\": False,\n",
    "    \"gumbel_m\": 16,\n",
    "    \"policy_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"training_steps\": 20000, # Reduced for benchmark speed\n",
    "    \"transfer_interval\": 1,\n",
    "    \"num_workers\": 4,\n",
    "    \"world_model_cls\": MuzeroWorldModel,\n",
    "    \"search_batch_size\": 0, # Iterative\n",
    "    \"use_virtual_mean\": False,\n",
    "    \"virtual_loss\": 3.0,\n",
    "    \"compile\": True,\n",
    "    \"use_mixed_precision\": True,\n",
    "}\n",
    "\n",
    "game_config = VariableTurnTicTacToeConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Multi Turn Tic Tac Toe ---\n",
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 20000\n",
      "Using default adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using default learning_rate                 : 0.001\n",
      "Using default clipnorm                      : 0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using default num_minibatches               : 1\n",
      "Using default training_iterations           : 1\n",
      "Using default lr_schedule_type              : none\n",
      "Using default lr_schedule_steps             : []\n",
      "Using default lr_schedule_steps             : []\n",
      "Using default lr_schedule_values            : []\n",
      "Using         use_mixed_precision           : True\n",
      "Using         compile                       : True\n",
      "Using default compile_mode                  : default\n",
      "Using         minibatch_size                : 8\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using default min_replay_buffer_size        : 8\n",
      "Using         n_step                        : 10\n",
      "Using default discount_factor               : 0.99\n",
      "Using         per_alpha                     : 0.0\n",
      "Using         per_beta                      : 0.0\n",
      "Using         per_beta_final                : 0.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default per_use_batch_weights         : False\n",
      "Using default per_use_initial_max_priority  : True\n",
      "Using default loss_function                 : <class 'losses.basic_losses.MSELoss'>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         prob_layer_initializer        : None\n",
      "Using default norm_type                     : none\n",
      "Using default soft_update                   : False\n",
      "Using default min_max_epsilon               : 0.01\n",
      "Using         world_model_cls               : <class 'modules.world_models.muzero_world_model.MuzeroWorldModel'>\n",
      "Using         known_bounds                  : [-1, 1]\n",
      "Using         residual_layers               : [(24, 3, 1)]\n",
      "Using default conv_layers                   : []\n",
      "Using default dense_layer_widths            : []\n",
      "Using default representation_residual_layers: [(24, 3, 1)]\n",
      "Using default representation_conv_layers    : []\n",
      "Using default representation_dense_layer_widths: []\n",
      "Using default dynamics_residual_layers      : [(24, 3, 1)]\n",
      "Using default dynamics_conv_layers          : []\n",
      "Using default dynamics_dense_layer_widths   : []\n",
      "Using         reward_conv_layers            : [(16, 1, 1)]\n",
      "Using         reward_dense_layer_widths     : []\n",
      "Using         to_play_conv_layers           : [(16, 1, 1)]\n",
      "Using         to_play_dense_layer_widths    : []\n",
      "Using         critic_conv_layers            : [(16, 1, 1)]\n",
      "Using         critic_dense_layer_widths     : []\n",
      "Using         actor_conv_layers             : [(16, 1, 1)]\n",
      "Using         actor_dense_layer_widths      : []\n",
      "Using default noisy_sigma                   : 0.0\n",
      "Using default games_per_generation          : 100\n",
      "Using default value_loss_factor             : 1.0\n",
      "Using default to_play_loss_factor           : 1.0\n",
      "Using         num_simulations               : 25\n",
      "Using         search_batch_size             : 5\n",
      "Using         use_virtual_mean              : True\n",
      "Using         virtual_loss                  : 3.0\n",
      "Using         root_dirichlet_alpha          : 0.25\n",
      "Using default root_exploration_fraction     : 0.25\n",
      "Using default root_dirichlet_alpha_adaptive : False\n",
      "Using         gumbel                        : False\n",
      "Using         gumbel_m                      : 16\n",
      "Using default gumbel_cvisit                 : 50\n",
      "Using default gumbel_cscale                 : 1.0\n",
      "Using default pb_c_base                     : 19652\n",
      "Using default pb_c_init                     : 1.25\n",
      "Using default temperatures                  : [1.0, 0.0]\n",
      "Using default temperature_updates           : [5]\n",
      "Using default temperature_with_training_steps: False\n",
      "Using default clip_low_prob                 : 0.0\n",
      "Using default value_loss_function           : <losses.basic_losses.MSELoss object at 0x14a7df320>\n",
      "Using default reward_loss_function          : <losses.basic_losses.MSELoss object at 0x14c33a690>\n",
      "Using         policy_loss_function          : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x14a42a210>\n",
      "Using default to_play_loss_function         : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x14a4e4350>\n",
      "Using default unroll_steps                  : 5\n",
      "Using default atom_size                     : 1\n",
      "Using         support_range                 : None\n",
      "Using default multi_process                 : True\n",
      "Using         num_workers                   : 4\n",
      "Using default lr_ratio                      : inf\n",
      "Using         transfer_interval             : 1\n",
      "Using default reanalyze_ratio               : 0.0\n",
      "Using default quantize                      : False\n",
      "Using default reanalyze_method              : mcts\n",
      "Using default reanalyze_tau                 : 0.3\n",
      "Using default injection_frac                : 0.0\n",
      "Using default reanalyze_noise               : False\n",
      "Using default reanalyze_update_priorities   : False\n",
      "Using default consistency_loss_factor       : 0.0\n",
      "Using default projector_output_dim          : 128\n",
      "Using default projector_hidden_dim          : 128\n",
      "Using default predictor_output_dim          : 128\n",
      "Using default predictor_hidden_dim          : 64\n",
      "Using default mask_absorbing                : True\n",
      "Using default value_prefix                  : False\n",
      "Using default lstm_horizon_len              : 5\n",
      "Using default lstm_hidden_size              : 64\n",
      "Using default q_estimation_method           : v_mix\n",
      "Using default stochastic                    : False\n",
      "Using default use_true_chance_codes         : False\n",
      "Using default num_chance                    : 32\n",
      "Using default sigma_loss                    : <losses.basic_losses.CategoricalCrossentropyLoss object at 0x14a4e4ad0>\n",
      "Using default afterstate_residual_layers    : [(24, 3, 1)]\n",
      "Using default afterstate_conv_layers        : []\n",
      "Using default afterstate_dense_layer_widths : []\n",
      "Using default chance_conv_layers            : [(32, 3, 1)]\n",
      "Using default chance_dense_layer_widths     : [256]\n",
      "Using default vqvae_commitment_cost_factor  : 1.0\n",
      "Using default action_embedding_dim          : 32\n",
      "Using default single_action_plane           : False\n",
      "Using default latent_viz_method             : umap\n",
      "Using default latent_viz_interval           : 10\n",
      "[variable_turn_tictactoe_muzero] Using device: cpu\n",
      "Observation dimensions: torch.Size([9, 3, 3])\n",
      "Num actions: 9 (Discrete: True)\n",
      "Making test env...\n",
      "Test env configured for video recording.\n",
      "MARL Agent 'variable_turn_tictactoe_muzero' initialized. Test agents: ['random', 'tictactoe_expert']\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "Compiling models...\n",
      "Max size: 100000\n",
      "Initializing stat 'score' with subkeys None\n",
      "Initializing stat 'policy_loss' with subkeys None\n",
      "Initializing stat 'value_loss' with subkeys None\n",
      "Initializing stat 'reward_loss' with subkeys None\n",
      "Initializing stat 'to_play_loss' with subkeys None\n",
      "Initializing stat 'cons_loss' with subkeys None\n",
      "Initializing stat 'loss' with subkeys None\n",
      "Initializing stat 'test_score' with subkeys ['score', 'max_score', 'min_score']\n",
      "Initializing stat 'episode_length' with subkeys None\n",
      "Initializing stat 'policy_entropy' with subkeys None\n",
      "Initializing stat 'value_diff' with subkeys None\n",
      "Initializing stat 'policy_improvement' with subkeys ['network', 'search']\n",
      "Initializing stat 'root_children_values' with subkeys None\n",
      "Initializing stat 'test_score_vs_random' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
      "Initializing stat 'test_score_vs_tictactoe_expert' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Worker 0] Starting self-play...[Worker 3] Starting self-play...\n",
      "\n",
      "[Worker 2] Starting self-play...[Worker 1] Starting self-play...\n",
      "\n",
      "Started recording episode 0 to ./videos/variable_turn_tictactoe_muzero/0/episode_000000.mp4\n",
      "Started recording episode 0 to ./videos/variable_turn_tictactoe_muzero/3/episode_000000.mp4Started recording episode 0 to ./videos/variable_turn_tictactoe_muzero/2/episode_000000.mp4\n",
      "\n",
      "Started recording episode 0 to ./videos/variable_turn_tictactoe_muzero/1/episode_000000.mp4\n",
      "Stopped recording episode 0. Recorded 7 frames.\n",
      "Size: 0\n",
      "Stopped recording episode 0. Recorded 9 frames.\n",
      "Size: 7\n",
      "learning\n",
      "Stopped recording episode 0. Recorded 10 frames.\n",
      "Size: 16\n",
      "Stopped recording episode 0. Recorded 10 frames.\n",
      "Size: 26\n",
      "0\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 5, 1, 0, 4],\n",
      "        [5, 1, 0, 4, 3],\n",
      "        [0, 4, 3, 0, 3],\n",
      "        [3, 0, 2, 5, 3],\n",
      "        [1, 0, 7, 2, 5],\n",
      "        [7, 2, 5, 8, 6],\n",
      "        [2, 5, 8, 6, 4],\n",
      "        [5, 8, 6, 4, 0]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.0781],\n",
      "         [-0.0342],\n",
      "         [ 0.0057],\n",
      "         [-0.0014],\n",
      "         [-0.0220],\n",
      "         [-0.0405]],\n",
      "\n",
      "        [[-0.1416],\n",
      "         [-0.1406],\n",
      "         [-0.1162],\n",
      "         [-0.0947],\n",
      "         [-0.0811],\n",
      "         [-0.0771]],\n",
      "\n",
      "        [[-0.1963],\n",
      "         [-0.1367],\n",
      "         [-0.1318],\n",
      "         [-0.1328],\n",
      "         [-0.1396],\n",
      "         [-0.1338]],\n",
      "\n",
      "        [[ 0.0206],\n",
      "         [ 0.0427],\n",
      "         [ 0.0452],\n",
      "         [ 0.0334],\n",
      "         [ 0.0074],\n",
      "         [-0.0493]],\n",
      "\n",
      "        [[-0.0781],\n",
      "         [-0.1631],\n",
      "         [-0.1309],\n",
      "         [-0.1260],\n",
      "         [-0.1455],\n",
      "         [-0.1484]],\n",
      "\n",
      "        [[-0.2217],\n",
      "         [-0.2451],\n",
      "         [-0.2119],\n",
      "         [-0.1865],\n",
      "         [-0.1553],\n",
      "         [-0.1318]],\n",
      "\n",
      "        [[-0.1826],\n",
      "         [-0.1807],\n",
      "         [-0.1865],\n",
      "         [-0.1855],\n",
      "         [-0.1807],\n",
      "         [-0.1973]],\n",
      "\n",
      "        [[-0.1689],\n",
      "         [-0.1699],\n",
      "         [-0.1494],\n",
      "         [-0.1553],\n",
      "         [-0.1787],\n",
      "         [-0.2041]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0047],\n",
      "         [ 0.0186],\n",
      "         [ 0.0043],\n",
      "         [-0.0021],\n",
      "         [-0.0161]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0405],\n",
      "         [ 0.0598],\n",
      "         [ 0.0786],\n",
      "         [ 0.0664],\n",
      "         [ 0.0713]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0864],\n",
      "         [-0.0508],\n",
      "         [-0.0669],\n",
      "         [-0.0747],\n",
      "         [-0.0654]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0549],\n",
      "         [-0.0830],\n",
      "         [-0.0933],\n",
      "         [-0.0845],\n",
      "         [-0.0898]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0396],\n",
      "         [ 0.0649],\n",
      "         [ 0.0574],\n",
      "         [ 0.0359],\n",
      "         [ 0.0233]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.1025],\n",
      "         [-0.0815],\n",
      "         [-0.0718],\n",
      "         [-0.0708],\n",
      "         [-0.0874]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0747],\n",
      "         [-0.0747],\n",
      "         [-0.0552],\n",
      "         [-0.0513],\n",
      "         [-0.0437]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0574],\n",
      "         [ 0.0447],\n",
      "         [ 0.0195],\n",
      "         [ 0.0048],\n",
      "         [-0.0025]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.4863, 0.5156],\n",
      "         [0.4922, 0.5078],\n",
      "         [0.4922, 0.5078],\n",
      "         [0.4902, 0.5078],\n",
      "         [0.4941, 0.5039]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5156, 0.4863],\n",
      "         [0.5156, 0.4844],\n",
      "         [0.5117, 0.4883],\n",
      "         [0.5117, 0.4883],\n",
      "         [0.5078, 0.4922]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4902, 0.5078],\n",
      "         [0.4844, 0.5156],\n",
      "         [0.4824, 0.5156],\n",
      "         [0.4863, 0.5156],\n",
      "         [0.4863, 0.5156]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4629, 0.5391],\n",
      "         [0.4746, 0.5234],\n",
      "         [0.4863, 0.5156],\n",
      "         [0.4883, 0.5117],\n",
      "         [0.4824, 0.5156]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4766, 0.5234],\n",
      "         [0.4766, 0.5234],\n",
      "         [0.4766, 0.5234],\n",
      "         [0.4824, 0.5156],\n",
      "         [0.4941, 0.5078]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4668, 0.5352],\n",
      "         [0.4746, 0.5273],\n",
      "         [0.4863, 0.5156],\n",
      "         [0.4902, 0.5078],\n",
      "         [0.4883, 0.5117]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4766, 0.5234],\n",
      "         [0.4863, 0.5117],\n",
      "         [0.4961, 0.5039],\n",
      "         [0.4941, 0.5039],\n",
      "         [0.4961, 0.5039]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4941, 0.5078],\n",
      "         [0.4902, 0.5117],\n",
      "         [0.4863, 0.5156],\n",
      "         [0.4805, 0.5195],\n",
      "         [0.4707, 0.5273]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "Size: 36\n",
      "Initializing stat 'q_loss' with subkeys None\n",
      "Initializing stat 'sigma_loss' with subkeys None\n",
      "Initializing stat 'vqvae_commitment_cost' with subkeys None\n",
      "learning\n",
      "Size: 42\n",
      "learning\n",
      "Size: 48\n",
      "Size: 55\n",
      "learning\n",
      "Size: 65\n",
      "Size: 74\n",
      "learning\n",
      "Size: 83\n",
      "learning\n",
      "Size: 90\n",
      "Size: 100\n",
      "learning\n",
      "Size: 110\n",
      "Size: 120\n",
      "learning\n",
      "Size: 130\n",
      "learning\n",
      "Size: 139\n",
      "Size: 149\n",
      "learning\n",
      "Size: 156\n",
      "Size: 165\n",
      "learning\n",
      "Size: 172\n",
      "learning\n",
      "Size: 178\n",
      "Size: 188\n",
      "learning\n",
      "Size: 198\n",
      "Size: 208\n",
      "learning\n",
      "Size: 215\n",
      "Size: 225\n",
      "learning\n",
      "Size: 232\n",
      "Size: 242\n",
      "learning\n",
      "Size: 249\n",
      "learning\n",
      "Size: 259\n",
      "Size: 268\n",
      "Size: 274\n",
      "learning\n",
      "Size: 283\n",
      "learning\n",
      "Size: 290\n",
      "Size: 297\n",
      "learning\n",
      "learning\n",
      "Size: 304\n",
      "Size: 314\n",
      "Size: 324\n",
      "learning\n",
      "Size: 334\n",
      "learning\n",
      "Size: 344\n",
      "learning\n",
      "Size: 351\n",
      "Size: 361\n",
      "Size: 371\n",
      "learning\n",
      "learning\n",
      "Size: 381\n",
      "Size: 387\n",
      "Size: 397\n",
      "learning\n",
      "Size: 407\n",
      "learning\n",
      "Size: 416\n",
      "Size: 426\n",
      "Size: 433\n",
      "learning\n",
      "Size: 443\n",
      "learning\n",
      "Size: 453\n",
      "Size: 460\n",
      "Size: 467\n",
      "learning\n",
      "learning\n",
      "Size: 474\n",
      "Size: 481\n",
      "Size: 491\n",
      "learning\n",
      "Size: 499\n",
      "learning\n",
      "Size: 509\n",
      "Size: 519\n",
      "learning\n",
      "Size: 529\n",
      "Size: 539\n",
      "learning\n",
      "Size: 547\n",
      "Size: 553\n",
      "Size: 560\n",
      "learning\n",
      "Size: 566\n",
      "learning\n",
      "Size: 576\n",
      "Size: 585\n",
      "learning\n",
      "Size: 593\n",
      "learning\n",
      "Size: 602\n",
      "Size: 612\n",
      "learning\n",
      "Size: 619\n",
      "Size: 628\n",
      "learning\n",
      "Size: 638\n",
      "learning\n",
      "Size: 648\n",
      "Size: 657\n",
      "Size: 664\n",
      "learning\n",
      "Size: 674\n",
      "learning\n",
      "learning\n",
      "Size: 681\n",
      "Size: 691\n",
      "Size: 700\n",
      "learning\n",
      "Size: 710\n",
      "Size: 720\n",
      "learning\n",
      "Size: 727\n",
      "learning\n",
      "Size: 736\n",
      "learning\n",
      "Size: 746\n",
      "Size: 756\n",
      "Size: 763\n",
      "learning\n",
      "Size: 773\n",
      "Size: 783\n",
      "learning\n",
      "Size: 790\n",
      "Size: 797\n",
      "learning\n",
      "learning\n",
      "Size: 807\n",
      "Size: 816\n",
      "learning\n",
      "Size: 826\n",
      "Size: 836\n",
      "learning\n",
      "Size: 846\n",
      "Size: 853\n",
      "learning\n",
      "Size: 863\n",
      "Size: 870\n",
      "learning\n",
      "Size: 879\n",
      "Size: 885\n",
      "learning\n",
      "learning\n",
      "Size: 894\n",
      "Size: 904\n",
      "learning\n",
      "Size: 913\n",
      "Size: 922\n",
      "learning\n",
      "Size: 931\n",
      "Size: 938\n",
      "Size: 944\n",
      "Size: 950\n",
      "learning\n",
      "learning\n",
      "Size: 959\n",
      "Size: 966\n",
      "learning\n",
      "Size: 976\n",
      "Size: 985\n",
      "learning\n",
      "Size: 995\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 0, 0, 6, 5],\n",
      "        [4, 0, 3, 2, 5],\n",
      "        [2, 1, 0, 6, 5],\n",
      "        [4, 0, 8, 6, 5],\n",
      "        [2, 6, 3, 5, 7],\n",
      "        [4, 3, 8, 6, 5],\n",
      "        [6, 1, 0, 6, 5],\n",
      "        [6, 1, 5, 0, 7]])\n",
      "target value tensor([[-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900]])\n",
      "predicted values tensor([[[-0.1328],\n",
      "         [ 0.0732],\n",
      "         [ 0.1123],\n",
      "         [ 0.0806],\n",
      "         [ 0.1289],\n",
      "         [ 0.1875]],\n",
      "\n",
      "        [[ 0.7344],\n",
      "         [ 0.2148],\n",
      "         [-0.1328],\n",
      "         [-0.1206],\n",
      "         [-0.0334],\n",
      "         [ 0.1436]],\n",
      "\n",
      "        [[-0.4805],\n",
      "         [ 0.0040],\n",
      "         [ 0.1099],\n",
      "         [ 0.0938],\n",
      "         [ 0.1660],\n",
      "         [ 0.2080]],\n",
      "\n",
      "        [[ 0.4102],\n",
      "         [ 0.1689],\n",
      "         [ 0.0103],\n",
      "         [-0.0554],\n",
      "         [-0.0037],\n",
      "         [ 0.0850]],\n",
      "\n",
      "        [[ 0.7344],\n",
      "         [ 0.1299],\n",
      "         [-0.1279],\n",
      "         [-0.1387],\n",
      "         [-0.0393],\n",
      "         [ 0.0388]],\n",
      "\n",
      "        [[ 0.4004],\n",
      "         [-0.2109],\n",
      "         [-0.2012],\n",
      "         [-0.1089],\n",
      "         [ 0.0918],\n",
      "         [ 0.2158]],\n",
      "\n",
      "        [[-0.2451],\n",
      "         [ 0.0664],\n",
      "         [ 0.1289],\n",
      "         [ 0.1099],\n",
      "         [ 0.1865],\n",
      "         [ 0.1865]],\n",
      "\n",
      "        [[ 0.9844],\n",
      "         [ 0.1011],\n",
      "         [-0.1641],\n",
      "         [-0.0908],\n",
      "         [-0.0013],\n",
      "         [ 0.1050]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.2236],\n",
      "         [ 0.2617],\n",
      "         [ 0.2324],\n",
      "         [ 0.2500],\n",
      "         [ 0.2539]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0693],\n",
      "         [-0.0128],\n",
      "         [ 0.0046],\n",
      "         [ 0.0220],\n",
      "         [ 0.0933]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2168],\n",
      "         [ 0.1807],\n",
      "         [ 0.1475],\n",
      "         [ 0.1660],\n",
      "         [ 0.2041]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2422],\n",
      "         [ 0.1855],\n",
      "         [ 0.2109],\n",
      "         [ 0.2012],\n",
      "         [ 0.2305]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0242],\n",
      "         [ 0.0135],\n",
      "         [ 0.0176],\n",
      "         [ 0.0554],\n",
      "         [ 0.1099]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0869],\n",
      "         [ 0.0859],\n",
      "         [ 0.1396],\n",
      "         [ 0.1855],\n",
      "         [ 0.2314]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1182],\n",
      "         [ 0.1816],\n",
      "         [ 0.1982],\n",
      "         [ 0.2578],\n",
      "         [ 0.2734]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0811],\n",
      "         [ 0.0479],\n",
      "         [ 0.1260],\n",
      "         [ 0.1191],\n",
      "         [ 0.1660]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.5547, 0.4434],\n",
      "         [0.6055, 0.3945],\n",
      "         [0.6328, 0.3691],\n",
      "         [0.6289, 0.3711],\n",
      "         [0.6367, 0.3652]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5156, 0.4824],\n",
      "         [0.5312, 0.4688],\n",
      "         [0.5586, 0.4434],\n",
      "         [0.5703, 0.4297],\n",
      "         [0.5859, 0.4121]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6094, 0.3906],\n",
      "         [0.5938, 0.4062],\n",
      "         [0.6133, 0.3887],\n",
      "         [0.6016, 0.3984],\n",
      "         [0.6133, 0.3848]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5469, 0.4551],\n",
      "         [0.5664, 0.4336],\n",
      "         [0.5781, 0.4238],\n",
      "         [0.5781, 0.4219],\n",
      "         [0.5938, 0.4043]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5234, 0.4766],\n",
      "         [0.5195, 0.4785],\n",
      "         [0.5312, 0.4668],\n",
      "         [0.5586, 0.4395],\n",
      "         [0.5664, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4668, 0.5312],\n",
      "         [0.5117, 0.4883],\n",
      "         [0.5547, 0.4453],\n",
      "         [0.5898, 0.4121],\n",
      "         [0.6094, 0.3906]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5391, 0.4629],\n",
      "         [0.5547, 0.4434],\n",
      "         [0.5977, 0.4043],\n",
      "         [0.5977, 0.4023],\n",
      "         [0.6094, 0.3906]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5352, 0.4629],\n",
      "         [0.5742, 0.4258],\n",
      "         [0.6094, 0.3906],\n",
      "         [0.6172, 0.3828],\n",
      "         [0.5977, 0.4023]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 100 to ./videos/variable_turn_tictactoe_muzero/0/episode_000100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 100 to ./videos/variable_turn_tictactoe_muzero/2/episode_000100.mp4\n",
      "Stopped recording episode 100. Recorded 7 frames.\n",
      "Started recording episode 100 to ./videos/variable_turn_tictactoe_muzero/1/episode_000100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 100. Recorded 10 frames.\n",
      "Started recording episode 100 to ./videos/variable_turn_tictactoe_muzero/3/episode_000100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 7, 3, 2, 8],\n",
      "        [6, 0, 3, 4, 3],\n",
      "        [6, 5, 1, 0, 2],\n",
      "        [1, 4, 8, 7, 3],\n",
      "        [7, 2, 4, 0, 3],\n",
      "        [4, 1, 0, 0, 3],\n",
      "        [5, 0, 0, 4, 3],\n",
      "        [0, 1, 0, 4, 3]])\n",
      "target value tensor([[ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.1108],\n",
      "         [-0.1455],\n",
      "         [-0.1221],\n",
      "         [ 0.0889],\n",
      "         [ 0.1377],\n",
      "         [ 0.0923]],\n",
      "\n",
      "        [[ 0.7109],\n",
      "         [ 0.4121],\n",
      "         [-0.0304],\n",
      "         [ 0.0337],\n",
      "         [ 0.0381],\n",
      "         [ 0.0552]],\n",
      "\n",
      "        [[ 0.4395],\n",
      "         [ 0.1357],\n",
      "         [ 0.0938],\n",
      "         [ 0.0874],\n",
      "         [-0.0249],\n",
      "         [-0.0280]],\n",
      "\n",
      "        [[ 0.3105],\n",
      "         [-0.1221],\n",
      "         [-0.1650],\n",
      "         [-0.0981],\n",
      "         [ 0.0569],\n",
      "         [ 0.1475]],\n",
      "\n",
      "        [[ 0.0089],\n",
      "         [-0.0045],\n",
      "         [-0.0801],\n",
      "         [-0.0737],\n",
      "         [-0.1973],\n",
      "         [-0.0708]],\n",
      "\n",
      "        [[-0.0540],\n",
      "         [-0.0469],\n",
      "         [-0.0659],\n",
      "         [-0.2129],\n",
      "         [-0.2119],\n",
      "         [-0.0835]],\n",
      "\n",
      "        [[ 0.3652],\n",
      "         [ 0.1758],\n",
      "         [ 0.0204],\n",
      "         [-0.0967],\n",
      "         [-0.1025],\n",
      "         [ 0.0376]],\n",
      "\n",
      "        [[ 0.1982],\n",
      "         [ 0.0588],\n",
      "         [-0.0205],\n",
      "         [-0.1201],\n",
      "         [-0.1328],\n",
      "         [-0.0742]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0408],\n",
      "         [ 0.0393],\n",
      "         [ 0.0957],\n",
      "         [ 0.1030],\n",
      "         [ 0.1875]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2949],\n",
      "         [ 0.0972],\n",
      "         [ 0.1455],\n",
      "         [ 0.2422],\n",
      "         [ 0.1504]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1387],\n",
      "         [ 0.2090],\n",
      "         [ 0.1680],\n",
      "         [ 0.0835],\n",
      "         [ 0.1533]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0124],\n",
      "         [ 0.0869],\n",
      "         [ 0.1377],\n",
      "         [ 0.1953],\n",
      "         [ 0.1719]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2334],\n",
      "         [ 0.2852],\n",
      "         [ 0.3203],\n",
      "         [ 0.1807],\n",
      "         [ 0.1992]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3086],\n",
      "         [ 0.1816],\n",
      "         [ 0.1099],\n",
      "         [ 0.0723],\n",
      "         [ 0.1201]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2178],\n",
      "         [ 0.1523],\n",
      "         [ 0.0630],\n",
      "         [ 0.1465],\n",
      "         [ 0.2090]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1118],\n",
      "         [-0.0160],\n",
      "         [-0.0391],\n",
      "         [ 0.1001],\n",
      "         [ 0.1445]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.3711, 0.6289],\n",
      "         [0.4727, 0.5273],\n",
      "         [0.5977, 0.4043],\n",
      "         [0.6445, 0.3574],\n",
      "         [0.6914, 0.3086]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5391, 0.4590],\n",
      "         [0.5391, 0.4590],\n",
      "         [0.5898, 0.4121],\n",
      "         [0.5781, 0.4219],\n",
      "         [0.6289, 0.3730]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6172, 0.3809],\n",
      "         [0.6641, 0.3359],\n",
      "         [0.6602, 0.3398],\n",
      "         [0.6875, 0.3125],\n",
      "         [0.7031, 0.2949]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4102, 0.5898],\n",
      "         [0.4434, 0.5547],\n",
      "         [0.5547, 0.4453],\n",
      "         [0.6211, 0.3789],\n",
      "         [0.6758, 0.3242]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5547, 0.4473],\n",
      "         [0.5820, 0.4199],\n",
      "         [0.6133, 0.3848],\n",
      "         [0.6523, 0.3496],\n",
      "         [0.6992, 0.3027]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5117, 0.4883],\n",
      "         [0.5898, 0.4121],\n",
      "         [0.6836, 0.3184],\n",
      "         [0.7070, 0.2910],\n",
      "         [0.7188, 0.2793]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6328, 0.3691],\n",
      "         [0.6562, 0.3457],\n",
      "         [0.6523, 0.3496],\n",
      "         [0.6406, 0.3594],\n",
      "         [0.6797, 0.3203]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6289, 0.3691],\n",
      "         [0.6445, 0.3555],\n",
      "         [0.6680, 0.3340],\n",
      "         [0.6406, 0.3613],\n",
      "         [0.6680, 0.3320]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 0, 8, 8, 0],\n",
      "        [1, 6, 0, 3, 0],\n",
      "        [5, 4, 1, 6, 0],\n",
      "        [1, 5, 6, 7, 0],\n",
      "        [5, 0, 1, 2, 4],\n",
      "        [8, 3, 6, 5, 0],\n",
      "        [5, 7, 6, 0, 0],\n",
      "        [6, 8, 0, 0, 0]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2852],\n",
      "         [ 0.2988],\n",
      "         [ 0.0344],\n",
      "         [ 0.0830],\n",
      "         [ 0.1338],\n",
      "         [ 0.0520]],\n",
      "\n",
      "        [[ 0.5508],\n",
      "         [ 0.2490],\n",
      "         [ 0.2910],\n",
      "         [ 0.2070],\n",
      "         [ 0.3164],\n",
      "         [ 0.2207]],\n",
      "\n",
      "        [[ 0.3418],\n",
      "         [-0.0825],\n",
      "         [ 0.1855],\n",
      "         [ 0.2715],\n",
      "         [ 0.2500],\n",
      "         [ 0.1699]],\n",
      "\n",
      "        [[-0.4590],\n",
      "         [-0.0282],\n",
      "         [ 0.1973],\n",
      "         [ 0.1196],\n",
      "         [ 0.2100],\n",
      "         [ 0.2109]],\n",
      "\n",
      "        [[-0.5781],\n",
      "         [-0.0259],\n",
      "         [ 0.1963],\n",
      "         [ 0.1318],\n",
      "         [ 0.1621],\n",
      "         [ 0.1865]],\n",
      "\n",
      "        [[-0.5000],\n",
      "         [ 0.2051],\n",
      "         [ 0.3574],\n",
      "         [ 0.2891],\n",
      "         [ 0.2139],\n",
      "         [ 0.2070]],\n",
      "\n",
      "        [[-0.6602],\n",
      "         [ 0.2051],\n",
      "         [ 0.3906],\n",
      "         [ 0.3496],\n",
      "         [ 0.2070],\n",
      "         [ 0.1582]],\n",
      "\n",
      "        [[-0.0309],\n",
      "         [ 0.3398],\n",
      "         [ 0.3398],\n",
      "         [ 0.2578],\n",
      "         [ 0.1738],\n",
      "         [ 0.1113]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 2.4512e-01],\n",
      "         [ 4.4434e-02],\n",
      "         [ 7.9590e-02],\n",
      "         [ 8.3984e-02],\n",
      "         [ 1.2302e-04]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 3.0469e-01],\n",
      "         [ 3.7109e-01],\n",
      "         [ 2.4902e-01],\n",
      "         [ 2.9688e-01],\n",
      "         [ 1.6699e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 3.5156e-02],\n",
      "         [ 1.2109e-01],\n",
      "         [ 4.2236e-02],\n",
      "         [ 1.4160e-01],\n",
      "         [ 3.6621e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-4.3213e-02],\n",
      "         [ 6.0547e-02],\n",
      "         [ 9.2773e-02],\n",
      "         [ 1.3574e-01],\n",
      "         [ 3.9062e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.0801e-02],\n",
      "         [ 1.2695e-01],\n",
      "         [ 1.4160e-01],\n",
      "         [ 2.9102e-01],\n",
      "         [ 3.0469e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.4189e-02],\n",
      "         [ 5.6885e-02],\n",
      "         [ 2.0020e-01],\n",
      "         [ 2.0410e-01],\n",
      "         [ 1.4551e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.0840e-01],\n",
      "         [ 2.1094e-01],\n",
      "         [ 2.5391e-01],\n",
      "         [ 1.2598e-01],\n",
      "         [ 2.1606e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.8906e-01],\n",
      "         [ 3.5742e-01],\n",
      "         [ 2.7734e-01],\n",
      "         [ 1.8848e-01],\n",
      "         [ 1.2451e-01]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.4707, 0.5273],\n",
      "         [0.5625, 0.4395],\n",
      "         [0.6328, 0.3691],\n",
      "         [0.6836, 0.3184],\n",
      "         [0.7266, 0.2734]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5391, 0.4609],\n",
      "         [0.6484, 0.3516],\n",
      "         [0.6836, 0.3184],\n",
      "         [0.6914, 0.3086],\n",
      "         [0.6602, 0.3398]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.1875, 0.8125],\n",
      "         [0.3945, 0.6055],\n",
      "         [0.5977, 0.4023],\n",
      "         [0.6445, 0.3535],\n",
      "         [0.6680, 0.3320]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4824, 0.5195],\n",
      "         [0.6523, 0.3477],\n",
      "         [0.6562, 0.3438],\n",
      "         [0.6250, 0.3730],\n",
      "         [0.6641, 0.3379]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6094, 0.3887],\n",
      "         [0.7383, 0.2617],\n",
      "         [0.7344, 0.2637],\n",
      "         [0.7461, 0.2559],\n",
      "         [0.6953, 0.3066]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4688, 0.5312],\n",
      "         [0.6797, 0.3203],\n",
      "         [0.6836, 0.3145],\n",
      "         [0.6523, 0.3496],\n",
      "         [0.6562, 0.3457]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6562, 0.3438],\n",
      "         [0.6758, 0.3242],\n",
      "         [0.6406, 0.3574],\n",
      "         [0.6797, 0.3203],\n",
      "         [0.6797, 0.3184]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5742, 0.4258],\n",
      "         [0.6406, 0.3594],\n",
      "         [0.6602, 0.3398],\n",
      "         [0.6523, 0.3477],\n",
      "         [0.6602, 0.3418]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 200 to ./videos/variable_turn_tictactoe_muzero/1/episode_000200.mp4\n",
      "learning\n",
      "learning\n",
      "Started recording episode 200 to ./videos/variable_turn_tictactoe_muzero/0/episode_000200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 200. Recorded 10 frames.\n",
      "Stopped recording episode 200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 200 to ./videos/variable_turn_tictactoe_muzero/3/episode_000200.mp4\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Started recording episode 200 to ./videos/variable_turn_tictactoe_muzero/2/episode_000200.mp4\n",
      "Stopped recording episode 200. Recorded 10 frames.\n",
      "Stopped recording episode 200. Recorded 10 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 0, 2, 8, 1],\n",
      "        [8, 5, 0, 4, 3],\n",
      "        [3, 2, 0, 8, 1],\n",
      "        [8, 4, 7, 2, 0],\n",
      "        [7, 5, 0, 3, 6],\n",
      "        [8, 0, 2, 8, 1],\n",
      "        [6, 5, 0, 8, 1],\n",
      "        [0, 0, 2, 8, 1]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4258],\n",
      "         [ 0.0054],\n",
      "         [-0.1807],\n",
      "         [ 0.0300],\n",
      "         [ 0.3848],\n",
      "         [ 0.2910]],\n",
      "\n",
      "        [[-0.3418],\n",
      "         [-0.0320],\n",
      "         [ 0.3965],\n",
      "         [ 0.4395],\n",
      "         [ 0.1631],\n",
      "         [ 0.0771]],\n",
      "\n",
      "        [[-0.2871],\n",
      "         [ 0.3184],\n",
      "         [ 0.3027],\n",
      "         [-0.0454],\n",
      "         [-0.0134],\n",
      "         [ 0.0156]],\n",
      "\n",
      "        [[-0.0183],\n",
      "         [ 0.0752],\n",
      "         [-0.2520],\n",
      "         [-0.0820],\n",
      "         [ 0.2393],\n",
      "         [ 0.0947]],\n",
      "\n",
      "        [[ 0.5469],\n",
      "         [ 0.1924],\n",
      "         [-0.3965],\n",
      "         [-0.4238],\n",
      "         [ 0.3984],\n",
      "         [ 0.4355]],\n",
      "\n",
      "        [[ 0.7344],\n",
      "         [ 0.3086],\n",
      "         [-0.1240],\n",
      "         [ 0.0620],\n",
      "         [ 0.2178],\n",
      "         [ 0.1572]],\n",
      "\n",
      "        [[ 0.3203],\n",
      "         [ 0.4414],\n",
      "         [ 0.2080],\n",
      "         [ 0.0447],\n",
      "         [ 0.0698],\n",
      "         [ 0.1943]],\n",
      "\n",
      "        [[ 0.8047],\n",
      "         [-0.2559],\n",
      "         [-0.3184],\n",
      "         [ 0.2354],\n",
      "         [ 0.3555],\n",
      "         [ 0.1611]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.4082],\n",
      "         [ 0.3086],\n",
      "         [ 0.3379],\n",
      "         [ 0.3926],\n",
      "         [ 0.4199]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0237],\n",
      "         [ 0.0359],\n",
      "         [ 0.1494],\n",
      "         [ 0.3145],\n",
      "         [ 0.3105]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1895],\n",
      "         [ 0.4395],\n",
      "         [ 0.2988],\n",
      "         [ 0.3242],\n",
      "         [ 0.2812]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2080],\n",
      "         [ 0.2354],\n",
      "         [ 0.2061],\n",
      "         [ 0.3770],\n",
      "         [ 0.2676]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0947],\n",
      "         [ 0.0297],\n",
      "         [-0.0601],\n",
      "         [-0.0238],\n",
      "         [ 0.1953]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2793],\n",
      "         [ 0.1836],\n",
      "         [ 0.3105],\n",
      "         [ 0.3223],\n",
      "         [ 0.3477]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3496],\n",
      "         [ 0.3945],\n",
      "         [ 0.3125],\n",
      "         [ 0.3086],\n",
      "         [ 0.2910]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3027],\n",
      "         [ 0.1777],\n",
      "         [ 0.3516],\n",
      "         [ 0.4375],\n",
      "         [ 0.4043]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.5391, 0.4609],\n",
      "         [0.1074, 0.8906],\n",
      "         [0.3125, 0.6875],\n",
      "         [0.8047, 0.1934],\n",
      "         [0.7070, 0.2930]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.3574, 0.6406],\n",
      "         [0.9180, 0.0835],\n",
      "         [0.8945, 0.1069],\n",
      "         [0.4160, 0.5859],\n",
      "         [0.3652, 0.6367]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8594, 0.1426],\n",
      "         [0.7852, 0.2148],\n",
      "         [0.5586, 0.4414],\n",
      "         [0.5938, 0.4082],\n",
      "         [0.6641, 0.3359]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.4629, 0.5352],\n",
      "         [0.1196, 0.8789],\n",
      "         [0.7109, 0.2891],\n",
      "         [0.8984, 0.1021],\n",
      "         [0.6953, 0.3047]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9180, 0.0830],\n",
      "         [0.0374, 0.9609],\n",
      "         [0.0542, 0.9453],\n",
      "         [0.9336, 0.0659],\n",
      "         [0.9336, 0.0679]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.7227, 0.2773],\n",
      "         [0.2178, 0.7812],\n",
      "         [0.6133, 0.3867],\n",
      "         [0.6953, 0.3027],\n",
      "         [0.6445, 0.3535]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8047, 0.1934],\n",
      "         [0.5625, 0.4375],\n",
      "         [0.4082, 0.5898],\n",
      "         [0.4004, 0.5977],\n",
      "         [0.6016, 0.3965]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.2930, 0.7070],\n",
      "         [0.3086, 0.6914],\n",
      "         [0.8477, 0.1514],\n",
      "         [0.8008, 0.2002],\n",
      "         [0.5352, 0.4629]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 6, 7, 5, 4],\n",
      "        [3, 0, 3, 2, 5],\n",
      "        [7, 0, 5, 1, 8],\n",
      "        [1, 0, 4, 8, 6],\n",
      "        [8, 5, 6, 4, 7],\n",
      "        [7, 6, 5, 2, 1],\n",
      "        [6, 0, 0, 2, 5],\n",
      "        [6, 8, 3, 5, 7]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.3906],\n",
      "         [ 0.1729],\n",
      "         [-0.2910],\n",
      "         [-0.2695],\n",
      "         [ 0.2168],\n",
      "         [ 0.1768]],\n",
      "\n",
      "        [[ 0.8945],\n",
      "         [ 0.4199],\n",
      "         [ 0.0757],\n",
      "         [ 0.0201],\n",
      "         [ 0.2949],\n",
      "         [ 0.1816]],\n",
      "\n",
      "        [[-0.7891],\n",
      "         [ 0.3125],\n",
      "         [ 0.3477],\n",
      "         [ 0.1099],\n",
      "         [-0.0718],\n",
      "         [ 0.0217]],\n",
      "\n",
      "        [[ 0.3906],\n",
      "         [ 0.1729],\n",
      "         [-0.3262],\n",
      "         [-0.4102],\n",
      "         [ 0.1904],\n",
      "         [ 0.2715]],\n",
      "\n",
      "        [[-0.2910],\n",
      "         [ 0.2178],\n",
      "         [ 0.3242],\n",
      "         [ 0.1504],\n",
      "         [-0.1172],\n",
      "         [ 0.0420]],\n",
      "\n",
      "        [[ 0.6328],\n",
      "         [-0.4512],\n",
      "         [-0.3027],\n",
      "         [ 0.3340],\n",
      "         [ 0.3008],\n",
      "         [-0.1436]],\n",
      "\n",
      "        [[ 0.1641],\n",
      "         [ 0.3086],\n",
      "         [ 0.0074],\n",
      "         [-0.1011],\n",
      "         [-0.0021],\n",
      "         [ 0.0547]],\n",
      "\n",
      "        [[ 0.4629],\n",
      "         [-0.3262],\n",
      "         [-0.2617],\n",
      "         [ 0.3867],\n",
      "         [ 0.1562],\n",
      "         [ 0.0125]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0200],\n",
      "         [-0.0060],\n",
      "         [-0.0349],\n",
      "         [ 0.0286],\n",
      "         [ 0.2119]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3594],\n",
      "         [ 0.1455],\n",
      "         [ 0.0786],\n",
      "         [ 0.1855],\n",
      "         [ 0.2295]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0139],\n",
      "         [ 0.0288],\n",
      "         [ 0.1768],\n",
      "         [ 0.1533],\n",
      "         [ 0.1206]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0200],\n",
      "         [-0.1118],\n",
      "         [-0.0708],\n",
      "         [-0.0708],\n",
      "         [ 0.1289]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0245],\n",
      "         [ 0.1426],\n",
      "         [ 0.2715],\n",
      "         [ 0.2148],\n",
      "         [ 0.1387]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0894],\n",
      "         [-0.0087],\n",
      "         [ 0.0132],\n",
      "         [ 0.2295],\n",
      "         [ 0.2598]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1611],\n",
      "         [ 0.0393],\n",
      "         [-0.0439],\n",
      "         [ 0.1758],\n",
      "         [ 0.1875]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0488],\n",
      "         [ 0.0193],\n",
      "         [-0.0148],\n",
      "         [ 0.1562],\n",
      "         [ 0.2295]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.9375, 0.0630],\n",
      "         [0.0244, 0.9766],\n",
      "         [0.0210, 0.9805],\n",
      "         [0.9727, 0.0272],\n",
      "         [0.9570, 0.0444]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8516, 0.1494],\n",
      "         [0.4180, 0.5820],\n",
      "         [0.2988, 0.7031],\n",
      "         [0.8398, 0.1602],\n",
      "         [0.7695, 0.2324]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9062, 0.0942],\n",
      "         [0.9648, 0.0354],\n",
      "         [0.7383, 0.2598],\n",
      "         [0.2695, 0.7305],\n",
      "         [0.4434, 0.5586]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9375, 0.0630],\n",
      "         [0.0248, 0.9766],\n",
      "         [0.0349, 0.9648],\n",
      "         [0.9336, 0.0669],\n",
      "         [0.9727, 0.0280]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8945, 0.1069],\n",
      "         [0.9297, 0.0693],\n",
      "         [0.5625, 0.4355],\n",
      "         [0.2070, 0.7930],\n",
      "         [0.4062, 0.5938]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0115, 0.9883],\n",
      "         [0.0194, 0.9805],\n",
      "         [0.9844, 0.0157],\n",
      "         [0.9688, 0.0332],\n",
      "         [0.4004, 0.6016]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8828, 0.1177],\n",
      "         [0.2969, 0.7031],\n",
      "         [0.1729, 0.8281],\n",
      "         [0.5664, 0.4336],\n",
      "         [0.8125, 0.1875]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0083, 0.9922],\n",
      "         [0.0266, 0.9727],\n",
      "         [0.9688, 0.0325],\n",
      "         [0.8477, 0.1543],\n",
      "         [0.1504, 0.8516]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 300 to ./videos/variable_turn_tictactoe_muzero/0/episode_000300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 300. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 300 to ./videos/variable_turn_tictactoe_muzero/1/episode_000300.mp4\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Stopped recording episode 300. Recorded 7 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 300 to ./videos/variable_turn_tictactoe_muzero/3/episode_000300.mp4\n",
      "learning\n",
      "600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 4, 3, 0, 2],\n",
      "        [0, 1, 7, 8, 4],\n",
      "        [0, 0, 6, 0, 8],\n",
      "        [7, 8, 0, 0, 8],\n",
      "        [2, 4, 5, 0, 8],\n",
      "        [7, 1, 6, 2, 0],\n",
      "        [4, 0, 1, 2, 3],\n",
      "        [1, 3, 4, 7, 2]])\n",
      "target value tensor([[ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900]])\n",
      "predicted values tensor([[[ 0.5703],\n",
      "         [ 0.3906],\n",
      "         [-0.3984],\n",
      "         [-0.4531],\n",
      "         [ 0.4688],\n",
      "         [ 0.3652]],\n",
      "\n",
      "        [[ 0.6367],\n",
      "         [-0.4355],\n",
      "         [-0.4102],\n",
      "         [ 0.4414],\n",
      "         [ 0.4414],\n",
      "         [ 0.1494]],\n",
      "\n",
      "        [[ 0.5117],\n",
      "         [ 0.1582],\n",
      "         [-0.0121],\n",
      "         [ 0.1797],\n",
      "         [ 0.3398],\n",
      "         [ 0.3418]],\n",
      "\n",
      "        [[ 0.7070],\n",
      "         [ 0.3691],\n",
      "         [-0.0957],\n",
      "         [-0.0845],\n",
      "         [ 0.4375],\n",
      "         [ 0.4297]],\n",
      "\n",
      "        [[-0.1973],\n",
      "         [ 0.1069],\n",
      "         [ 0.0074],\n",
      "         [-0.0225],\n",
      "         [ 0.1084],\n",
      "         [ 0.1836]],\n",
      "\n",
      "        [[-0.4980],\n",
      "         [-0.3652],\n",
      "         [ 0.4512],\n",
      "         [ 0.5586],\n",
      "         [ 0.1309],\n",
      "         [-0.1406]],\n",
      "\n",
      "        [[-0.2500],\n",
      "         [-0.0752],\n",
      "         [ 0.5625],\n",
      "         [ 0.3164],\n",
      "         [ 0.0090],\n",
      "         [-0.2285]],\n",
      "\n",
      "        [[ 0.7188],\n",
      "         [-0.3184],\n",
      "         [-0.3711],\n",
      "         [ 0.5391],\n",
      "         [ 0.3613],\n",
      "         [-0.0498]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0135],\n",
      "         [ 0.0806],\n",
      "         [-0.0369],\n",
      "         [-0.0532],\n",
      "         [ 0.2773]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0518],\n",
      "         [-0.0698],\n",
      "         [ 0.0029],\n",
      "         [ 0.0991],\n",
      "         [ 0.2793]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2891],\n",
      "         [ 0.0173],\n",
      "         [-0.0200],\n",
      "         [ 0.0220],\n",
      "         [ 0.2061]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3691],\n",
      "         [ 0.1357],\n",
      "         [-0.0237],\n",
      "         [ 0.1436],\n",
      "         [ 0.2793]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1514],\n",
      "         [ 0.2949],\n",
      "         [ 0.2197],\n",
      "         [ 0.1582],\n",
      "         [ 0.2070]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0247],\n",
      "         [-0.0006],\n",
      "         [ 0.2432],\n",
      "         [ 0.4375],\n",
      "         [ 0.0669]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0635],\n",
      "         [ 0.0295],\n",
      "         [ 0.1387],\n",
      "         [ 0.2910],\n",
      "         [ 0.1562]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0067],\n",
      "         [-0.0928],\n",
      "         [ 0.0786],\n",
      "         [ 0.2246],\n",
      "         [ 0.3418]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.9688, 0.0322],\n",
      "         [0.0029, 0.9961],\n",
      "         [0.0046, 0.9961],\n",
      "         [0.9844, 0.0156],\n",
      "         [0.9844, 0.0176]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0030, 0.9961],\n",
      "         [0.0011, 1.0000],\n",
      "         [0.8984, 0.1025],\n",
      "         [0.9883, 0.0110],\n",
      "         [0.4043, 0.5977]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.5391, 0.4609],\n",
      "         [0.0615, 0.9375],\n",
      "         [0.0908, 0.9102],\n",
      "         [0.8242, 0.1768],\n",
      "         [0.8984, 0.1021]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6836, 0.3184],\n",
      "         [0.0221, 0.9766],\n",
      "         [0.0102, 0.9883],\n",
      "         [0.8828, 0.1182],\n",
      "         [0.9727, 0.0267]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8281, 0.1738],\n",
      "         [0.2559, 0.7422],\n",
      "         [0.0850, 0.9141],\n",
      "         [0.2344, 0.7656],\n",
      "         [0.5859, 0.4141]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0031, 0.9961],\n",
      "         [0.8945, 0.1060],\n",
      "         [0.9883, 0.0130],\n",
      "         [0.4414, 0.5586],\n",
      "         [0.0181, 0.9805]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0114, 0.9883],\n",
      "         [0.9766, 0.0226],\n",
      "         [0.9258, 0.0737],\n",
      "         [0.1875, 0.8125],\n",
      "         [0.0041, 0.9961]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0017, 1.0000],\n",
      "         [0.0012, 1.0000],\n",
      "         [0.9570, 0.0430],\n",
      "         [0.9766, 0.0217],\n",
      "         [0.2676, 0.7305]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 300. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 300 to ./videos/variable_turn_tictactoe_muzero/2/episode_000300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 300. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "700\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 1, 5, 0, 2],\n",
      "        [7, 0, 3, 0, 2],\n",
      "        [8, 6, 2, 0, 4],\n",
      "        [4, 3, 0, 0, 2],\n",
      "        [7, 0, 0, 0, 2],\n",
      "        [3, 1, 5, 0, 8],\n",
      "        [3, 5, 2, 6, 4],\n",
      "        [8, 7, 3, 4, 2]])\n",
      "target value tensor([[-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2754],\n",
      "         [ 0.1787],\n",
      "         [ 0.0820],\n",
      "         [ 0.1650],\n",
      "         [ 0.0796],\n",
      "         [ 0.0874]],\n",
      "\n",
      "        [[ 0.1348],\n",
      "         [ 0.2129],\n",
      "         [ 0.2656],\n",
      "         [ 0.1206],\n",
      "         [ 0.1338],\n",
      "         [ 0.1484]],\n",
      "\n",
      "        [[ 0.3574],\n",
      "         [ 0.3047],\n",
      "         [-0.2148],\n",
      "         [-0.3066],\n",
      "         [ 0.3535],\n",
      "         [ 0.2949]],\n",
      "\n",
      "        [[ 0.3789],\n",
      "         [ 0.3457],\n",
      "         [ 0.1050],\n",
      "         [-0.0530],\n",
      "         [ 0.1836],\n",
      "         [ 0.3164]],\n",
      "\n",
      "        [[ 0.0255],\n",
      "         [ 0.3008],\n",
      "         [ 0.1680],\n",
      "         [ 0.1025],\n",
      "         [ 0.0615],\n",
      "         [ 0.0830]],\n",
      "\n",
      "        [[-0.3652],\n",
      "         [ 0.4883],\n",
      "         [ 0.3125],\n",
      "         [ 0.0125],\n",
      "         [ 0.0581],\n",
      "         [ 0.2832]],\n",
      "\n",
      "        [[ 0.1465],\n",
      "         [ 0.1245],\n",
      "         [-0.0354],\n",
      "         [ 0.3652],\n",
      "         [ 0.2598],\n",
      "         [ 0.0388]],\n",
      "\n",
      "        [[ 0.4336],\n",
      "         [-0.2734],\n",
      "         [-0.1992],\n",
      "         [ 0.4844],\n",
      "         [ 0.3965],\n",
      "         [ 0.1021]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.3906],\n",
      "         [ 0.2930],\n",
      "         [ 0.4902],\n",
      "         [ 0.4023],\n",
      "         [ 0.4395]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2637],\n",
      "         [ 0.3105],\n",
      "         [ 0.2891],\n",
      "         [ 0.0129],\n",
      "         [ 0.2256]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0211],\n",
      "         [ 0.0747],\n",
      "         [ 0.0425],\n",
      "         [ 0.0272],\n",
      "         [ 0.1562]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2207],\n",
      "         [ 0.2988],\n",
      "         [-0.0227],\n",
      "         [-0.0209],\n",
      "         [ 0.1865]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3184],\n",
      "         [ 0.3301],\n",
      "         [ 0.0654],\n",
      "         [-0.0264],\n",
      "         [ 0.1611]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0537],\n",
      "         [ 0.1069],\n",
      "         [ 0.2236],\n",
      "         [ 0.0703],\n",
      "         [ 0.2656]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0128],\n",
      "         [ 0.0192],\n",
      "         [ 0.1250],\n",
      "         [ 0.1670],\n",
      "         [ 0.2734]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0464],\n",
      "         [-0.0425],\n",
      "         [-0.1011],\n",
      "         [ 0.1079],\n",
      "         [ 0.3008]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.5703, 0.4297],\n",
      "         [0.2539, 0.7461],\n",
      "         [0.6328, 0.3672],\n",
      "         [0.7539, 0.2461],\n",
      "         [0.6523, 0.3457]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.1162, 0.8828],\n",
      "         [0.9453, 0.0530],\n",
      "         [0.8555, 0.1436],\n",
      "         [0.2285, 0.7695],\n",
      "         [0.3066, 0.6914]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9883, 0.0120],\n",
      "         [0.0112, 0.9883],\n",
      "         [0.0031, 0.9961],\n",
      "         [0.9922, 0.0097],\n",
      "         [0.9922, 0.0064]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9922, 0.0070],\n",
      "         [0.4141, 0.5859],\n",
      "         [0.0089, 0.9922],\n",
      "         [0.8477, 0.1533],\n",
      "         [0.9844, 0.0157]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8750, 0.1260],\n",
      "         [0.7852, 0.2129],\n",
      "         [0.3418, 0.6562],\n",
      "         [0.3457, 0.6562],\n",
      "         [0.6484, 0.3535]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9922, 0.0074],\n",
      "         [0.9688, 0.0317],\n",
      "         [0.1592, 0.8398],\n",
      "         [0.0374, 0.9609],\n",
      "         [0.6953, 0.3047]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0481, 0.9531],\n",
      "         [0.0041, 0.9961],\n",
      "         [0.9727, 0.0270],\n",
      "         [0.9883, 0.0127],\n",
      "         [0.3496, 0.6523]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0032, 0.9961],\n",
      "         [0.0090, 0.9922],\n",
      "         [0.9961, 0.0052],\n",
      "         [0.9844, 0.0156],\n",
      "         [0.3867, 0.6133]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 400 to ./videos/variable_turn_tictactoe_muzero/0/episode_000400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Stopped recording episode 400. Recorded 9 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 400 to ./videos/variable_turn_tictactoe_muzero/1/episode_000400.mp4\n",
      "Stopped recording episode 400. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "800\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 8, 7, 3, 1],\n",
      "        [1, 5, 6, 7, 0],\n",
      "        [6, 3, 8, 5, 1],\n",
      "        [2, 3, 7, 4, 8],\n",
      "        [6, 7, 0, 2, 1],\n",
      "        [5, 1, 4, 8, 3],\n",
      "        [1, 3, 0, 4, 5],\n",
      "        [4, 3, 8, 0, 6]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[-0.5234],\n",
      "         [-0.2578],\n",
      "         [ 0.4727],\n",
      "         [ 0.1572],\n",
      "         [-0.0160],\n",
      "         [-0.0045]],\n",
      "\n",
      "        [[-0.5508],\n",
      "         [-0.3223],\n",
      "         [ 0.3379],\n",
      "         [ 0.2598],\n",
      "         [-0.0811],\n",
      "         [-0.0928]],\n",
      "\n",
      "        [[-0.3262],\n",
      "         [ 0.4531],\n",
      "         [ 0.3809],\n",
      "         [ 0.1108],\n",
      "         [-0.0325],\n",
      "         [ 0.2539]],\n",
      "\n",
      "        [[ 0.2988],\n",
      "         [ 0.2676],\n",
      "         [-0.1982],\n",
      "         [-0.2490],\n",
      "         [ 0.5547],\n",
      "         [ 0.2578]],\n",
      "\n",
      "        [[ 0.2734],\n",
      "         [-0.1631],\n",
      "         [-0.3887],\n",
      "         [ 0.4082],\n",
      "         [ 0.3145],\n",
      "         [-0.0369]],\n",
      "\n",
      "        [[ 0.5859],\n",
      "         [-0.3887],\n",
      "         [-0.2773],\n",
      "         [ 0.4941],\n",
      "         [ 0.2969],\n",
      "         [-0.0547]],\n",
      "\n",
      "        [[ 0.3047],\n",
      "         [ 0.1826],\n",
      "         [ 0.2090],\n",
      "         [ 0.0227],\n",
      "         [-0.0369],\n",
      "         [ 0.0022]],\n",
      "\n",
      "        [[ 0.2988],\n",
      "         [ 0.4199],\n",
      "         [-0.2949],\n",
      "         [-0.3242],\n",
      "         [ 0.4512],\n",
      "         [ 0.3457]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0209],\n",
      "         [ 0.0187],\n",
      "         [ 0.2295],\n",
      "         [ 0.3105],\n",
      "         [ 0.0898]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0679],\n",
      "         [ 0.0087],\n",
      "         [ 0.2275],\n",
      "         [ 0.3301],\n",
      "         [-0.0459]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0918],\n",
      "         [ 0.1187],\n",
      "         [ 0.2891],\n",
      "         [ 0.1279],\n",
      "         [ 0.2695]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0400],\n",
      "         [ 0.0107],\n",
      "         [-0.0471],\n",
      "         [ 0.0693],\n",
      "         [ 0.2021]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0850],\n",
      "         [-0.0762],\n",
      "         [ 0.0378],\n",
      "         [ 0.2080],\n",
      "         [ 0.3184]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0184],\n",
      "         [-0.1104],\n",
      "         [ 0.0449],\n",
      "         [ 0.1621],\n",
      "         [ 0.2256]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2871],\n",
      "         [ 0.4219],\n",
      "         [ 0.1777],\n",
      "         [ 0.0757],\n",
      "         [ 0.1226]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0461],\n",
      "         [ 0.0598],\n",
      "         [-0.0304],\n",
      "         [ 0.0092],\n",
      "         [ 0.1934]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.0127, 0.9883],\n",
      "         [0.9922, 0.0079],\n",
      "         [0.9609, 0.0393],\n",
      "         [0.2656, 0.7344],\n",
      "         [0.0193, 0.9805]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0029, 0.9961],\n",
      "         [0.9844, 0.0145],\n",
      "         [0.9883, 0.0103],\n",
      "         [0.2217, 0.7773],\n",
      "         [0.0403, 0.9609]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9648, 0.0337],\n",
      "         [0.9727, 0.0273],\n",
      "         [0.3359, 0.6641],\n",
      "         [0.0354, 0.9648],\n",
      "         [0.7383, 0.2617]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9883, 0.0117],\n",
      "         [0.0110, 0.9883],\n",
      "         [0.0084, 0.9922],\n",
      "         [0.9883, 0.0125],\n",
      "         [0.9727, 0.0273]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0364, 0.9648],\n",
      "         [0.0029, 0.9961],\n",
      "         [0.9805, 0.0205],\n",
      "         [0.9883, 0.0100],\n",
      "         [0.2969, 0.7031]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0063, 0.9922],\n",
      "         [0.0034, 0.9961],\n",
      "         [0.9844, 0.0173],\n",
      "         [0.9883, 0.0120],\n",
      "         [0.2871, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.6172, 0.3809],\n",
      "         [0.9375, 0.0630],\n",
      "         [0.7422, 0.2559],\n",
      "         [0.4375, 0.5625],\n",
      "         [0.3594, 0.6406]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9883, 0.0102],\n",
      "         [0.0120, 0.9883],\n",
      "         [0.0036, 0.9961],\n",
      "         [0.9883, 0.0103],\n",
      "         [0.9883, 0.0115]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 400 to ./videos/variable_turn_tictactoe_muzero/3/episode_000400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 400. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 400 to ./videos/variable_turn_tictactoe_muzero/2/episode_000400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 400. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "900\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 3, 4, 7, 1],\n",
      "        [7, 2, 8, 0, 0],\n",
      "        [4, 1, 0, 7, 0],\n",
      "        [6, 0, 0, 7, 0],\n",
      "        [1, 2, 0, 7, 0],\n",
      "        [4, 6, 7, 2, 3],\n",
      "        [1, 5, 2, 0, 0],\n",
      "        [8, 5, 2, 3, 4]])\n",
      "target value tensor([[-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801]])\n",
      "predicted values tensor([[[-0.3633],\n",
      "         [ 0.1138],\n",
      "         [ 0.2520],\n",
      "         [ 0.0031],\n",
      "         [-0.1611],\n",
      "         [ 0.3164]],\n",
      "\n",
      "        [[ 0.9258],\n",
      "         [ 0.1621],\n",
      "         [-0.0378],\n",
      "         [ 0.1318],\n",
      "         [ 0.1196],\n",
      "         [-0.0564]],\n",
      "\n",
      "        [[-0.0947],\n",
      "         [-0.1758],\n",
      "         [ 0.2334],\n",
      "         [ 0.0884],\n",
      "         [-0.0342],\n",
      "         [-0.0084]],\n",
      "\n",
      "        [[-0.7344],\n",
      "         [ 0.2988],\n",
      "         [ 0.2734],\n",
      "         [-0.1089],\n",
      "         [-0.1611],\n",
      "         [-0.0972]],\n",
      "\n",
      "        [[ 0.7539],\n",
      "         [ 0.3926],\n",
      "         [-0.1152],\n",
      "         [-0.1924],\n",
      "         [ 0.1245],\n",
      "         [ 0.1553]],\n",
      "\n",
      "        [[-0.2246],\n",
      "         [-0.3984],\n",
      "         [ 0.2969],\n",
      "         [ 0.2695],\n",
      "         [-0.0192],\n",
      "         [-0.0747]],\n",
      "\n",
      "        [[-0.3203],\n",
      "         [-0.0781],\n",
      "         [ 0.3340],\n",
      "         [ 0.2129],\n",
      "         [-0.0654],\n",
      "         [-0.0669]],\n",
      "\n",
      "        [[ 0.2080],\n",
      "         [-0.3535],\n",
      "         [-0.2812],\n",
      "         [ 0.3340],\n",
      "         [ 0.3027],\n",
      "         [-0.0289]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0498],\n",
      "         [-0.0522],\n",
      "         [ 0.3047],\n",
      "         [ 0.0620],\n",
      "         [ 0.3398]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3691],\n",
      "         [ 0.1436],\n",
      "         [ 0.2148],\n",
      "         [ 0.0684],\n",
      "         [-0.0275]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0591],\n",
      "         [ 0.2676],\n",
      "         [ 0.1484],\n",
      "         [ 0.1455],\n",
      "         [-0.1030]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0208],\n",
      "         [ 0.0752],\n",
      "         [ 0.0889],\n",
      "         [-0.0143],\n",
      "         [-0.0762]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1377],\n",
      "         [ 0.2559],\n",
      "         [-0.1226],\n",
      "         [ 0.1221],\n",
      "         [ 0.0216]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0535],\n",
      "         [-0.0430],\n",
      "         [ 0.0170],\n",
      "         [ 0.3672],\n",
      "         [ 0.0166]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0635],\n",
      "         [ 0.2852],\n",
      "         [ 0.4922],\n",
      "         [ 0.1484],\n",
      "         [-0.1064]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.1133],\n",
      "         [-0.0286],\n",
      "         [ 0.0718],\n",
      "         [ 0.0698],\n",
      "         [ 0.2812]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.6094e-01, 3.8086e-02],\n",
      "         [9.9609e-01, 5.7373e-03],\n",
      "         [3.5742e-01, 6.4062e-01],\n",
      "         [8.3008e-03, 9.9219e-01],\n",
      "         [8.4375e-01, 1.5527e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.5625e-01, 3.4375e-01],\n",
      "         [5.2979e-02, 9.4531e-01],\n",
      "         [3.0859e-01, 6.9141e-01],\n",
      "         [9.1016e-01, 8.8867e-02],\n",
      "         [6.3672e-01, 3.6133e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.8931e-02, 9.7266e-01],\n",
      "         [8.2422e-01, 1.7480e-01],\n",
      "         [9.2188e-01, 7.9590e-02],\n",
      "         [2.9883e-01, 6.9922e-01],\n",
      "         [1.4648e-01, 8.5156e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.7266e-01, 2.7344e-02],\n",
      "         [9.8828e-01, 1.0986e-02],\n",
      "         [3.3789e-01, 6.6016e-01],\n",
      "         [3.8574e-02, 9.6094e-01],\n",
      "         [1.7480e-01, 8.2422e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.7266e-01, 2.6367e-02],\n",
      "         [1.6211e-01, 8.3594e-01],\n",
      "         [4.6692e-03, 9.9609e-01],\n",
      "         [6.1719e-01, 3.8086e-01],\n",
      "         [9.7656e-01, 2.4780e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.5449e-04, 1.0000e+00],\n",
      "         [9.6094e-01, 3.9062e-02],\n",
      "         [9.9609e-01, 5.7373e-03],\n",
      "         [2.9297e-01, 7.0703e-01],\n",
      "         [6.1951e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.1035e-03, 9.9219e-01],\n",
      "         [7.7344e-01, 2.2656e-01],\n",
      "         [9.7266e-01, 2.6367e-02],\n",
      "         [4.1406e-01, 5.8594e-01],\n",
      "         [1.8262e-01, 8.1641e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.7079e-03, 9.9609e-01],\n",
      "         [2.7618e-03, 9.9609e-01],\n",
      "         [9.9219e-01, 6.5002e-03],\n",
      "         [9.9219e-01, 8.9722e-03],\n",
      "         [3.2812e-01, 6.7188e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 500 to ./videos/variable_turn_tictactoe_muzero/1/episode_000500.mp4\n",
      "learning\n",
      "1000\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 3, 2, 7, 8],\n",
      "        [5, 2, 6, 8, 4],\n",
      "        [1, 3, 6, 4, 8],\n",
      "        [7, 2, 0, 1, 8],\n",
      "        [3, 6, 1, 2, 5],\n",
      "        [0, 7, 1, 8, 5],\n",
      "        [2, 8, 0, 6, 7],\n",
      "        [4, 0, 3, 5, 8]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4160],\n",
      "         [ 0.3691],\n",
      "         [-0.4629],\n",
      "         [-0.5859],\n",
      "         [ 0.4746],\n",
      "         [ 0.4141]],\n",
      "\n",
      "        [[-0.1670],\n",
      "         [ 0.2773],\n",
      "         [ 0.3750],\n",
      "         [-0.0157],\n",
      "         [-0.0476],\n",
      "         [ 0.2500]],\n",
      "\n",
      "        [[ 0.2520],\n",
      "         [-0.3340],\n",
      "         [-0.1562],\n",
      "         [ 0.3320],\n",
      "         [ 0.1445],\n",
      "         [-0.1523]],\n",
      "\n",
      "        [[ 0.0104],\n",
      "         [ 0.3672],\n",
      "         [-0.0498],\n",
      "         [-0.2129],\n",
      "         [ 0.5117],\n",
      "         [ 0.1787]],\n",
      "\n",
      "        [[ 0.4160],\n",
      "         [ 0.3223],\n",
      "         [-0.4180],\n",
      "         [-0.4121],\n",
      "         [ 0.3770],\n",
      "         [ 0.2930]],\n",
      "\n",
      "        [[-0.8125],\n",
      "         [-0.7070],\n",
      "         [ 0.4023],\n",
      "         [ 0.4043],\n",
      "         [-0.0184],\n",
      "         [-0.2031]],\n",
      "\n",
      "        [[ 0.3398],\n",
      "         [ 0.2236],\n",
      "         [ 0.1318],\n",
      "         [-0.0457],\n",
      "         [-0.0062],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[-0.4277],\n",
      "         [-0.5195],\n",
      "         [ 0.2031],\n",
      "         [ 0.3203],\n",
      "         [-0.0688],\n",
      "         [-0.2080]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0152],\n",
      "         [-0.0245],\n",
      "         [ 0.0016],\n",
      "         [ 0.0192],\n",
      "         [ 0.0121]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0193],\n",
      "         [ 0.0654],\n",
      "         [ 0.2314],\n",
      "         [ 0.0184],\n",
      "         [ 0.3418]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0167],\n",
      "         [-0.0303],\n",
      "         [-0.0029],\n",
      "         [ 0.1396],\n",
      "         [ 0.2598]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2266],\n",
      "         [ 0.2656],\n",
      "         [ 0.0972],\n",
      "         [ 0.3262],\n",
      "         [ 0.4746]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0388],\n",
      "         [-0.0581],\n",
      "         [-0.0913],\n",
      "         [ 0.0081],\n",
      "         [ 0.0693]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0017],\n",
      "         [-0.0520],\n",
      "         [ 0.0041],\n",
      "         [ 0.2754],\n",
      "         [ 0.1445]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3613],\n",
      "         [ 0.5430],\n",
      "         [ 0.1533],\n",
      "         [ 0.1777],\n",
      "         [ 0.1973]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0103],\n",
      "         [-0.0586],\n",
      "         [-0.0179],\n",
      "         [ 0.2988],\n",
      "         [ 0.1060]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.9978e-03],\n",
      "         [2.3193e-03, 9.9609e-01],\n",
      "         [1.0147e-03, 1.0000e+00],\n",
      "         [9.8828e-01, 1.2146e-02],\n",
      "         [9.9609e-01, 2.4719e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.1797e-01, 8.2520e-02],\n",
      "         [9.9219e-01, 6.5918e-03],\n",
      "         [2.0020e-01, 8.0078e-01],\n",
      "         [3.8910e-03, 9.9609e-01],\n",
      "         [6.8750e-01, 3.1250e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.3885e-03, 1.0000e+00],\n",
      "         [7.8125e-03, 9.9219e-01],\n",
      "         [1.0000e+00, 1.7242e-03],\n",
      "         [9.9609e-01, 5.6458e-03],\n",
      "         [1.4551e-01, 8.5547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.4531e-01, 5.5908e-02],\n",
      "         [3.8818e-02, 9.6094e-01],\n",
      "         [4.8218e-03, 9.9609e-01],\n",
      "         [9.3359e-01, 6.5430e-02],\n",
      "         [9.8828e-01, 1.0986e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 6.3782e-03],\n",
      "         [8.2779e-04, 1.0000e+00],\n",
      "         [1.0681e-03, 1.0000e+00],\n",
      "         [9.9609e-01, 4.9744e-03],\n",
      "         [9.9609e-01, 2.0142e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0300e-03, 1.0000e+00],\n",
      "         [9.9219e-01, 7.5684e-03],\n",
      "         [1.0000e+00, 1.6479e-03],\n",
      "         [2.4316e-01, 7.5781e-01],\n",
      "         [3.4790e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.1406e-01, 8.7402e-02],\n",
      "         [9.6875e-01, 3.1982e-02],\n",
      "         [6.3672e-01, 3.6523e-01],\n",
      "         [2.6953e-01, 7.3047e-01],\n",
      "         [4.6484e-01, 5.3516e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.8076e-03, 9.9609e-01],\n",
      "         [9.8828e-01, 1.2634e-02],\n",
      "         [9.9609e-01, 2.8381e-03],\n",
      "         [2.7344e-01, 7.2656e-01],\n",
      "         [4.2114e-03, 9.9609e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "Started recording episode 500 to ./videos/variable_turn_tictactoe_muzero/0/episode_000500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 500. Recorded 10 frames.\n",
      "learning\n",
      "Stopped recording episode 500. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 500 to ./videos/variable_turn_tictactoe_muzero/3/episode_000500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 500. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 500 to ./videos/variable_turn_tictactoe_muzero/2/episode_000500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 500. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "Testing Player 0 vs Agent random\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0800, 0.0400, 0.1200, 0.0400, 0.2000, 0.0800, 0.2000, 0.0800, 0.1600]), tensor([0.0800, 0.0400, 0.1200, 0.0400, 0.2000, 0.0800, 0.2000, 0.0800, 0.1600]), 0.29303108614408047, tensor(4), {'network_policy': tensor([0.0547, 0.0664, 0.1289, 0.0913, 0.1934, 0.0884, 0.1953, 0.0918, 0.0898],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.419921875, 'search_policy': tensor([0.0800, 0.0400, 0.1200, 0.0400, 0.2000, 0.0800, 0.2000, 0.0800, 0.1600]), 'search_value': 0.29303108614408047, 'root_children_values': tensor([0.3164, 0.3672, 0.3429, 0.2910, 0.3885, 0.3496, 0.2969, 0.3273, 0.3147])})\n",
      "action: 4\n",
      "Player 0 prediction: (tensor([0.0800, 0.0800, 0.1200, 0.2400, 0.0000, 0.1200, 0.2000, 0.0400, 0.1200]), tensor([0.0800, 0.0800, 0.1200, 0.2400, 0.0000, 0.1200, 0.2000, 0.0400, 0.1200]), 0.44888141679030197, tensor(3), {'network_policy': tensor([0.1035, 0.0864, 0.1328, 0.1455, 0.0000, 0.1328, 0.1582, 0.1055, 0.1348],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.703125, 'search_policy': tensor([0.0800, 0.0800, 0.1200, 0.2400, 0.0000, 0.1200, 0.2000, 0.0400, 0.1200]), 'search_value': 0.44888141679030197, 'root_children_values': tensor([-0.5117, -0.4219, -0.4473, -0.4229,  0.0000, -0.3344, -0.3916, -0.2930,\n",
      "        -0.4160])})\n",
      "action: 3\n",
      "Player 1 random action: 7\n",
      "Player 1 random action: 6\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.1200, 0.2800, 0.2000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.2000]), tensor([0.1200, 0.2800, 0.2000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.2000]), 0.368021263282189, tensor(1), {'network_policy': tensor([0.1719, 0.1099, 0.1982, 0.0000, 0.0000, 0.2539, 0.0000, 0.0000, 0.2598],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.74609375, 'search_policy': tensor([0.1200, 0.2800, 0.2000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.2000]), 'search_value': 0.368021263282189, 'root_children_values': tensor([0.3164, 0.2486, 0.2663, 0.0000, 0.0000, 0.2581, 0.0000, 0.0000, 0.2610])})\n",
      "action: 1\n",
      "Player 0 prediction: (tensor([0.2400, 0.0000, 0.3600, 0.0000, 0.0000, 0.1200, 0.0000, 0.0000, 0.2800]), tensor([0.2400, 0.0000, 0.3600, 0.0000, 0.0000, 0.1200, 0.0000, 0.0000, 0.2800]), 0.061847447753906264, tensor(2), {'network_policy': tensor([0.2090, 0.0000, 0.2334, 0.0000, 0.0000, 0.2363, 0.0000, 0.0000, 0.3184],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.53515625, 'search_policy': tensor([0.2400, 0.0000, 0.3600, 0.0000, 0.0000, 0.1200, 0.0000, 0.0000, 0.2800]), 'search_value': 0.061847447753906264, 'root_children_values': tensor([0.1457, 0.0000, 0.0682, 0.0000, 0.0000, 0.2282, 0.0000, 0.0000, 0.0769])})\n",
      "action: 2\n",
      "Player 1 random action: 0\n",
      "Player 1 random action: 8\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 5, 4, 1, 6],\n",
      "        [0, 2, 5, 0, 5],\n",
      "        [6, 1, 5, 2, 7],\n",
      "        [7, 0, 1, 5, 4],\n",
      "        [6, 2, 0, 5, 5],\n",
      "        [4, 0, 4, 5, 5],\n",
      "        [8, 4, 3, 7, 0],\n",
      "        [1, 3, 2, 4, 0]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4258],\n",
      "         [ 0.3770],\n",
      "         [-0.2598],\n",
      "         [-0.2012],\n",
      "         [ 0.4609],\n",
      "         [ 0.2930]],\n",
      "\n",
      "        [[-0.1846],\n",
      "         [-0.0574],\n",
      "         [ 0.2695],\n",
      "         [ 0.1738],\n",
      "         [ 0.0347],\n",
      "         [ 0.0520]],\n",
      "\n",
      "        [[ 0.5273],\n",
      "         [-0.1367],\n",
      "         [-0.2002],\n",
      "         [ 0.4121],\n",
      "         [ 0.3184],\n",
      "         [ 0.0884]],\n",
      "\n",
      "        [[-0.1670],\n",
      "         [-0.0154],\n",
      "         [ 0.5352],\n",
      "         [ 0.3789],\n",
      "         [ 0.1309],\n",
      "         [ 0.1289]],\n",
      "\n",
      "        [[ 0.7188],\n",
      "         [ 0.3867],\n",
      "         [ 0.1104],\n",
      "         [-0.0302],\n",
      "         [ 0.2461],\n",
      "         [ 0.2637]],\n",
      "\n",
      "        [[ 0.4707],\n",
      "         [ 0.1152],\n",
      "         [ 0.0471],\n",
      "         [ 0.0498],\n",
      "         [ 0.1689],\n",
      "         [ 0.0063]],\n",
      "\n",
      "        [[ 0.3691],\n",
      "         [-0.2598],\n",
      "         [-0.1973],\n",
      "         [ 0.4141],\n",
      "         [ 0.3281],\n",
      "         [ 0.0776]],\n",
      "\n",
      "        [[ 0.1895],\n",
      "         [-0.0811],\n",
      "         [ 0.2891],\n",
      "         [ 0.4180],\n",
      "         [ 0.0820],\n",
      "         [ 0.0266]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0422],\n",
      "         [-0.0061],\n",
      "         [ 0.0038],\n",
      "         [-0.0271],\n",
      "         [ 0.1074]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0505],\n",
      "         [ 0.2168],\n",
      "         [ 0.4766],\n",
      "         [ 0.0859],\n",
      "         [ 0.0243]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0898],\n",
      "         [ 0.0125],\n",
      "         [ 0.0118],\n",
      "         [ 0.1533],\n",
      "         [ 0.2969]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0698],\n",
      "         [ 0.0121],\n",
      "         [ 0.1152],\n",
      "         [ 0.2539],\n",
      "         [ 0.2412]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2168],\n",
      "         [ 0.2754],\n",
      "         [-0.0183],\n",
      "         [ 0.1758],\n",
      "         [ 0.1943]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4219],\n",
      "         [-0.0471],\n",
      "         [ 0.1738],\n",
      "         [ 0.2490],\n",
      "         [ 0.2080]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0119],\n",
      "         [ 0.0718],\n",
      "         [-0.0576],\n",
      "         [ 0.1221],\n",
      "         [ 0.3301]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0199],\n",
      "         [ 0.0245],\n",
      "         [ 0.0742],\n",
      "         [ 0.3125],\n",
      "         [ 0.0569]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.8047e-01, 2.0752e-02],\n",
      "         [1.0681e-03, 1.0000e+00],\n",
      "         [3.3264e-03, 9.9609e-01],\n",
      "         [9.9609e-01, 4.7607e-03],\n",
      "         [9.9609e-01, 4.1199e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.2773e-03, 9.9219e-01],\n",
      "         [4.3750e-01, 5.6250e-01],\n",
      "         [9.1797e-01, 8.2031e-02],\n",
      "         [6.9531e-01, 3.0469e-01],\n",
      "         [2.0605e-01, 7.9297e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4343e-03, 1.0000e+00],\n",
      "         [1.7853e-03, 1.0000e+00],\n",
      "         [9.9609e-01, 4.3335e-03],\n",
      "         [9.9609e-01, 2.3956e-03],\n",
      "         [2.5781e-01, 7.4219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.5918e-03, 9.9219e-01],\n",
      "         [9.9609e-01, 4.1199e-03],\n",
      "         [9.8828e-01, 1.1658e-02],\n",
      "         [1.8555e-01, 8.1250e-01],\n",
      "         [8.8501e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.8828e-01, 1.2329e-02],\n",
      "         [2.9883e-01, 7.0312e-01],\n",
      "         [7.9346e-03, 9.9219e-01],\n",
      "         [6.5234e-01, 3.4766e-01],\n",
      "         [9.8828e-01, 1.2268e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.1875e-01, 2.8125e-01],\n",
      "         [2.1240e-02, 9.8047e-01],\n",
      "         [1.1816e-01, 8.8281e-01],\n",
      "         [8.9453e-01, 1.0693e-01],\n",
      "         [8.3594e-01, 1.6211e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.3842e-04, 1.0000e+00],\n",
      "         [8.6060e-03, 9.9219e-01],\n",
      "         [9.9609e-01, 2.8076e-03],\n",
      "         [9.8828e-01, 1.2695e-02],\n",
      "         [3.0078e-01, 6.9922e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.3945e-03, 9.9609e-01],\n",
      "         [1.0986e-01, 8.9062e-01],\n",
      "         [9.9219e-01, 7.2327e-03],\n",
      "         [9.0234e-01, 9.9609e-02],\n",
      "         [1.6895e-01, 8.3203e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 0 win percentage vs random: 64.0 and average score: 0.46\n",
      "Testing Player 1 vs Agent random\n",
      "Player 0 random action: 5\n",
      "Player 0 random action: 0\n",
      "Player 1 prediction: (tensor([0.0000, 0.0800, 0.0800, 0.2000, 0.2000, 0.0000, 0.2000, 0.1200, 0.1200]), tensor([0.0000, 0.0800, 0.0800, 0.2000, 0.2000, 0.0000, 0.2000, 0.1200, 0.1200]), -0.3949641686072716, tensor(3), {'network_policy': tensor([0.0000, 0.0981, 0.1260, 0.1543, 0.1641, 0.0000, 0.1436, 0.1465, 0.1641],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.1767578125, 'search_policy': tensor([0.0000, 0.0800, 0.0800, 0.2000, 0.2000, 0.0000, 0.2000, 0.1200, 0.1200]), 'search_value': -0.3949641686072716, 'root_children_values': tensor([ 0.0000, -0.3945, -0.3477, -0.4373, -0.3001,  0.0000, -0.3638, -0.3863,\n",
      "        -0.3812])})\n",
      "action: 3\n",
      "Player 1 prediction: (tensor([0.0000, 0.0800, 0.0800, 0.0000, 0.2000, 0.0000, 0.1600, 0.1200, 0.3600]), tensor([0.0000, 0.0800, 0.0800, 0.0000, 0.2000, 0.0000, 0.1600, 0.1200, 0.3600]), -0.47270751533390926, tensor(8), {'network_policy': tensor([0.0000, 0.1445, 0.1299, 0.0000, 0.1973, 0.0000, 0.1719, 0.1729, 0.1787],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.1806640625, 'search_policy': tensor([0.0000, 0.0800, 0.0800, 0.0000, 0.2000, 0.0000, 0.1600, 0.1200, 0.3600]), 'search_value': -0.47270751533390926, 'root_children_values': tensor([0.0000, 0.4688, 0.4141, 0.0000, 0.4094, 0.0000, 0.4125, 0.5057, 0.5025])})\n",
      "action: 8\n",
      "Player 0 random action: 7\n",
      "Player 0 random action: 4\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.0000, 0.1600, 0.4800, 0.0000, 0.0000, 0.0000, 0.3600, 0.0000, 0.0000]), tensor([0.0000, 0.1600, 0.4800, 0.0000, 0.0000, 0.0000, 0.3600, 0.0000, 0.0000]), -0.20503823453491204, tensor(2), {'network_policy': tensor([0.0000, 0.2559, 0.4102, 0.0000, 0.0000, 0.0000, 0.3184, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.2177734375, 'search_policy': tensor([0.0000, 0.1600, 0.4800, 0.0000, 0.0000, 0.0000, 0.3600, 0.0000, 0.0000]), 'search_value': -0.20503823453491204, 'root_children_values': tensor([ 0.0000, -0.1960, -0.3192,  0.0000,  0.0000,  0.0000, -0.2978,  0.0000,\n",
      "         0.0000])})\n",
      "action: 2\n",
      "Player 1 prediction: (tensor([0.0000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.0000, 0.0000]), tensor([0.0000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.0000, 0.0000]), -0.3159092432861328, tensor(6), {'network_policy': tensor([0.0000, 0.4727, 0.0000, 0.0000, 0.0000, 0.0000, 0.5117, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.15625, 'search_policy': tensor([0.0000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.0000, 0.0000]), 'search_value': -0.3159092432861328, 'root_children_values': tensor([0.0000, 0.6340, 0.0000, 0.0000, 0.0000, 0.0000, 0.6013, 0.0000, 0.0000])})\n",
      "action: 6\n",
      "Player 0 random action: 1\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs random: 36.0 and average score: -0.18\n",
      "Results vs random: {'player_0_score': 0.46, 'player_0_win%': 0.64, 'player_1_score': -0.18, 'player_1_win%': 0.36, 'score': 0.14}\n",
      "Testing Player 0 vs Agent tictactoe_expert\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.1600, 0.0400, 0.2400, 0.0400, 0.2400, 0.1200, 0.0800]), tensor([0.0400, 0.0400, 0.1600, 0.0400, 0.2400, 0.0400, 0.2400, 0.1200, 0.0800]), 0.30173972590519826, tensor(4), {'network_policy': tensor([0.0547, 0.0664, 0.1289, 0.0913, 0.1934, 0.0884, 0.1953, 0.0918, 0.0898],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.419921875, 'search_policy': tensor([0.0400, 0.0400, 0.1600, 0.0400, 0.2400, 0.0400, 0.2400, 0.1200, 0.0800]), 'search_value': 0.30173972590519826, 'root_children_values': tensor([0.3379, 0.3672, 0.3202, 0.2910, 0.3858, 0.3516, 0.3086, 0.2893, 0.3711])})\n",
      "action: 4\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0800, 0.0800, 0.1600, 0.1200, 0.0000, 0.1200, 0.1200, 0.1200, 0.2000]), tensor([0.0800, 0.0800, 0.1600, 0.1200, 0.0000, 0.1200, 0.1200, 0.1200, 0.2000]), 0.450137500821627, tensor(8), {'network_policy': tensor([0.1035, 0.0864, 0.1328, 0.1455, 0.0000, 0.1328, 0.1582, 0.1055, 0.1348],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.703125, 'search_policy': tensor([0.0800, 0.0800, 0.1600, 0.1200, 0.0000, 0.1200, 0.1200, 0.1200, 0.2000]), 'search_value': 0.450137500821627, 'root_children_values': tensor([-0.5117, -0.4219, -0.4575, -0.4375,  0.0000, -0.3344, -0.4181, -0.3239,\n",
      "        -0.4179])})\n",
      "action: 8\n",
      "Player 1 tictactoe_expert action: 0\n",
      "Player 1 tictactoe_expert action: 6\n",
      "Player 0 prediction: (tensor([0.0000, 0.0400, 0.1600, 0.2000, 0.0000, 0.4000, 0.0000, 0.2000, 0.0000]), tensor([0.0000, 0.0400, 0.1600, 0.2000, 0.0000, 0.4000, 0.0000, 0.2000, 0.0000]), 0.6543945435884915, tensor(5), {'network_policy': tensor([0.0000, 0.1011, 0.2100, 0.2344, 0.0000, 0.2383, 0.0000, 0.2100, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.59765625, 'search_policy': tensor([0.0000, 0.0400, 0.1600, 0.2000, 0.0000, 0.4000, 0.0000, 0.2000, 0.0000]), 'search_value': 0.6543945435884915, 'root_children_values': tensor([0.0000, 0.3438, 0.3034, 0.3337, 0.0000, 0.4730, 0.0000, 0.4318, 0.0000])})\n",
      "action: 5\n",
      "Player 0 prediction: (tensor([0.0000, 0.0800, 0.1600, 0.5200, 0.0000, 0.0000, 0.0000, 0.2400, 0.0000]), tensor([0.0000, 0.0800, 0.1600, 0.5200, 0.0000, 0.0000, 0.0000, 0.2400, 0.0000]), 0.4191508401570014, tensor(3), {'network_policy': tensor([0.0000, 0.1230, 0.2158, 0.3398, 0.0000, 0.0000, 0.0000, 0.3145, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.51953125, 'search_policy': tensor([0.0000, 0.0800, 0.1600, 0.5200, 0.0000, 0.0000, 0.0000, 0.2400, 0.0000]), 'search_value': 0.4191508401570014, 'root_children_values': tensor([ 0.0000,  0.1758,  0.1189, -0.0296,  0.0000,  0.0000,  0.0000,  0.1429,\n",
      "         0.0000])})\n",
      "action: 3\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 6, 2, 3, 4],\n",
      "        [0, 8, 1, 6, 7],\n",
      "        [4, 1, 0, 3, 0],\n",
      "        [4, 3, 1, 5, 0],\n",
      "        [8, 4, 6, 2, 0],\n",
      "        [6, 8, 3, 4, 2],\n",
      "        [5, 4, 6, 3, 7],\n",
      "        [5, 1, 4, 3, 6]])\n",
      "target value tensor([[ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.5352],\n",
      "         [-0.3203],\n",
      "         [-0.2754],\n",
      "         [ 0.3750],\n",
      "         [ 0.3281],\n",
      "         [ 0.1128]],\n",
      "\n",
      "        [[-0.5234],\n",
      "         [ 0.2910],\n",
      "         [ 0.2070],\n",
      "         [-0.0374],\n",
      "         [-0.1416],\n",
      "         [ 0.2559]],\n",
      "\n",
      "        [[ 0.4316],\n",
      "         [-0.4023],\n",
      "         [-0.3926],\n",
      "         [ 0.3516],\n",
      "         [ 0.1914],\n",
      "         [-0.0603]],\n",
      "\n",
      "        [[-0.4844],\n",
      "         [-0.4922],\n",
      "         [ 0.3789],\n",
      "         [ 0.1484],\n",
      "         [-0.0923],\n",
      "         [-0.1729]],\n",
      "\n",
      "        [[-0.1172],\n",
      "         [ 0.1504],\n",
      "         [ 0.2695],\n",
      "         [ 0.0081],\n",
      "         [-0.1279],\n",
      "         [ 0.1147]],\n",
      "\n",
      "        [[ 0.4023],\n",
      "         [ 0.3926],\n",
      "         [-0.3047],\n",
      "         [-0.4219],\n",
      "         [ 0.1240],\n",
      "         [ 0.2480]],\n",
      "\n",
      "        [[-0.4844],\n",
      "         [-0.4375],\n",
      "         [ 0.1787],\n",
      "         [ 0.1885],\n",
      "         [-0.0425],\n",
      "         [-0.1631]],\n",
      "\n",
      "        [[-0.2988],\n",
      "         [-0.3359],\n",
      "         [ 0.3730],\n",
      "         [ 0.1689],\n",
      "         [-0.0645],\n",
      "         [-0.1230]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0092],\n",
      "         [-0.0669],\n",
      "         [ 0.0771],\n",
      "         [ 0.0698],\n",
      "         [ 0.3887]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0503],\n",
      "         [ 0.1299],\n",
      "         [ 0.2188],\n",
      "         [ 0.0840],\n",
      "         [ 0.2539]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0771],\n",
      "         [-0.1226],\n",
      "         [-0.0835],\n",
      "         [ 0.1650],\n",
      "         [ 0.0713]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0444],\n",
      "         [-0.1074],\n",
      "         [ 0.0226],\n",
      "         [ 0.2520],\n",
      "         [ 0.0576]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0811],\n",
      "         [-0.0325],\n",
      "         [ 0.3125],\n",
      "         [ 0.1108],\n",
      "         [ 0.2500]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0090],\n",
      "         [ 0.0306],\n",
      "         [-0.0732],\n",
      "         [-0.0071],\n",
      "         [ 0.0801]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0239],\n",
      "         [-0.0044],\n",
      "         [ 0.2324],\n",
      "         [ 0.3516],\n",
      "         [ 0.0923]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0005],\n",
      "         [-0.0664],\n",
      "         [ 0.1138],\n",
      "         [ 0.2520],\n",
      "         [ 0.0125]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.0018, 1.0000],\n",
      "         [0.0032, 0.9961],\n",
      "         [0.9961, 0.0051],\n",
      "         [0.9961, 0.0034],\n",
      "         [0.4277, 0.5742]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9961, 0.0045],\n",
      "         [0.9805, 0.0178],\n",
      "         [0.1768, 0.8242],\n",
      "         [0.0034, 0.9961],\n",
      "         [0.6719, 0.3281]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0011, 1.0000],\n",
      "         [0.0049, 0.9961],\n",
      "         [1.0000, 0.0015],\n",
      "         [0.9961, 0.0041],\n",
      "         [0.2930, 0.7070]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0033, 0.9961],\n",
      "         [0.9961, 0.0025],\n",
      "         [0.9922, 0.0065],\n",
      "         [0.2637, 0.7383],\n",
      "         [0.0094, 0.9922]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.8398, 0.1592],\n",
      "         [1.0000, 0.0011],\n",
      "         [0.3809, 0.6172],\n",
      "         [0.0072, 0.9922],\n",
      "         [0.3906, 0.6094]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9961, 0.0020],\n",
      "         [0.0030, 0.9961],\n",
      "         [0.0014, 1.0000],\n",
      "         [0.9688, 0.0330],\n",
      "         [0.9961, 0.0031]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0028, 0.9961],\n",
      "         [0.9961, 0.0042],\n",
      "         [0.9961, 0.0042],\n",
      "         [0.2598, 0.7383],\n",
      "         [0.0036, 0.9961]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0045, 0.9961],\n",
      "         [0.9922, 0.0094],\n",
      "         [0.9961, 0.0023],\n",
      "         [0.2070, 0.7930],\n",
      "         [0.0054, 0.9961]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 600 to ./videos/variable_turn_tictactoe_muzero/1/episode_000600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 600. Recorded 10 frames.\n",
      "learning\n",
      "Started recording episode 600 to ./videos/variable_turn_tictactoe_muzero/0/episode_000600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 600. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 0 win percentage vs tictactoe_expert: 36.0 and average score: -0.06\n",
      "Testing Player 1 vs Agent tictactoe_expert\n",
      "Player 0 tictactoe_expert action: 7\n",
      "Player 0 tictactoe_expert action: 6\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.0800, 0.0800, 0.3200, 0.1600, 0.1600, 0.0800, 0.0000, 0.0000, 0.1200]), tensor([0.0800, 0.0800, 0.3200, 0.1600, 0.1600, 0.0800, 0.0000, 0.0000, 0.1200]), -0.37494559359975965, tensor(2), {'network_policy': tensor([0.1289, 0.0942, 0.1670, 0.1387, 0.1553, 0.1318, 0.0000, 0.0000, 0.1797],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.01177978515625, 'search_policy': tensor([0.0800, 0.0800, 0.3200, 0.1600, 0.1600, 0.0800, 0.0000, 0.0000, 0.1200]), 'search_value': -0.37494559359975965, 'root_children_values': tensor([-0.3223, -0.3281, -0.3192, -0.4122, -0.3586, -0.3066,  0.0000,  0.0000,\n",
      "        -0.3368])})\n",
      "action: 2\n",
      "Player 1 prediction: (tensor([0.1200, 0.2400, 0.0000, 0.0800, 0.2800, 0.1200, 0.0000, 0.0000, 0.1600]), tensor([0.1200, 0.2400, 0.0000, 0.0800, 0.2800, 0.1200, 0.0000, 0.0000, 0.1600]), -0.31722188407428437, tensor(4), {'network_policy': tensor([0.1406, 0.1055, 0.0000, 0.1387, 0.2393, 0.1729, 0.0000, 0.0000, 0.1992],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.150390625, 'search_policy': tensor([0.1200, 0.2400, 0.0000, 0.0800, 0.2800, 0.1200, 0.0000, 0.0000, 0.1600]), 'search_value': -0.31722188407428437, 'root_children_values': tensor([0.2188, 0.3635, 0.0000, 0.3340, 0.2570, 0.3959, 0.0000, 0.0000, 0.2617])})\n",
      "action: 4\n",
      "Player 0 tictactoe_expert action: 8\n",
      "learning\n",
      "learning\n",
      "Started recording episode 600 to ./videos/variable_turn_tictactoe_muzero/3/episode_000600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 600. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 600 to ./videos/variable_turn_tictactoe_muzero/2/episode_000600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 600. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs tictactoe_expert: 2.0 and average score: -0.88\n",
      "Results vs tictactoe_expert: {'player_0_score': -0.06, 'player_0_win%': 0.36, 'player_1_score': -0.88, 'player_1_win%': 0.02, 'score': -0.47}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 0, 1, 6, 1],\n",
      "        [7, 8, 4, 5, 3],\n",
      "        [6, 1, 0, 7, 2],\n",
      "        [6, 0, 1, 6, 1],\n",
      "        [5, 7, 6, 0, 2],\n",
      "        [8, 2, 7, 0, 4],\n",
      "        [8, 1, 4, 2, 0],\n",
      "        [1, 4, 6, 0, 1]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4707],\n",
      "         [ 0.1094],\n",
      "         [-0.0013],\n",
      "         [ 0.1670],\n",
      "         [ 0.1914],\n",
      "         [ 0.0767]],\n",
      "\n",
      "        [[ 0.6406],\n",
      "         [ 0.3633],\n",
      "         [ 0.0540],\n",
      "         [ 0.0559],\n",
      "         [ 0.1631],\n",
      "         [ 0.1338]],\n",
      "\n",
      "        [[-0.3750],\n",
      "         [-0.2930],\n",
      "         [ 0.3438],\n",
      "         [ 0.2617],\n",
      "         [-0.0091],\n",
      "         [ 0.0101]],\n",
      "\n",
      "        [[ 0.6484],\n",
      "         [ 0.1377],\n",
      "         [ 0.0481],\n",
      "         [ 0.0806],\n",
      "         [ 0.2002],\n",
      "         [ 0.1079]],\n",
      "\n",
      "        [[ 0.2451],\n",
      "         [ 0.2617],\n",
      "         [-0.2256],\n",
      "         [-0.2559],\n",
      "         [ 0.2891],\n",
      "         [ 0.2227]],\n",
      "\n",
      "        [[ 0.4590],\n",
      "         [-0.3125],\n",
      "         [-0.3477],\n",
      "         [ 0.3340],\n",
      "         [ 0.2344],\n",
      "         [ 0.0811]],\n",
      "\n",
      "        [[ 0.4062],\n",
      "         [ 0.2266],\n",
      "         [-0.0464],\n",
      "         [-0.1152],\n",
      "         [ 0.3047],\n",
      "         [ 0.0261]],\n",
      "\n",
      "        [[-0.1729],\n",
      "         [-0.1807],\n",
      "         [ 0.1816],\n",
      "         [ 0.1680],\n",
      "         [-0.0039],\n",
      "         [ 0.0942]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.3848],\n",
      "         [-0.0048],\n",
      "         [ 0.1221],\n",
      "         [ 0.1689],\n",
      "         [ 0.1943]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1216],\n",
      "         [ 0.2539],\n",
      "         [ 0.2012],\n",
      "         [ 0.3711],\n",
      "         [ 0.4766]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0063],\n",
      "         [ 0.0347],\n",
      "         [ 0.0618],\n",
      "         [ 0.3652],\n",
      "         [ 0.1826]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3711],\n",
      "         [ 0.0742],\n",
      "         [-0.0417],\n",
      "         [ 0.1484],\n",
      "         [ 0.1455]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0023],\n",
      "         [ 0.0199],\n",
      "         [-0.0302],\n",
      "         [-0.0294],\n",
      "         [ 0.0776]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0471],\n",
      "         [ 0.0588],\n",
      "         [ 0.0398],\n",
      "         [ 0.0032],\n",
      "         [ 0.4238]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1904],\n",
      "         [ 0.1934],\n",
      "         [ 0.0815],\n",
      "         [ 0.3379],\n",
      "         [ 0.4609]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0084],\n",
      "         [ 0.0173],\n",
      "         [ 0.0732],\n",
      "         [ 0.2617],\n",
      "         [ 0.0767]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000, 0.0000],\n",
      "         [0.8867, 0.1143],\n",
      "         [0.1689, 0.8320],\n",
      "         [0.7070, 0.2910],\n",
      "         [0.9414, 0.0574],\n",
      "         [0.7695, 0.2305]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9961, 0.0043],\n",
      "         [0.5469, 0.4551],\n",
      "         [0.0110, 0.9883],\n",
      "         [0.4648, 0.5352],\n",
      "         [0.9648, 0.0334]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0021, 0.9961],\n",
      "         [0.9961, 0.0028],\n",
      "         [1.0000, 0.0014],\n",
      "         [0.3887, 0.6094],\n",
      "         [0.0056, 0.9961]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9648, 0.0354],\n",
      "         [0.4492, 0.5508],\n",
      "         [0.0718, 0.9297],\n",
      "         [0.4766, 0.5234],\n",
      "         [0.9258, 0.0737]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [1.0000, 0.0013],\n",
      "         [0.0051, 0.9961],\n",
      "         [0.0021, 0.9961],\n",
      "         [0.9922, 0.0082],\n",
      "         [1.0000, 0.0011]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0023, 0.9961],\n",
      "         [0.0012, 1.0000],\n",
      "         [0.9922, 0.0068],\n",
      "         [0.9961, 0.0023],\n",
      "         [0.6641, 0.3359]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.9922, 0.0061],\n",
      "         [0.1367, 0.8633],\n",
      "         [0.0071, 0.9922],\n",
      "         [0.5781, 0.4238],\n",
      "         [0.9531, 0.0481]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0077, 0.9922],\n",
      "         [0.9688, 0.0332],\n",
      "         [0.9922, 0.0060],\n",
      "         [0.3535, 0.6484],\n",
      "         [0.0255, 0.9727]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 4, 7, 5, 2],\n",
      "        [1, 4, 5, 0, 0],\n",
      "        [7, 0, 1, 3, 5],\n",
      "        [1, 0, 3, 8, 7],\n",
      "        [7, 0, 0, 8, 7],\n",
      "        [3, 7, 0, 8, 7],\n",
      "        [6, 8, 1, 2, 0],\n",
      "        [5, 4, 6, 2, 8]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4082],\n",
      "         [ 0.2969],\n",
      "         [-0.3711],\n",
      "         [-0.4590],\n",
      "         [ 0.5430],\n",
      "         [ 0.3027]],\n",
      "\n",
      "        [[ 0.7109],\n",
      "         [ 0.0188],\n",
      "         [-0.1328],\n",
      "         [ 0.3320],\n",
      "         [ 0.0312],\n",
      "         [-0.0186]],\n",
      "\n",
      "        [[-0.4805],\n",
      "         [-0.4102],\n",
      "         [ 0.5820],\n",
      "         [ 0.2734],\n",
      "         [-0.0540],\n",
      "         [-0.0854]],\n",
      "\n",
      "        [[ 0.6289],\n",
      "         [ 0.0918],\n",
      "         [-0.1118],\n",
      "         [ 0.0398],\n",
      "         [ 0.4082],\n",
      "         [ 0.0515]],\n",
      "\n",
      "        [[-0.4707],\n",
      "         [ 0.6250],\n",
      "         [ 0.0923],\n",
      "         [ 0.0359],\n",
      "         [ 0.0493],\n",
      "         [ 0.2324]],\n",
      "\n",
      "        [[-0.1104],\n",
      "         [ 0.4336],\n",
      "         [ 0.2949],\n",
      "         [-0.0025],\n",
      "         [-0.0537],\n",
      "         [ 0.2090]],\n",
      "\n",
      "        [[ 0.5586],\n",
      "         [ 0.2539],\n",
      "         [-0.0942],\n",
      "         [-0.1016],\n",
      "         [ 0.2451],\n",
      "         [ 0.0187]],\n",
      "\n",
      "        [[-0.1367],\n",
      "         [ 0.4648],\n",
      "         [ 0.2617],\n",
      "         [-0.0258],\n",
      "         [-0.1436],\n",
      "         [ 0.2373]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0193],\n",
      "         [ 0.0625],\n",
      "         [-0.0050],\n",
      "         [ 0.0178],\n",
      "         [ 0.2129]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2207],\n",
      "         [ 0.1152],\n",
      "         [ 0.3145],\n",
      "         [ 0.6562],\n",
      "         [ 0.0518]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0057],\n",
      "         [ 0.0322],\n",
      "         [ 0.1123],\n",
      "         [ 0.2969],\n",
      "         [ 0.1445]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0439],\n",
      "         [ 0.0898],\n",
      "         [ 0.1572],\n",
      "         [ 0.3535],\n",
      "         [ 0.4062]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2471],\n",
      "         [ 0.7109],\n",
      "         [ 0.0757],\n",
      "         [ 0.0101],\n",
      "         [ 0.0796]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0688],\n",
      "         [ 0.1235],\n",
      "         [ 0.3730],\n",
      "         [ 0.2246],\n",
      "         [ 0.3340]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3477],\n",
      "         [ 0.2197],\n",
      "         [ 0.0312],\n",
      "         [ 0.4414],\n",
      "         [ 0.2441]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0131],\n",
      "         [ 0.2090],\n",
      "         [ 0.3320],\n",
      "         [ 0.0825],\n",
      "         [ 0.4375]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 8.1787e-03],\n",
      "         [1.5717e-03, 1.0000e+00],\n",
      "         [7.4387e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 4.8218e-03],\n",
      "         [9.9609e-01, 2.4719e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.6895e-01, 8.3203e-01],\n",
      "         [2.2583e-03, 9.9609e-01],\n",
      "         [6.4453e-01, 3.5352e-01],\n",
      "         [9.7656e-01, 2.2339e-02],\n",
      "         [4.2969e-01, 5.7031e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.3651e-03, 9.9609e-01],\n",
      "         [9.9609e-01, 3.4332e-03],\n",
      "         [9.9609e-01, 3.8910e-03],\n",
      "         [2.5195e-01, 7.4609e-01],\n",
      "         [8.1787e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.8672e-01, 1.1377e-01],\n",
      "         [1.0010e-02, 9.8828e-01],\n",
      "         [2.3560e-02, 9.7656e-01],\n",
      "         [8.7500e-01, 1.2402e-01],\n",
      "         [9.2578e-01, 7.5684e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.8281e-01, 1.1865e-01],\n",
      "         [9.8438e-01, 1.5564e-02],\n",
      "         [4.0625e-01, 5.9375e-01],\n",
      "         [2.7954e-02, 9.7266e-01],\n",
      "         [4.4141e-01, 5.5859e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 4.8218e-03],\n",
      "         [9.8828e-01, 1.1597e-02],\n",
      "         [4.3555e-01, 5.6641e-01],\n",
      "         [2.0752e-02, 9.8047e-01],\n",
      "         [5.2734e-01, 4.7461e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.4531e-01, 5.3711e-02],\n",
      "         [1.1182e-01, 8.8672e-01],\n",
      "         [1.0193e-02, 9.8828e-01],\n",
      "         [7.8906e-01, 2.1289e-01],\n",
      "         [8.3203e-01, 1.6895e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 4.3335e-03],\n",
      "         [9.9609e-01, 3.8300e-03],\n",
      "         [2.9883e-01, 6.9922e-01],\n",
      "         [7.6904e-03, 9.9219e-01],\n",
      "         [5.6641e-01, 4.3555e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 700 to ./videos/variable_turn_tictactoe_muzero/1/episode_000700.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 700. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 700 to ./videos/variable_turn_tictactoe_muzero/0/episode_000700.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 700. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 700 to ./videos/variable_turn_tictactoe_muzero/3/episode_000700.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 700. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 700 to ./videos/variable_turn_tictactoe_muzero/2/episode_000700.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 700. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "average score: 0.38\n",
      "Test score {'score': 0.38, 'max_score': 1, 'min_score': -1}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[8, 0, 7, 8, 2],\n",
      "        [6, 3, 2, 4, 0],\n",
      "        [2, 5, 0, 0, 2],\n",
      "        [3, 7, 4, 6, 0],\n",
      "        [6, 2, 5, 0, 2],\n",
      "        [5, 3, 1, 0, 2],\n",
      "        [5, 7, 6, 0, 2],\n",
      "        [5, 6, 4, 8, 7]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900]])\n",
      "predicted values tensor([[[ 0.1016],\n",
      "         [ 0.3887],\n",
      "         [ 0.0105],\n",
      "         [-0.0204],\n",
      "         [-0.0361],\n",
      "         [ 0.2471]],\n",
      "\n",
      "        [[ 0.5117],\n",
      "         [ 0.0293],\n",
      "         [-0.1758],\n",
      "         [ 0.4922],\n",
      "         [ 0.0522],\n",
      "         [-0.0471]],\n",
      "\n",
      "        [[-0.1396],\n",
      "         [-0.0408],\n",
      "         [ 0.1172],\n",
      "         [ 0.2021],\n",
      "         [-0.0110],\n",
      "         [-0.0295]],\n",
      "\n",
      "        [[ 0.5430],\n",
      "         [ 0.2852],\n",
      "         [ 0.0608],\n",
      "         [-0.0840],\n",
      "         [ 0.4199],\n",
      "         [ 0.0176]],\n",
      "\n",
      "        [[-0.6914],\n",
      "         [ 0.4648],\n",
      "         [ 0.2871],\n",
      "         [ 0.0215],\n",
      "         [ 0.0786],\n",
      "         [ 0.0610]],\n",
      "\n",
      "        [[ 0.4180],\n",
      "         [ 0.0830],\n",
      "         [-0.1973],\n",
      "         [ 0.3262],\n",
      "         [ 0.0913],\n",
      "         [ 0.0059]],\n",
      "\n",
      "        [[ 0.2285],\n",
      "         [ 0.1582],\n",
      "         [-0.0679],\n",
      "         [ 0.4961],\n",
      "         [ 0.0391],\n",
      "         [-0.0259]],\n",
      "\n",
      "        [[ 0.3965],\n",
      "         [ 0.3770],\n",
      "         [-0.2812],\n",
      "         [-0.2012],\n",
      "         [ 0.4336],\n",
      "         [ 0.2266]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.3145],\n",
      "         [ 0.5508],\n",
      "         [ 0.1924],\n",
      "         [ 0.0596],\n",
      "         [ 0.2266]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4473],\n",
      "         [ 0.0796],\n",
      "         [ 0.2578],\n",
      "         [ 0.5273],\n",
      "         [ 0.0835]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2363],\n",
      "         [ 0.1514],\n",
      "         [ 0.3223],\n",
      "         [ 0.0571],\n",
      "         [ 0.1846]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1621],\n",
      "         [ 0.2520],\n",
      "         [ 0.2139],\n",
      "         [ 0.3008],\n",
      "         [ 0.5078]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0069],\n",
      "         [ 0.2578],\n",
      "         [ 0.4004],\n",
      "         [-0.0303],\n",
      "         [ 0.2715]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4414],\n",
      "         [ 0.1582],\n",
      "         [ 0.3477],\n",
      "         [ 0.1494],\n",
      "         [ 0.2061]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3086],\n",
      "         [ 0.0854],\n",
      "         [ 0.3086],\n",
      "         [ 0.5273],\n",
      "         [ 0.3691]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0007],\n",
      "         [-0.0192],\n",
      "         [-0.0684],\n",
      "         [ 0.0280],\n",
      "         [ 0.1533]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [8.6719e-01, 1.3281e-01],\n",
      "         [9.8438e-01, 1.7212e-02],\n",
      "         [5.1562e-01, 4.8633e-01],\n",
      "         [9.3994e-03, 9.9219e-01],\n",
      "         [6.7188e-01, 3.3008e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4961e-01, 6.4844e-01],\n",
      "         [2.5940e-03, 9.9609e-01],\n",
      "         [8.6328e-01, 1.3770e-01],\n",
      "         [9.7266e-01, 2.5757e-02],\n",
      "         [7.1484e-01, 2.8516e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0352e-01, 8.9844e-01],\n",
      "         [1.4258e-01, 8.5938e-01],\n",
      "         [7.3047e-01, 2.6953e-01],\n",
      "         [8.2812e-01, 1.7285e-01],\n",
      "         [7.3047e-01, 2.6953e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 7.4463e-03],\n",
      "         [3.5547e-01, 6.4453e-01],\n",
      "         [9.5825e-03, 9.9219e-01],\n",
      "         [7.6172e-01, 2.3828e-01],\n",
      "         [9.7266e-01, 2.6001e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.0212e-03],\n",
      "         [1.0000e+00, 8.9645e-04],\n",
      "         [6.7969e-01, 3.2031e-01],\n",
      "         [2.0020e-02, 9.8047e-01],\n",
      "         [5.1953e-01, 4.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.6406e-01, 3.3594e-01],\n",
      "         [2.8931e-02, 9.7266e-01],\n",
      "         [7.6562e-01, 2.3340e-01],\n",
      "         [9.0625e-01, 9.1797e-02],\n",
      "         [7.9297e-01, 2.0898e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.6680e-01, 5.3125e-01],\n",
      "         [1.8066e-02, 9.8047e-01],\n",
      "         [7.8125e-01, 2.1973e-01],\n",
      "         [9.6484e-01, 3.6377e-02],\n",
      "         [7.7344e-01, 2.2656e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.1798e-04],\n",
      "         [2.3956e-03, 9.9609e-01],\n",
      "         [2.4719e-03, 9.9609e-01],\n",
      "         [1.0000e+00, 1.3657e-03],\n",
      "         [1.0000e+00, 1.6251e-03]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[2, 0, 5, 6, 4],\n",
      "        [4, 3, 1, 8, 5],\n",
      "        [2, 0, 1, 8, 0],\n",
      "        [7, 6, 0, 6, 4],\n",
      "        [4, 2, 5, 8, 3],\n",
      "        [1, 6, 0, 6, 4],\n",
      "        [2, 6, 1, 8, 0],\n",
      "        [2, 0, 5, 6, 4]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.4492],\n",
      "         [-0.3848],\n",
      "         [ 0.2285],\n",
      "         [ 0.2754],\n",
      "         [ 0.0850],\n",
      "         [ 0.0339]],\n",
      "\n",
      "        [[-0.3613],\n",
      "         [-0.3164],\n",
      "         [ 0.4004],\n",
      "         [ 0.1875],\n",
      "         [-0.0282],\n",
      "         [-0.0011]],\n",
      "\n",
      "        [[-0.0840],\n",
      "         [ 0.0522],\n",
      "         [ 0.1357],\n",
      "         [ 0.2100],\n",
      "         [ 0.0767],\n",
      "         [-0.0737]],\n",
      "\n",
      "        [[-0.7305],\n",
      "         [ 0.4414],\n",
      "         [ 0.2559],\n",
      "         [ 0.0188],\n",
      "         [ 0.0069],\n",
      "         [-0.0045]],\n",
      "\n",
      "        [[ 0.1973],\n",
      "         [ 0.2539],\n",
      "         [-0.2891],\n",
      "         [-0.3477],\n",
      "         [ 0.0977],\n",
      "         [ 0.2793]],\n",
      "\n",
      "        [[ 0.1309],\n",
      "         [ 0.2637],\n",
      "         [ 0.0481],\n",
      "         [ 0.0479],\n",
      "         [ 0.0747],\n",
      "         [ 0.1055]],\n",
      "\n",
      "        [[-0.0693],\n",
      "         [ 0.0923],\n",
      "         [ 0.0271],\n",
      "         [ 0.2910],\n",
      "         [ 0.0679],\n",
      "         [-0.0723]],\n",
      "\n",
      "        [[-0.2617],\n",
      "         [ 0.2002],\n",
      "         [-0.0192],\n",
      "         [-0.0161],\n",
      "         [ 0.0530],\n",
      "         [-0.0029]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0081],\n",
      "         [-0.0967],\n",
      "         [ 0.0530],\n",
      "         [ 0.3848],\n",
      "         [ 0.2715]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0040],\n",
      "         [-0.0189],\n",
      "         [ 0.0645],\n",
      "         [ 0.2891],\n",
      "         [ 0.0820]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3555],\n",
      "         [ 0.1865],\n",
      "         [ 0.2236],\n",
      "         [ 0.4121],\n",
      "         [ 0.0022]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0801],\n",
      "         [ 0.1621],\n",
      "         [ 0.3457],\n",
      "         [ 0.1289],\n",
      "         [ 0.1709]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0339],\n",
      "         [ 0.1060],\n",
      "         [ 0.0508],\n",
      "         [ 0.0510],\n",
      "         [ 0.0884]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0393],\n",
      "         [ 0.2969],\n",
      "         [-0.0144],\n",
      "         [ 0.1167],\n",
      "         [ 0.1826]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4102],\n",
      "         [ 0.1143],\n",
      "         [ 0.2793],\n",
      "         [ 0.5352],\n",
      "         [ 0.0059]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2793],\n",
      "         [ 0.0996],\n",
      "         [ 0.1465],\n",
      "         [ 0.1729],\n",
      "         [ 0.2471]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.2583e-03, 9.9609e-01],\n",
      "         [1.0000e+00, 1.7014e-03],\n",
      "         [1.0000e+00, 9.6893e-04],\n",
      "         [3.9258e-01, 6.0547e-01],\n",
      "         [9.3994e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.8910e-03, 9.9609e-01],\n",
      "         [9.9609e-01, 2.4719e-03],\n",
      "         [1.0000e+00, 1.4114e-03],\n",
      "         [2.6367e-01, 7.3828e-01],\n",
      "         [4.2725e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.8828e-01, 5.1172e-01],\n",
      "         [1.3379e-01, 8.6719e-01],\n",
      "         [4.9023e-01, 5.0781e-01],\n",
      "         [9.4141e-01, 5.9570e-02],\n",
      "         [8.9844e-01, 1.0059e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 2.2125e-03],\n",
      "         [1.0000e+00, 1.0300e-03],\n",
      "         [4.8828e-01, 5.1172e-01],\n",
      "         [7.2327e-03, 9.9219e-01],\n",
      "         [1.5430e-01, 8.4766e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 8.4305e-04],\n",
      "         [9.5825e-03, 9.9219e-01],\n",
      "         [7.9346e-04, 1.0000e+00],\n",
      "         [9.6094e-01, 3.9062e-02],\n",
      "         [1.0000e+00, 3.2997e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 4.1199e-03],\n",
      "         [2.6953e-01, 7.3047e-01],\n",
      "         [5.6458e-03, 9.9609e-01],\n",
      "         [1.4941e-01, 8.5156e-01],\n",
      "         [9.7266e-01, 2.6001e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.0078e-01, 6.9922e-01],\n",
      "         [3.4790e-03, 9.9609e-01],\n",
      "         [6.2891e-01, 3.6914e-01],\n",
      "         [9.8047e-01, 1.9287e-02],\n",
      "         [6.9141e-01, 3.0859e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.9688e-01, 2.0117e-01],\n",
      "         [9.2188e-01, 7.7637e-02],\n",
      "         [8.6719e-01, 1.3184e-01],\n",
      "         [4.3750e-01, 5.6250e-01],\n",
      "         [6.7969e-01, 3.2227e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 800 to ./videos/variable_turn_tictactoe_muzero/0/episode_000800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 800. Recorded 10 frames.\n",
      "learning\n",
      "Started recording episode 800 to ./videos/variable_turn_tictactoe_muzero/1/episode_000800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 800. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 800 to ./videos/variable_turn_tictactoe_muzero/3/episode_000800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 800 to ./videos/variable_turn_tictactoe_muzero/2/episode_000800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1700\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[2, 4, 6, 3, 8],\n",
      "        [2, 6, 8, 0, 3],\n",
      "        [7, 3, 8, 1, 0],\n",
      "        [5, 0, 8, 2, 7],\n",
      "        [4, 0, 3, 7, 6],\n",
      "        [6, 5, 0, 8, 2],\n",
      "        [6, 8, 0, 7, 6],\n",
      "        [8, 6, 3, 0, 6]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.4258],\n",
      "         [ 0.5820],\n",
      "         [ 0.3203],\n",
      "         [ 0.0884],\n",
      "         [ 0.0635],\n",
      "         [ 0.6797]],\n",
      "\n",
      "        [[ 0.2412],\n",
      "         [ 0.2930],\n",
      "         [-0.2402],\n",
      "         [-0.3359],\n",
      "         [ 0.2656],\n",
      "         [ 0.3066]],\n",
      "\n",
      "        [[ 0.1738],\n",
      "         [ 0.2344],\n",
      "         [ 0.0135],\n",
      "         [-0.0085],\n",
      "         [ 0.6211],\n",
      "         [ 0.0698]],\n",
      "\n",
      "        [[ 0.2412],\n",
      "         [ 0.2852],\n",
      "         [-0.2139],\n",
      "         [-0.3906],\n",
      "         [ 0.2324],\n",
      "         [ 0.2197]],\n",
      "\n",
      "        [[-0.0287],\n",
      "         [ 0.0251],\n",
      "         [-0.0557],\n",
      "         [ 0.3359],\n",
      "         [ 0.3555],\n",
      "         [ 0.0747]],\n",
      "\n",
      "        [[ 0.4258],\n",
      "         [-0.3926],\n",
      "         [-0.4277],\n",
      "         [ 0.2559],\n",
      "         [ 0.2100],\n",
      "         [ 0.0276]],\n",
      "\n",
      "        [[ 0.2695],\n",
      "         [ 0.2656],\n",
      "         [ 0.0496],\n",
      "         [-0.0029],\n",
      "         [ 0.0820],\n",
      "         [ 0.1816]],\n",
      "\n",
      "        [[ 0.1045],\n",
      "         [ 0.3555],\n",
      "         [ 0.0391],\n",
      "         [-0.1426],\n",
      "         [ 0.1270],\n",
      "         [ 0.0801]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0097],\n",
      "         [ 0.1270],\n",
      "         [ 0.3828],\n",
      "         [-0.0014],\n",
      "         [ 0.2432]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0334],\n",
      "         [ 0.0549],\n",
      "         [ 0.0417],\n",
      "         [ 0.0732],\n",
      "         [ 0.1196]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1719],\n",
      "         [ 0.3418],\n",
      "         [ 0.0396],\n",
      "         [ 0.2256],\n",
      "         [ 0.4844]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0234],\n",
      "         [ 0.0334],\n",
      "         [ 0.0308],\n",
      "         [ 0.0085],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2354],\n",
      "         [-0.0537],\n",
      "         [ 0.0747],\n",
      "         [ 0.2383],\n",
      "         [ 0.4219]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0615],\n",
      "         [-0.0117],\n",
      "         [ 0.0229],\n",
      "         [ 0.1245],\n",
      "         [ 0.5703]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3691],\n",
      "         [ 0.5703],\n",
      "         [ 0.0149],\n",
      "         [-0.0212],\n",
      "         [ 0.0957]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2490],\n",
      "         [ 0.3516],\n",
      "         [ 0.1157],\n",
      "         [ 0.2119],\n",
      "         [ 0.1719]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [1.0000e+00, 7.9346e-04],\n",
      "         [3.9258e-01, 6.0547e-01],\n",
      "         [6.5918e-03, 9.9219e-01],\n",
      "         [7.7344e-01, 2.2461e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.3705e-04],\n",
      "         [2.2888e-03, 9.9609e-01],\n",
      "         [7.2098e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 3.2806e-03],\n",
      "         [1.0000e+00, 1.4343e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.5945e-03],\n",
      "         [1.8848e-01, 8.1250e-01],\n",
      "         [2.5940e-03, 9.9609e-01],\n",
      "         [7.1484e-01, 2.8320e-01],\n",
      "         [9.8438e-01, 1.5320e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.8528e-04],\n",
      "         [4.1199e-03, 9.9609e-01],\n",
      "         [8.5449e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.6245e-03],\n",
      "         [1.0000e+00, 3.2043e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.5859e-01, 4.4141e-01],\n",
      "         [4.3335e-03, 9.9609e-01],\n",
      "         [4.0820e-01, 5.8984e-01],\n",
      "         [9.6094e-01, 3.7842e-02],\n",
      "         [8.8281e-01, 1.1816e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.3651e-03, 9.9609e-01],\n",
      "         [9.6893e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3275e-03],\n",
      "         [1.0000e+00, 1.1368e-03],\n",
      "         [5.3125e-01, 4.6875e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.8359e-01, 3.1836e-01],\n",
      "         [9.2578e-01, 7.3242e-02],\n",
      "         [7.2266e-01, 2.7930e-01],\n",
      "         [2.3047e-01, 7.6953e-01],\n",
      "         [6.6016e-01, 3.4180e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 2.5482e-03],\n",
      "         [1.4160e-01, 8.5938e-01],\n",
      "         [2.0447e-03, 9.9609e-01],\n",
      "         [7.4219e-01, 2.5977e-01],\n",
      "         [9.6484e-01, 3.4180e-02]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1800\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[5, 0, 0, 3, 2],\n",
      "        [2, 0, 0, 3, 2],\n",
      "        [5, 2, 3, 6, 4],\n",
      "        [3, 0, 0, 3, 2],\n",
      "        [0, 2, 8, 1, 0],\n",
      "        [8, 0, 0, 3, 2],\n",
      "        [8, 4, 2, 0, 2],\n",
      "        [7, 8, 1, 4, 0]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900]])\n",
      "predicted values tensor([[[ 0.0830],\n",
      "         [-0.0371],\n",
      "         [-0.1348],\n",
      "         [ 0.2100],\n",
      "         [ 0.1875],\n",
      "         [ 0.0498]],\n",
      "\n",
      "        [[ 0.2871],\n",
      "         [ 0.1064],\n",
      "         [-0.0557],\n",
      "         [-0.0311],\n",
      "         [ 0.1055],\n",
      "         [ 0.1387]],\n",
      "\n",
      "        [[-0.5273],\n",
      "         [ 0.3789],\n",
      "         [ 0.2344],\n",
      "         [ 0.0493],\n",
      "         [-0.0491],\n",
      "         [ 0.2139]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [-0.0884],\n",
      "         [-0.3281],\n",
      "         [ 0.1133],\n",
      "         [ 0.2559],\n",
      "         [ 0.0041]],\n",
      "\n",
      "        [[ 0.2871],\n",
      "         [ 0.3164],\n",
      "         [ 0.1099],\n",
      "         [-0.0474],\n",
      "         [ 0.2246],\n",
      "         [ 0.1094]],\n",
      "\n",
      "        [[ 0.3125],\n",
      "         [ 0.1416],\n",
      "         [ 0.0092],\n",
      "         [ 0.1377],\n",
      "         [ 0.2656],\n",
      "         [ 0.0884]],\n",
      "\n",
      "        [[-0.4512],\n",
      "         [ 0.4180],\n",
      "         [ 0.2500],\n",
      "         [ 0.0522],\n",
      "         [-0.0674],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[-0.3086],\n",
      "         [-0.1177],\n",
      "         [ 0.4180],\n",
      "         [ 0.1387],\n",
      "         [ 0.0192],\n",
      "         [ 0.0209]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 1.8652e-01],\n",
      "         [-1.3184e-02],\n",
      "         [ 7.3242e-02],\n",
      "         [ 1.6113e-01],\n",
      "         [ 3.6719e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.1797e-01],\n",
      "         [ 4.2383e-01],\n",
      "         [-4.1748e-02],\n",
      "         [-2.2949e-02],\n",
      "         [ 1.5332e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.0010e-01],\n",
      "         [ 5.3467e-02],\n",
      "         [ 3.1445e-01],\n",
      "         [ 9.7656e-02],\n",
      "         [ 3.7500e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 3.5156e-01],\n",
      "         [-7.4219e-02],\n",
      "         [-3.0708e-04],\n",
      "         [ 6.1279e-02],\n",
      "         [ 2.5781e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 6.2988e-02],\n",
      "         [ 3.2617e-01],\n",
      "         [ 2.0020e-01],\n",
      "         [ 3.0469e-01],\n",
      "         [ 1.5234e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.9297e-01],\n",
      "         [ 4.0054e-04],\n",
      "         [-1.8921e-02],\n",
      "         [-5.7983e-03],\n",
      "         [ 2.3926e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.2583e-02],\n",
      "         [ 1.8359e-01],\n",
      "         [ 5.3125e-01],\n",
      "         [ 1.7212e-02],\n",
      "         [ 2.7930e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 5.0354e-03],\n",
      "         [ 8.0566e-03],\n",
      "         [ 3.4332e-03],\n",
      "         [ 3.1445e-01],\n",
      "         [ 2.5391e-02]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.5527e-01, 8.4375e-01],\n",
      "         [2.8839e-03, 9.9609e-01],\n",
      "         [8.0859e-01, 1.9238e-01],\n",
      "         [9.9219e-01, 8.7280e-03],\n",
      "         [6.1719e-01, 3.8281e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.0156e-01, 3.9844e-01],\n",
      "         [8.9844e-01, 9.9609e-02],\n",
      "         [7.8125e-01, 2.1973e-01],\n",
      "         [6.3281e-01, 3.6914e-01],\n",
      "         [7.4609e-01, 2.5195e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.7853e-03],\n",
      "         [1.0000e+00, 7.0953e-04],\n",
      "         [2.5586e-01, 7.4609e-01],\n",
      "         [1.4572e-03, 1.0000e+00],\n",
      "         [6.2109e-01, 3.8086e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.3242e-01, 7.6953e-01],\n",
      "         [5.2643e-04, 1.0000e+00],\n",
      "         [6.0156e-01, 3.9844e-01],\n",
      "         [9.9609e-01, 3.2806e-03],\n",
      "         [6.2500e-01, 3.7500e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.6479e-03],\n",
      "         [9.3359e-01, 6.6895e-02],\n",
      "         [3.7842e-02, 9.6094e-01],\n",
      "         [3.4375e-01, 6.5625e-01],\n",
      "         [8.0078e-01, 1.9824e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.4531e-01, 5.5469e-01],\n",
      "         [2.4719e-03, 9.9609e-01],\n",
      "         [4.1406e-01, 5.8594e-01],\n",
      "         [9.7656e-01, 2.4780e-02],\n",
      "         [7.7734e-01, 2.2461e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.4343e-03],\n",
      "         [1.0000e+00, 6.9809e-04],\n",
      "         [5.5078e-01, 4.5117e-01],\n",
      "         [1.8997e-03, 1.0000e+00],\n",
      "         [5.1953e-01, 4.8242e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.6235e-02, 9.8438e-01],\n",
      "         [1.0000e+00, 8.1635e-04],\n",
      "         [1.0000e+00, 1.0147e-03],\n",
      "         [2.0605e-01, 7.9297e-01],\n",
      "         [1.8997e-03, 1.0000e+00]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 900 to ./videos/variable_turn_tictactoe_muzero/0/episode_000900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 900. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 900 to ./videos/variable_turn_tictactoe_muzero/1/episode_000900.mp4\n",
      "learning\n",
      "learning\n",
      "Started recording episode 900 to ./videos/variable_turn_tictactoe_muzero/3/episode_000900.mp4\n",
      "learning\n",
      "Stopped recording episode 900. Recorded 6 frames.\n",
      "learning\n",
      "Stopped recording episode 900. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 900 to ./videos/variable_turn_tictactoe_muzero/2/episode_000900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 900. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "1900\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[2, 0, 8, 4, 8],\n",
      "        [8, 7, 6, 5, 4],\n",
      "        [4, 1, 5, 0, 3],\n",
      "        [2, 5, 1, 6, 0],\n",
      "        [6, 5, 0, 4, 8],\n",
      "        [5, 3, 0, 6, 2],\n",
      "        [6, 3, 5, 7, 4],\n",
      "        [1, 2, 5, 0, 8]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2773],\n",
      "         [ 0.0850],\n",
      "         [ 0.0874],\n",
      "         [ 0.1865],\n",
      "         [ 0.0023],\n",
      "         [ 0.0070]],\n",
      "\n",
      "        [[-0.5430],\n",
      "         [ 0.3750],\n",
      "         [ 0.2832],\n",
      "         [ 0.0593],\n",
      "         [ 0.1318],\n",
      "         [ 0.2168]],\n",
      "\n",
      "        [[ 0.2871],\n",
      "         [-0.3887],\n",
      "         [-0.4609],\n",
      "         [ 0.6211],\n",
      "         [ 0.3066],\n",
      "         [ 0.0781]],\n",
      "\n",
      "        [[ 0.1592],\n",
      "         [ 0.0579],\n",
      "         [ 0.1211],\n",
      "         [ 0.3516],\n",
      "         [ 0.0145],\n",
      "         [-0.0432]],\n",
      "\n",
      "        [[-0.0544],\n",
      "         [ 0.2480],\n",
      "         [ 0.0312],\n",
      "         [-0.0261],\n",
      "         [ 0.0023],\n",
      "         [-0.0058]],\n",
      "\n",
      "        [[-0.1836],\n",
      "         [-0.2100],\n",
      "         [ 0.5117],\n",
      "         [ 0.2539],\n",
      "         [ 0.0374],\n",
      "         [ 0.0801]],\n",
      "\n",
      "        [[ 0.2871],\n",
      "         [-0.2197],\n",
      "         [-0.3516],\n",
      "         [ 0.4141],\n",
      "         [ 0.3027],\n",
      "         [ 0.0393]],\n",
      "\n",
      "        [[-0.6445],\n",
      "         [ 0.5469],\n",
      "         [ 0.3789],\n",
      "         [ 0.0713],\n",
      "         [ 0.1011],\n",
      "         [ 0.0238]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.4141],\n",
      "         [-0.0403],\n",
      "         [ 0.3203],\n",
      "         [ 0.3203],\n",
      "         [ 0.3828]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0008],\n",
      "         [ 0.1011],\n",
      "         [ 0.3418],\n",
      "         [ 0.1089],\n",
      "         [ 0.4844]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0049],\n",
      "         [ 0.0388],\n",
      "         [ 0.0579],\n",
      "         [ 0.1963],\n",
      "         [ 0.4668]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4355],\n",
      "         [ 0.2207],\n",
      "         [ 0.4141],\n",
      "         [ 0.7148],\n",
      "         [ 0.0308]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3926],\n",
      "         [ 0.6836],\n",
      "         [ 0.1069],\n",
      "         [ 0.1147],\n",
      "         [ 0.3184]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0095],\n",
      "         [ 0.0201],\n",
      "         [ 0.1050],\n",
      "         [ 0.4180],\n",
      "         [ 0.0820]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0179],\n",
      "         [ 0.0322],\n",
      "         [ 0.0747],\n",
      "         [ 0.1270],\n",
      "         [ 0.4395]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.1270],\n",
      "         [ 0.1436],\n",
      "         [ 0.5156],\n",
      "         [ 0.0771],\n",
      "         [ 0.4746]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.8711e-01, 7.1484e-01],\n",
      "         [2.2125e-03, 9.9609e-01],\n",
      "         [6.5234e-01, 3.4570e-01],\n",
      "         [9.8438e-01, 1.4282e-02],\n",
      "         [5.7422e-01, 4.2578e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0147e-03],\n",
      "         [1.0000e+00, 7.9346e-04],\n",
      "         [4.0430e-01, 5.9766e-01],\n",
      "         [8.0566e-03, 9.9219e-01],\n",
      "         [5.8203e-01, 4.1992e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.0953e-04, 1.0000e+00],\n",
      "         [3.9291e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.7466e-04],\n",
      "         [1.0000e+00, 6.6757e-04],\n",
      "         [4.7852e-01, 5.2344e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.8750e-01, 3.1250e-01],\n",
      "         [2.1240e-02, 9.8047e-01],\n",
      "         [7.9297e-01, 2.0801e-01],\n",
      "         [9.8438e-01, 1.6235e-02],\n",
      "         [7.6953e-01, 2.2949e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.5156e-01, 1.4941e-01],\n",
      "         [9.9219e-01, 7.5684e-03],\n",
      "         [5.6250e-01, 4.3945e-01],\n",
      "         [1.9165e-02, 9.8047e-01],\n",
      "         [3.3008e-01, 6.7188e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.4658e-02, 9.7656e-01],\n",
      "         [1.0000e+00, 8.0490e-04],\n",
      "         [1.0000e+00, 1.2817e-03],\n",
      "         [4.2969e-01, 5.7031e-01],\n",
      "         [3.8300e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4343e-03, 1.0000e+00],\n",
      "         [6.3705e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [1.0000e+00, 4.3106e-04],\n",
      "         [3.9258e-01, 6.0547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.2561e-04],\n",
      "         [1.0000e+00, 4.8065e-04],\n",
      "         [5.8984e-01, 4.1016e-01],\n",
      "         [6.6833e-03, 9.9219e-01],\n",
      "         [4.2188e-01, 5.7812e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 1000 to ./videos/variable_turn_tictactoe_muzero/0/episode_001000.mp4\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped recording episode 1000. Recorded 10 frames.\n",
      "learning\n",
      "2000\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 3, 0, 2, 7],\n",
      "        [4, 0, 7, 2, 7],\n",
      "        [1, 0, 3, 8, 5],\n",
      "        [3, 0, 7, 2, 7],\n",
      "        [6, 0, 7, 2, 7],\n",
      "        [8, 6, 7, 5, 0],\n",
      "        [8, 0, 7, 2, 7],\n",
      "        [5, 3, 2, 1, 6]])\n",
      "target value tensor([[ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.3828],\n",
      "         [ 0.2852],\n",
      "         [ 0.0623],\n",
      "         [ 0.1309],\n",
      "         [ 0.1914],\n",
      "         [ 0.0591]],\n",
      "\n",
      "        [[ 0.0874],\n",
      "         [ 0.0518],\n",
      "         [ 0.0145],\n",
      "         [-0.0591],\n",
      "         [ 0.0654],\n",
      "         [ 0.2559]],\n",
      "\n",
      "        [[ 0.3477],\n",
      "         [ 0.3203],\n",
      "         [-0.1235],\n",
      "         [-0.1650],\n",
      "         [ 0.3477],\n",
      "         [ 0.3340]],\n",
      "\n",
      "        [[ 0.4609],\n",
      "         [ 0.0869],\n",
      "         [-0.0654],\n",
      "         [ 0.3809],\n",
      "         [ 0.0132],\n",
      "         [ 0.0162]],\n",
      "\n",
      "        [[ 0.2354],\n",
      "         [ 0.1338],\n",
      "         [ 0.0811],\n",
      "         [ 0.1934],\n",
      "         [ 0.0586],\n",
      "         [ 0.0212]],\n",
      "\n",
      "        [[-0.1611],\n",
      "         [-0.2520],\n",
      "         [ 0.1572],\n",
      "         [ 0.1699],\n",
      "         [ 0.0811],\n",
      "         [ 0.2188]],\n",
      "\n",
      "        [[ 0.2891],\n",
      "         [ 0.2539],\n",
      "         [ 0.0786],\n",
      "         [-0.0054],\n",
      "         [ 0.1260],\n",
      "         [ 0.1455]],\n",
      "\n",
      "        [[-0.2148],\n",
      "         [ 0.4746],\n",
      "         [ 0.3320],\n",
      "         [ 0.1270],\n",
      "         [ 0.0903],\n",
      "         [ 0.2119]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.1582],\n",
      "         [ 0.3633],\n",
      "         [ 0.1113],\n",
      "         [ 0.4316],\n",
      "         [ 0.4414]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4043],\n",
      "         [ 0.1592],\n",
      "         [ 0.2539],\n",
      "         [ 0.2061],\n",
      "         [ 0.1553]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0405],\n",
      "         [ 0.0518],\n",
      "         [ 0.0527],\n",
      "         [ 0.0703],\n",
      "         [ 0.1631]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4121],\n",
      "         [ 0.0513],\n",
      "         [ 0.2354],\n",
      "         [ 0.6484],\n",
      "         [ 0.2930]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6875],\n",
      "         [ 0.0330],\n",
      "         [ 0.2559],\n",
      "         [ 0.4395],\n",
      "         [ 0.3164]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0571],\n",
      "         [ 0.0903],\n",
      "         [ 0.1602],\n",
      "         [ 0.3574],\n",
      "         [ 0.0630]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3965],\n",
      "         [ 0.1660],\n",
      "         [ 0.1523],\n",
      "         [ 0.3047],\n",
      "         [ 0.2061]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0498],\n",
      "         [ 0.3164],\n",
      "         [ 0.4316],\n",
      "         [ 0.1855],\n",
      "         [ 0.4824]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.4790e-03],\n",
      "         [4.8828e-01, 5.1172e-01],\n",
      "         [1.5076e-02, 9.8438e-01],\n",
      "         [6.6406e-01, 3.3594e-01],\n",
      "         [9.4141e-01, 5.6641e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.1953e-01, 4.8242e-01],\n",
      "         [9.0625e-01, 9.3262e-02],\n",
      "         [9.3359e-01, 6.5430e-02],\n",
      "         [4.7656e-01, 5.2344e-01],\n",
      "         [3.4424e-02, 9.6484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3428e-03],\n",
      "         [1.3275e-03, 1.0000e+00],\n",
      "         [1.6479e-03, 1.0000e+00],\n",
      "         [9.9609e-01, 4.0588e-03],\n",
      "         [1.0000e+00, 3.9864e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.1719e-01, 3.8281e-01],\n",
      "         [1.9836e-03, 9.9609e-01],\n",
      "         [7.4609e-01, 2.5195e-01],\n",
      "         [9.9609e-01, 5.7373e-03],\n",
      "         [4.1211e-01, 5.8594e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.8750e-01, 3.1445e-01],\n",
      "         [5.6152e-02, 9.4531e-01],\n",
      "         [8.2812e-01, 1.7090e-01],\n",
      "         [9.6094e-01, 3.7598e-02],\n",
      "         [3.9844e-01, 6.0156e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.5259e-03, 1.0000e+00],\n",
      "         [9.9609e-01, 2.8839e-03],\n",
      "         [9.9609e-01, 2.4719e-03],\n",
      "         [3.0078e-01, 6.9922e-01],\n",
      "         [6.3782e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.1406e-01, 5.8594e-01],\n",
      "         [8.7109e-01, 1.2891e-01],\n",
      "         [8.2031e-01, 1.7871e-01],\n",
      "         [6.2109e-01, 3.7891e-01],\n",
      "         [5.8594e-01, 4.1211e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.6757e-04],\n",
      "         [9.9219e-01, 6.5002e-03],\n",
      "         [5.1953e-01, 4.8047e-01],\n",
      "         [2.3956e-03, 9.9609e-01],\n",
      "         [5.4688e-01, 4.5312e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "Started recording episode 1000 to ./videos/variable_turn_tictactoe_muzero/1/episode_001000.mp4\n",
      "learning\n",
      "Started recording episode 1000 to ./videos/variable_turn_tictactoe_muzero/3/episode_001000.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1000. Recorded 7 frames.\n",
      "learning\n",
      "Stopped recording episode 1000. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1000 to ./videos/variable_turn_tictactoe_muzero/2/episode_001000.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1000. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "Testing Player 0 vs Agent random\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.0800, 0.0800, 0.2000, 0.0800, 0.2800, 0.1200, 0.0800]), tensor([0.0400, 0.0400, 0.0800, 0.0800, 0.2000, 0.0800, 0.2800, 0.1200, 0.0800]), 0.29088922119140614, tensor(6), {'network_policy': tensor([0.0586, 0.0586, 0.0957, 0.0884, 0.2197, 0.0928, 0.2002, 0.0801, 0.1050],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.3359375, 'search_policy': tensor([0.0400, 0.0400, 0.0800, 0.0800, 0.2000, 0.0800, 0.2800, 0.1200, 0.0800]), 'search_value': 0.29088922119140614, 'root_children_values': tensor([0.3164, 0.2930, 0.3789, 0.3486, 0.3885, 0.3730, 0.2643, 0.3023, 0.3945])})\n",
      "action: 6\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.2000, 0.0800, 0.3200, 0.0800, 0.0000, 0.0800, 0.1600]), tensor([0.0400, 0.0400, 0.2000, 0.0800, 0.3200, 0.0800, 0.0000, 0.0800, 0.1600]), 0.27095194544396023, tensor(4), {'network_policy': tensor([0.0825, 0.0752, 0.1279, 0.1445, 0.2148, 0.1157, 0.0000, 0.1079, 0.1318],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.24609375, 'search_policy': tensor([0.0400, 0.0400, 0.2000, 0.0800, 0.3200, 0.0800, 0.0000, 0.0800, 0.1600]), 'search_value': 0.27095194544396023, 'root_children_values': tensor([-0.1914, -0.1602, -0.2578, -0.2319, -0.3272, -0.1875,  0.0000, -0.1777,\n",
      "        -0.2570])})\n",
      "action: 4\n",
      "Player 1 random action: 3\n",
      "Player 1 random action: 5\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.1200, 0.1200, 0.2400, 0.0000, 0.0000, 0.0000, 0.0000, 0.1600, 0.3600]), tensor([0.1200, 0.1200, 0.2400, 0.0000, 0.0000, 0.0000, 0.0000, 0.1600, 0.3600]), 0.4182169240382268, tensor(8), {'network_policy': tensor([0.1611, 0.1416, 0.2412, 0.0000, 0.0000, 0.0000, 0.0000, 0.1396, 0.3145],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.50390625, 'search_policy': tensor([0.1200, 0.1200, 0.2400, 0.0000, 0.0000, 0.0000, 0.0000, 0.1600, 0.3600]), 'search_value': 0.4182169240382268, 'root_children_values': tensor([0.3906, 0.2207, 0.3683, 0.0000, 0.0000, 0.0000, 0.0000, 0.3018, 0.4670])})\n",
      "action: 8\n",
      "Player 0 prediction: (tensor([0.2800, 0.1200, 0.5600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0400, 0.0000]), tensor([0.2800, 0.1200, 0.5600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0400, 0.0000]), 0.5039918666710317, tensor(2), {'network_policy': tensor([0.2617, 0.2773, 0.3496, 0.0000, 0.0000, 0.0000, 0.0000, 0.1089, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.5234375, 'search_policy': tensor([0.2800, 0.1200, 0.5600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0400, 0.0000]), 'search_value': 0.5039918666710317, 'root_children_values': tensor([0.1121, 0.0893, 0.2617, 0.0000, 0.0000, 0.0000, 0.0000, 0.0586, 0.0000])})\n",
      "action: 2\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 1, 0, 8, 2],\n",
      "        [1, 6, 5, 2, 0],\n",
      "        [7, 5, 6, 8, 0],\n",
      "        [6, 8, 7, 4, 5],\n",
      "        [4, 6, 8, 0, 2],\n",
      "        [8, 6, 0, 7, 2],\n",
      "        [8, 6, 7, 2, 0],\n",
      "        [5, 0, 1, 7, 2]])\n",
      "target value tensor([[-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.1689],\n",
      "         [-0.4297],\n",
      "         [ 0.3086],\n",
      "         [ 0.1631],\n",
      "         [-0.0020],\n",
      "         [-0.0084]],\n",
      "\n",
      "        [[ 0.5156],\n",
      "         [ 0.4336],\n",
      "         [-0.3027],\n",
      "         [-0.3105],\n",
      "         [ 0.4336],\n",
      "         [ 0.3164]],\n",
      "\n",
      "        [[-0.4297],\n",
      "         [-0.5000],\n",
      "         [ 0.5898],\n",
      "         [ 0.3203],\n",
      "         [ 0.0317],\n",
      "         [-0.0272]],\n",
      "\n",
      "        [[ 0.5156],\n",
      "         [ 0.4258],\n",
      "         [-0.3223],\n",
      "         [-0.4023],\n",
      "         [ 0.2461],\n",
      "         [ 0.2598]],\n",
      "\n",
      "        [[-0.4160],\n",
      "         [ 0.3398],\n",
      "         [ 0.1914],\n",
      "         [ 0.0277],\n",
      "         [ 0.0371],\n",
      "         [ 0.0752]],\n",
      "\n",
      "        [[ 1.0312],\n",
      "         [ 0.3398],\n",
      "         [-0.0806],\n",
      "         [-0.1221],\n",
      "         [ 0.3145],\n",
      "         [ 0.1099]],\n",
      "\n",
      "        [[ 0.5156],\n",
      "         [ 0.4805],\n",
      "         [-0.3340],\n",
      "         [-0.4160],\n",
      "         [ 0.4238],\n",
      "         [ 0.2236]],\n",
      "\n",
      "        [[ 0.7227],\n",
      "         [ 0.1865],\n",
      "         [ 0.0854],\n",
      "         [ 0.1279],\n",
      "         [ 0.0564],\n",
      "         [ 0.0811]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0449],\n",
      "         [-0.1089],\n",
      "         [ 0.0544],\n",
      "         [ 0.2715],\n",
      "         [ 0.1797]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0825],\n",
      "         [-0.0598],\n",
      "         [-0.0869],\n",
      "         [-0.0483],\n",
      "         [ 0.1172]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0233],\n",
      "         [-0.0894],\n",
      "         [ 0.0664],\n",
      "         [ 0.3008],\n",
      "         [-0.0679]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0388],\n",
      "         [-0.0320],\n",
      "         [-0.0732],\n",
      "         [-0.0200],\n",
      "         [ 0.0427]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0187],\n",
      "         [ 0.2119],\n",
      "         [ 0.2754],\n",
      "         [ 0.0374],\n",
      "         [ 0.3652]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1924],\n",
      "         [ 0.3672],\n",
      "         [ 0.0413],\n",
      "         [ 0.2012],\n",
      "         [ 0.4082]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0052],\n",
      "         [-0.0334],\n",
      "         [-0.0752],\n",
      "         [ 0.0535],\n",
      "         [ 0.1631]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.5508],\n",
      "         [-0.0894],\n",
      "         [ 0.1709],\n",
      "         [ 0.2715],\n",
      "         [ 0.3047]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [4.3335e-03, 9.9609e-01],\n",
      "         [1.0000e+00, 1.6251e-03],\n",
      "         [9.9609e-01, 4.1199e-03],\n",
      "         [2.9688e-01, 7.0312e-01],\n",
      "         [3.5400e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3657e-03],\n",
      "         [5.5313e-04, 1.0000e+00],\n",
      "         [8.9645e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.5717e-03],\n",
      "         [1.0000e+00, 5.2643e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.3242e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 5.1270e-03],\n",
      "         [1.0000e+00, 6.5613e-04],\n",
      "         [3.5938e-01, 6.4062e-01],\n",
      "         [3.0212e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.1771e-04],\n",
      "         [1.0986e-03, 1.0000e+00],\n",
      "         [8.0490e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.3651e-03],\n",
      "         [1.0000e+00, 1.0986e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 5.6458e-03],\n",
      "         [9.9609e-01, 1.9531e-03],\n",
      "         [3.5352e-01, 6.4844e-01],\n",
      "         [4.6692e-03, 9.9609e-01],\n",
      "         [4.7461e-01, 5.2344e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.8828e-01, 1.2634e-02],\n",
      "         [5.1953e-01, 4.8047e-01],\n",
      "         [3.8300e-03, 9.9609e-01],\n",
      "         [6.7188e-01, 3.2617e-01],\n",
      "         [9.6094e-01, 4.0283e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.6539e-04],\n",
      "         [1.9302e-03, 1.0000e+00],\n",
      "         [7.7820e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.0142e-03],\n",
      "         [1.0000e+00, 7.4387e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.3438e-01, 2.6562e-01],\n",
      "         [3.7109e-02, 9.6484e-01],\n",
      "         [3.9258e-01, 6.0938e-01],\n",
      "         [8.2422e-01, 1.7578e-01],\n",
      "         [7.4219e-01, 2.5781e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 0 win percentage vs random: 96.0 and average score: 0.92\n",
      "Testing Player 1 vs Agent random\n",
      "Player 0 random action: 2\n",
      "Player 0 random action: 8\n",
      "Player 1 prediction: (tensor([0.0800, 0.0800, 0.0000, 0.1200, 0.3600, 0.1200, 0.1200, 0.1200, 0.0000]), tensor([0.0800, 0.0800, 0.0000, 0.1200, 0.3600, 0.1200, 0.1200, 0.1200, 0.0000]), -0.2915701858849159, tensor(4), {'network_policy': tensor([0.1074, 0.1138, 0.0000, 0.1064, 0.2188, 0.1494, 0.1455, 0.1553, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.228515625, 'search_policy': tensor([0.0800, 0.0800, 0.0000, 0.1200, 0.3600, 0.1200, 0.1200, 0.1200, 0.0000]), 'search_value': -0.2915701858849159, 'root_children_values': tensor([-0.2363, -0.2480,  0.0000, -0.3730, -0.3399, -0.3122, -0.2295, -0.3616,\n",
      "         0.0000])})\n",
      "action: 4\n",
      "Player 1 prediction: (tensor([0.1200, 0.1200, 0.0000, 0.0400, 0.0000, 0.1200, 0.4000, 0.2000, 0.0000]), tensor([0.1200, 0.1200, 0.0000, 0.0400, 0.0000, 0.1200, 0.4000, 0.2000, 0.0000]), -0.2802690698242188, tensor(6), {'network_policy': tensor([0.1523, 0.1543, 0.0000, 0.1406, 0.0000, 0.2061, 0.1855, 0.1562, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.1533203125, 'search_policy': tensor([0.1200, 0.1200, 0.0000, 0.0400, 0.0000, 0.1200, 0.4000, 0.2000, 0.0000]), 'search_value': -0.2802690698242188, 'root_children_values': tensor([0.2344, 0.3279, 0.0000, 0.5156, 0.0000, 0.4652, 0.3500, 0.3739, 0.0000])})\n",
      "action: 6\n",
      "Player 0 random action: 5\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs random: 30.0 and average score: -0.24\n",
      "Results vs random: {'player_0_score': 0.92, 'player_0_win%': 0.96, 'player_1_score': -0.24, 'player_1_win%': 0.3, 'score': 0.34}\n",
      "Testing Player 0 vs Agent tictactoe_expert\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.2000, 0.0400, 0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0400, 0.0800]), tensor([0.2000, 0.0400, 0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0400, 0.0800]), 0.29163572528545667, tensor(4), {'network_policy': tensor([0.0586, 0.0586, 0.0957, 0.0884, 0.2197, 0.0928, 0.2002, 0.0801, 0.1050],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.3359375, 'search_policy': tensor([0.2000, 0.0400, 0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0400, 0.0800]), 'search_value': 0.29163572528545667, 'root_children_values': tensor([0.2836, 0.2930, 0.3789, 0.3594, 0.3916, 0.3730, 0.2809, 0.2617, 0.3945])})\n",
      "action: 4\n",
      "Player 0 prediction: (tensor([0.1600, 0.0400, 0.1200, 0.0800, 0.0000, 0.0800, 0.1600, 0.2000, 0.1600]), tensor([0.1600, 0.0400, 0.1200, 0.0800, 0.0000, 0.0800, 0.1600, 0.2000, 0.1600]), 0.41794174339587886, tensor(7), {'network_policy': tensor([0.0967, 0.0908, 0.1504, 0.1387, 0.0000, 0.1201, 0.1592, 0.0815, 0.1621],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.470703125, 'search_policy': tensor([0.1600, 0.0400, 0.1200, 0.0800, 0.0000, 0.0800, 0.1600, 0.2000, 0.1600]), 'search_value': 0.41794174339587886, 'root_children_values': tensor([-0.3701, -0.3750, -0.3827, -0.3242,  0.0000, -0.3457, -0.3744, -0.4131,\n",
      "        -0.4122])})\n",
      "action: 7\n",
      "Player 1 tictactoe_expert action: 1\n",
      "Player 1 tictactoe_expert action: 8\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.3200, 0.0000, 0.2800, 0.1200, 0.0000, 0.1200, 0.1600, 0.0000, 0.0000]), tensor([0.3200, 0.0000, 0.2800, 0.1200, 0.0000, 0.1200, 0.1600, 0.0000, 0.0000]), 0.4298953639171307, tensor(0), {'network_policy': tensor([0.1387, 0.0000, 0.2354, 0.1885, 0.0000, 0.1914, 0.2441, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.4375, 'search_policy': tensor([0.3200, 0.0000, 0.2800, 0.1200, 0.0000, 0.1200, 0.1600, 0.0000, 0.0000]), 'search_value': 0.4298953639171307, 'root_children_values': tensor([0.5154, 0.0000, 0.4388, 0.2296, 0.0000, 0.1918, 0.2220, 0.0000, 0.0000])})\n",
      "action: 0\n",
      "Player 0 prediction: (tensor([0.0000, 0.0000, 0.2800, 0.4000, 0.0000, 0.1200, 0.2000, 0.0000, 0.0000]), tensor([0.0000, 0.0000, 0.2800, 0.4000, 0.0000, 0.1200, 0.2000, 0.0000, 0.0000]), 0.1940335580655612, tensor(3), {'network_policy': tensor([0.0000, 0.0000, 0.2832, 0.2363, 0.0000, 0.2070, 0.2676, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.396484375, 'search_policy': tensor([0.0000, 0.0000, 0.2800, 0.4000, 0.0000, 0.1200, 0.2000, 0.0000, 0.0000]), 'search_value': 0.1940335580655612, 'root_children_values': tensor([0.0000, 0.0000, 0.1634, 0.0800, 0.0000, 0.1073, 0.1735, 0.0000, 0.0000])})\n",
      "action: 3\n",
      "Player 1 tictactoe_expert action: 5\n",
      "Player 1 tictactoe_expert action: 2\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 1100 to ./videos/variable_turn_tictactoe_muzero/0/episode_001100.mp4\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n",
      "Stopped recording episode 1100. Recorded 10 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 1100 to ./videos/variable_turn_tictactoe_muzero/1/episode_001100.mp4\n",
      "learning\n",
      "2200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[8, 6, 1, 7, 5],\n",
      "        [7, 5, 0, 4, 1],\n",
      "        [0, 6, 3, 7, 2],\n",
      "        [8, 0, 1, 4, 1],\n",
      "        [8, 6, 1, 3, 7],\n",
      "        [1, 4, 0, 4, 1],\n",
      "        [4, 2, 0, 4, 1],\n",
      "        [8, 5, 0, 2, 3]])\n",
      "target value tensor([[ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4570],\n",
      "         [ 0.4414],\n",
      "         [-0.3887],\n",
      "         [-0.3457],\n",
      "         [ 0.3906],\n",
      "         [ 0.2451]],\n",
      "\n",
      "        [[ 0.5586],\n",
      "         [ 0.3887],\n",
      "         [ 0.0311],\n",
      "         [-0.0255],\n",
      "         [-0.0535],\n",
      "         [ 0.0620]],\n",
      "\n",
      "        [[-0.5703],\n",
      "         [ 0.5664],\n",
      "         [ 0.2520],\n",
      "         [-0.0618],\n",
      "         [-0.1338],\n",
      "         [ 0.2852]],\n",
      "\n",
      "        [[ 0.5898],\n",
      "         [ 0.0249],\n",
      "         [-0.1226],\n",
      "         [ 0.3398],\n",
      "         [ 0.0525],\n",
      "         [ 0.0405]],\n",
      "\n",
      "        [[ 0.7148],\n",
      "         [-0.6289],\n",
      "         [-0.5312],\n",
      "         [ 0.4980],\n",
      "         [ 0.4531],\n",
      "         [ 0.0337]],\n",
      "\n",
      "        [[ 0.3809],\n",
      "         [ 0.3320],\n",
      "         [ 0.0520],\n",
      "         [ 0.0280],\n",
      "         [-0.0120],\n",
      "         [ 0.0820]],\n",
      "\n",
      "        [[ 0.3730],\n",
      "         [ 0.3086],\n",
      "         [ 0.0306],\n",
      "         [ 0.0796],\n",
      "         [ 0.0311],\n",
      "         [ 0.0255]],\n",
      "\n",
      "        [[ 0.7148],\n",
      "         [-0.6289],\n",
      "         [-0.6328],\n",
      "         [ 0.5625],\n",
      "         [ 0.3340],\n",
      "         [-0.0962]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0087],\n",
      "         [-0.0508],\n",
      "         [-0.0217],\n",
      "         [-0.0031],\n",
      "         [ 0.0786]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1069],\n",
      "         [ 0.3359],\n",
      "         [-0.0371],\n",
      "         [ 0.2432],\n",
      "         [ 0.1543]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0142],\n",
      "         [ 0.1807],\n",
      "         [ 0.2432],\n",
      "         [ 0.0664],\n",
      "         [ 0.3633]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3652],\n",
      "         [-0.0840],\n",
      "         [ 0.1904],\n",
      "         [ 0.2949],\n",
      "         [ 0.1094]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0173],\n",
      "         [-0.0588],\n",
      "         [-0.0114],\n",
      "         [ 0.0737],\n",
      "         [ 0.2559]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0845],\n",
      "         [ 0.3984],\n",
      "         [-0.0374],\n",
      "         [ 0.2891],\n",
      "         [ 0.1748]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1099],\n",
      "         [ 0.3750],\n",
      "         [ 0.0016],\n",
      "         [ 0.3457],\n",
      "         [ 0.1758]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0173],\n",
      "         [-0.0659],\n",
      "         [-0.0742],\n",
      "         [ 0.2559],\n",
      "         [ 0.3691]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.5368e-04],\n",
      "         [8.9645e-04, 1.0000e+00],\n",
      "         [5.7220e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.6245e-03],\n",
      "         [9.9609e-01, 2.8381e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.5488e-03],\n",
      "         [3.4766e-01, 6.5234e-01],\n",
      "         [7.4463e-03, 9.9219e-01],\n",
      "         [5.0391e-01, 4.9609e-01],\n",
      "         [9.6484e-01, 3.5400e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.8665e-04],\n",
      "         [9.9609e-01, 2.2583e-03],\n",
      "         [3.0859e-01, 6.9141e-01],\n",
      "         [7.5684e-03, 9.9219e-01],\n",
      "         [6.9531e-01, 3.0469e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.9258e-01, 6.0547e-01],\n",
      "         [3.4332e-03, 9.9609e-01],\n",
      "         [6.7969e-01, 3.2031e-01],\n",
      "         [9.7266e-01, 2.6733e-02],\n",
      "         [2.5781e-01, 7.4219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.4468e-04, 1.0000e+00],\n",
      "         [7.2098e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.9864e-04],\n",
      "         [1.0000e+00, 7.0953e-04],\n",
      "         [3.0078e-01, 6.9922e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.4387e-04],\n",
      "         [4.1602e-01, 5.8594e-01],\n",
      "         [2.0142e-03, 9.9609e-01],\n",
      "         [2.1680e-01, 7.8516e-01],\n",
      "         [9.4141e-01, 5.7129e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3428e-03],\n",
      "         [6.5234e-01, 3.4961e-01],\n",
      "         [1.3733e-02, 9.8438e-01],\n",
      "         [4.1406e-01, 5.8594e-01],\n",
      "         [9.2188e-01, 8.0078e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.4468e-04, 1.0000e+00],\n",
      "         [7.3242e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.5368e-04],\n",
      "         [1.0000e+00, 4.7302e-04],\n",
      "         [5.4688e-01, 4.5312e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "Stopped recording episode 1100. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1100 to ./videos/variable_turn_tictactoe_muzero/3/episode_001100.mp4\n",
      "Player 0 win percentage vs tictactoe_expert: 50.0 and average score: 0.06\n",
      "Testing Player 1 vs Agent tictactoe_expert\n",
      "Player 0 tictactoe_expert action: 7\n",
      "Player 0 tictactoe_expert action: 5\n",
      "Player 1 prediction: (tensor([0.0800, 0.0800, 0.1200, 0.1200, 0.1200, 0.0000, 0.1600, 0.0000, 0.3200]), tensor([0.0800, 0.0800, 0.1200, 0.1200, 0.1200, 0.0000, 0.1600, 0.0000, 0.3200]), -0.24494242013784556, tensor(8), {'network_policy': tensor([0.1001, 0.1260, 0.1338, 0.1465, 0.1729, 0.0000, 0.1299, 0.0000, 0.1865],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.1005859375, 'search_policy': tensor([0.0800, 0.0800, 0.1200, 0.1200, 0.1200, 0.0000, 0.1600, 0.0000, 0.3200]), 'search_value': -0.24494242013784556, 'root_children_values': tensor([-0.1562, -0.2197, -0.2695, -0.3224, -0.3166,  0.0000, -0.2246,  0.0000,\n",
      "        -0.3292])})\n",
      "action: 8\n",
      "Player 1 prediction: (tensor([0.1200, 0.2400, 0.1200, 0.1200, 0.2000, 0.0000, 0.2000, 0.0000, 0.0000]), tensor([0.1200, 0.2400, 0.1200, 0.1200, 0.2000, 0.0000, 0.2000, 0.0000, 0.0000]), -0.35998071585787267, tensor(1), {'network_policy': tensor([0.1455, 0.1768, 0.1729, 0.1621, 0.1807, 0.0000, 0.1602, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.008544921875, 'search_policy': tensor([0.1200, 0.2400, 0.1200, 0.1200, 0.2000, 0.0000, 0.2000, 0.0000, 0.0000]), 'search_value': -0.35998071585787267, 'root_children_values': tensor([0.2578, 0.3430, 0.4121, 0.4973, 0.3326, 0.0000, 0.2740, 0.0000, 0.0000])})\n",
      "action: 1\n",
      "Player 0 tictactoe_expert action: 2\n",
      "Player 0 tictactoe_expert action: 3\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000, 0.4400, 0.0000, 0.0000]), tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000, 0.4400, 0.0000, 0.0000]), 0.30528504056969263, tensor(6), {'network_policy': tensor([0.3320, 0.0000, 0.0000, 0.0000, 0.4141, 0.0000, 0.2451, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.0927734375, 'search_policy': tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000, 0.4400, 0.0000, 0.0000]), 'search_value': 0.30528504056969263, 'root_children_values': tensor([ 0.0161,  0.0000,  0.0000,  0.0000, -0.0257,  0.0000,  0.4270,  0.0000,\n",
      "         0.0000])})\n",
      "action: 6\n",
      "Player 1 prediction: (tensor([0.3200, 0.0000, 0.0000, 0.0000, 0.6800, 0.0000, 0.0000, 0.0000, 0.0000]), tensor([0.3200, 0.0000, 0.0000, 0.0000, 0.6800, 0.0000, 0.0000, 0.0000, 0.0000]), -0.35956453168715263, tensor(4), {'network_policy': tensor([0.4590, 0.0000, 0.0000, 0.0000, 0.5273, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.09033203125, 'search_policy': tensor([0.3200, 0.0000, 0.0000, 0.0000, 0.6800, 0.0000, 0.0000, 0.0000, 0.0000]), 'search_value': -0.35956453168715263, 'root_children_values': tensor([0.6106, 0.0000, 0.0000, 0.0000, 0.5307, 0.0000, 0.0000, 0.0000, 0.0000])})\n",
      "action: 4\n",
      "Player 0 tictactoe_expert action: 0\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1100 to ./videos/variable_turn_tictactoe_muzero/2/episode_001100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1100. Recorded 9 frames.\n",
      "learning\n",
      "Player 1 win percentage vs tictactoe_expert: 2.0 and average score: -0.9\n",
      "Results vs tictactoe_expert: {'player_0_score': 0.06, 'player_0_win%': 0.5, 'player_1_score': -0.9, 'player_1_win%': 0.02, 'score': -0.42000000000000004}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 4, 0, 3, 6],\n",
      "        [3, 7, 4, 8, 1],\n",
      "        [7, 3, 0, 6, 0],\n",
      "        [1, 8, 4, 2, 0],\n",
      "        [2, 8, 7, 6, 0],\n",
      "        [6, 1, 5, 3, 0],\n",
      "        [7, 4, 6, 8, 2],\n",
      "        [7, 0, 6, 6, 0]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4277],\n",
      "         [ 0.3047],\n",
      "         [-0.4473],\n",
      "         [-0.4551],\n",
      "         [ 0.4688],\n",
      "         [ 0.3105]],\n",
      "\n",
      "        [[ 0.4863],\n",
      "         [-0.3887],\n",
      "         [-0.4590],\n",
      "         [ 0.2539],\n",
      "         [ 0.3340],\n",
      "         [ 0.0452]],\n",
      "\n",
      "        [[-0.5625],\n",
      "         [ 0.6758],\n",
      "         [ 0.3711],\n",
      "         [ 0.0654],\n",
      "         [ 0.0134],\n",
      "         [ 0.1406]],\n",
      "\n",
      "        [[ 0.5039],\n",
      "         [-0.3086],\n",
      "         [-0.3613],\n",
      "         [ 0.3242],\n",
      "         [ 0.3066],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[ 0.5938],\n",
      "         [-0.5781],\n",
      "         [-0.5898],\n",
      "         [ 0.6484],\n",
      "         [ 0.4004],\n",
      "         [ 0.1064]],\n",
      "\n",
      "        [[-0.5273],\n",
      "         [ 0.4551],\n",
      "         [ 0.2871],\n",
      "         [ 0.1309],\n",
      "         [-0.0168],\n",
      "         [ 0.1846]],\n",
      "\n",
      "        [[ 0.4277],\n",
      "         [ 0.3047],\n",
      "         [-0.4473],\n",
      "         [-0.3984],\n",
      "         [ 0.3398],\n",
      "         [ 0.2715]],\n",
      "\n",
      "        [[ 0.5234],\n",
      "         [ 0.0654],\n",
      "         [ 0.0393],\n",
      "         [ 0.1631],\n",
      "         [ 0.1064],\n",
      "         [ 0.0437]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0471],\n",
      "         [ 0.0132],\n",
      "         [-0.0620],\n",
      "         [-0.0125],\n",
      "         [ 0.1533]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0503],\n",
      "         [-0.0767],\n",
      "         [-0.1133],\n",
      "         [-0.0232],\n",
      "         [ 0.2480]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0757],\n",
      "         [ 0.0737],\n",
      "         [ 0.2578],\n",
      "         [ 0.1050],\n",
      "         [ 0.1270]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0435],\n",
      "         [-0.0471],\n",
      "         [-0.0197],\n",
      "         [ 0.1777],\n",
      "         [ 0.1758]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0432],\n",
      "         [-0.0128],\n",
      "         [ 0.0308],\n",
      "         [ 0.3066],\n",
      "         [ 0.3555]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0359],\n",
      "         [ 0.1147],\n",
      "         [ 0.3066],\n",
      "         [ 0.1631],\n",
      "         [ 0.1299]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0471],\n",
      "         [ 0.0132],\n",
      "         [-0.0515],\n",
      "         [ 0.0396],\n",
      "         [ 0.1465]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6484],\n",
      "         [-0.0640],\n",
      "         [ 0.1836],\n",
      "         [ 0.1914],\n",
      "         [-0.0598]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.1520e-03],\n",
      "         [1.8082e-03, 1.0000e+00],\n",
      "         [7.7820e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [1.0000e+00, 7.6675e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.6757e-04, 1.0000e+00],\n",
      "         [6.7902e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 4.9133e-03],\n",
      "         [1.0000e+00, 6.2561e-04],\n",
      "         [3.4180e-01, 6.6016e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.2043e-04],\n",
      "         [1.0000e+00, 1.3046e-03],\n",
      "         [4.5508e-01, 5.4688e-01],\n",
      "         [7.4463e-03, 9.9219e-01],\n",
      "         [4.7656e-01, 5.2344e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.2561e-04, 1.0000e+00],\n",
      "         [6.0654e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.0142e-03],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [5.1953e-01, 4.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.2665e-03, 1.0000e+00],\n",
      "         [6.1798e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.1090e-04],\n",
      "         [1.0000e+00, 6.6757e-04],\n",
      "         [6.7188e-01, 3.2617e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2436e-03],\n",
      "         [9.9609e-01, 3.3722e-03],\n",
      "         [4.7266e-01, 5.2734e-01],\n",
      "         [2.4414e-03, 9.9609e-01],\n",
      "         [3.1445e-01, 6.8359e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.1520e-03],\n",
      "         [1.8082e-03, 1.0000e+00],\n",
      "         [2.0142e-03, 9.9609e-01],\n",
      "         [1.0000e+00, 8.6975e-04],\n",
      "         [1.0000e+00, 3.3569e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.3750e-01, 6.1035e-02],\n",
      "         [1.0205e-01, 8.9844e-01],\n",
      "         [5.1953e-01, 4.8047e-01],\n",
      "         [8.3984e-01, 1.5918e-01],\n",
      "         [6.4062e-01, 3.6133e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 1200 to ./videos/variable_turn_tictactoe_muzero/0/episode_001200.mp4\n",
      "Started recording episode 1200 to ./videos/variable_turn_tictactoe_muzero/1/episode_001200.mp4\n",
      "Stopped recording episode 1200. Recorded 7 frames.\n",
      "Stopped recording episode 1200. Recorded 9 frames.\n",
      "Started recording episode 1200 to ./videos/variable_turn_tictactoe_muzero/3/episode_001200.mp4\n",
      "learning\n",
      "2400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[5, 0, 0, 6, 0],\n",
      "        [0, 0, 7, 6, 0],\n",
      "        [1, 3, 4, 0, 0],\n",
      "        [2, 0, 7, 6, 0],\n",
      "        [1, 2, 4, 3, 0],\n",
      "        [1, 3, 5, 2, 0],\n",
      "        [0, 6, 4, 2, 5],\n",
      "        [2, 5, 7, 4, 0]])\n",
      "target value tensor([[-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703]])\n",
      "predicted values tensor([[[ 0.0036],\n",
      "         [ 0.5977],\n",
      "         [ 0.0576],\n",
      "         [-0.0398],\n",
      "         [ 0.0613],\n",
      "         [ 0.0209]],\n",
      "\n",
      "        [[ 0.2324],\n",
      "         [ 0.1670],\n",
      "         [-0.0093],\n",
      "         [-0.0610],\n",
      "         [ 0.0138],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[-0.2012],\n",
      "         [ 0.3359],\n",
      "         [ 0.3418],\n",
      "         [ 0.0359],\n",
      "         [ 0.0112],\n",
      "         [ 0.0742]],\n",
      "\n",
      "        [[ 0.6016],\n",
      "         [ 0.1011],\n",
      "         [ 0.0898],\n",
      "         [ 0.1689],\n",
      "         [ 0.0437],\n",
      "         [ 0.0113]],\n",
      "\n",
      "        [[ 0.4199],\n",
      "         [ 0.3926],\n",
      "         [-0.3750],\n",
      "         [-0.3105],\n",
      "         [ 0.3652],\n",
      "         [ 0.2100]],\n",
      "\n",
      "        [[-0.5547],\n",
      "         [-0.5469],\n",
      "         [ 0.5703],\n",
      "         [ 0.4258],\n",
      "         [ 0.0532],\n",
      "         [ 0.0283]],\n",
      "\n",
      "        [[ 0.4199],\n",
      "         [ 0.4004],\n",
      "         [-0.3359],\n",
      "         [-0.3242],\n",
      "         [ 0.1982],\n",
      "         [ 0.2793]],\n",
      "\n",
      "        [[ 0.4199],\n",
      "         [ 0.4531],\n",
      "         [-0.4395],\n",
      "         [-0.3594],\n",
      "         [ 0.3867],\n",
      "         [ 0.1631]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.2471],\n",
      "         [ 0.4941],\n",
      "         [-0.0540],\n",
      "         [-0.0055],\n",
      "         [-0.0537]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3887],\n",
      "         [ 0.0288],\n",
      "         [ 0.0496],\n",
      "         [ 0.1494],\n",
      "         [-0.0850]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0374],\n",
      "         [ 0.0087],\n",
      "         [ 0.4062],\n",
      "         [-0.0188],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6484],\n",
      "         [ 0.0098],\n",
      "         [ 0.2109],\n",
      "         [ 0.2871],\n",
      "         [-0.0282]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0525],\n",
      "         [-0.0097],\n",
      "         [ 0.0564],\n",
      "         [-0.0183],\n",
      "         [ 0.0576]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0007],\n",
      "         [ 0.0031],\n",
      "         [ 0.1895],\n",
      "         [ 0.5508],\n",
      "         [-0.0251]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0221],\n",
      "         [-0.0864],\n",
      "         [-0.0089],\n",
      "         [ 0.0562],\n",
      "         [ 0.1011]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0119],\n",
      "         [ 0.0200],\n",
      "         [-0.0378],\n",
      "         [-0.0388],\n",
      "         [ 0.0664]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [8.0469e-01, 1.9434e-01],\n",
      "         [9.9609e-01, 5.2185e-03],\n",
      "         [2.5977e-01, 7.3828e-01],\n",
      "         [1.2329e-02, 9.8828e-01],\n",
      "         [3.9453e-01, 6.0547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.3906e-01, 4.5898e-01],\n",
      "         [8.0469e-01, 1.9336e-01],\n",
      "         [4.9414e-01, 5.0781e-01],\n",
      "         [2.0508e-01, 7.9688e-01],\n",
      "         [2.6367e-01, 7.3828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 9.1171e-04],\n",
      "         [1.0000e+00, 3.6240e-04],\n",
      "         [5.1953e-01, 4.8047e-01],\n",
      "         [1.2512e-02, 9.8828e-01],\n",
      "         [4.4531e-01, 5.5469e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.6484e-01, 5.3516e-01],\n",
      "         [8.9722e-03, 9.9219e-01],\n",
      "         [5.6250e-01, 4.3555e-01],\n",
      "         [8.7891e-01, 1.2158e-01],\n",
      "         [2.6562e-01, 7.3438e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3046e-03],\n",
      "         [1.9073e-04, 1.0000e+00],\n",
      "         [9.6893e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2283e-03],\n",
      "         [1.0000e+00, 1.7014e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.7302e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.4414e-03],\n",
      "         [1.0000e+00, 8.5449e-04],\n",
      "         [6.0938e-01, 3.9258e-01],\n",
      "         [5.3711e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0300e-03],\n",
      "         [7.9346e-04, 1.0000e+00],\n",
      "         [1.7014e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.7548e-03],\n",
      "         [9.9609e-01, 2.1210e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 8.8120e-04],\n",
      "         [5.1880e-04, 1.0000e+00],\n",
      "         [1.6479e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.5488e-03],\n",
      "         [1.0000e+00, 1.1520e-03]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "average score: 0.57\n",
      "Test score {'score': 0.57, 'max_score': 1, 'min_score': -1}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1200 to ./videos/variable_turn_tictactoe_muzero/2/episode_001200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1200. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 3, 4, 0, 5],\n",
      "        [4, 5, 8, 3, 6],\n",
      "        [6, 2, 8, 4, 3],\n",
      "        [5, 2, 0, 6, 5],\n",
      "        [3, 8, 5, 7, 0],\n",
      "        [2, 0, 0, 6, 5],\n",
      "        [2, 5, 3, 4, 8],\n",
      "        [6, 0, 8, 3, 7]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900]])\n",
      "predicted values tensor([[[ 4.3359e-01],\n",
      "         [ 3.4570e-01],\n",
      "         [-4.2969e-01],\n",
      "         [-4.0234e-01],\n",
      "         [ 2.0215e-01],\n",
      "         [ 3.3984e-01]],\n",
      "\n",
      "        [[-2.3047e-01],\n",
      "         [ 7.5378e-03],\n",
      "         [ 2.8711e-01],\n",
      "         [ 2.5146e-02],\n",
      "         [-7.4219e-02],\n",
      "         [ 4.7852e-01]],\n",
      "\n",
      "        [[ 2.1680e-01],\n",
      "         [-3.9648e-01],\n",
      "         [-3.6719e-01],\n",
      "         [ 3.7305e-01],\n",
      "         [ 2.2754e-01],\n",
      "         [ 3.6377e-02]],\n",
      "\n",
      "        [[-5.0391e-01],\n",
      "         [ 5.6641e-01],\n",
      "         [ 4.8047e-01],\n",
      "         [ 4.9591e-04],\n",
      "         [-1.6992e-01],\n",
      "         [ 7.2754e-02]],\n",
      "\n",
      "        [[-6.7969e-01],\n",
      "         [-5.2344e-01],\n",
      "         [ 4.9609e-01],\n",
      "         [ 5.0391e-01],\n",
      "         [-4.3335e-03],\n",
      "         [-3.4912e-02]],\n",
      "\n",
      "        [[ 3.3398e-01],\n",
      "         [-7.4463e-03],\n",
      "         [-1.6016e-01],\n",
      "         [-7.1777e-02],\n",
      "         [ 7.0801e-02],\n",
      "         [-7.0801e-03]],\n",
      "\n",
      "        [[-2.0410e-01],\n",
      "         [-2.2754e-01],\n",
      "         [ 4.6289e-01],\n",
      "         [ 2.7930e-01],\n",
      "         [ 8.7891e-02],\n",
      "         [-7.6660e-02]],\n",
      "\n",
      "        [[-7.8125e-01],\n",
      "         [-5.4688e-01],\n",
      "         [ 3.2031e-01],\n",
      "         [ 2.7734e-01],\n",
      "         [ 8.1543e-02],\n",
      "         [-5.6396e-02]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0557],\n",
      "         [-0.0439],\n",
      "         [-0.0352],\n",
      "         [-0.0302],\n",
      "         [ 0.0806]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1167],\n",
      "         [ 0.0576],\n",
      "         [ 0.3652],\n",
      "         [ 0.0918],\n",
      "         [ 0.3340]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0182],\n",
      "         [-0.0005],\n",
      "         [ 0.0161],\n",
      "         [ 0.1187],\n",
      "         [ 0.3066]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0491],\n",
      "         [ 0.2559],\n",
      "         [ 0.3496],\n",
      "         [ 0.1836],\n",
      "         [ 0.2275]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0237],\n",
      "         [-0.0315],\n",
      "         [ 0.0610],\n",
      "         [ 0.3867],\n",
      "         [ 0.0493]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.5234],\n",
      "         [ 0.0061],\n",
      "         [-0.0192],\n",
      "         [ 0.0481],\n",
      "         [ 0.2656]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0491],\n",
      "         [ 0.0625],\n",
      "         [ 0.0293],\n",
      "         [ 0.4902],\n",
      "         [ 0.1147]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0182],\n",
      "         [ 0.0422],\n",
      "         [ 0.1084],\n",
      "         [ 0.4316],\n",
      "         [ 0.0923]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.7902e-04],\n",
      "         [4.5204e-04, 1.0000e+00],\n",
      "         [1.3657e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 5.9891e-04],\n",
      "         [1.0000e+00, 1.4114e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.6094e-01, 4.0771e-02],\n",
      "         [1.0000e+00, 1.9455e-04],\n",
      "         [3.3008e-01, 6.6797e-01],\n",
      "         [1.7548e-03, 1.0000e+00],\n",
      "         [7.1094e-01, 2.8711e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4523e-04, 1.0000e+00],\n",
      "         [1.7014e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.8215e-04],\n",
      "         [1.0000e+00, 9.3842e-04],\n",
      "         [2.0703e-01, 7.9297e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 9.6893e-04],\n",
      "         [1.0000e+00, 5.6076e-04],\n",
      "         [6.3672e-01, 3.6328e-01],\n",
      "         [7.8125e-03, 9.9219e-01],\n",
      "         [1.0107e-01, 8.9844e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.3242e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.2643e-04],\n",
      "         [1.0000e+00, 3.1090e-04],\n",
      "         [5.2344e-01, 4.7852e-01],\n",
      "         [2.5940e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.9805e-01, 5.0000e-01],\n",
      "         [1.2054e-03, 1.0000e+00],\n",
      "         [7.2656e-01, 2.7539e-01],\n",
      "         [1.0000e+00, 1.8692e-03],\n",
      "         [3.5742e-01, 6.4062e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4343e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 2.2697e-04],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [3.9453e-01, 6.0547e-01],\n",
      "         [1.0834e-03, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4019e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 8.1635e-04],\n",
      "         [1.0000e+00, 6.2561e-04],\n",
      "         [3.5352e-01, 6.4844e-01],\n",
      "         [1.4343e-03, 1.0000e+00]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1300 to ./videos/variable_turn_tictactoe_muzero/3/episode_001300.mp4\n",
      "Started recording episode 1300 to ./videos/variable_turn_tictactoe_muzero/0/episode_001300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1300. Recorded 7 frames.\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Stopped recording episode 1300. Recorded 10 frames.\n",
      "Started recording episode 1300 to ./videos/variable_turn_tictactoe_muzero/1/episode_001300.mp4\n",
      "Stopped recording episode 1300. Recorded 10 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[0, 1, 3, 5, 6],\n",
      "        [6, 0, 0, 7, 0],\n",
      "        [7, 6, 2, 4, 0],\n",
      "        [5, 2, 6, 8, 4],\n",
      "        [8, 2, 6, 5, 1],\n",
      "        [7, 0, 6, 7, 0],\n",
      "        [8, 3, 4, 0, 6],\n",
      "        [0, 0, 6, 7, 0]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2969],\n",
      "         [ 0.3457],\n",
      "         [-0.3633],\n",
      "         [-0.2910],\n",
      "         [ 0.6445],\n",
      "         [ 0.3438]],\n",
      "\n",
      "        [[-0.3906],\n",
      "         [ 0.4375],\n",
      "         [-0.0347],\n",
      "         [-0.0308],\n",
      "         [ 0.0432],\n",
      "         [-0.0199]],\n",
      "\n",
      "        [[-0.1885],\n",
      "         [ 0.4219],\n",
      "         [ 0.3574],\n",
      "         [ 0.0815],\n",
      "         [-0.0544],\n",
      "         [ 0.1206]],\n",
      "\n",
      "        [[ 0.1021],\n",
      "         [-0.3418],\n",
      "         [-0.1904],\n",
      "         [ 0.4199],\n",
      "         [ 0.2197],\n",
      "         [ 0.0977]],\n",
      "\n",
      "        [[-0.6641],\n",
      "         [-0.5781],\n",
      "         [ 0.3457],\n",
      "         [ 0.3145],\n",
      "         [ 0.0815],\n",
      "         [ 0.0028]],\n",
      "\n",
      "        [[ 0.6523],\n",
      "         [ 0.0815],\n",
      "         [-0.0422],\n",
      "         [ 0.0028],\n",
      "         [ 0.2324],\n",
      "         [ 0.0298]],\n",
      "\n",
      "        [[ 0.1021],\n",
      "         [-0.3945],\n",
      "         [-0.2314],\n",
      "         [ 0.4883],\n",
      "         [ 0.2324],\n",
      "         [ 0.0496]],\n",
      "\n",
      "        [[ 0.2246],\n",
      "         [ 0.0977],\n",
      "         [ 0.0131],\n",
      "         [ 0.0496],\n",
      "         [ 0.0767],\n",
      "         [-0.0014]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0219],\n",
      "         [-0.0364],\n",
      "         [-0.0347],\n",
      "         [-0.0491],\n",
      "         [ 0.0396]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1826],\n",
      "         [ 0.5859],\n",
      "         [-0.1201],\n",
      "         [-0.0493],\n",
      "         [-0.1787]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0337],\n",
      "         [ 0.0281],\n",
      "         [ 0.3887],\n",
      "         [ 0.1416],\n",
      "         [ 0.2852]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0442],\n",
      "         [-0.0194],\n",
      "         [-0.0026],\n",
      "         [ 0.1826],\n",
      "         [ 0.3516]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0276],\n",
      "         [-0.0247],\n",
      "         [ 0.0525],\n",
      "         [ 0.3574],\n",
      "         [ 0.0442]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.5195],\n",
      "         [-0.0615],\n",
      "         [ 0.0942],\n",
      "         [ 0.0253],\n",
      "         [-0.0396]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0220],\n",
      "         [-0.0152],\n",
      "         [-0.0593],\n",
      "         [ 0.0554],\n",
      "         [ 0.4258]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2139],\n",
      "         [-0.0215],\n",
      "         [ 0.1357],\n",
      "         [ 0.0265],\n",
      "         [-0.1660]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 1.9836e-03],\n",
      "         [4.8828e-04, 1.0000e+00],\n",
      "         [1.3885e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3542e-04],\n",
      "         [1.0000e+00, 2.8610e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.9766e-01, 4.0039e-01],\n",
      "         [9.6875e-01, 2.9785e-02],\n",
      "         [2.4902e-01, 7.5000e-01],\n",
      "         [5.1514e-02, 9.4922e-01],\n",
      "         [5.7422e-01, 4.2383e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.8828e-01, 1.3550e-02],\n",
      "         [1.0000e+00, 5.5313e-04],\n",
      "         [5.0391e-01, 4.9609e-01],\n",
      "         [2.8076e-03, 9.9609e-01],\n",
      "         [5.5859e-01, 4.3945e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.6675e-04, 1.0000e+00],\n",
      "         [5.9204e-03, 9.9219e-01],\n",
      "         [1.0000e+00, 4.1246e-05],\n",
      "         [9.9609e-01, 5.0659e-03],\n",
      "         [2.6172e-01, 7.3828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.9073e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.6076e-04],\n",
      "         [1.0000e+00, 2.5368e-04],\n",
      "         [3.3008e-01, 6.7188e-01],\n",
      "         [1.5717e-03, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.5312e-01, 4.7363e-02],\n",
      "         [8.0566e-03, 9.9219e-01],\n",
      "         [2.5391e-01, 7.4609e-01],\n",
      "         [9.9609e-01, 3.7689e-03],\n",
      "         [4.9414e-01, 5.0391e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.0654e-04, 1.0000e+00],\n",
      "         [1.1902e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 6.6757e-04],\n",
      "         [1.0000e+00, 1.3657e-03],\n",
      "         [5.0781e-01, 4.9414e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.6328e-01, 6.3672e-01],\n",
      "         [6.8750e-01, 3.1055e-01],\n",
      "         [8.3203e-01, 1.6797e-01],\n",
      "         [5.1562e-01, 4.8633e-01],\n",
      "         [4.5898e-01, 5.3906e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1300 to ./videos/variable_turn_tictactoe_muzero/2/episode_001300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1300. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2700\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 3, 4, 0, 2],\n",
      "        [1, 0, 2, 8, 7],\n",
      "        [7, 4, 0, 8, 7],\n",
      "        [6, 0, 2, 8, 7],\n",
      "        [4, 1, 8, 0, 6],\n",
      "        [1, 0, 2, 8, 7],\n",
      "        [4, 0, 2, 8, 7],\n",
      "        [5, 3, 0, 4, 6]])\n",
      "target value tensor([[-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801]])\n",
      "predicted values tensor([[[ 0.2539],\n",
      "         [-0.2158],\n",
      "         [-0.3477],\n",
      "         [ 0.2539],\n",
      "         [ 0.1416],\n",
      "         [ 0.0503]],\n",
      "\n",
      "        [[ 0.6133],\n",
      "         [ 0.1050],\n",
      "         [-0.0474],\n",
      "         [ 0.0698],\n",
      "         [ 0.0359],\n",
      "         [ 0.0167]],\n",
      "\n",
      "        [[ 0.3027],\n",
      "         [ 0.2891],\n",
      "         [ 0.0447],\n",
      "         [ 0.1328],\n",
      "         [ 0.2930],\n",
      "         [ 0.1514]],\n",
      "\n",
      "        [[ 0.6602],\n",
      "         [ 0.0459],\n",
      "         [-0.0342],\n",
      "         [ 0.0088],\n",
      "         [ 0.1094],\n",
      "         [ 0.0121]],\n",
      "\n",
      "        [[ 0.3281],\n",
      "         [-0.2695],\n",
      "         [-0.4629],\n",
      "         [ 0.3984],\n",
      "         [ 0.2988],\n",
      "         [ 0.0649]],\n",
      "\n",
      "        [[ 0.0425],\n",
      "         [ 0.2949],\n",
      "         [ 0.0289],\n",
      "         [ 0.0383],\n",
      "         [ 0.0820],\n",
      "         [ 0.1758]],\n",
      "\n",
      "        [[ 0.3047],\n",
      "         [ 0.0820],\n",
      "         [ 0.0115],\n",
      "         [-0.0339],\n",
      "         [ 0.0981],\n",
      "         [ 0.0278]],\n",
      "\n",
      "        [[ 0.4258],\n",
      "         [ 0.3848],\n",
      "         [-0.4141],\n",
      "         [-0.3398],\n",
      "         [ 0.2402],\n",
      "         [ 0.1855]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0023],\n",
      "         [-0.0056],\n",
      "         [-0.0569],\n",
      "         [ 0.0894],\n",
      "         [ 0.3906]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3770],\n",
      "         [ 0.0035],\n",
      "         [ 0.2598],\n",
      "         [ 0.3457],\n",
      "         [ 0.2617]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0554],\n",
      "         [ 0.3145],\n",
      "         [ 0.0015],\n",
      "         [ 0.4102],\n",
      "         [ 0.2891]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6055],\n",
      "         [ 0.1113],\n",
      "         [ 0.3379],\n",
      "         [ 0.4492],\n",
      "         [ 0.2734]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0315],\n",
      "         [-0.0096],\n",
      "         [-0.0117],\n",
      "         [ 0.0986],\n",
      "         [ 0.4082]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2324],\n",
      "         [ 0.1553],\n",
      "         [ 0.2402],\n",
      "         [ 0.1836],\n",
      "         [ 0.2002]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.7031],\n",
      "         [ 0.0474],\n",
      "         [ 0.1504],\n",
      "         [ 0.3223],\n",
      "         [ 0.2773]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0850],\n",
      "         [-0.0232],\n",
      "         [-0.0253],\n",
      "         [ 0.0244],\n",
      "         [ 0.1807]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.2125e-03, 9.9609e-01],\n",
      "         [3.7384e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3657e-03],\n",
      "         [9.9609e-01, 3.0823e-03],\n",
      "         [3.5547e-01, 6.4453e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.5000e-01, 2.4902e-01],\n",
      "         [3.6469e-03, 9.9609e-01],\n",
      "         [4.4336e-01, 5.5469e-01],\n",
      "         [9.6484e-01, 3.4424e-02],\n",
      "         [6.5625e-01, 3.4375e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 8.9645e-04],\n",
      "         [3.4570e-01, 6.5234e-01],\n",
      "         [1.1841e-02, 9.8828e-01],\n",
      "         [6.1719e-01, 3.8281e-01],\n",
      "         [9.6094e-01, 3.8818e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.2109e-01, 3.7891e-01],\n",
      "         [5.3101e-03, 9.9609e-01],\n",
      "         [3.4570e-01, 6.5234e-01],\n",
      "         [9.8828e-01, 1.2146e-02],\n",
      "         [8.3594e-01, 1.6309e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.1520e-03, 1.0000e+00],\n",
      "         [5.8746e-04, 1.0000e+00],\n",
      "         [9.9219e-01, 6.8054e-03],\n",
      "         [1.0000e+00, 2.8229e-04],\n",
      "         [5.1562e-01, 4.8633e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.1953e-01, 4.8047e-01],\n",
      "         [9.3750e-01, 6.3477e-02],\n",
      "         [7.1875e-01, 2.7930e-01],\n",
      "         [2.8320e-01, 7.1875e-01],\n",
      "         [6.2500e-01, 3.7695e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.6484e-01, 3.4180e-02],\n",
      "         [1.6357e-02, 9.8438e-01],\n",
      "         [5.2979e-02, 9.4531e-01],\n",
      "         [9.2969e-01, 6.9336e-02],\n",
      "         [9.6484e-01, 3.5156e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.8229e-04],\n",
      "         [7.6675e-04, 1.0000e+00],\n",
      "         [1.2283e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 8.8120e-04],\n",
      "         [1.0000e+00, 6.4468e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1400 to ./videos/variable_turn_tictactoe_muzero/3/episode_001400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1400. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1400 to ./videos/variable_turn_tictactoe_muzero/0/episode_001400.mp4\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1400 to ./videos/variable_turn_tictactoe_muzero/1/episode_001400.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1400. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1400. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 1400 to ./videos/variable_turn_tictactoe_muzero/2/episode_001400.mp4\n",
      "learning\n",
      "2800\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 3, 5, 4, 7],\n",
      "        [7, 0, 8, 6, 5],\n",
      "        [1, 6, 3, 2, 0],\n",
      "        [8, 0, 8, 6, 5],\n",
      "        [8, 0, 4, 6, 3],\n",
      "        [2, 0, 8, 3, 1],\n",
      "        [5, 0, 7, 6, 4],\n",
      "        [2, 6, 0, 0, 5]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.2432],\n",
      "         [-0.2207],\n",
      "         [ 0.4902],\n",
      "         [ 0.2910],\n",
      "         [ 0.0791],\n",
      "         [ 0.0723]],\n",
      "\n",
      "        [[ 0.3184],\n",
      "         [ 0.2910],\n",
      "         [ 0.0732],\n",
      "         [ 0.0310],\n",
      "         [ 0.2002],\n",
      "         [ 0.1152]],\n",
      "\n",
      "        [[-0.3711],\n",
      "         [ 0.4004],\n",
      "         [ 0.3652],\n",
      "         [ 0.0195],\n",
      "         [ 0.0593],\n",
      "         [ 0.1523]],\n",
      "\n",
      "        [[ 0.6094],\n",
      "         [ 0.4180],\n",
      "         [ 0.0898],\n",
      "         [-0.0737],\n",
      "         [ 0.3789],\n",
      "         [ 0.1768]],\n",
      "\n",
      "        [[ 0.3965],\n",
      "         [-0.2373],\n",
      "         [-0.3164],\n",
      "         [ 0.3008],\n",
      "         [ 0.2910],\n",
      "         [ 0.0452]],\n",
      "\n",
      "        [[-0.3730],\n",
      "         [-0.4141],\n",
      "         [ 0.4238],\n",
      "         [ 0.3516],\n",
      "         [ 0.0674],\n",
      "         [ 0.1787]],\n",
      "\n",
      "        [[ 0.4473],\n",
      "         [-0.2559],\n",
      "         [-0.2676],\n",
      "         [ 0.4062],\n",
      "         [ 0.2148],\n",
      "         [ 0.0732]],\n",
      "\n",
      "        [[ 0.8008],\n",
      "         [-0.0072],\n",
      "         [-0.0903],\n",
      "         [ 0.2295],\n",
      "         [ 0.0693],\n",
      "         [ 0.0139]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 2.8564e-02],\n",
      "         [ 5.3467e-02],\n",
      "         [ 1.5723e-01],\n",
      "         [ 4.9023e-01],\n",
      "         [ 5.9082e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.2891e-01],\n",
      "         [ 1.5625e-01],\n",
      "         [ 1.7188e-01],\n",
      "         [ 4.4727e-01],\n",
      "         [ 3.0664e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.1729e-02],\n",
      "         [ 1.4746e-01],\n",
      "         [ 4.1016e-01],\n",
      "         [ 1.6699e-01],\n",
      "         [ 3.6328e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.3730e-02],\n",
      "         [ 1.9434e-01],\n",
      "         [ 1.1523e-01],\n",
      "         [ 1.9141e-01],\n",
      "         [ 2.3633e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.0294e-03],\n",
      "         [ 1.6724e-02],\n",
      "         [ 6.3477e-02],\n",
      "         [ 2.1484e-01],\n",
      "         [ 4.6680e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.7607e-02],\n",
      "         [ 3.4027e-03],\n",
      "         [ 2.3535e-01],\n",
      "         [ 4.2188e-01],\n",
      "         [ 2.0703e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-8.7738e-05],\n",
      "         [-4.8828e-02],\n",
      "         [-5.2002e-02],\n",
      "         [ 2.0312e-01],\n",
      "         [ 4.8828e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 3.7109e-01],\n",
      "         [ 6.0547e-02],\n",
      "         [ 2.6758e-01],\n",
      "         [-2.7710e-02],\n",
      "         [ 2.5586e-01]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.8501e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2436e-03],\n",
      "         [1.0000e+00, 1.9073e-04],\n",
      "         [4.5703e-01, 5.4297e-01],\n",
      "         [9.7046e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 6.5918e-03],\n",
      "         [1.6797e-01, 8.3203e-01],\n",
      "         [3.3264e-03, 9.9609e-01],\n",
      "         [4.2969e-01, 5.7031e-01],\n",
      "         [9.1016e-01, 8.8867e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.7956e-04],\n",
      "         [1.0000e+00, 1.7014e-03],\n",
      "         [4.0430e-01, 5.9766e-01],\n",
      "         [3.6469e-03, 9.9609e-01],\n",
      "         [4.1992e-01, 5.7812e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.6131e-04],\n",
      "         [2.7734e-01, 7.2266e-01],\n",
      "         [1.9531e-03, 9.9609e-01],\n",
      "         [8.2812e-01, 1.7090e-01],\n",
      "         [9.9609e-01, 4.7607e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0681e-03, 1.0000e+00],\n",
      "         [2.8610e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0681e-03],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [3.4375e-01, 6.5625e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.1648e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.2643e-04],\n",
      "         [1.0000e+00, 2.0027e-04],\n",
      "         [4.1211e-01, 5.8594e-01],\n",
      "         [3.6011e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.2643e-04, 1.0000e+00],\n",
      "         [2.9182e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.7929e-04],\n",
      "         [1.0000e+00, 5.2643e-04],\n",
      "         [4.1602e-01, 5.8594e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.0820e-01, 5.8984e-01],\n",
      "         [3.1281e-03, 9.9609e-01],\n",
      "         [6.8750e-01, 3.1055e-01],\n",
      "         [8.5547e-01, 1.4453e-01],\n",
      "         [4.0430e-01, 5.9766e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "Stopped recording episode 1400. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "2900\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[0, 7, 8, 1, 6],\n",
      "        [4, 0, 7, 1, 2],\n",
      "        [2, 7, 4, 8, 3],\n",
      "        [4, 7, 3, 5, 0],\n",
      "        [0, 7, 1, 6, 2],\n",
      "        [5, 3, 8, 0, 6],\n",
      "        [3, 8, 2, 4, 0],\n",
      "        [1, 5, 3, 0, 2]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.1758],\n",
      "         [ 0.3242],\n",
      "         [ 0.0227],\n",
      "         [-0.1260],\n",
      "         [ 0.5430],\n",
      "         [ 0.0211]],\n",
      "\n",
      "        [[ 0.4297],\n",
      "         [ 0.1885],\n",
      "         [ 0.0815],\n",
      "         [ 0.2617],\n",
      "         [ 0.1904],\n",
      "         [ 0.1084]],\n",
      "\n",
      "        [[ 0.2734],\n",
      "         [-0.4355],\n",
      "         [-0.3652],\n",
      "         [ 0.3418],\n",
      "         [ 0.1846],\n",
      "         [-0.0201]],\n",
      "\n",
      "        [[ 0.3203],\n",
      "         [-0.6562],\n",
      "         [-0.6094],\n",
      "         [ 0.7461],\n",
      "         [ 0.4219],\n",
      "         [ 0.0913]],\n",
      "\n",
      "        [[ 0.4375],\n",
      "         [-0.6992],\n",
      "         [-0.5352],\n",
      "         [ 0.6406],\n",
      "         [ 0.3887],\n",
      "         [ 0.0732]],\n",
      "\n",
      "        [[ 0.4375],\n",
      "         [-0.5078],\n",
      "         [-0.4355],\n",
      "         [ 0.5859],\n",
      "         [ 0.1992],\n",
      "         [ 0.0157]],\n",
      "\n",
      "        [[-0.5820],\n",
      "         [-0.4746],\n",
      "         [ 0.5234],\n",
      "         [ 0.2949],\n",
      "         [ 0.0728],\n",
      "         [ 0.0309]],\n",
      "\n",
      "        [[-0.1084],\n",
      "         [ 0.2344],\n",
      "         [ 0.3418],\n",
      "         [ 0.0986],\n",
      "         [ 0.0026],\n",
      "         [ 0.0039]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0586],\n",
      "         [ 0.2461],\n",
      "         [ 0.1768],\n",
      "         [ 0.2969],\n",
      "         [ 0.7422]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.7031],\n",
      "         [ 0.0461],\n",
      "         [ 0.0903],\n",
      "         [ 0.2891],\n",
      "         [ 0.3848]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0432],\n",
      "         [-0.0092],\n",
      "         [ 0.1118],\n",
      "         [ 0.3770],\n",
      "         [ 0.2314]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0306],\n",
      "         [ 0.0022],\n",
      "         [-0.0442],\n",
      "         [ 0.3008],\n",
      "         [ 0.2373]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0762],\n",
      "         [ 0.0967],\n",
      "         [ 0.0352],\n",
      "         [ 0.2949],\n",
      "         [ 0.5703]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0349],\n",
      "         [ 0.1035],\n",
      "         [ 0.0659],\n",
      "         [ 0.0962],\n",
      "         [ 0.5391]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0352],\n",
      "         [ 0.0444],\n",
      "         [ 0.3203],\n",
      "         [ 0.7461],\n",
      "         [-0.0076]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2119],\n",
      "         [ 0.4355],\n",
      "         [ 0.5234],\n",
      "         [ 0.0028],\n",
      "         [ 0.1699]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.4142e-04],\n",
      "         [2.1582e-01, 7.8516e-01],\n",
      "         [1.7014e-03, 1.0000e+00],\n",
      "         [6.7578e-01, 3.2617e-01],\n",
      "         [9.9609e-01, 2.8839e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.9453e-01, 1.0498e-01],\n",
      "         [9.0820e-02, 9.1016e-01],\n",
      "         [2.0215e-01, 7.9688e-01],\n",
      "         [8.4766e-01, 1.5039e-01],\n",
      "         [9.2188e-01, 7.7637e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.3406e-04, 1.0000e+00],\n",
      "         [3.7956e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.6479e-03],\n",
      "         [1.0000e+00, 1.3885e-03],\n",
      "         [3.0664e-01, 6.9141e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.1587e-04, 1.0000e+00],\n",
      "         [5.1880e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.7956e-04],\n",
      "         [1.0000e+00, 7.4387e-04],\n",
      "         [3.3984e-01, 6.6016e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.5613e-04, 1.0000e+00],\n",
      "         [3.3264e-03, 9.9609e-01],\n",
      "         [1.0000e+00, 5.8746e-04],\n",
      "         [1.0000e+00, 4.3678e-04],\n",
      "         [7.2266e-01, 2.7734e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.6893e-04, 1.0000e+00],\n",
      "         [2.0142e-03, 9.9609e-01],\n",
      "         [9.9609e-01, 2.4414e-03],\n",
      "         [1.0000e+00, 1.8692e-03],\n",
      "         [4.2383e-01, 5.7812e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.5449e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3161e-04],\n",
      "         [1.0000e+00, 1.2302e-04],\n",
      "         [8.1641e-01, 1.8262e-01],\n",
      "         [1.5198e-02, 9.8438e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.4463e-03, 9.9219e-01],\n",
      "         [4.2188e-01, 5.7812e-01],\n",
      "         [9.9219e-01, 6.1035e-03],\n",
      "         [5.1953e-01, 4.7852e-01],\n",
      "         [2.5977e-01, 7.3828e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1500 to ./videos/variable_turn_tictactoe_muzero/3/episode_001500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1500. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1500 to ./videos/variable_turn_tictactoe_muzero/0/episode_001500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1500. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1500 to ./videos/variable_turn_tictactoe_muzero/1/episode_001500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1500. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1500 to ./videos/variable_turn_tictactoe_muzero/2/episode_001500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1500. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3000\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 8, 5, 7, 2],\n",
      "        [0, 8, 5, 2, 3],\n",
      "        [5, 1, 8, 7, 0],\n",
      "        [7, 8, 4, 3, 1],\n",
      "        [6, 1, 2, 7, 0],\n",
      "        [4, 2, 0, 6, 0],\n",
      "        [8, 6, 0, 6, 0],\n",
      "        [6, 4, 0, 5, 8]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[-0.3398],\n",
      "         [ 0.3652],\n",
      "         [ 0.2637],\n",
      "         [ 0.0238],\n",
      "         [-0.0054],\n",
      "         [ 0.5664]],\n",
      "\n",
      "        [[-0.6094],\n",
      "         [ 0.5117],\n",
      "         [ 0.3691],\n",
      "         [ 0.0703],\n",
      "         [ 0.1436],\n",
      "         [ 0.4941]],\n",
      "\n",
      "        [[-0.4961],\n",
      "         [ 0.5742],\n",
      "         [ 0.3809],\n",
      "         [ 0.1216],\n",
      "         [-0.0157],\n",
      "         [ 0.4922]],\n",
      "\n",
      "        [[ 0.3477],\n",
      "         [-0.1865],\n",
      "         [-0.1357],\n",
      "         [ 0.2578],\n",
      "         [ 0.1235],\n",
      "         [-0.0347]],\n",
      "\n",
      "        [[-0.4531],\n",
      "         [ 0.4512],\n",
      "         [ 0.2754],\n",
      "         [ 0.1328],\n",
      "         [-0.0072],\n",
      "         [ 0.3145]],\n",
      "\n",
      "        [[ 0.1660],\n",
      "         [ 0.3691],\n",
      "         [ 0.1270],\n",
      "         [ 0.0131],\n",
      "         [ 0.0310],\n",
      "         [ 0.0889]],\n",
      "\n",
      "        [[ 0.6211],\n",
      "         [ 0.4746],\n",
      "         [ 0.1167],\n",
      "         [-0.0073],\n",
      "         [-0.0119],\n",
      "         [ 0.1016]],\n",
      "\n",
      "        [[ 0.3926],\n",
      "         [ 0.2969],\n",
      "         [-0.3906],\n",
      "         [-0.5195],\n",
      "         [ 0.5039],\n",
      "         [ 0.4160]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0549],\n",
      "         [ 0.1455],\n",
      "         [ 0.4023],\n",
      "         [ 0.0278],\n",
      "         [ 0.2773]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0315],\n",
      "         [ 0.0996],\n",
      "         [ 0.3184],\n",
      "         [ 0.2305],\n",
      "         [ 0.4629]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0439],\n",
      "         [ 0.0728],\n",
      "         [ 0.4707],\n",
      "         [-0.0286],\n",
      "         [ 0.2139]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0089],\n",
      "         [ 0.0109],\n",
      "         [-0.0210],\n",
      "         [ 0.2305],\n",
      "         [ 0.1235]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0344],\n",
      "         [-0.0183],\n",
      "         [ 0.5469],\n",
      "         [ 0.0200],\n",
      "         [ 0.3945]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2383],\n",
      "         [ 0.8477],\n",
      "         [ 0.0195],\n",
      "         [ 0.3223],\n",
      "         [-0.0981]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3066],\n",
      "         [ 0.6875],\n",
      "         [ 0.0062],\n",
      "         [ 0.1865],\n",
      "         [-0.0092]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0352],\n",
      "         [ 0.0068],\n",
      "         [-0.0320],\n",
      "         [-0.0062],\n",
      "         [ 0.0459]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [1.0000e+00, 6.0654e-04],\n",
      "         [4.1602e-01, 5.8594e-01],\n",
      "         [4.3335e-03, 9.9609e-01],\n",
      "         [7.5781e-01, 2.4121e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.5204e-04],\n",
      "         [1.0000e+00, 2.0027e-04],\n",
      "         [3.2422e-01, 6.7578e-01],\n",
      "         [4.6692e-03, 9.9609e-01],\n",
      "         [7.4219e-01, 2.5586e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.4128e-04],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [4.8633e-01, 5.1562e-01],\n",
      "         [4.1199e-03, 9.9609e-01],\n",
      "         [7.3047e-01, 2.6953e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.4556e-03, 9.9609e-01],\n",
      "         [1.0925e-02, 9.8828e-01],\n",
      "         [1.0000e+00, 1.4114e-03],\n",
      "         [9.9219e-01, 7.3547e-03],\n",
      "         [1.8457e-01, 8.1641e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.8828e-04],\n",
      "         [1.0000e+00, 1.0147e-03],\n",
      "         [4.7070e-01, 5.3125e-01],\n",
      "         [2.8381e-03, 9.9609e-01],\n",
      "         [5.1172e-01, 4.8828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0986e-03],\n",
      "         [7.9688e-01, 2.0117e-01],\n",
      "         [1.7212e-02, 9.8438e-01],\n",
      "         [5.0000e-01, 5.0000e-01],\n",
      "         [9.8438e-01, 1.6968e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0834e-03],\n",
      "         [7.6562e-01, 2.3535e-01],\n",
      "         [6.0120e-03, 9.9219e-01],\n",
      "         [4.4336e-01, 5.5469e-01],\n",
      "         [9.9609e-01, 3.9978e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.4387e-04],\n",
      "         [8.9645e-04, 1.0000e+00],\n",
      "         [6.2561e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 9.2983e-05],\n",
      "         [1.0000e+00, 1.7357e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "learning\n",
      "Testing Player 0 vs Agent random\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.2800, 0.0400, 0.2000, 0.0400, 0.1200, 0.0400, 0.2000]), tensor([0.0400, 0.0400, 0.2800, 0.0400, 0.2000, 0.0400, 0.1200, 0.0400, 0.2000]), 0.3667195898789626, tensor(2), {'network_policy': tensor([0.0747, 0.0708, 0.1118, 0.0830, 0.2227, 0.0933, 0.1543, 0.0791, 0.1099],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.3359375, 'search_policy': tensor([0.0400, 0.0400, 0.2800, 0.0400, 0.2000, 0.0400, 0.1200, 0.0400, 0.2000]), 'search_value': 0.3667195898789626, 'root_children_values': tensor([0.2754, 0.2520, 0.4788, 0.1357, 0.4679, 0.2910, 0.3641, 0.2832, 0.4083])})\n",
      "action: 2\n",
      "Player 0 prediction: (tensor([0.0800, 0.0400, 0.0000, 0.0800, 0.2800, 0.0800, 0.0800, 0.0400, 0.3200]), tensor([0.0800, 0.0400, 0.0000, 0.0800, 0.2800, 0.0800, 0.0800, 0.0400, 0.3200]), 0.5053233334467961, tensor(8), {'network_policy': tensor([0.0996, 0.0898, 0.0000, 0.0986, 0.2314, 0.1167, 0.1348, 0.1011, 0.1279],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.412109375, 'search_policy': tensor([0.0800, 0.0400, 0.0000, 0.0800, 0.2800, 0.0800, 0.0800, 0.0400, 0.3200]), 'search_value': 0.5053233334467961, 'root_children_values': tensor([-0.4922, -0.3848,  0.0000, -0.4727, -0.5521, -0.4531, -0.4356, -0.4277,\n",
      "        -0.5208])})\n",
      "action: 8\n",
      "Player 1 random action: 4\n",
      "Player 1 random action: 5\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.1200, 0.1200, 0.0000, 0.1200, 0.0000, 0.0000, 0.3600, 0.2800, 0.0000]), tensor([0.1200, 0.1200, 0.0000, 0.1200, 0.0000, 0.0000, 0.3600, 0.2800, 0.0000]), 0.5034542587597188, tensor(6), {'network_policy': tensor([0.1836, 0.1396, 0.0000, 0.1816, 0.0000, 0.0000, 0.2949, 0.1982, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.337890625, 'search_policy': tensor([0.1200, 0.1200, 0.0000, 0.1200, 0.0000, 0.0000, 0.3600, 0.2800, 0.0000]), 'search_value': 0.5034542587597188, 'root_children_values': tensor([0.2463, 0.2393, 0.0000, 0.2966, 0.0000, 0.0000, 0.1892, 0.3833, 0.0000])})\n",
      "action: 6\n",
      "Player 0 prediction: (tensor([0.2400, 0.1600, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000]), tensor([0.2400, 0.1600, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000]), 0.1803032296550105, tensor(7), {'network_policy': tensor([0.2520, 0.1650, 0.0000, 0.2490, 0.0000, 0.0000, 0.0000, 0.3281, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.412109375, 'search_policy': tensor([0.2400, 0.1600, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000]), 'search_value': 0.1803032296550105, 'root_children_values': tensor([0.2253, 0.0361, 0.0000, 0.1671, 0.0000, 0.0000, 0.0000, 0.2689, 0.0000])})\n",
      "action: 7\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Player 0 win percentage vs random: 94.0 and average score: 0.9\n",
      "Testing Player 1 vs Agent random\n",
      "Player 0 random action: 1\n",
      "Player 0 random action: 3\n",
      "Player 1 prediction: (tensor([0.1200, 0.0000, 0.0800, 0.0000, 0.1600, 0.0800, 0.1200, 0.3200, 0.1200]), tensor([0.1200, 0.0000, 0.0800, 0.0000, 0.1600, 0.0800, 0.1200, 0.3200, 0.1200]), -0.2453448766573392, tensor(7), {'network_policy': tensor([0.1035, 0.0000, 0.1328, 0.0000, 0.1865, 0.1357, 0.1357, 0.1562, 0.1475],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.30859375, 'search_policy': tensor([0.1200, 0.0000, 0.0800, 0.0000, 0.1600, 0.0800, 0.1200, 0.3200, 0.1200]), 'search_value': -0.2453448766573392, 'root_children_values': tensor([-0.2305,  0.0000, -0.2578,  0.0000, -0.2746, -0.2793, -0.2500, -0.2999,\n",
      "        -0.2557])})\n",
      "action: 7\n",
      "Player 1 prediction: (tensor([0.1200, 0.0000, 0.2800, 0.0000, 0.2000, 0.0800, 0.1600, 0.0000, 0.1600]), tensor([0.1200, 0.0000, 0.2800, 0.0000, 0.2000, 0.0800, 0.1600, 0.0000, 0.1600]), -0.25326311341271046, tensor(2), {'network_policy': tensor([0.1328, 0.0000, 0.1455, 0.0000, 0.2246, 0.1582, 0.1562, 0.0000, 0.1797],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.359375, 'search_policy': tensor([0.1200, 0.0000, 0.2800, 0.0000, 0.2000, 0.0800, 0.1600, 0.0000, 0.1600]), 'search_value': -0.25326311341271046, 'root_children_values': tensor([0.2773, 0.0000, 0.3540, 0.0000, 0.2544, 0.3828, 0.2751, 0.0000, 0.3112])})\n",
      "action: 2\n",
      "Player 0 random action: 6\n",
      "Player 0 random action: 5\n",
      "Player 1 prediction: (tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.5600, 0.0000, 0.0000, 0.0000, 0.2800]), tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.5600, 0.0000, 0.0000, 0.0000, 0.2800]), 0.2092246454942406, tensor(4), {'network_policy': tensor([0.2891, 0.0000, 0.0000, 0.0000, 0.3711, 0.0000, 0.0000, 0.0000, 0.3379],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.1396484375, 'search_policy': tensor([0.1600, 0.0000, 0.0000, 0.0000, 0.5600, 0.0000, 0.0000, 0.0000, 0.2800]), 'search_value': 0.2092246454942406, 'root_children_values': tensor([-0.0089,  0.0000,  0.0000,  0.0000,  0.2854,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0821])})\n",
      "action: 4\n",
      "Player 1 prediction: (tensor([0.6400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3600]), tensor([0.6400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3600]), 0.5597001216740535, tensor(0), {'network_policy': tensor([0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5039],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.171875, 'search_policy': tensor([0.6400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3600]), 'search_value': 0.5597001216740535, 'root_children_values': tensor([0.2794, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1554])})\n",
      "action: 0\n",
      "Player 0 random action: 8\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 3, 5, 2, 7],\n",
      "        [3, 6, 1, 0, 3],\n",
      "        [6, 0, 1, 8, 3],\n",
      "        [8, 4, 1, 5, 2],\n",
      "        [4, 0, 1, 8, 3],\n",
      "        [6, 4, 8, 3, 5],\n",
      "        [2, 0, 1, 8, 3],\n",
      "        [0, 3, 4, 6, 2]])\n",
      "target value tensor([[-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2637],\n",
      "         [-0.2051],\n",
      "         [-0.3496],\n",
      "         [ 0.4199],\n",
      "         [ 0.2656],\n",
      "         [ 0.0466]],\n",
      "\n",
      "        [[-0.5039],\n",
      "         [ 0.5273],\n",
      "         [ 0.3965],\n",
      "         [ 0.1133],\n",
      "         [-0.0126],\n",
      "         [ 0.2480]],\n",
      "\n",
      "        [[ 0.3906],\n",
      "         [-0.0530],\n",
      "         [ 0.1650],\n",
      "         [-0.0215],\n",
      "         [-0.0221],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[ 0.3340],\n",
      "         [ 0.4082],\n",
      "         [-0.4727],\n",
      "         [-0.5195],\n",
      "         [ 0.5703],\n",
      "         [ 0.3867]],\n",
      "\n",
      "        [[ 0.4824],\n",
      "         [ 0.3633],\n",
      "         [ 0.0227],\n",
      "         [-0.0806],\n",
      "         [ 0.3496],\n",
      "         [ 0.2598]],\n",
      "\n",
      "        [[-0.3301],\n",
      "         [-0.3379],\n",
      "         [ 0.2793],\n",
      "         [ 0.2559],\n",
      "         [ 0.0437],\n",
      "         [-0.0908]],\n",
      "\n",
      "        [[ 0.5664],\n",
      "         [ 0.1079],\n",
      "         [ 0.1611],\n",
      "         [ 0.2178],\n",
      "         [ 0.0054],\n",
      "         [ 0.0056]],\n",
      "\n",
      "        [[ 0.3711],\n",
      "         [-0.2754],\n",
      "         [-0.3633],\n",
      "         [ 0.3770],\n",
      "         [ 0.2139],\n",
      "         [ 0.0840]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0219],\n",
      "         [-0.0125],\n",
      "         [ 0.0535],\n",
      "         [ 0.0364],\n",
      "         [ 0.0942]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0265],\n",
      "         [ 0.1396],\n",
      "         [ 0.3594],\n",
      "         [ 0.0322],\n",
      "         [ 0.1924]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0991],\n",
      "         [ 0.3516],\n",
      "         [ 0.1973],\n",
      "         [ 0.3359],\n",
      "         [ 0.2305]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0554],\n",
      "         [-0.0078],\n",
      "         [ 0.0298],\n",
      "         [-0.0359],\n",
      "         [ 0.1543]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0129],\n",
      "         [ 0.2139],\n",
      "         [ 0.0981],\n",
      "         [ 0.1816],\n",
      "         [ 0.1123]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0029],\n",
      "         [-0.0025],\n",
      "         [ 0.1270],\n",
      "         [ 0.2559],\n",
      "         [ 0.0625]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.5742],\n",
      "         [ 0.0796],\n",
      "         [ 0.2832],\n",
      "         [ 0.3438],\n",
      "         [ 0.2871]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0103],\n",
      "         [ 0.0200],\n",
      "         [-0.0349],\n",
      "         [-0.0488],\n",
      "         [ 0.4336]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.5717e-03, 1.0000e+00],\n",
      "         [2.7466e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2817e-03],\n",
      "         [1.0000e+00, 3.5667e-04],\n",
      "         [1.4453e-01, 8.5547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.4114e-03],\n",
      "         [1.0000e+00, 3.5095e-04],\n",
      "         [2.7930e-01, 7.2266e-01],\n",
      "         [1.2283e-03, 1.0000e+00],\n",
      "         [4.9219e-01, 5.0781e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.1117e-04, 1.0000e+00],\n",
      "         [5.3906e-01, 4.6289e-01],\n",
      "         [9.4531e-01, 5.3467e-02],\n",
      "         [7.1094e-01, 2.8711e-01],\n",
      "         [1.7676e-01, 8.2422e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.2098e-04],\n",
      "         [7.0953e-04, 1.0000e+00],\n",
      "         [3.5095e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.4877e-04],\n",
      "         [1.0000e+00, 3.1471e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 2.0142e-03],\n",
      "         [1.2402e-01, 8.7500e-01],\n",
      "         [3.5400e-03, 9.9609e-01],\n",
      "         [7.5781e-01, 2.4316e-01],\n",
      "         [9.9219e-01, 7.8125e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.5667e-04, 1.0000e+00],\n",
      "         [9.9219e-01, 6.5002e-03],\n",
      "         [1.0000e+00, 6.5613e-04],\n",
      "         [1.3965e-01, 8.5938e-01],\n",
      "         [1.4343e-03, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.6016e-01, 3.3789e-01],\n",
      "         [1.2695e-02, 9.8828e-01],\n",
      "         [3.6523e-01, 6.3281e-01],\n",
      "         [8.4375e-01, 1.5723e-01],\n",
      "         [7.5781e-01, 2.4219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.2098e-04, 1.0000e+00],\n",
      "         [2.5749e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.3193e-03],\n",
      "         [9.9609e-01, 3.2806e-03],\n",
      "         [4.0234e-01, 5.9766e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1600 to ./videos/variable_turn_tictactoe_muzero/3/episode_001600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1600. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1600 to ./videos/variable_turn_tictactoe_muzero/0/episode_001600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1600. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1600 to ./videos/variable_turn_tictactoe_muzero/1/episode_001600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1600. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs random: 44.0 and average score: -0.04\n",
      "Results vs random: {'player_0_score': 0.9, 'player_0_win%': 0.94, 'player_1_score': -0.04, 'player_1_win%': 0.44, 'score': 0.43}\n",
      "Testing Player 0 vs Agent tictactoe_expert\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.1200, 0.0400, 0.2000, 0.1200, 0.1200, 0.1200, 0.2000]), tensor([0.0400, 0.0400, 0.1200, 0.0400, 0.2000, 0.1200, 0.1200, 0.1200, 0.2000]), 0.37459100349308877, tensor(4), {'network_policy': tensor([0.0747, 0.0708, 0.1118, 0.0830, 0.2227, 0.0933, 0.1543, 0.0791, 0.1099],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.3359375, 'search_policy': tensor([0.0400, 0.0400, 0.1200, 0.0400, 0.2000, 0.1200, 0.1200, 0.1200, 0.2000]), 'search_value': 0.37459100349308877, 'root_children_values': tensor([0.2754, 0.2520, 0.5000, 0.1357, 0.4679, 0.3752, 0.3641, 0.3849, 0.4514])})\n",
      "action: 4\n",
      "Player 0 prediction: (tensor([0.2000, 0.2000, 0.1200, 0.0800, 0.0000, 0.0800, 0.1200, 0.0800, 0.1200]), tensor([0.2000, 0.2000, 0.1200, 0.0800, 0.0000, 0.0800, 0.1200, 0.0800, 0.1200]), 0.5082649168894842, tensor(0), {'network_policy': tensor([0.1143, 0.0791, 0.1602, 0.1245, 0.0000, 0.1152, 0.1416, 0.1045, 0.1592],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.353515625, 'search_policy': tensor([0.2000, 0.2000, 0.1200, 0.0800, 0.0000, 0.0800, 0.1200, 0.0800, 0.1200]), 'search_value': 0.5082649168894842, 'root_children_values': tensor([-0.5539, -0.5184, -0.5490, -0.5156,  0.0000, -0.4961, -0.4834, -0.4805,\n",
      "        -0.5406])})\n",
      "action: 0\n",
      "Player 1 tictactoe_expert action: 8\n",
      "Player 1 tictactoe_expert action: 2\n",
      "Player 0 prediction: (tensor([0.0000, 0.0400, 0.0000, 0.2000, 0.0000, 0.2000, 0.3600, 0.2000, 0.0000]), tensor([0.0000, 0.0400, 0.0000, 0.2000, 0.0000, 0.2000, 0.3600, 0.2000, 0.0000]), 0.6508471399911733, tensor(6), {'network_policy': tensor([0.0000, 0.1152, 0.0000, 0.1992, 0.0000, 0.1895, 0.3164, 0.1729, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.33203125, 'search_policy': tensor([0.0000, 0.0400, 0.0000, 0.2000, 0.0000, 0.2000, 0.3600, 0.2000, 0.0000]), 'search_value': 0.6508471399911733, 'root_children_values': tensor([0.0000, 0.1270, 0.0000, 0.3782, 0.0000, 0.3022, 0.3824, 0.5052, 0.0000])})\n",
      "action: 6\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0000, 0.2400, 0.0000, 0.3600, 0.0000, 0.1600, 0.0000, 0.2400, 0.0000]), tensor([0.0000, 0.2400, 0.0000, 0.3600, 0.0000, 0.1600, 0.0000, 0.2400, 0.0000]), 0.19465061444166926, tensor(3), {'network_policy': tensor([0.0000, 0.1699, 0.0000, 0.2715, 0.0000, 0.2578, 0.0000, 0.2949, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.359375, 'search_policy': tensor([0.0000, 0.2400, 0.0000, 0.3600, 0.0000, 0.1600, 0.0000, 0.2400, 0.0000]), 'search_value': 0.19465061444166926, 'root_children_values': tensor([0.0000, 0.2831, 0.0000, 0.3283, 0.0000, 0.1751, 0.0000, 0.3798, 0.0000])})\n",
      "action: 3\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1600 to ./videos/variable_turn_tictactoe_muzero/2/episode_001600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1600. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Player 0 win percentage vs tictactoe_expert: 70.0 and average score: 0.48\n",
      "Testing Player 1 vs Agent tictactoe_expert\n",
      "Player 0 tictactoe_expert action: 6\n",
      "Player 0 tictactoe_expert action: 8\n",
      "Player 1 prediction: (tensor([0.2800, 0.1600, 0.1200, 0.0800, 0.1600, 0.0800, 0.0000, 0.1200, 0.0000]), tensor([0.2800, 0.1600, 0.1200, 0.0800, 0.1600, 0.0800, 0.0000, 0.1200, 0.0000]), -0.2643211418644832, tensor(0), {'network_policy': tensor([0.1196, 0.1177, 0.1572, 0.1230, 0.1865, 0.1260, 0.0000, 0.1670, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.357421875, 'search_policy': tensor([0.2800, 0.1600, 0.1200, 0.0800, 0.1600, 0.0800, 0.0000, 0.1200, 0.0000]), 'search_value': -0.2643211418644832, 'root_children_values': tensor([-0.3332, -0.3129, -0.2793, -0.3242, -0.2557, -0.3496,  0.0000, -0.3453,\n",
      "         0.0000])})\n",
      "action: 0\n",
      "Player 1 prediction: (tensor([0.0000, 0.2400, 0.1600, 0.1600, 0.2000, 0.0800, 0.0000, 0.1600, 0.0000]), tensor([0.0000, 0.2400, 0.1600, 0.1600, 0.2000, 0.0800, 0.0000, 0.1600, 0.0000]), -0.28461455173903244, tensor(1), {'network_policy': tensor([0.0000, 0.1523, 0.1641, 0.1504, 0.2422, 0.1182, 0.0000, 0.1699, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.390625, 'search_policy': tensor([0.0000, 0.2400, 0.1600, 0.1600, 0.2000, 0.0800, 0.0000, 0.1600, 0.0000]), 'search_value': -0.28461455173903244, 'root_children_values': tensor([0.0000, 0.3011, 0.3310, 0.2937, 0.2344, 0.3887, 0.0000, 0.5314, 0.0000])})\n",
      "action: 1\n",
      "Player 0 tictactoe_expert action: 7\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 8, 7, 0, 5],\n",
      "        [1, 5, 7, 8, 6],\n",
      "        [6, 2, 0, 7, 5],\n",
      "        [5, 4, 3, 8, 6],\n",
      "        [3, 2, 0, 0, 5],\n",
      "        [4, 6, 0, 1, 5],\n",
      "        [2, 0, 6, 1, 5],\n",
      "        [4, 8, 6, 0, 2]])\n",
      "target value tensor([[-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.2393],\n",
      "         [ 0.2100],\n",
      "         [ 0.0728],\n",
      "         [ 0.3535],\n",
      "         [ 0.0537],\n",
      "         [ 0.0091]],\n",
      "\n",
      "        [[-0.1865],\n",
      "         [ 0.2002],\n",
      "         [ 0.1768],\n",
      "         [ 0.0078],\n",
      "         [-0.0820],\n",
      "         [ 0.2656]],\n",
      "\n",
      "        [[ 0.2578],\n",
      "         [-0.3125],\n",
      "         [-0.3086],\n",
      "         [ 0.2500],\n",
      "         [ 0.2559],\n",
      "         [ 0.1260]],\n",
      "\n",
      "        [[ 0.4062],\n",
      "         [ 0.3125],\n",
      "         [-0.3906],\n",
      "         [-0.4473],\n",
      "         [ 0.3633],\n",
      "         [ 0.2188]],\n",
      "\n",
      "        [[ 0.0248],\n",
      "         [ 0.1982],\n",
      "         [ 0.0371],\n",
      "         [ 0.0564],\n",
      "         [ 0.0908],\n",
      "         [ 0.0728]],\n",
      "\n",
      "        [[ 0.7852],\n",
      "         [ 0.3613],\n",
      "         [ 0.1963],\n",
      "         [-0.0051],\n",
      "         [ 0.2197],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[ 0.4824],\n",
      "         [ 0.0466],\n",
      "         [-0.0132],\n",
      "         [ 0.0679],\n",
      "         [ 0.1069],\n",
      "         [ 0.0444]],\n",
      "\n",
      "        [[ 0.4062],\n",
      "         [ 0.4141],\n",
      "         [-0.5547],\n",
      "         [-0.4590],\n",
      "         [ 0.5664],\n",
      "         [ 0.3809]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 3.1641e-01],\n",
      "         [ 1.3965e-01],\n",
      "         [ 3.8477e-01],\n",
      "         [ 8.8379e-02],\n",
      "         [ 4.4336e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-5.1758e-02],\n",
      "         [ 1.6113e-01],\n",
      "         [ 1.5137e-01],\n",
      "         [ 4.5654e-02],\n",
      "         [ 4.0039e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.5410e-02],\n",
      "         [ 9.0942e-03],\n",
      "         [-6.8665e-03],\n",
      "         [ 4.6875e-02],\n",
      "         [ 2.3242e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.1016e-02],\n",
      "         [ 2.2583e-02],\n",
      "         [-6.5918e-03],\n",
      "         [ 3.0060e-03],\n",
      "         [ 3.9795e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-2.0752e-02],\n",
      "         [ 9.8145e-02],\n",
      "         [ 1.6016e-01],\n",
      "         [ 2.0410e-01],\n",
      "         [ 3.3398e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.0352e-01],\n",
      "         [ 5.5859e-01],\n",
      "         [ 4.0039e-02],\n",
      "         [ 2.0898e-01],\n",
      "         [ 2.9688e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.6172e-01],\n",
      "         [ 3.1738e-02],\n",
      "         [ 3.5742e-01],\n",
      "         [ 1.6504e-01],\n",
      "         [ 4.4727e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-5.0735e-04],\n",
      "         [-3.1494e-02],\n",
      "         [-7.6904e-03],\n",
      "         [ 3.0518e-02],\n",
      "         [ 1.9238e-01]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.1816e-01, 8.8281e-01],\n",
      "         [3.9864e-04, 1.0000e+00],\n",
      "         [5.7812e-01, 4.2188e-01],\n",
      "         [8.5156e-01, 1.4941e-01],\n",
      "         [9.6094e-01, 3.8574e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 7.1106e-03],\n",
      "         [9.9609e-01, 2.0905e-03],\n",
      "         [8.8379e-02, 9.1016e-01],\n",
      "         [3.6812e-04, 1.0000e+00],\n",
      "         [5.3125e-01, 4.7070e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.2997e-04, 1.0000e+00],\n",
      "         [1.7357e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0147e-03],\n",
      "         [1.0000e+00, 3.1471e-04],\n",
      "         [1.6895e-01, 8.3203e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.7820e-04],\n",
      "         [9.6321e-05, 1.0000e+00],\n",
      "         [4.1008e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [1.0000e+00, 4.6539e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 8.1787e-03],\n",
      "         [2.6001e-02, 9.7266e-01],\n",
      "         [3.7689e-03, 9.9609e-01],\n",
      "         [4.2383e-01, 5.7422e-01],\n",
      "         [9.2969e-01, 7.0801e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 7.6294e-03],\n",
      "         [6.4844e-01, 3.5156e-01],\n",
      "         [3.8910e-03, 9.9609e-01],\n",
      "         [4.9609e-01, 5.0391e-01],\n",
      "         [9.5312e-01, 4.6631e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.3438e-01, 2.6562e-01],\n",
      "         [5.9891e-04, 1.0000e+00],\n",
      "         [3.9648e-01, 6.0547e-01],\n",
      "         [9.8047e-01, 1.8311e-02],\n",
      "         [4.5508e-01, 5.4688e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2436e-03],\n",
      "         [7.4863e-05, 1.0000e+00],\n",
      "         [2.3746e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.9591e-04],\n",
      "         [1.0000e+00, 1.1253e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs tictactoe_expert: 2.0 and average score: -0.94\n",
      "Results vs tictactoe_expert: {'player_0_score': 0.48, 'player_0_win%': 0.7, 'player_1_score': -0.94, 'player_1_win%': 0.02, 'score': -0.22999999999999998}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Started recording episode 1700 to ./videos/variable_turn_tictactoe_muzero/3/episode_001700.mp4\n",
      "Stopped recording episode 1700. Recorded 10 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 1700 to ./videos/variable_turn_tictactoe_muzero/0/episode_001700.mp4\n",
      "Stopped recording episode 1700. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n",
      "Started recording episode 1700 to ./videos/variable_turn_tictactoe_muzero/1/episode_001700.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped recording episode 1700. Recorded 6 frames.\n",
      "learning\n",
      "3300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 2, 7, 5, 0],\n",
      "        [8, 2, 0, 6, 8],\n",
      "        [2, 3, 5, 1, 7],\n",
      "        [3, 0, 5, 6, 8],\n",
      "        [1, 8, 2, 7, 6],\n",
      "        [1, 8, 0, 6, 0],\n",
      "        [6, 7, 0, 8, 0],\n",
      "        [2, 1, 3, 5, 0]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.6680],\n",
      "         [ 0.0767],\n",
      "         [-0.0913],\n",
      "         [ 0.5273],\n",
      "         [ 0.1953],\n",
      "         [ 0.0864]],\n",
      "\n",
      "        [[ 0.5547],\n",
      "         [ 0.2930],\n",
      "         [ 0.1050],\n",
      "         [ 0.1904],\n",
      "         [ 0.1738],\n",
      "         [ 0.1611]],\n",
      "\n",
      "        [[-0.5312],\n",
      "         [-0.4102],\n",
      "         [ 0.8203],\n",
      "         [ 0.5508],\n",
      "         [ 0.1660],\n",
      "         [ 0.0598]],\n",
      "\n",
      "        [[ 0.7812],\n",
      "         [ 0.1943],\n",
      "         [ 0.1621],\n",
      "         [ 0.1172],\n",
      "         [ 0.2490],\n",
      "         [ 0.1641]],\n",
      "\n",
      "        [[ 0.5352],\n",
      "         [ 0.3242],\n",
      "         [-0.3203],\n",
      "         [-0.2715],\n",
      "         [ 0.5547],\n",
      "         [ 0.4316]],\n",
      "\n",
      "        [[-0.3711],\n",
      "         [-0.5039],\n",
      "         [ 0.6250],\n",
      "         [ 0.5117],\n",
      "         [ 0.1494],\n",
      "         [ 0.0491]],\n",
      "\n",
      "        [[-0.5352],\n",
      "         [-0.3867],\n",
      "         [ 0.5898],\n",
      "         [ 0.3887],\n",
      "         [ 0.1777],\n",
      "         [ 0.1572]],\n",
      "\n",
      "        [[ 0.4648],\n",
      "         [-0.3281],\n",
      "         [-0.2949],\n",
      "         [ 0.7734],\n",
      "         [ 0.5820],\n",
      "         [ 0.1807]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.2109],\n",
      "         [ 0.0830],\n",
      "         [ 0.2354],\n",
      "         [ 0.3965],\n",
      "         [-0.0815]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1113],\n",
      "         [ 0.6328],\n",
      "         [ 0.0728],\n",
      "         [ 0.2793],\n",
      "         [ 0.2275]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0064],\n",
      "         [ 0.0209],\n",
      "         [ 0.1719],\n",
      "         [ 0.3242],\n",
      "         [ 0.0449]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4492],\n",
      "         [-0.0388],\n",
      "         [ 0.0505],\n",
      "         [ 0.1045],\n",
      "         [ 0.1504]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0542],\n",
      "         [-0.0209],\n",
      "         [-0.0479],\n",
      "         [-0.0520],\n",
      "         [ 0.1211]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0270],\n",
      "         [-0.0166],\n",
      "         [ 0.0728],\n",
      "         [ 0.3574],\n",
      "         [-0.0023]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0276],\n",
      "         [ 0.0520],\n",
      "         [ 0.1226],\n",
      "         [ 0.4609],\n",
      "         [ 0.0115]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0393],\n",
      "         [ 0.0082],\n",
      "         [-0.0535],\n",
      "         [ 0.0566],\n",
      "         [ 0.1641]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-02, 9.0234e-01],\n",
      "         [3.1090e-04, 1.0000e+00],\n",
      "         [7.4219e-01, 2.5781e-01],\n",
      "         [1.0000e+00, 4.8828e-04],\n",
      "         [2.1484e-01, 7.8516e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 2.0142e-03],\n",
      "         [5.6641e-01, 4.3359e-01],\n",
      "         [2.1729e-02, 9.7656e-01],\n",
      "         [5.2344e-01, 4.7656e-01],\n",
      "         [9.6484e-01, 3.4424e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.6478e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.6076e-04],\n",
      "         [1.0000e+00, 5.8174e-05],\n",
      "         [2.7539e-01, 7.2266e-01],\n",
      "         [5.1117e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.8828e-01, 1.1597e-02],\n",
      "         [2.0630e-02, 9.8047e-01],\n",
      "         [4.4678e-02, 9.5703e-01],\n",
      "         [9.9609e-01, 4.3945e-03],\n",
      "         [9.9219e-01, 9.1553e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.4141e-01, 5.7861e-02],\n",
      "         [1.2302e-04, 1.0000e+00],\n",
      "         [2.7847e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.3167e-05],\n",
      "         [1.0000e+00, 5.1117e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.2983e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 3.2997e-04],\n",
      "         [1.0000e+00, 2.3079e-04],\n",
      "         [1.2207e-01, 8.7891e-01],\n",
      "         [1.3046e-03, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.7248e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 4.5776e-04],\n",
      "         [1.0000e+00, 1.0538e-04],\n",
      "         [5.7422e-01, 4.2578e-01],\n",
      "         [8.4229e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.2684e-04, 1.0000e+00],\n",
      "         [4.1246e-05, 1.0000e+00],\n",
      "         [9.9609e-01, 2.5940e-03],\n",
      "         [1.0000e+00, 1.5831e-04],\n",
      "         [2.3730e-01, 7.6172e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1700 to ./videos/variable_turn_tictactoe_muzero/2/episode_001700.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1700. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "average score: 0.64\n",
      "Test score {'score': 0.64, 'max_score': 1, 'min_score': -1}\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[8, 3, 4, 6, 0],\n",
      "        [7, 0, 4, 0, 7],\n",
      "        [1, 0, 8, 0, 7],\n",
      "        [3, 0, 6, 7, 8],\n",
      "        [4, 6, 5, 8, 1],\n",
      "        [4, 1, 8, 0, 2],\n",
      "        [4, 7, 1, 5, 0],\n",
      "        [3, 4, 6, 2, 1]])\n",
      "target value tensor([[-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.0159],\n",
      "         [ 0.2773],\n",
      "         [ 0.1562],\n",
      "         [ 0.1196],\n",
      "         [ 0.2441],\n",
      "         [ 0.0505]],\n",
      "\n",
      "        [[ 0.2168],\n",
      "         [ 0.2969],\n",
      "         [ 0.1055],\n",
      "         [-0.0206],\n",
      "         [ 0.0630],\n",
      "         [ 0.1133]],\n",
      "\n",
      "        [[-0.6133],\n",
      "         [ 0.5195],\n",
      "         [ 0.4941],\n",
      "         [ 0.1582],\n",
      "         [ 0.0077],\n",
      "         [ 0.3945]],\n",
      "\n",
      "        [[-0.5078],\n",
      "         [ 0.6562],\n",
      "         [ 0.4180],\n",
      "         [ 0.1631],\n",
      "         [ 0.0383],\n",
      "         [ 0.2832]],\n",
      "\n",
      "        [[ 0.4941],\n",
      "         [ 0.5742],\n",
      "         [-0.4492],\n",
      "         [-0.5039],\n",
      "         [ 0.5703],\n",
      "         [ 0.3789]],\n",
      "\n",
      "        [[ 0.4941],\n",
      "         [ 0.5742],\n",
      "         [-0.6094],\n",
      "         [-0.6836],\n",
      "         [ 0.5742],\n",
      "         [ 0.5430]],\n",
      "\n",
      "        [[ 0.2520],\n",
      "         [ 0.2031],\n",
      "         [ 0.0396],\n",
      "         [ 0.3867],\n",
      "         [ 0.0928],\n",
      "         [ 0.0342]],\n",
      "\n",
      "        [[ 0.4941],\n",
      "         [ 0.2891],\n",
      "         [-0.4395],\n",
      "         [-0.4395],\n",
      "         [ 0.3965],\n",
      "         [ 0.2334]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0938],\n",
      "         [ 0.2139],\n",
      "         [ 0.2305],\n",
      "         [ 0.5312],\n",
      "         [ 0.1455]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3887],\n",
      "         [ 0.1436],\n",
      "         [ 0.4395],\n",
      "         [ 0.0067],\n",
      "         [ 0.0996]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0459],\n",
      "         [ 0.1338],\n",
      "         [ 0.5469],\n",
      "         [-0.0193],\n",
      "         [ 0.2344]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.1025],\n",
      "         [ 0.0869],\n",
      "         [ 0.5312],\n",
      "         [ 0.0972],\n",
      "         [ 0.4297]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0096],\n",
      "         [-0.0113],\n",
      "         [-0.0128],\n",
      "         [ 0.0522],\n",
      "         [ 0.1064]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0096],\n",
      "         [-0.0449],\n",
      "         [ 0.0320],\n",
      "         [ 0.0145],\n",
      "         [ 0.2158]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4199],\n",
      "         [ 0.1660],\n",
      "         [ 0.3320],\n",
      "         [ 0.3516],\n",
      "         [-0.0135]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0605],\n",
      "         [-0.0233],\n",
      "         [-0.0075],\n",
      "         [-0.0175],\n",
      "         [-0.0080]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.6131e-04],\n",
      "         [2.8516e-01, 7.1484e-01],\n",
      "         [4.0588e-03, 9.9609e-01],\n",
      "         [3.6523e-01, 6.3281e-01],\n",
      "         [9.1016e-01, 8.9844e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.7305e-01, 6.2500e-01],\n",
      "         [9.8047e-01, 1.9409e-02],\n",
      "         [9.4922e-01, 5.1025e-02],\n",
      "         [2.8711e-01, 7.1094e-01],\n",
      "         [8.8379e-02, 9.1016e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.7929e-04],\n",
      "         [1.0000e+00, 4.8399e-05],\n",
      "         [6.5625e-01, 3.4570e-01],\n",
      "         [7.7820e-04, 1.0000e+00],\n",
      "         [7.1875e-01, 2.7930e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.8501e-04],\n",
      "         [1.0000e+00, 2.5368e-04],\n",
      "         [6.4453e-01, 3.5352e-01],\n",
      "         [3.2196e-03, 9.9609e-01],\n",
      "         [5.2734e-01, 4.7266e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [3.6240e-04, 1.0000e+00],\n",
      "         [2.9564e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0538e-04],\n",
      "         [1.0000e+00, 2.2316e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [2.9564e-04, 1.0000e+00],\n",
      "         [2.0981e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.8174e-05],\n",
      "         [1.0000e+00, 1.9550e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.3789e-01, 6.6016e-01],\n",
      "         [1.7014e-03, 1.0000e+00],\n",
      "         [6.3281e-01, 3.6914e-01],\n",
      "         [1.0000e+00, 3.2997e-04],\n",
      "         [5.7031e-01, 4.2969e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.7242e-03],\n",
      "         [1.0986e-03, 1.0000e+00],\n",
      "         [2.0313e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 9.6321e-05],\n",
      "         [1.0000e+00, 4.5776e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1800 to ./videos/variable_turn_tictactoe_muzero/3/episode_001800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1800 to ./videos/variable_turn_tictactoe_muzero/0/episode_001800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1800 to ./videos/variable_turn_tictactoe_muzero/1/episode_001800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1800. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 5, 2, 0, 0],\n",
      "        [2, 0, 8, 5, 0],\n",
      "        [0, 5, 7, 2, 0],\n",
      "        [4, 1, 5, 3, 6],\n",
      "        [1, 4, 5, 2, 8],\n",
      "        [6, 8, 3, 7, 0],\n",
      "        [4, 0, 8, 2, 0],\n",
      "        [2, 4, 0, 6, 3]])\n",
      "target value tensor([[-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.5508],\n",
      "         [ 0.1113],\n",
      "         [-0.0139],\n",
      "         [ 0.6367],\n",
      "         [ 0.0198],\n",
      "         [ 0.0471]],\n",
      "\n",
      "        [[ 0.6406],\n",
      "         [ 0.0938],\n",
      "         [ 0.1152],\n",
      "         [ 0.1221],\n",
      "         [ 0.1113],\n",
      "         [ 0.0669]],\n",
      "\n",
      "        [[-0.2197],\n",
      "         [-0.2969],\n",
      "         [ 0.4434],\n",
      "         [ 0.4375],\n",
      "         [ 0.1855],\n",
      "         [ 0.1709]],\n",
      "\n",
      "        [[ 0.4570],\n",
      "         [-0.3809],\n",
      "         [-0.4434],\n",
      "         [ 0.6719],\n",
      "         [ 0.4785],\n",
      "         [ 0.1191]],\n",
      "\n",
      "        [[ 0.0444],\n",
      "         [-0.0175],\n",
      "         [ 0.3672],\n",
      "         [ 0.1846],\n",
      "         [ 0.2119],\n",
      "         [ 0.2969]],\n",
      "\n",
      "        [[-0.4863],\n",
      "         [ 0.6562],\n",
      "         [ 0.5195],\n",
      "         [ 0.0859],\n",
      "         [ 0.1924],\n",
      "         [ 0.3535]],\n",
      "\n",
      "        [[-0.1816],\n",
      "         [-0.2012],\n",
      "         [ 0.2637],\n",
      "         [ 0.1631],\n",
      "         [ 0.1611],\n",
      "         [ 0.1099]],\n",
      "\n",
      "        [[ 0.3008],\n",
      "         [ 0.2695],\n",
      "         [ 0.1328],\n",
      "         [ 0.1436],\n",
      "         [ 0.3105],\n",
      "         [ 0.1187]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.1768],\n",
      "         [-0.0398],\n",
      "         [ 0.1914],\n",
      "         [ 0.4980],\n",
      "         [ 0.0242]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6016],\n",
      "         [-0.0361],\n",
      "         [ 0.4238],\n",
      "         [ 0.2412],\n",
      "         [ 0.0292]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0630],\n",
      "         [-0.0747],\n",
      "         [ 0.0133],\n",
      "         [ 0.4121],\n",
      "         [-0.0510]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0483],\n",
      "         [ 0.0437],\n",
      "         [-0.0530],\n",
      "         [ 0.1406],\n",
      "         [ 0.4414]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0087],\n",
      "         [ 0.0708],\n",
      "         [-0.0305],\n",
      "         [ 0.3164],\n",
      "         [ 0.1641]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0537],\n",
      "         [ 0.1670],\n",
      "         [ 0.5625],\n",
      "         [ 0.0674],\n",
      "         [ 0.2969]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0054],\n",
      "         [-0.0535],\n",
      "         [-0.0214],\n",
      "         [ 0.4727],\n",
      "         [-0.0334]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0065],\n",
      "         [ 0.3828],\n",
      "         [-0.0038],\n",
      "         [ 0.4512],\n",
      "         [ 0.3730]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.7344e-01, 7.2656e-01],\n",
      "         [1.7853e-03, 1.0000e+00],\n",
      "         [8.0469e-01, 1.9434e-01],\n",
      "         [9.9609e-01, 4.3335e-03],\n",
      "         [3.8672e-01, 6.1328e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.1641e-01, 1.8262e-01],\n",
      "         [2.9053e-02, 9.7266e-01],\n",
      "         [4.2969e-01, 5.7031e-01],\n",
      "         [8.2422e-01, 1.7578e-01],\n",
      "         [6.9922e-01, 3.0078e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.1648e-04, 1.0000e+00],\n",
      "         [9.8828e-01, 1.2329e-02],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [4.4336e-01, 5.5469e-01],\n",
      "         [1.8677e-02, 9.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.5313e-04, 1.0000e+00],\n",
      "         [2.1648e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.0654e-04],\n",
      "         [1.0000e+00, 2.6894e-04],\n",
      "         [4.2383e-01, 5.7812e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.3711e-03, 9.9609e-01],\n",
      "         [9.9219e-01, 8.0566e-03],\n",
      "         [1.0000e+00, 1.0300e-03],\n",
      "         [3.2031e-01, 6.7969e-01],\n",
      "         [2.0020e-02, 9.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.3406e-04],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [7.1875e-01, 2.8320e-01],\n",
      "         [6.5002e-03, 9.9219e-01],\n",
      "         [6.0156e-01, 3.9844e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.1880e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 4.4556e-03],\n",
      "         [1.0000e+00, 2.1648e-04],\n",
      "         [5.7812e-01, 4.2188e-01],\n",
      "         [2.2888e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.8910e-03],\n",
      "         [3.7891e-01, 6.2109e-01],\n",
      "         [3.8528e-04, 1.0000e+00],\n",
      "         [4.9023e-01, 5.1172e-01],\n",
      "         [9.9609e-01, 4.3335e-03]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1800 to ./videos/variable_turn_tictactoe_muzero/2/episode_001800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 8, 5, 4, 1],\n",
      "        [4, 3, 8, 6, 1],\n",
      "        [6, 7, 3, 0, 5],\n",
      "        [0, 4, 2, 6, 1],\n",
      "        [4, 3, 8, 7, 6],\n",
      "        [1, 2, 0, 6, 6],\n",
      "        [5, 2, 1, 7, 0],\n",
      "        [0, 1, 2, 0, 6]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.1118],\n",
      "         [-0.2412],\n",
      "         [ 0.3867],\n",
      "         [ 0.1914],\n",
      "         [ 0.0118],\n",
      "         [-0.0391]],\n",
      "\n",
      "        [[-0.6055],\n",
      "         [-0.2471],\n",
      "         [ 0.3691],\n",
      "         [ 0.1982],\n",
      "         [ 0.1123],\n",
      "         [ 0.1230]],\n",
      "\n",
      "        [[-0.5938],\n",
      "         [-0.4805],\n",
      "         [ 0.5234],\n",
      "         [ 0.3594],\n",
      "         [ 0.1147],\n",
      "         [ 0.0981]],\n",
      "\n",
      "        [[ 0.3633],\n",
      "         [ 0.4316],\n",
      "         [-0.4023],\n",
      "         [-0.5469],\n",
      "         [ 0.3594],\n",
      "         [ 0.1670]],\n",
      "\n",
      "        [[ 0.3633],\n",
      "         [ 0.4941],\n",
      "         [-0.4844],\n",
      "         [-0.6641],\n",
      "         [ 0.5352],\n",
      "         [ 0.4629]],\n",
      "\n",
      "        [[ 0.3594],\n",
      "         [ 0.1416],\n",
      "         [ 0.1152],\n",
      "         [ 0.0771],\n",
      "         [ 0.1328],\n",
      "         [ 0.0050]],\n",
      "\n",
      "        [[-0.3984],\n",
      "         [ 0.3301],\n",
      "         [ 0.4434],\n",
      "         [ 0.1299],\n",
      "         [ 0.1289],\n",
      "         [ 0.1118]],\n",
      "\n",
      "        [[-0.5117],\n",
      "         [-0.4004],\n",
      "         [ 0.4062],\n",
      "         [ 0.2773],\n",
      "         [ 0.0674],\n",
      "         [ 0.1270]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0070],\n",
      "         [ 0.0311],\n",
      "         [ 0.0240],\n",
      "         [ 0.6719],\n",
      "         [ 0.0053]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0071],\n",
      "         [ 0.0356],\n",
      "         [ 0.1162],\n",
      "         [ 0.7031],\n",
      "         [ 0.2275]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0287],\n",
      "         [ 0.0342],\n",
      "         [ 0.0281],\n",
      "         [ 0.2715],\n",
      "         [ 0.1318]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0344],\n",
      "         [ 0.0820],\n",
      "         [ 0.0243],\n",
      "         [ 0.0183],\n",
      "         [ 0.1768]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0118],\n",
      "         [-0.0554],\n",
      "         [-0.0508],\n",
      "         [-0.0309],\n",
      "         [ 0.1826]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0109],\n",
      "         [ 0.3750],\n",
      "         [ 0.0654],\n",
      "         [ 0.6250],\n",
      "         [ 0.4473]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0330],\n",
      "         [ 0.2969],\n",
      "         [ 0.4902],\n",
      "         [ 0.2178],\n",
      "         [ 0.4941]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0317],\n",
      "         [ 0.0723],\n",
      "         [ 0.3066],\n",
      "         [ 0.1885],\n",
      "         [ 0.0016]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.9073e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 4.3945e-03],\n",
      "         [1.0000e+00, 7.9632e-05],\n",
      "         [5.8594e-01, 4.1406e-01],\n",
      "         [7.1106e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9945e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.5488e-03],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [6.2891e-01, 3.7305e-01],\n",
      "         [2.2827e-02, 9.7656e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.5286e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.7220e-04],\n",
      "         [1.0000e+00, 1.4877e-04],\n",
      "         [4.3359e-01, 5.6641e-01],\n",
      "         [1.2451e-02, 9.8828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.8787e-04],\n",
      "         [6.3782e-03, 9.9219e-01],\n",
      "         [4.5300e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 1.6708e-03],\n",
      "         [1.0000e+00, 7.9632e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.0654e-04],\n",
      "         [8.5449e-04, 1.0000e+00],\n",
      "         [3.7670e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.3406e-04],\n",
      "         [1.0000e+00, 1.0872e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.0695e-04],\n",
      "         [6.6797e-01, 3.3008e-01],\n",
      "         [5.6458e-03, 9.9609e-01],\n",
      "         [4.1211e-01, 5.8984e-01],\n",
      "         [9.1016e-01, 8.8379e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2302e-04],\n",
      "         [1.0000e+00, 4.1246e-05],\n",
      "         [5.6250e-01, 4.3945e-01],\n",
      "         [7.8125e-03, 9.9219e-01],\n",
      "         [3.9258e-01, 6.0547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.6131e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.2425e-04],\n",
      "         [1.0000e+00, 6.1989e-05],\n",
      "         [8.1641e-01, 1.8457e-01],\n",
      "         [1.6235e-02, 9.8438e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1900 to ./videos/variable_turn_tictactoe_muzero/3/episode_001900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1900 to ./videos/variable_turn_tictactoe_muzero/0/episode_001900.mp4\n",
      "Stopped recording episode 1900. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1900. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1900 to ./videos/variable_turn_tictactoe_muzero/1/episode_001900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1900. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 1900 to ./videos/variable_turn_tictactoe_muzero/2/episode_001900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 1900. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3700\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[5, 1, 6, 0, 4],\n",
      "        [7, 0, 2, 1, 4],\n",
      "        [4, 1, 3, 7, 6],\n",
      "        [0, 0, 4, 3, 4],\n",
      "        [4, 6, 2, 8, 0],\n",
      "        [4, 0, 8, 5, 0],\n",
      "        [7, 2, 6, 8, 0],\n",
      "        [3, 0, 8, 6, 2]])\n",
      "target value tensor([[-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.0488],\n",
      "         [ 0.0654],\n",
      "         [ 0.4551],\n",
      "         [ 0.0461],\n",
      "         [-0.0498],\n",
      "         [-0.0322]],\n",
      "\n",
      "        [[-0.3105],\n",
      "         [-0.2734],\n",
      "         [ 0.5703],\n",
      "         [ 0.3359],\n",
      "         [ 0.0977],\n",
      "         [ 0.0786]],\n",
      "\n",
      "        [[ 0.5000],\n",
      "         [ 0.6836],\n",
      "         [-0.6094],\n",
      "         [-0.5586],\n",
      "         [ 0.6094],\n",
      "         [ 0.5078]],\n",
      "\n",
      "        [[ 0.7500],\n",
      "         [ 0.0317],\n",
      "         [-0.0747],\n",
      "         [ 0.0439],\n",
      "         [ 0.0596],\n",
      "         [-0.0209]],\n",
      "\n",
      "        [[ 0.5703],\n",
      "         [-0.5352],\n",
      "         [-0.5117],\n",
      "         [ 0.3984],\n",
      "         [ 0.3066],\n",
      "         [ 0.0845]],\n",
      "\n",
      "        [[-0.3828],\n",
      "         [-0.2578],\n",
      "         [ 0.2520],\n",
      "         [ 0.2559],\n",
      "         [ 0.1099],\n",
      "         [ 0.0498]],\n",
      "\n",
      "        [[ 0.6836],\n",
      "         [-0.5234],\n",
      "         [-0.5742],\n",
      "         [ 0.6094],\n",
      "         [ 0.3965],\n",
      "         [ 0.0386]],\n",
      "\n",
      "        [[ 0.6836],\n",
      "         [-0.4629],\n",
      "         [-0.6016],\n",
      "         [ 0.5352],\n",
      "         [ 0.5195],\n",
      "         [ 0.0957]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 2.0996e-01],\n",
      "         [ 3.6523e-01],\n",
      "         [ 8.1641e-01],\n",
      "         [ 1.4453e-01],\n",
      "         [ 3.3398e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 5.0964e-03],\n",
      "         [ 2.3956e-03],\n",
      "         [ 2.4414e-01],\n",
      "         [ 3.5742e-01],\n",
      "         [ 3.0273e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 6.7383e-02],\n",
      "         [ 4.2969e-02],\n",
      "         [ 5.8838e-02],\n",
      "         [-2.5177e-04],\n",
      "         [ 3.0078e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 4.8242e-01],\n",
      "         [-5.1025e-02],\n",
      "         [ 1.2500e-01],\n",
      "         [ 3.3789e-01],\n",
      "         [ 5.8984e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 6.2012e-02],\n",
      "         [-3.3936e-02],\n",
      "         [ 3.2227e-02],\n",
      "         [ 3.0078e-01],\n",
      "         [ 2.0215e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.3926e-02],\n",
      "         [-2.1515e-03],\n",
      "         [ 2.5195e-01],\n",
      "         [ 5.4297e-01],\n",
      "         [ 3.2715e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.9775e-02],\n",
      "         [ 1.6235e-02],\n",
      "         [ 2.9144e-03],\n",
      "         [ 2.4902e-01],\n",
      "         [ 4.5312e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-2.0996e-02],\n",
      "         [-3.5400e-02],\n",
      "         [-3.3691e-02],\n",
      "         [ 2.2168e-01],\n",
      "         [ 7.6953e-01]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.5513e-02, 9.7266e-01],\n",
      "         [6.3281e-01, 3.6719e-01],\n",
      "         [9.9609e-01, 5.4626e-03],\n",
      "         [9.0625e-01, 9.2285e-02],\n",
      "         [2.2949e-01, 7.6953e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.1471e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2684e-04],\n",
      "         [1.0000e+00, 7.2479e-05],\n",
      "         [4.7266e-01, 5.2734e-01],\n",
      "         [2.2583e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.1471e-04],\n",
      "         [3.8528e-04, 1.0000e+00],\n",
      "         [1.1253e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 3.0823e-03],\n",
      "         [1.0000e+00, 2.6131e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.1719e-01, 3.8281e-01],\n",
      "         [2.5757e-02, 9.7266e-01],\n",
      "         [8.1641e-01, 1.8262e-01],\n",
      "         [1.0000e+00, 1.4801e-03],\n",
      "         [8.4766e-01, 1.5137e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.7618e-03, 9.9609e-01],\n",
      "         [1.6880e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 8.4877e-05],\n",
      "         [1.0000e+00, 2.3460e-04],\n",
      "         [6.4453e-01, 3.5547e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.8065e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.2343e-04],\n",
      "         [1.0000e+00, 1.7929e-04],\n",
      "         [5.0781e-01, 4.9219e-01],\n",
      "         [1.0925e-02, 9.8828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.7161e-03, 9.9609e-01],\n",
      "         [1.0252e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 7.4863e-05],\n",
      "         [1.0000e+00, 3.8862e-05],\n",
      "         [6.7578e-01, 3.2422e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.2806e-03, 9.9609e-01],\n",
      "         [1.9741e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 9.9182e-05],\n",
      "         [1.0000e+00, 7.7248e-05],\n",
      "         [7.1094e-01, 2.8906e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 2000 to ./videos/variable_turn_tictactoe_muzero/3/episode_002000.mp4\n",
      "Started recording episode 2000 to ./videos/variable_turn_tictactoe_muzero/0/episode_002000.mp4\n",
      "Stopped recording episode 2000. Recorded 7 frames.\n",
      "Stopped recording episode 2000. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n",
      "Started recording episode 2000 to ./videos/variable_turn_tictactoe_muzero/1/episode_002000.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped recording episode 2000. Recorded 7 frames.\n",
      "learning\n",
      "3800\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 6, 7, 0, 4],\n",
      "        [8, 3, 2, 1, 0],\n",
      "        [2, 8, 5, 0, 6],\n",
      "        [5, 8, 6, 7, 1],\n",
      "        [1, 2, 8, 3, 0],\n",
      "        [8, 0, 1, 7, 6],\n",
      "        [2, 0, 1, 3, 5],\n",
      "        [0, 3, 0, 7, 6]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.3926],\n",
      "         [ 0.3262],\n",
      "         [-0.2832],\n",
      "         [-0.3789],\n",
      "         [ 0.4062],\n",
      "         [ 0.2637]],\n",
      "\n",
      "        [[ 0.5859],\n",
      "         [-0.8125],\n",
      "         [-0.7109],\n",
      "         [ 0.7617],\n",
      "         [ 0.3828],\n",
      "         [ 0.0063]],\n",
      "\n",
      "        [[-0.0308],\n",
      "         [ 0.0708],\n",
      "         [ 0.3027],\n",
      "         [-0.0522],\n",
      "         [-0.0889],\n",
      "         [-0.0093]],\n",
      "\n",
      "        [[-0.5938],\n",
      "         [ 0.5156],\n",
      "         [ 0.4160],\n",
      "         [ 0.0718],\n",
      "         [-0.0679],\n",
      "         [ 0.4043]],\n",
      "\n",
      "        [[-0.8672],\n",
      "         [-0.7969],\n",
      "         [ 0.3379],\n",
      "         [ 0.3125],\n",
      "         [-0.0562],\n",
      "         [-0.0564]],\n",
      "\n",
      "        [[ 0.6953],\n",
      "         [ 0.0238],\n",
      "         [-0.1094],\n",
      "         [-0.0603],\n",
      "         [-0.0413],\n",
      "         [ 0.1797]],\n",
      "\n",
      "        [[ 0.5859],\n",
      "         [-0.7031],\n",
      "         [-0.6680],\n",
      "         [ 0.4629],\n",
      "         [ 0.3906],\n",
      "         [ 0.0491]],\n",
      "\n",
      "        [[ 0.1138],\n",
      "         [ 0.1846],\n",
      "         [ 0.0250],\n",
      "         [-0.1250],\n",
      "         [ 0.3281],\n",
      "         [ 0.1562]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0562],\n",
      "         [ 0.0154],\n",
      "         [ 0.0055],\n",
      "         [ 0.0028],\n",
      "         [ 0.0723]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0197],\n",
      "         [ 0.0040],\n",
      "         [-0.0498],\n",
      "         [ 0.1611],\n",
      "         [ 0.4844]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0129],\n",
      "         [ 0.4941],\n",
      "         [ 0.4199],\n",
      "         [ 0.0461],\n",
      "         [-0.0376]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0049],\n",
      "         [ 0.1631],\n",
      "         [ 0.8516],\n",
      "         [ 0.1816],\n",
      "         [ 0.3398]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0134],\n",
      "         [-0.0050],\n",
      "         [ 0.1768],\n",
      "         [ 0.4238],\n",
      "         [ 0.1182]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6016],\n",
      "         [ 0.3301],\n",
      "         [ 0.2158],\n",
      "         [ 0.1943],\n",
      "         [ 0.2617]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0513],\n",
      "         [-0.0605],\n",
      "         [ 0.0461],\n",
      "         [ 0.1445],\n",
      "         [ 0.7656]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0898],\n",
      "         [ 0.5742],\n",
      "         [ 0.0125],\n",
      "         [ 0.2295],\n",
      "         [ 0.2451]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.8746e-04],\n",
      "         [8.4305e-04, 1.0000e+00],\n",
      "         [4.8828e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 7.9632e-05],\n",
      "         [1.0000e+00, 7.2479e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.5204e-04, 1.0000e+00],\n",
      "         [7.2479e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 3.7384e-04],\n",
      "         [1.0000e+00, 1.9455e-04],\n",
      "         [8.0859e-01, 1.9238e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.6479e-03, 1.0000e+00],\n",
      "         [5.3906e-01, 4.5898e-01],\n",
      "         [1.0000e+00, 1.6251e-03],\n",
      "         [5.3125e-01, 4.6680e-01],\n",
      "         [2.0752e-02, 9.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.9591e-04],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [8.0078e-01, 1.9824e-01],\n",
      "         [2.2125e-03, 9.9609e-01],\n",
      "         [6.8750e-01, 3.1055e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.6894e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.8692e-03],\n",
      "         [1.0000e+00, 8.4877e-05],\n",
      "         [3.8867e-01, 6.1328e-01],\n",
      "         [6.5613e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.3125e-01, 4.6680e-01],\n",
      "         [9.8438e-01, 1.4526e-02],\n",
      "         [8.8672e-01, 1.1475e-01],\n",
      "         [9.3750e-02, 9.0625e-01],\n",
      "         [8.2422e-01, 1.7676e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.8746e-04, 1.0000e+00],\n",
      "         [1.7357e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.4836e-05],\n",
      "         [1.0000e+00, 1.0538e-04],\n",
      "         [8.6328e-01, 1.3770e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.9809e-04],\n",
      "         [6.3672e-01, 3.6328e-01],\n",
      "         [9.2773e-03, 9.9219e-01],\n",
      "         [8.3594e-01, 1.6309e-01],\n",
      "         [1.0000e+00, 1.0147e-03]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2000 to ./videos/variable_turn_tictactoe_muzero/2/episode_002000.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2000. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "3900\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 5, 0, 4, 2],\n",
      "        [2, 0, 6, 0, 8],\n",
      "        [6, 4, 3, 0, 8],\n",
      "        [2, 8, 0, 7, 8],\n",
      "        [6, 8, 7, 4, 0],\n",
      "        [5, 4, 0, 2, 8],\n",
      "        [5, 6, 0, 0, 8],\n",
      "        [3, 8, 2, 6, 0]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.3770],\n",
      "         [ 0.4395],\n",
      "         [ 0.4121],\n",
      "         [ 0.0133],\n",
      "         [-0.0129],\n",
      "         [ 0.2949]],\n",
      "\n",
      "        [[ 0.1758],\n",
      "         [-0.0479],\n",
      "         [-0.2021],\n",
      "         [ 0.3477],\n",
      "         [-0.0194],\n",
      "         [-0.0315]],\n",
      "\n",
      "        [[-0.3398],\n",
      "         [ 0.3574],\n",
      "         [ 0.3828],\n",
      "         [-0.0139],\n",
      "         [ 0.0068],\n",
      "         [-0.0064]],\n",
      "\n",
      "        [[-0.0132],\n",
      "         [ 0.2559],\n",
      "         [ 0.0190],\n",
      "         [ 0.0537],\n",
      "         [ 0.0009],\n",
      "         [-0.0063]],\n",
      "\n",
      "        [[-0.3555],\n",
      "         [-0.3652],\n",
      "         [ 0.3125],\n",
      "         [ 0.1328],\n",
      "         [ 0.0298],\n",
      "         [-0.0173]],\n",
      "\n",
      "        [[ 0.5508],\n",
      "         [-0.4453],\n",
      "         [-0.3066],\n",
      "         [ 0.3359],\n",
      "         [ 0.2793],\n",
      "         [ 0.1006]],\n",
      "\n",
      "        [[ 0.4941],\n",
      "         [-0.0183],\n",
      "         [-0.1982],\n",
      "         [ 0.2656],\n",
      "         [-0.0143],\n",
      "         [ 0.0400]],\n",
      "\n",
      "        [[-0.8477],\n",
      "         [-0.7070],\n",
      "         [ 0.7227],\n",
      "         [ 0.5000],\n",
      "         [ 0.0679],\n",
      "         [-0.0211]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [-8.2520e-02],\n",
      "         [ 6.3477e-02],\n",
      "         [ 6.3965e-02],\n",
      "         [ 9.8633e-02],\n",
      "         [ 3.0859e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.3633e-01],\n",
      "         [-4.4189e-02],\n",
      "         [ 3.1445e-01],\n",
      "         [ 7.3242e-02],\n",
      "         [ 3.7109e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-2.6489e-02],\n",
      "         [-4.7119e-02],\n",
      "         [ 8.2422e-01],\n",
      "         [ 1.4343e-02],\n",
      "         [ 2.0020e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.1289e-02],\n",
      "         [ 1.9141e-01],\n",
      "         [ 1.1230e-01],\n",
      "         [ 1.7188e-01],\n",
      "         [ 2.9688e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-4.2725e-02],\n",
      "         [-8.0566e-02],\n",
      "         [ 9.9609e-02],\n",
      "         [ 4.0820e-01],\n",
      "         [ 4.1260e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.3794e-02],\n",
      "         [-5.1025e-02],\n",
      "         [-4.7119e-02],\n",
      "         [ 4.5471e-03],\n",
      "         [ 7.0703e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 5.3125e-01],\n",
      "         [-2.3438e-02],\n",
      "         [ 2.9102e-01],\n",
      "         [ 6.9824e-02],\n",
      "         [ 3.4766e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-3.1982e-02],\n",
      "         [-2.3174e-04],\n",
      "         [ 1.5430e-01],\n",
      "         [ 1.1250e+00],\n",
      "         [ 1.4526e-02]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.8300e-03],\n",
      "         [1.0000e+00, 4.8399e-05],\n",
      "         [1.1719e-01, 8.8281e-01],\n",
      "         [1.0681e-03, 1.0000e+00],\n",
      "         [6.9141e-01, 3.0859e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.9844e-01, 6.0156e-01],\n",
      "         [4.2343e-04, 1.0000e+00],\n",
      "         [7.4609e-01, 2.5391e-01],\n",
      "         [9.7266e-01, 2.8687e-02],\n",
      "         [8.7109e-01, 1.2695e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [1.0000e+00, 1.4877e-04],\n",
      "         [8.9062e-01, 1.1084e-01],\n",
      "         [1.0315e-02, 9.8828e-01],\n",
      "         [4.2969e-01, 5.7031e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.1880e-04],\n",
      "         [1.0000e+00, 5.7983e-04],\n",
      "         [2.9297e-01, 7.0703e-01],\n",
      "         [8.0566e-03, 9.9219e-01],\n",
      "         [3.8086e-01, 6.2109e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.5095e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.8188e-05],\n",
      "         [1.0000e+00, 1.5831e-04],\n",
      "         [4.6289e-01, 5.3906e-01],\n",
      "         [7.4387e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.2343e-04, 1.0000e+00],\n",
      "         [2.7466e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 9.0122e-05],\n",
      "         [1.0000e+00, 8.4877e-05],\n",
      "         [7.8516e-01, 2.1484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.2891e-01, 3.7109e-01],\n",
      "         [1.8501e-04, 1.0000e+00],\n",
      "         [5.3906e-01, 4.5898e-01],\n",
      "         [9.8047e-01, 1.8677e-02],\n",
      "         [8.9062e-01, 1.0938e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.2187e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 2.0313e-04],\n",
      "         [1.0000e+00, 2.9325e-05],\n",
      "         [9.4531e-01, 5.4932e-02],\n",
      "         [8.0566e-03, 9.9219e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2100 to ./videos/variable_turn_tictactoe_muzero/0/episode_002100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2100 to ./videos/variable_turn_tictactoe_muzero/1/episode_002100.mp4\n",
      "learning\n",
      "Stopped recording episode 2100. Recorded 7 frames.\n",
      "Started recording episode 2100 to ./videos/variable_turn_tictactoe_muzero/3/episode_002100.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2100. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Started recording episode 2100 to ./videos/variable_turn_tictactoe_muzero/2/episode_002100.mp4\n",
      "Stopped recording episode 2100. Recorded 6 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4000\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[5, 1, 8, 3, 6],\n",
      "        [0, 0, 3, 1, 2],\n",
      "        [6, 0, 0, 1, 2],\n",
      "        [2, 4, 8, 7, 1],\n",
      "        [4, 3, 7, 6, 2],\n",
      "        [8, 0, 4, 2, 0],\n",
      "        [3, 0, 3, 1, 2],\n",
      "        [3, 0, 5, 1, 4]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.4512],\n",
      "         [ 0.3379],\n",
      "         [-0.3066],\n",
      "         [-0.3750],\n",
      "         [ 0.4336],\n",
      "         [ 0.3438]],\n",
      "\n",
      "        [[ 0.7266],\n",
      "         [ 0.0322],\n",
      "         [-0.0469],\n",
      "         [ 0.1367],\n",
      "         [ 0.1270],\n",
      "         [ 0.0483]],\n",
      "\n",
      "        [[-0.1206],\n",
      "         [ 0.1455],\n",
      "         [ 0.2598],\n",
      "         [-0.0070],\n",
      "         [ 0.1118],\n",
      "         [ 0.1650]],\n",
      "\n",
      "        [[ 0.4512],\n",
      "         [ 0.4492],\n",
      "         [-0.4727],\n",
      "         [-0.4824],\n",
      "         [ 0.6367],\n",
      "         [ 0.2256]],\n",
      "\n",
      "        [[-0.2617],\n",
      "         [-0.2490],\n",
      "         [ 0.1523],\n",
      "         [ 0.0574],\n",
      "         [ 0.0947],\n",
      "         [ 0.1348]],\n",
      "\n",
      "        [[-0.1826],\n",
      "         [ 0.3887],\n",
      "         [-0.0017],\n",
      "         [-0.0157],\n",
      "         [ 0.0781],\n",
      "         [ 0.0569]],\n",
      "\n",
      "        [[ 0.5742],\n",
      "         [ 0.2930],\n",
      "         [ 0.0986],\n",
      "         [-0.0042],\n",
      "         [ 0.3047],\n",
      "         [ 0.0776]],\n",
      "\n",
      "        [[ 0.4512],\n",
      "         [ 0.3574],\n",
      "         [-0.2598],\n",
      "         [-0.4062],\n",
      "         [ 0.4648],\n",
      "         [ 0.2266]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 7.2754e-02],\n",
      "         [-1.9073e-04],\n",
      "         [ 7.3853e-03],\n",
      "         [ 2.8381e-03],\n",
      "         [ 5.9082e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.7734e-01],\n",
      "         [-3.5645e-02],\n",
      "         [ 2.7344e-01],\n",
      "         [ 2.1680e-01],\n",
      "         [ 3.9844e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.5513e-02],\n",
      "         [ 5.3125e-01],\n",
      "         [ 5.8594e-02],\n",
      "         [ 2.0410e-01],\n",
      "         [ 3.8281e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-2.0996e-02],\n",
      "         [ 3.5400e-02],\n",
      "         [-1.4221e-02],\n",
      "         [ 3.4912e-02],\n",
      "         [ 2.5391e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-3.1586e-03],\n",
      "         [-3.6133e-02],\n",
      "         [ 1.0449e-01],\n",
      "         [ 4.3750e-01],\n",
      "         [ 1.2793e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.4893e-02],\n",
      "         [ 8.5938e-02],\n",
      "         [ 5.8594e-01],\n",
      "         [ 1.4160e-01],\n",
      "         [ 3.4766e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 3.6133e-01],\n",
      "         [ 2.0508e-01],\n",
      "         [ 1.6699e-01],\n",
      "         [ 2.9883e-01],\n",
      "         [ 5.7031e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-8.4473e-02],\n",
      "         [ 1.2329e-02],\n",
      "         [ 4.7363e-02],\n",
      "         [ 7.9590e-02],\n",
      "         [ 2.7734e-01]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.9325e-05],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.1648e-04],\n",
      "         [1.0000e+00, 2.2173e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.6094e-01, 4.0283e-02],\n",
      "         [1.9165e-02, 9.8047e-01],\n",
      "         [2.7734e-01, 7.2266e-01],\n",
      "         [9.4141e-01, 6.0547e-02],\n",
      "         [6.3281e-01, 3.6719e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4282e-02, 9.8438e-01],\n",
      "         [5.5859e-01, 4.4336e-01],\n",
      "         [9.2578e-01, 7.3730e-02],\n",
      "         [8.4375e-01, 1.5625e-01],\n",
      "         [3.8281e-01, 6.1719e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.8188e-05],\n",
      "         [3.6240e-04, 1.0000e+00],\n",
      "         [2.7537e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 8.4877e-05],\n",
      "         [1.0000e+00, 4.5204e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.7983e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0834e-03],\n",
      "         [1.0000e+00, 1.2665e-03],\n",
      "         [2.6367e-01, 7.3828e-01],\n",
      "         [9.5367e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.8610e-04],\n",
      "         [9.9609e-01, 2.4414e-03],\n",
      "         [6.1719e-01, 3.8086e-01],\n",
      "         [8.8120e-04, 1.0000e+00],\n",
      "         [4.3750e-01, 5.6250e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2684e-04],\n",
      "         [6.2109e-01, 3.7695e-01],\n",
      "         [8.3008e-03, 9.9219e-01],\n",
      "         [8.0078e-01, 1.9922e-01],\n",
      "         [9.8047e-01, 2.1484e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.1648e-04],\n",
      "         [1.9531e-03, 9.9609e-01],\n",
      "         [1.5831e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.4414e-03],\n",
      "         [1.0000e+00, 1.6308e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "learning\n",
      "Testing Player 0 vs Agent random\n",
      "Player 0 prediction: (tensor([0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0800, 0.1200, 0.0400, 0.1200]), tensor([0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0800, 0.1200, 0.0400, 0.1200]), 0.3905782451641376, tensor(2), {'network_policy': tensor([0.0752, 0.0752, 0.1133, 0.0938, 0.2070, 0.0840, 0.1602, 0.0801, 0.1108],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.43359375, 'search_policy': tensor([0.0800, 0.0400, 0.2400, 0.0800, 0.2000, 0.0800, 0.1200, 0.0400, 0.1200]), 'search_value': 0.3905782451641376, 'root_children_values': tensor([0.4570, 0.2734, 0.4935, 0.4258, 0.5247, 0.4219, 0.4566, 0.3008, 0.4395])})\n",
      "action: 2\n",
      "Player 0 prediction: (tensor([0.0800, 0.0400, 0.0000, 0.0400, 0.3600, 0.0400, 0.0800, 0.1600, 0.2000]), tensor([0.0800, 0.0400, 0.0000, 0.0400, 0.3600, 0.0400, 0.0800, 0.1600, 0.2000]), 0.48024241156944864, tensor(4), {'network_policy': tensor([0.1021, 0.0986, 0.0000, 0.0898, 0.2832, 0.0947, 0.1235, 0.0908, 0.1167],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.50390625, 'search_policy': tensor([0.0800, 0.0400, 0.0000, 0.0400, 0.3600, 0.0400, 0.0800, 0.1600, 0.2000]), 'search_value': 0.48024241156944864, 'root_children_values': tensor([-0.4746, -0.3906,  0.0000, -0.3945, -0.7008, -0.3457, -0.4564, -0.4420,\n",
      "        -0.5717])})\n",
      "action: 4\n",
      "Player 1 random action: 3\n",
      "Player 1 random action: 1\n",
      "Player 0 prediction: (tensor([0.0800, 0.0000, 0.0000, 0.0000, 0.0000, 0.1200, 0.5200, 0.1200, 0.1600]), tensor([0.0800, 0.0000, 0.0000, 0.0000, 0.0000, 0.1200, 0.5200, 0.1200, 0.1600]), 0.7994747275367151, tensor(6), {'network_policy': tensor([0.1289, 0.0000, 0.0000, 0.0000, 0.0000, 0.2012, 0.3086, 0.1758, 0.1826],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.58984375, 'search_policy': tensor([0.0800, 0.0000, 0.0000, 0.0000, 0.0000, 0.1200, 0.5200, 0.1200, 0.1600]), 'search_value': 0.7994747275367151, 'root_children_values': tensor([0.5312, 0.0000, 0.0000, 0.0000, 0.0000, 0.5124, 0.5676, 0.5945, 0.8350])})\n",
      "action: 6\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Player 0 win percentage vs random: 100.0 and average score: 1.0\n",
      "Testing Player 1 vs Agent random\n",
      "Player 0 random action: 6\n",
      "Player 0 random action: 0\n",
      "Player 1 prediction: (tensor([0.0000, 0.0800, 0.1200, 0.0800, 0.4400, 0.0400, 0.0000, 0.1200, 0.1200]), tensor([0.0000, 0.0800, 0.1200, 0.0800, 0.4400, 0.0400, 0.0000, 0.1200, 0.1200]), -0.3039571970426118, tensor(4), {'network_policy': tensor([0.0000, 0.1177, 0.1709, 0.1270, 0.1963, 0.0825, 0.0000, 0.1572, 0.1484],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.365234375, 'search_policy': tensor([0.0000, 0.0800, 0.1200, 0.0800, 0.4400, 0.0400, 0.0000, 0.1200, 0.1200]), 'search_value': -0.3039571970426118, 'root_children_values': tensor([ 0.0000, -0.3164, -0.3539, -0.3047, -0.2657, -0.4043,  0.0000, -0.3876,\n",
      "        -0.4141])})\n",
      "action: 4\n",
      "Player 1 prediction: (tensor([0.0000, 0.3200, 0.2000, 0.1200, 0.0000, 0.0800, 0.0000, 0.1200, 0.1600]), tensor([0.0000, 0.3200, 0.2000, 0.1200, 0.0000, 0.0800, 0.0000, 0.1200, 0.1600]), -0.2913034489558293, tensor(1), {'network_policy': tensor([0.0000, 0.1367, 0.2617, 0.1621, 0.0000, 0.0933, 0.0000, 0.1680, 0.1777],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.2265625, 'search_policy': tensor([0.0000, 0.3200, 0.2000, 0.1200, 0.0000, 0.0800, 0.0000, 0.1200, 0.1600]), 'search_value': -0.2913034489558293, 'root_children_values': tensor([0.0000, 0.3305, 0.2922, 0.3640, 0.0000, 0.3359, 0.0000, 0.3501, 0.2287])})\n",
      "action: 1\n",
      "Player 0 random action: 7\n",
      "Player 0 random action: 3\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 8, 0, 4, 1],\n",
      "        [0, 6, 0, 8, 0],\n",
      "        [7, 3, 2, 4, 5],\n",
      "        [4, 8, 2, 3, 0],\n",
      "        [2, 0, 5, 8, 0],\n",
      "        [1, 0, 0, 8, 0],\n",
      "        [4, 8, 2, 7, 1],\n",
      "        [6, 7, 0, 8, 3]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801]])\n",
      "predicted values tensor([[[ 4.4141e-01],\n",
      "         [ 2.8711e-01],\n",
      "         [-3.7109e-01],\n",
      "         [-5.0781e-01],\n",
      "         [ 2.8906e-01],\n",
      "         [ 3.5156e-02]],\n",
      "\n",
      "        [[-1.7334e-02],\n",
      "         [ 5.6250e-01],\n",
      "         [ 8.3008e-02],\n",
      "         [ 7.2754e-02],\n",
      "         [ 2.9541e-02],\n",
      "         [-2.6172e-01]],\n",
      "\n",
      "        [[ 4.4141e-01],\n",
      "         [ 2.8711e-01],\n",
      "         [-3.0469e-01],\n",
      "         [-4.0820e-01],\n",
      "         [ 1.1621e-01],\n",
      "         [ 1.9287e-02]],\n",
      "\n",
      "        [[ 5.4297e-01],\n",
      "         [ 1.4648e-01],\n",
      "         [ 1.5918e-01],\n",
      "         [ 8.2520e-02],\n",
      "         [-4.9316e-02],\n",
      "         [ 3.3691e-02]],\n",
      "\n",
      "        [[ 2.3926e-01],\n",
      "         [ 1.3574e-01],\n",
      "         [-1.9932e-04],\n",
      "         [ 1.3672e-01],\n",
      "         [ 1.2500e-01],\n",
      "         [ 1.7383e-01]],\n",
      "\n",
      "        [[ 2.5391e-01],\n",
      "         [ 4.5508e-01],\n",
      "         [ 1.6479e-02],\n",
      "         [ 7.4707e-02],\n",
      "         [ 2.5024e-02],\n",
      "         [-1.8945e-01]],\n",
      "\n",
      "        [[ 4.3359e-01],\n",
      "         [-5.7812e-01],\n",
      "         [-5.7031e-01],\n",
      "         [ 5.3516e-01],\n",
      "         [ 4.3945e-01],\n",
      "         [ 1.8164e-01]],\n",
      "\n",
      "        [[ 4.4141e-01],\n",
      "         [ 4.4336e-01],\n",
      "         [-1.8457e-01],\n",
      "         [-4.0820e-01],\n",
      "         [ 3.1055e-01],\n",
      "         [ 1.2109e-01]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0459],\n",
      "         [-0.0259],\n",
      "         [-0.0483],\n",
      "         [ 0.0043],\n",
      "         [ 0.1582]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1099],\n",
      "         [ 0.7656],\n",
      "         [ 0.0381],\n",
      "         [ 0.0679],\n",
      "         [-0.0713]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0459],\n",
      "         [-0.0311],\n",
      "         [-0.0869],\n",
      "         [-0.0461],\n",
      "         [ 0.0786]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2734],\n",
      "         [ 0.1099],\n",
      "         [ 0.5586],\n",
      "         [ 0.3340],\n",
      "         [-0.0090]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.6797],\n",
      "         [ 0.0225],\n",
      "         [ 0.1865],\n",
      "         [ 0.3457],\n",
      "         [-0.0493]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2295],\n",
      "         [ 0.3633],\n",
      "         [ 0.0212],\n",
      "         [ 0.0574],\n",
      "         [-0.0830]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0791],\n",
      "         [-0.0234],\n",
      "         [-0.0405],\n",
      "         [ 0.0894],\n",
      "         [ 0.3359]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0092],\n",
      "         [ 0.0209],\n",
      "         [-0.0275],\n",
      "         [-0.0135],\n",
      "         [ 0.0227]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.6280e-05],\n",
      "         [6.1798e-04, 1.0000e+00],\n",
      "         [1.1253e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3161e-04],\n",
      "         [1.0000e+00, 1.0681e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.2969e-01, 7.2266e-02],\n",
      "         [9.9609e-01, 1.9836e-03],\n",
      "         [5.9766e-01, 4.0234e-01],\n",
      "         [6.8054e-03, 9.9219e-01],\n",
      "         [7.0190e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.6280e-05],\n",
      "         [1.2817e-03, 1.0000e+00],\n",
      "         [6.3896e-05, 1.0000e+00],\n",
      "         [9.9609e-01, 1.9531e-03],\n",
      "         [1.0000e+00, 5.3406e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4766e-01, 6.5234e-01],\n",
      "         [9.6436e-03, 9.9219e-01],\n",
      "         [4.6875e-01, 5.3125e-01],\n",
      "         [1.0000e+00, 1.2054e-03],\n",
      "         [3.7695e-01, 6.2500e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.9258e-01, 6.0938e-01],\n",
      "         [7.9688e-01, 2.0215e-01],\n",
      "         [9.3359e-01, 6.4453e-02],\n",
      "         [5.6641e-01, 4.3359e-01],\n",
      "         [9.9609e-02, 8.9844e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.7344e-01, 2.2754e-01],\n",
      "         [1.0000e+00, 1.3046e-03],\n",
      "         [3.3789e-01, 6.6406e-01],\n",
      "         [8.4229e-03, 9.9219e-01],\n",
      "         [1.1572e-01, 8.8281e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.6240e-04, 1.0000e+00],\n",
      "         [1.1253e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 8.4043e-06],\n",
      "         [1.0000e+00, 4.5300e-05],\n",
      "         [6.5234e-01, 3.4766e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 9.8348e-06],\n",
      "         [7.0190e-03, 9.9219e-01],\n",
      "         [1.3161e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.8528e-04],\n",
      "         [1.0000e+00, 9.9182e-05]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2200 to ./videos/variable_turn_tictactoe_muzero/0/episode_002200.mp4\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2200 to ./videos/variable_turn_tictactoe_muzero/1/episode_002200.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2200. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2200 to ./videos/variable_turn_tictactoe_muzero/3/episode_002200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs random: 36.0 and average score: -0.22\n",
      "Results vs random: {'player_0_score': 1.0, 'player_0_win%': 1.0, 'player_1_score': -0.22, 'player_1_win%': 0.36, 'score': 0.39}\n",
      "Testing Player 0 vs Agent tictactoe_expert\n",
      "Player 0 prediction: (tensor([0.0400, 0.2000, 0.0800, 0.1200, 0.2000, 0.0400, 0.1600, 0.0400, 0.1200]), tensor([0.0400, 0.2000, 0.0800, 0.1200, 0.2000, 0.0400, 0.1600, 0.0400, 0.1200]), 0.3751516125300481, tensor(1), {'network_policy': tensor([0.0752, 0.0752, 0.1133, 0.0938, 0.2070, 0.0840, 0.1602, 0.0801, 0.1108],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.43359375, 'search_policy': tensor([0.0400, 0.2000, 0.0800, 0.1200, 0.2000, 0.0400, 0.1600, 0.0400, 0.1200]), 'search_value': 0.3751516125300481, 'root_children_values': tensor([0.3574, 0.3848, 0.5078, 0.3907, 0.5247, 0.2832, 0.4904, 0.3008, 0.4395])})\n",
      "action: 1\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0800, 0.0000, 0.0400, 0.0800, 0.4800, 0.1600, 0.0400, 0.0400, 0.0800]), tensor([0.0800, 0.0000, 0.0400, 0.0800, 0.4800, 0.1600, 0.0400, 0.0400, 0.0800]), 0.4300582803579476, tensor(4), {'network_policy': tensor([0.1055, 0.0000, 0.1025, 0.1118, 0.2432, 0.0986, 0.1221, 0.1001, 0.1147],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.318359375, 'search_policy': tensor([0.0800, 0.0000, 0.0400, 0.0800, 0.4800, 0.1600, 0.0400, 0.0400, 0.0800]), 'search_value': 0.4300582803579476, 'root_children_values': tensor([-0.4518,  0.0000, -0.4434, -0.4180, -0.6410, -0.3966, -0.3984, -0.3770,\n",
      "        -0.4805])})\n",
      "action: 4\n",
      "Player 1 tictactoe_expert action: 7\n",
      "Player 1 tictactoe_expert action: 6\n",
      "Player 0 prediction: (tensor([0.2000, 0.0000, 0.3600, 0.0800, 0.0000, 0.2000, 0.0000, 0.0000, 0.1600]), tensor([0.2000, 0.0000, 0.3600, 0.0800, 0.0000, 0.2000, 0.0000, 0.0000, 0.1600]), 0.3896280943509615, tensor(2), {'network_policy': tensor([0.1553, 0.0000, 0.2275, 0.1748, 0.0000, 0.1875, 0.0000, 0.0000, 0.2520],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.470703125, 'search_policy': tensor([0.2000, 0.0000, 0.3600, 0.0800, 0.0000, 0.2000, 0.0000, 0.0000, 0.1600]), 'search_value': 0.3896280943509615, 'root_children_values': tensor([0.2891, 0.0000, 0.3769, 0.2129, 0.0000, 0.2859, 0.0000, 0.0000, 0.2923])})\n",
      "action: 2\n",
      "Player 0 prediction: (tensor([0.2400, 0.0000, 0.0000, 0.0800, 0.0000, 0.4400, 0.0000, 0.0000, 0.2400]), tensor([0.2400, 0.0000, 0.0000, 0.0800, 0.0000, 0.4400, 0.0000, 0.0000, 0.2400]), 0.43049479503455534, tensor(5), {'network_policy': tensor([0.2236, 0.0000, 0.0000, 0.1973, 0.0000, 0.2236, 0.0000, 0.0000, 0.3535],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.5078125, 'search_policy': tensor([0.2400, 0.0000, 0.0000, 0.0800, 0.0000, 0.4400, 0.0000, 0.0000, 0.2400]), 'search_value': 0.43049479503455534, 'root_children_values': tensor([-0.0263,  0.0000,  0.0000,  0.2034,  0.0000, -0.1296,  0.0000,  0.0000,\n",
      "         0.2227])})\n",
      "action: 5\n",
      "Player 1 tictactoe_expert action: 8\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2200 to ./videos/variable_turn_tictactoe_muzero/2/episode_002200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2200. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "Player 0 win percentage vs tictactoe_expert: 82.0 and average score: 0.66\n",
      "Testing Player 1 vs Agent tictactoe_expert\n",
      "Player 0 tictactoe_expert action: 8\n",
      "Player 0 tictactoe_expert action: 3\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Player 1 prediction: (tensor([0.0800, 0.3200, 0.1200, 0.0000, 0.1600, 0.0800, 0.1200, 0.1200, 0.0000]), tensor([0.0800, 0.3200, 0.1200, 0.0000, 0.1600, 0.0800, 0.1200, 0.1200, 0.0000]), -0.3745212475703313, tensor(1), {'network_policy': tensor([0.1348, 0.1328, 0.1357, 0.0000, 0.1514, 0.1187, 0.1777, 0.1484, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.27734375, 'search_policy': tensor([0.0800, 0.3200, 0.1200, 0.0000, 0.1600, 0.0800, 0.1200, 0.1200, 0.0000]), 'search_value': -0.3745212475703313, 'root_children_values': tensor([-0.4629, -0.4472, -0.2891,  0.0000, -0.2462, -0.4805, -0.3887, -0.3649,\n",
      "         0.0000])})\n",
      "action: 1\n",
      "Player 1 prediction: (tensor([0.0800, 0.0000, 0.1600, 0.0000, 0.2800, 0.1600, 0.2000, 0.1200, 0.0000]), tensor([0.0800, 0.0000, 0.1600, 0.0000, 0.2800, 0.1600, 0.2000, 0.1200, 0.0000]), -0.36611807910156247, tensor(4), {'network_policy': tensor([0.1533, 0.0000, 0.1475, 0.0000, 0.1973, 0.1387, 0.1865, 0.1738, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.416015625, 'search_policy': tensor([0.0800, 0.0000, 0.1600, 0.0000, 0.2800, 0.1600, 0.2000, 0.1200, 0.0000]), 'search_value': -0.36611807910156247, 'root_children_values': tensor([0.4238, 0.0000, 0.4884, 0.0000, 0.1418, 0.3337, 0.3576, 0.5043, 0.0000])})\n",
      "action: 4\n",
      "Player 0 tictactoe_expert action: 7\n",
      "Player 0 tictactoe_expert action: 6\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 6, 5, 8, 0],\n",
      "        [8, 2, 1, 5, 3],\n",
      "        [4, 3, 7, 8, 6],\n",
      "        [0, 6, 3, 0, 8],\n",
      "        [1, 3, 0, 6, 8],\n",
      "        [0, 0, 0, 6, 8],\n",
      "        [4, 0, 2, 0, 8],\n",
      "        [6, 2, 8, 0, 7]])\n",
      "target value tensor([[ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.3320],\n",
      "         [ 0.1016],\n",
      "         [-0.1011],\n",
      "         [ 0.5156],\n",
      "         [ 0.1309],\n",
      "         [ 0.0396]],\n",
      "\n",
      "        [[ 0.4688],\n",
      "         [-0.5547],\n",
      "         [-0.5352],\n",
      "         [ 0.6094],\n",
      "         [ 0.6055],\n",
      "         [ 0.0791]],\n",
      "\n",
      "        [[ 0.5352],\n",
      "         [ 0.6016],\n",
      "         [-0.5000],\n",
      "         [-0.6016],\n",
      "         [ 0.7852],\n",
      "         [ 0.6250]],\n",
      "\n",
      "        [[-0.5742],\n",
      "         [-0.5820],\n",
      "         [ 0.4590],\n",
      "         [ 0.3066],\n",
      "         [ 0.0337],\n",
      "         [-0.0214]],\n",
      "\n",
      "        [[ 0.1206],\n",
      "         [ 0.3711],\n",
      "         [ 0.0713],\n",
      "         [ 0.0820],\n",
      "         [ 0.0302],\n",
      "         [-0.0033]],\n",
      "\n",
      "        [[ 0.2656],\n",
      "         [ 0.1836],\n",
      "         [ 0.1045],\n",
      "         [ 0.0840],\n",
      "         [ 0.1309],\n",
      "         [ 0.1128]],\n",
      "\n",
      "        [[ 0.3867],\n",
      "         [-0.0457],\n",
      "         [-0.0229],\n",
      "         [ 0.2344],\n",
      "         [ 0.0248],\n",
      "         [ 0.0491]],\n",
      "\n",
      "        [[ 0.4688],\n",
      "         [-0.5391],\n",
      "         [-0.5234],\n",
      "         [ 0.4863],\n",
      "         [ 0.3184],\n",
      "         [ 0.1680]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.4141],\n",
      "         [ 0.1289],\n",
      "         [ 0.3281],\n",
      "         [ 0.6367],\n",
      "         [ 0.0250]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0017],\n",
      "         [ 0.0068],\n",
      "         [-0.0114],\n",
      "         [ 0.1016],\n",
      "         [ 0.6484]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0085],\n",
      "         [-0.0327],\n",
      "         [ 0.0117],\n",
      "         [-0.0071],\n",
      "         [ 0.0850]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0068],\n",
      "         [ 0.0032],\n",
      "         [ 0.2520],\n",
      "         [ 0.1406],\n",
      "         [ 0.0869]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3457],\n",
      "         [ 0.3672],\n",
      "         [ 0.0121],\n",
      "         [ 0.0286],\n",
      "         [ 0.0898]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4277],\n",
      "         [ 0.0251],\n",
      "         [-0.1035],\n",
      "         [-0.0320],\n",
      "         [ 0.2275]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2256],\n",
      "         [ 0.0557],\n",
      "         [ 0.4121],\n",
      "         [ 0.0815],\n",
      "         [ 0.4043]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0317],\n",
      "         [-0.0050],\n",
      "         [-0.0091],\n",
      "         [ 0.0349],\n",
      "         [ 0.3848]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.5723e-01, 8.4375e-01],\n",
      "         [1.6708e-03, 1.0000e+00],\n",
      "         [8.6719e-01, 1.3379e-01],\n",
      "         [1.0000e+00, 7.2098e-04],\n",
      "         [4.1992e-01, 5.7812e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.9591e-04, 1.0000e+00],\n",
      "         [2.2173e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.8174e-05],\n",
      "         [1.0000e+00, 2.1458e-05],\n",
      "         [6.2500e-01, 3.7305e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.5204e-04],\n",
      "         [5.5313e-04, 1.0000e+00],\n",
      "         [5.8174e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3161e-04],\n",
      "         [1.0000e+00, 9.2983e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.2302e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.9741e-04],\n",
      "         [1.0000e+00, 9.0122e-05],\n",
      "         [5.8594e-01, 4.1602e-01],\n",
      "         [4.8065e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.9062e-01, 1.0986e-01],\n",
      "         [9.8828e-01, 1.0010e-02],\n",
      "         [5.6250e-01, 4.3555e-01],\n",
      "         [6.5918e-03, 9.9219e-01],\n",
      "         [4.3555e-01, 5.6641e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4375e-01, 6.5625e-01],\n",
      "         [4.2383e-01, 5.7812e-01],\n",
      "         [2.3145e-01, 7.6953e-01],\n",
      "         [1.1865e-01, 8.8281e-01],\n",
      "         [4.7070e-01, 5.2734e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.9102e-02, 9.2188e-01],\n",
      "         [2.0996e-02, 9.8047e-01],\n",
      "         [6.4453e-01, 3.5742e-01],\n",
      "         [9.3359e-01, 6.6895e-02],\n",
      "         [7.9688e-01, 2.0410e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.5204e-04, 1.0000e+00],\n",
      "         [8.4877e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.1498e-05],\n",
      "         [1.0000e+00, 7.7248e-05],\n",
      "         [5.0000e-01, 5.0000e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs tictactoe_expert: 6.0 and average score: -0.84\n",
      "Results vs tictactoe_expert: {'player_0_score': 0.66, 'player_0_win%': 0.82, 'player_1_score': -0.84, 'player_1_win%': 0.06, 'score': -0.08999999999999997}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2300 to ./videos/variable_turn_tictactoe_muzero/0/episode_002300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2300 to ./videos/variable_turn_tictactoe_muzero/1/episode_002300.mp4\n",
      "learning\n",
      "Stopped recording episode 2300. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2300. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Started recording episode 2300 to ./videos/variable_turn_tictactoe_muzero/3/episode_002300.mp4\n",
      "Stopped recording episode 2300. Recorded 7 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 0, 2, 5, 0],\n",
      "        [5, 6, 7, 0, 1],\n",
      "        [3, 0, 5, 2, 3],\n",
      "        [2, 6, 5, 0, 4],\n",
      "        [2, 4, 0, 2, 3],\n",
      "        [0, 4, 0, 2, 3],\n",
      "        [4, 0, 5, 2, 3],\n",
      "        [7, 1, 6, 2, 0]])\n",
      "target value tensor([[-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.0469],\n",
      "         [ 0.0581],\n",
      "         [ 0.1514],\n",
      "         [ 0.1465],\n",
      "         [ 0.2266],\n",
      "         [ 0.0447]],\n",
      "\n",
      "        [[ 0.5195],\n",
      "         [ 0.3613],\n",
      "         [ 0.0591],\n",
      "         [-0.1855],\n",
      "         [ 0.2539],\n",
      "         [-0.0486]],\n",
      "\n",
      "        [[ 0.3711],\n",
      "         [ 0.0259],\n",
      "         [ 0.0483],\n",
      "         [-0.0134],\n",
      "         [ 0.2891],\n",
      "         [ 0.1699]],\n",
      "\n",
      "        [[ 0.3184],\n",
      "         [-0.2500],\n",
      "         [-0.3828],\n",
      "         [ 0.3594],\n",
      "         [ 0.1777],\n",
      "         [ 0.1758]],\n",
      "\n",
      "        [[ 0.3691],\n",
      "         [ 0.4297],\n",
      "         [ 0.1211],\n",
      "         [ 0.0277],\n",
      "         [ 0.0908],\n",
      "         [ 0.0991]],\n",
      "\n",
      "        [[ 0.7578],\n",
      "         [ 0.2539],\n",
      "         [ 0.0718],\n",
      "         [ 0.0615],\n",
      "         [ 0.1826],\n",
      "         [ 0.0840]],\n",
      "\n",
      "        [[ 0.4766],\n",
      "         [ 0.5000],\n",
      "         [ 0.0337],\n",
      "         [ 0.0654],\n",
      "         [ 0.0811],\n",
      "         [ 0.1064]],\n",
      "\n",
      "        [[-0.4883],\n",
      "         [-0.5586],\n",
      "         [ 0.6055],\n",
      "         [ 0.5312],\n",
      "         [ 0.0991],\n",
      "         [ 0.0576]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0248],\n",
      "         [ 0.1152],\n",
      "         [ 0.2139],\n",
      "         [ 0.4238],\n",
      "         [-0.0388]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0767],\n",
      "         [ 0.3672],\n",
      "         [ 0.0398],\n",
      "         [ 0.1206],\n",
      "         [ 0.3750]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.8633],\n",
      "         [-0.0461],\n",
      "         [ 0.0654],\n",
      "         [ 0.0654],\n",
      "         [ 0.2080]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0762],\n",
      "         [-0.0342],\n",
      "         [-0.0430],\n",
      "         [ 0.0732],\n",
      "         [ 0.4414]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0903],\n",
      "         [ 0.4941],\n",
      "         [-0.0430],\n",
      "         [ 0.2148],\n",
      "         [ 0.0459]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0603],\n",
      "         [ 0.3398],\n",
      "         [-0.0496],\n",
      "         [ 0.3164],\n",
      "         [ 0.2051]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2910],\n",
      "         [ 0.1367],\n",
      "         [ 0.0165],\n",
      "         [ 0.2617],\n",
      "         [ 0.0884]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0019],\n",
      "         [ 0.0159],\n",
      "         [ 0.0649],\n",
      "         [ 0.8672],\n",
      "         [-0.0139]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 2.1820e-03],\n",
      "         [6.5430e-02, 9.3359e-01],\n",
      "         [1.8082e-03, 1.0000e+00],\n",
      "         [5.7812e-01, 4.1992e-01],\n",
      "         [7.3828e-01, 2.5977e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.9073e-04],\n",
      "         [6.7383e-02, 9.3359e-01],\n",
      "         [4.8828e-04, 1.0000e+00],\n",
      "         [8.0859e-01, 1.9238e-01],\n",
      "         [1.0000e+00, 1.0147e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 8.3008e-03],\n",
      "         [3.3264e-03, 9.9609e-01],\n",
      "         [2.5024e-02, 9.7656e-01],\n",
      "         [1.0000e+00, 7.3242e-04],\n",
      "         [8.2812e-01, 1.7188e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.5313e-04, 1.0000e+00],\n",
      "         [1.1587e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.3828e-05],\n",
      "         [9.9219e-01, 5.9204e-03],\n",
      "         [2.9492e-01, 7.0703e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.8174e-05],\n",
      "         [4.5312e-01, 5.4688e-01],\n",
      "         [1.0872e-04, 1.0000e+00],\n",
      "         [3.8281e-01, 6.1719e-01],\n",
      "         [9.7656e-01, 2.2827e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.2969e-01, 6.9336e-02],\n",
      "         [2.1191e-01, 7.8906e-01],\n",
      "         [1.4572e-03, 1.0000e+00],\n",
      "         [3.7109e-01, 6.2891e-01],\n",
      "         [9.8828e-01, 1.2817e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3161e-04],\n",
      "         [6.1719e-01, 3.8086e-01],\n",
      "         [5.2643e-04, 1.0000e+00],\n",
      "         [3.6914e-01, 6.3281e-01],\n",
      "         [9.4922e-01, 5.2246e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.0313e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.3705e-04],\n",
      "         [1.0000e+00, 5.7220e-04],\n",
      "         [8.9062e-01, 1.1084e-01],\n",
      "         [1.2665e-03, 1.0000e+00]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2300 to ./videos/variable_turn_tictactoe_muzero/2/episode_002300.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2300. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "average score: 0.82\n",
      "Test score {'score': 0.82, 'max_score': 1, 'min_score': -1}\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 3, 0, 1, 6],\n",
      "        [2, 0, 5, 1, 0],\n",
      "        [4, 6, 1, 0, 3],\n",
      "        [0, 4, 2, 6, 8],\n",
      "        [2, 4, 0, 7, 0],\n",
      "        [2, 6, 3, 5, 0],\n",
      "        [0, 0, 3, 1, 6],\n",
      "        [2, 0, 3, 1, 6]])\n",
      "target value tensor([[-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[-0.3848],\n",
      "         [ 0.6953],\n",
      "         [ 0.6133],\n",
      "         [ 0.1494],\n",
      "         [ 0.2178],\n",
      "         [ 0.3848]],\n",
      "\n",
      "        [[ 0.0240],\n",
      "         [ 0.1147],\n",
      "         [-0.0486],\n",
      "         [ 0.3750],\n",
      "         [ 0.0552],\n",
      "         [ 0.0417]],\n",
      "\n",
      "        [[ 0.5469],\n",
      "         [ 0.7109],\n",
      "         [-0.5664],\n",
      "         [-0.5195],\n",
      "         [ 0.8633],\n",
      "         [ 0.5938]],\n",
      "\n",
      "        [[ 0.4336],\n",
      "         [-0.2891],\n",
      "         [-0.3320],\n",
      "         [ 0.3086],\n",
      "         [ 0.2988],\n",
      "         [ 0.2119]],\n",
      "\n",
      "        [[-0.3555],\n",
      "         [-0.4785],\n",
      "         [ 0.3867],\n",
      "         [ 0.2969],\n",
      "         [ 0.1660],\n",
      "         [ 0.0757]],\n",
      "\n",
      "        [[ 0.3867],\n",
      "         [ 0.2383],\n",
      "         [ 0.1836],\n",
      "         [ 0.1611],\n",
      "         [ 0.2129],\n",
      "         [ 0.0659]],\n",
      "\n",
      "        [[ 0.0166],\n",
      "         [ 0.3887],\n",
      "         [ 0.0425],\n",
      "         [ 0.0923],\n",
      "         [ 0.1221],\n",
      "         [ 0.2178]],\n",
      "\n",
      "        [[ 0.5625],\n",
      "         [ 0.1504],\n",
      "         [ 0.0554],\n",
      "         [ 0.0747],\n",
      "         [ 0.1338],\n",
      "         [ 0.1855]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0432],\n",
      "         [ 0.0908],\n",
      "         [ 0.0126],\n",
      "         [ 0.0559],\n",
      "         [ 0.1040]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1631],\n",
      "         [ 0.0996],\n",
      "         [ 0.2754],\n",
      "         [ 0.4082],\n",
      "         [-0.0698]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0179],\n",
      "         [-0.0317],\n",
      "         [ 0.0113],\n",
      "         [-0.0437],\n",
      "         [ 0.0996]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0206],\n",
      "         [ 0.0008],\n",
      "         [ 0.0255],\n",
      "         [ 0.1211],\n",
      "         [ 0.4160]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0030],\n",
      "         [ 0.0010],\n",
      "         [ 0.1011],\n",
      "         [ 0.3105],\n",
      "         [ 0.0090]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1128],\n",
      "         [ 0.3281],\n",
      "         [ 0.1582],\n",
      "         [ 0.5391],\n",
      "         [-0.1104]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2754],\n",
      "         [ 0.0260],\n",
      "         [ 0.4199],\n",
      "         [ 0.1455],\n",
      "         [ 0.2070]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4062],\n",
      "         [-0.1104],\n",
      "         [ 0.1885],\n",
      "         [ 0.2188],\n",
      "         [ 0.1699]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.5488e-03],\n",
      "         [1.0000e+00, 2.3460e-04],\n",
      "         [7.6953e-01, 2.3047e-01],\n",
      "         [1.2329e-02, 9.8828e-01],\n",
      "         [6.6406e-01, 3.3398e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.7373e-02, 9.4141e-01],\n",
      "         [6.1798e-04, 1.0000e+00],\n",
      "         [6.8359e-01, 3.1641e-01],\n",
      "         [1.0000e+00, 9.3842e-04],\n",
      "         [4.4531e-01, 5.5469e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.1362e-04],\n",
      "         [1.1139e-03, 1.0000e+00],\n",
      "         [1.0538e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 9.2983e-05],\n",
      "         [1.0000e+00, 3.8862e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.1171e-04, 1.0000e+00],\n",
      "         [1.0452e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 2.4128e-04],\n",
      "         [1.0000e+00, 1.8787e-04],\n",
      "         [5.9375e-01, 4.0625e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.1969e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.5368e-04],\n",
      "         [1.0000e+00, 8.2779e-04],\n",
      "         [4.5703e-01, 5.4297e-01],\n",
      "         [8.9722e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9219e-01, 6.5002e-03],\n",
      "         [5.1953e-01, 4.8242e-01],\n",
      "         [2.8076e-03, 9.9609e-01],\n",
      "         [3.3984e-01, 6.6016e-01],\n",
      "         [9.2578e-01, 7.3242e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.5391e-01, 2.4707e-01],\n",
      "         [9.4922e-01, 5.1025e-02],\n",
      "         [8.0469e-01, 1.9531e-01],\n",
      "         [9.6680e-02, 9.0234e-01],\n",
      "         [1.9409e-02, 9.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4258e-01, 8.5938e-01],\n",
      "         [1.1816e-01, 8.8281e-01],\n",
      "         [6.0938e-01, 3.9258e-01],\n",
      "         [9.6484e-01, 3.4424e-02],\n",
      "         [1.6113e-01, 8.3984e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2400 to ./videos/variable_turn_tictactoe_muzero/1/episode_002400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2400 to ./videos/variable_turn_tictactoe_muzero/0/episode_002400.mp4\n",
      "learning\n",
      "Stopped recording episode 2400. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2400. Recorded 9 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2400 to ./videos/variable_turn_tictactoe_muzero/3/episode_002400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2400. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2400 to ./videos/variable_turn_tictactoe_muzero/2/episode_002400.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2400. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 2, 3, 7, 5],\n",
      "        [0, 5, 3, 2, 8],\n",
      "        [2, 3, 8, 0, 1],\n",
      "        [3, 4, 6, 2, 8],\n",
      "        [8, 5, 0, 7, 1],\n",
      "        [1, 6, 4, 8, 0],\n",
      "        [2, 4, 0, 6, 8],\n",
      "        [2, 3, 6, 8, 0]])\n",
      "target value tensor([[ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 4.6094e-01],\n",
      "         [ 7.5000e-01],\n",
      "         [-5.1172e-01],\n",
      "         [-6.4062e-01],\n",
      "         [ 7.6562e-01],\n",
      "         [ 7.0312e-01]],\n",
      "\n",
      "        [[-3.7109e-01],\n",
      "         [-3.9062e-01],\n",
      "         [ 6.7188e-01],\n",
      "         [ 3.2617e-01],\n",
      "         [ 6.2012e-02],\n",
      "         [-7.9727e-04]],\n",
      "\n",
      "        [[ 3.8338e-04],\n",
      "         [ 1.4160e-01],\n",
      "         [ 2.5000e-01],\n",
      "         [ 2.6367e-01],\n",
      "         [ 5.0537e-02],\n",
      "         [ 2.4023e-01]],\n",
      "\n",
      "        [[ 4.6094e-01],\n",
      "         [ 4.8047e-01],\n",
      "         [-3.3203e-01],\n",
      "         [-4.2383e-01],\n",
      "         [ 2.1582e-01],\n",
      "         [ 2.7734e-01]],\n",
      "\n",
      "        [[ 6.5613e-03],\n",
      "         [ 2.6172e-01],\n",
      "         [ 2.4805e-01],\n",
      "         [ 1.2012e-01],\n",
      "         [ 3.0273e-01],\n",
      "         [ 1.5332e-01]],\n",
      "\n",
      "        [[-3.4961e-01],\n",
      "         [-3.0859e-01],\n",
      "         [ 5.6641e-01],\n",
      "         [ 4.3750e-01],\n",
      "         [ 1.6016e-01],\n",
      "         [ 6.3477e-02]],\n",
      "\n",
      "        [[ 4.6094e-01],\n",
      "         [ 4.9023e-01],\n",
      "         [-4.9609e-01],\n",
      "         [-5.5469e-01],\n",
      "         [ 7.2266e-01],\n",
      "         [ 3.9258e-01]],\n",
      "\n",
      "        [[-6.6406e-01],\n",
      "         [-4.0820e-01],\n",
      "         [ 6.3672e-01],\n",
      "         [ 4.3750e-01],\n",
      "         [ 1.4355e-01],\n",
      "         [ 1.9531e-02]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 2.1118e-02],\n",
      "         [ 1.0303e-01],\n",
      "         [-7.6904e-03],\n",
      "         [-3.3203e-02],\n",
      "         [ 2.0508e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.7090e-02],\n",
      "         [-3.0396e-02],\n",
      "         [ 2.7344e-01],\n",
      "         [ 4.2969e-01],\n",
      "         [ 1.1182e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.9824e-01],\n",
      "         [ 2.4316e-01],\n",
      "         [ 4.2188e-01],\n",
      "         [ 2.6245e-02],\n",
      "         [ 1.7480e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.4768e-03],\n",
      "         [ 3.0762e-02],\n",
      "         [ 2.3499e-03],\n",
      "         [-9.3460e-04],\n",
      "         [ 8.3984e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.4746e-01],\n",
      "         [ 3.0078e-01],\n",
      "         [ 9.5703e-02],\n",
      "         [ 3.4766e-01],\n",
      "         [ 3.6523e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 8.3618e-03],\n",
      "         [-3.4424e-02],\n",
      "         [ 1.5723e-01],\n",
      "         [ 4.8242e-01],\n",
      "         [-2.1851e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.5450e-04],\n",
      "         [ 8.3008e-02],\n",
      "         [-3.8574e-02],\n",
      "         [-2.3315e-02],\n",
      "         [ 3.0859e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 7.2632e-03],\n",
      "         [ 2.4292e-02],\n",
      "         [ 5.1562e-01],\n",
      "         [ 6.9531e-01],\n",
      "         [-5.5542e-03]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.2187e-05],\n",
      "         [1.7212e-02, 9.8438e-01],\n",
      "         [8.4877e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.0354e-04],\n",
      "         [1.0000e+00, 3.5286e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.5030e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.1253e-04],\n",
      "         [1.0000e+00, 1.1861e-05],\n",
      "         [4.0039e-01, 6.0156e-01],\n",
      "         [5.4626e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.5078e-01, 4.4922e-01],\n",
      "         [5.2246e-02, 9.4922e-01],\n",
      "         [5.9375e-01, 4.0430e-01],\n",
      "         [8.5156e-01, 1.4746e-01],\n",
      "         [8.6328e-01, 1.3770e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.6703e-05],\n",
      "         [1.3611e-02, 9.8828e-01],\n",
      "         [8.7738e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.7220e-04],\n",
      "         [1.0000e+00, 6.8188e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.6308e-04],\n",
      "         [5.3906e-01, 4.6094e-01],\n",
      "         [9.1553e-03, 9.9219e-01],\n",
      "         [6.9141e-01, 3.1055e-01],\n",
      "         [1.0000e+00, 7.3242e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.2665e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 1.5199e-05],\n",
      "         [1.0000e+00, 2.2697e-04],\n",
      "         [7.0312e-01, 2.9883e-01],\n",
      "         [3.1494e-02, 9.6875e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3828e-05],\n",
      "         [7.3547e-03, 9.9219e-01],\n",
      "         [2.3079e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 7.4863e-05],\n",
      "         [1.0000e+00, 1.1146e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.9302e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 3.2187e-05],\n",
      "         [1.0000e+00, 1.0872e-04],\n",
      "         [8.8281e-01, 1.1572e-01],\n",
      "         [4.1748e-02, 9.5703e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2500 to ./videos/variable_turn_tictactoe_muzero/1/episode_002500.mp4\n",
      "Started recording episode 2500 to ./videos/variable_turn_tictactoe_muzero/0/episode_002500.mp4\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Stopped recording episode 2500. Recorded 7 frames.\n",
      "Stopped recording episode 2500. Recorded 8 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 2500 to ./videos/variable_turn_tictactoe_muzero/3/episode_002500.mp4\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n",
      "Stopped recording episode 2500. Recorded 7 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 4, 7, 0, 5],\n",
      "        [2, 4, 0, 2, 5],\n",
      "        [0, 1, 8, 2, 3],\n",
      "        [5, 7, 0, 2, 5],\n",
      "        [2, 4, 7, 5, 1],\n",
      "        [2, 5, 6, 8, 1],\n",
      "        [0, 1, 6, 0, 5],\n",
      "        [5, 6, 7, 8, 2]])\n",
      "target value tensor([[-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4082],\n",
      "         [ 0.1240],\n",
      "         [ 0.1484],\n",
      "         [ 0.2051],\n",
      "         [ 0.0825],\n",
      "         [ 0.0962]],\n",
      "\n",
      "        [[-0.1357],\n",
      "         [ 0.3223],\n",
      "         [ 0.2285],\n",
      "         [ 0.2031],\n",
      "         [ 0.1050],\n",
      "         [ 0.1943]],\n",
      "\n",
      "        [[ 0.3633],\n",
      "         [-0.5586],\n",
      "         [-0.6367],\n",
      "         [ 0.7500],\n",
      "         [ 0.5781],\n",
      "         [ 0.0520]],\n",
      "\n",
      "        [[ 0.0684],\n",
      "         [ 0.2754],\n",
      "         [ 0.1099],\n",
      "         [ 0.0996],\n",
      "         [ 0.0623],\n",
      "         [ 0.0569]],\n",
      "\n",
      "        [[ 0.5469],\n",
      "         [ 0.5508],\n",
      "         [-0.5391],\n",
      "         [-0.5898],\n",
      "         [ 0.7344],\n",
      "         [ 0.6172]],\n",
      "\n",
      "        [[ 0.3633],\n",
      "         [-0.5430],\n",
      "         [-0.5742],\n",
      "         [ 0.6523],\n",
      "         [ 0.5352],\n",
      "         [ 0.1514]],\n",
      "\n",
      "        [[-0.0618],\n",
      "         [ 0.1895],\n",
      "         [ 0.2559],\n",
      "         [ 0.1357],\n",
      "         [ 0.0242],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[ 0.3633],\n",
      "         [-0.4980],\n",
      "         [-0.4199],\n",
      "         [ 0.5703],\n",
      "         [ 0.6328],\n",
      "         [ 0.1719]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.8047],\n",
      "         [ 0.4629],\n",
      "         [ 0.6641],\n",
      "         [ 0.0957],\n",
      "         [ 0.3105]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0175],\n",
      "         [ 0.1074],\n",
      "         [ 0.0737],\n",
      "         [ 0.1367],\n",
      "         [ 0.2715]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0265],\n",
      "         [ 0.0693],\n",
      "         [ 0.0391],\n",
      "         [ 0.2695],\n",
      "         [ 0.3418]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2266],\n",
      "         [ 0.6055],\n",
      "         [-0.0031],\n",
      "         [ 0.1240],\n",
      "         [ 0.1416]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0591],\n",
      "         [-0.0098],\n",
      "         [-0.0413],\n",
      "         [-0.0449],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0033],\n",
      "         [-0.0253],\n",
      "         [-0.0072],\n",
      "         [ 0.1699],\n",
      "         [ 0.0996]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4805],\n",
      "         [ 0.2119],\n",
      "         [ 0.7148],\n",
      "         [ 0.0581],\n",
      "         [ 0.4395]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0488],\n",
      "         [ 0.0060],\n",
      "         [-0.0267],\n",
      "         [ 0.1270],\n",
      "         [ 0.8672]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [6.0547e-01, 3.9453e-01],\n",
      "         [1.0498e-02, 9.8828e-01],\n",
      "         [1.6504e-01, 8.3594e-01],\n",
      "         [2.4121e-01, 7.5781e-01],\n",
      "         [8.2031e-01, 1.8066e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.3079e-04],\n",
      "         [1.0000e+00, 1.2684e-04],\n",
      "         [9.3262e-02, 9.0625e-01],\n",
      "         [2.6894e-04, 1.0000e+00],\n",
      "         [2.8320e-01, 7.1484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.7548e-03, 1.0000e+00],\n",
      "         [1.9550e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 8.2779e-04],\n",
      "         [1.0000e+00, 7.4863e-05],\n",
      "         [1.7578e-01, 8.2422e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.9219e-01, 5.0781e-01],\n",
      "         [9.2969e-01, 6.8848e-02],\n",
      "         [1.6113e-01, 8.3984e-01],\n",
      "         [3.1281e-03, 9.9609e-01],\n",
      "         [8.4961e-02, 9.1406e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.4142e-04],\n",
      "         [9.6321e-05, 1.0000e+00],\n",
      "         [3.8862e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 7.6675e-04],\n",
      "         [1.0000e+00, 1.3161e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4523e-04, 1.0000e+00],\n",
      "         [4.5300e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 4.4441e-04],\n",
      "         [1.0000e+00, 3.7670e-05],\n",
      "         [4.7119e-02, 9.5312e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.2383e-01, 5.7812e-01],\n",
      "         [3.1281e-03, 9.9609e-01],\n",
      "         [1.0693e-01, 8.9453e-01],\n",
      "         [6.6797e-01, 3.3203e-01],\n",
      "         [8.8672e-01, 1.1328e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.9073e-04, 1.0000e+00],\n",
      "         [6.8188e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 9.8419e-04],\n",
      "         [1.0000e+00, 6.8188e-05],\n",
      "         [7.2266e-01, 2.7539e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2500 to ./videos/variable_turn_tictactoe_muzero/2/episode_002500.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2500. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4700\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 0, 7, 2, 7],\n",
      "        [2, 7, 4, 1, 6],\n",
      "        [7, 0, 7, 2, 7],\n",
      "        [1, 0, 7, 2, 7],\n",
      "        [4, 0, 7, 2, 7],\n",
      "        [7, 5, 0, 2, 6],\n",
      "        [8, 3, 5, 6, 7],\n",
      "        [6, 1, 4, 3, 0]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.5508],\n",
      "         [ 0.2002],\n",
      "         [-0.1748],\n",
      "         [ 0.3477],\n",
      "         [ 0.2891],\n",
      "         [ 0.0674]],\n",
      "\n",
      "        [[-0.3477],\n",
      "         [ 0.7266],\n",
      "         [ 0.3594],\n",
      "         [ 0.1143],\n",
      "         [-0.0957],\n",
      "         [ 0.3398]],\n",
      "\n",
      "        [[ 0.2656],\n",
      "         [ 0.2168],\n",
      "         [ 0.1289],\n",
      "         [ 0.1201],\n",
      "         [ 0.0767],\n",
      "         [-0.0042]],\n",
      "\n",
      "        [[ 0.2539],\n",
      "         [ 0.2852],\n",
      "         [ 0.0179],\n",
      "         [-0.0214],\n",
      "         [ 0.1064],\n",
      "         [ 0.0275]],\n",
      "\n",
      "        [[ 0.7734],\n",
      "         [ 0.0232],\n",
      "         [ 0.0081],\n",
      "         [ 0.3359],\n",
      "         [ 0.2539],\n",
      "         [ 0.0500]],\n",
      "\n",
      "        [[ 0.6641],\n",
      "         [-0.7305],\n",
      "         [-0.7695],\n",
      "         [ 0.6133],\n",
      "         [ 0.6055],\n",
      "         [ 0.0781]],\n",
      "\n",
      "        [[-0.4297],\n",
      "         [ 0.2988],\n",
      "         [ 0.2256],\n",
      "         [ 0.0806],\n",
      "         [ 0.0938],\n",
      "         [ 0.2021]],\n",
      "\n",
      "        [[ 0.5391],\n",
      "         [ 0.5273],\n",
      "         [-0.3125],\n",
      "         [-0.3887],\n",
      "         [ 0.3555],\n",
      "         [ 0.3945]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.2393],\n",
      "         [-0.0042],\n",
      "         [ 0.1328],\n",
      "         [ 0.1250],\n",
      "         [ 0.1934]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0245],\n",
      "         [ 0.0620],\n",
      "         [ 0.5156],\n",
      "         [ 0.1211],\n",
      "         [ 0.4531]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.5234],\n",
      "         [ 0.1729],\n",
      "         [ 0.3672],\n",
      "         [ 0.4238],\n",
      "         [ 0.2422]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.7461],\n",
      "         [ 0.1187],\n",
      "         [ 0.1963],\n",
      "         [ 0.2676],\n",
      "         [ 0.2207]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3770],\n",
      "         [ 0.0654],\n",
      "         [ 0.2578],\n",
      "         [ 0.2832],\n",
      "         [ 0.3926]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0334],\n",
      "         [-0.0289],\n",
      "         [-0.0154],\n",
      "         [ 0.0366],\n",
      "         [ 0.8125]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0193],\n",
      "         [ 0.1030],\n",
      "         [ 0.8789],\n",
      "         [ 0.2021],\n",
      "         [ 0.4258]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0664],\n",
      "         [ 0.0222],\n",
      "         [-0.0269],\n",
      "         [-0.0593],\n",
      "         [ 0.0596]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [3.2422e-01, 6.7578e-01],\n",
      "         [2.2888e-03, 9.9609e-01],\n",
      "         [8.4375e-01, 1.5820e-01],\n",
      "         [1.0000e+00, 1.6308e-04],\n",
      "         [2.9102e-01, 7.1094e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.5736e-05],\n",
      "         [1.0000e+00, 2.2173e-05],\n",
      "         [2.9883e-01, 6.9922e-01],\n",
      "         [3.6240e-04, 1.0000e+00],\n",
      "         [5.5469e-01, 4.4727e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.0000e-01, 5.0000e-01],\n",
      "         [4.6143e-02, 9.5312e-01],\n",
      "         [3.0664e-01, 6.9531e-01],\n",
      "         [5.3906e-01, 4.6094e-01],\n",
      "         [4.3945e-01, 5.6250e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.4570e-01, 6.5625e-01],\n",
      "         [6.4062e-01, 3.5742e-01],\n",
      "         [5.7031e-01, 4.2969e-01],\n",
      "         [4.7656e-01, 5.2344e-01],\n",
      "         [2.8906e-01, 7.1094e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.1953e-01, 4.8242e-01],\n",
      "         [7.6904e-03, 9.9219e-01],\n",
      "         [6.7969e-01, 3.1836e-01],\n",
      "         [9.4141e-01, 5.6641e-02],\n",
      "         [5.8594e-01, 4.1406e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.1139e-03, 1.0000e+00],\n",
      "         [1.6880e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.0313e-04],\n",
      "         [1.0000e+00, 4.8399e-05],\n",
      "         [9.0625e-01, 9.2773e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.4605e-04],\n",
      "         [1.0000e+00, 1.0300e-03],\n",
      "         [8.2422e-01, 1.7676e-01],\n",
      "         [4.6631e-02, 9.5312e-01],\n",
      "         [3.6719e-01, 6.3281e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.5034e-05],\n",
      "         [6.5613e-04, 1.0000e+00],\n",
      "         [1.0538e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.3896e-05],\n",
      "         [1.0000e+00, 1.4400e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2600 to ./videos/variable_turn_tictactoe_muzero/0/episode_002600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2600. Recorded 7 frames.\n",
      "learning\n",
      "Started recording episode 2600 to ./videos/variable_turn_tictactoe_muzero/1/episode_002600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2600. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2600 to ./videos/variable_turn_tictactoe_muzero/3/episode_002600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2600. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2600 to ./videos/variable_turn_tictactoe_muzero/2/episode_002600.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2600. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4800\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 4, 2, 1, 5],\n",
      "        [7, 5, 2, 0, 1],\n",
      "        [6, 2, 8, 7, 0],\n",
      "        [3, 0, 6, 2, 0],\n",
      "        [0, 1, 0, 2, 1],\n",
      "        [7, 3, 6, 4, 8],\n",
      "        [2, 0, 8, 0, 1],\n",
      "        [6, 2, 0, 2, 1]])\n",
      "target value tensor([[ 0.9606,  0.9703, -0.9801, -0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4199],\n",
      "         [ 0.2871],\n",
      "         [ 0.0825],\n",
      "         [ 0.1084],\n",
      "         [ 0.3105],\n",
      "         [-0.0596]],\n",
      "\n",
      "        [[-0.6523],\n",
      "         [ 0.7305],\n",
      "         [ 0.7070],\n",
      "         [ 0.0374],\n",
      "         [-0.0396],\n",
      "         [ 0.3594]],\n",
      "\n",
      "        [[ 0.5703],\n",
      "         [ 0.5273],\n",
      "         [-0.5352],\n",
      "         [-0.5312],\n",
      "         [ 0.7227],\n",
      "         [ 0.4531]],\n",
      "\n",
      "        [[-0.7852],\n",
      "         [-0.6953],\n",
      "         [ 0.6680],\n",
      "         [ 0.6289],\n",
      "         [ 0.0527],\n",
      "         [-0.1191]],\n",
      "\n",
      "        [[ 0.1177],\n",
      "         [-0.1025],\n",
      "         [ 0.2871],\n",
      "         [-0.0781],\n",
      "         [ 0.0518],\n",
      "         [ 0.1270]],\n",
      "\n",
      "        [[ 0.5703],\n",
      "         [ 0.2305],\n",
      "         [-0.1836],\n",
      "         [-0.3750],\n",
      "         [-0.0082],\n",
      "         [ 0.0898]],\n",
      "\n",
      "        [[-0.5742],\n",
      "         [ 0.7578],\n",
      "         [ 0.5078],\n",
      "         [ 0.0510],\n",
      "         [ 0.0728],\n",
      "         [ 0.1514]],\n",
      "\n",
      "        [[ 0.9297],\n",
      "         [ 0.6562],\n",
      "         [ 0.0659],\n",
      "         [ 0.0593],\n",
      "         [ 0.0869],\n",
      "         [ 0.1074]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0067],\n",
      "         [ 0.3184],\n",
      "         [ 0.1592],\n",
      "         [ 0.4453],\n",
      "         [ 0.4941]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0425],\n",
      "         [ 0.1094],\n",
      "         [ 0.9688],\n",
      "         [ 0.0061],\n",
      "         [ 0.3555]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0879],\n",
      "         [ 0.0062],\n",
      "         [ 0.0139],\n",
      "         [ 0.0057],\n",
      "         [ 0.1895]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0056],\n",
      "         [ 0.0334],\n",
      "         [ 0.1216],\n",
      "         [ 0.9453],\n",
      "         [ 0.0117]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0618],\n",
      "         [ 0.2109],\n",
      "         [ 0.0562],\n",
      "         [ 0.3867],\n",
      "         [ 0.3496]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0170],\n",
      "         [ 0.0161],\n",
      "         [ 0.0251],\n",
      "         [ 0.0047],\n",
      "         [ 0.0388]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0086],\n",
      "         [ 0.2256],\n",
      "         [ 0.6914],\n",
      "         [-0.0327],\n",
      "         [ 0.3262]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.1299],\n",
      "         [ 0.9531],\n",
      "         [-0.0227],\n",
      "         [ 0.2793],\n",
      "         [ 0.3613]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 1.9531e-03],\n",
      "         [8.3496e-02, 9.1797e-01],\n",
      "         [2.3956e-03, 9.9609e-01],\n",
      "         [3.4375e-01, 6.5625e-01],\n",
      "         [1.0000e+00, 4.7302e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 4.9744e-03],\n",
      "         [1.0000e+00, 1.1253e-04],\n",
      "         [8.9062e-01, 1.0791e-01],\n",
      "         [1.3428e-03, 1.0000e+00],\n",
      "         [4.6094e-01, 5.3906e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 8.7738e-05],\n",
      "         [1.4019e-04, 1.0000e+00],\n",
      "         [3.3140e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 8.6427e-06],\n",
      "         [1.0000e+00, 6.3896e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.7537e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 6.1989e-05],\n",
      "         [1.0000e+00, 1.1861e-05],\n",
      "         [8.9062e-01, 1.1084e-01],\n",
      "         [4.6692e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.5667e-04, 1.0000e+00],\n",
      "         [6.4844e-01, 3.5352e-01],\n",
      "         [9.9219e-01, 6.8970e-03],\n",
      "         [6.2109e-01, 3.7891e-01],\n",
      "         [5.1172e-01, 4.8828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.5613e-04],\n",
      "         [4.6539e-04, 1.0000e+00],\n",
      "         [2.6131e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.2684e-04],\n",
      "         [1.0000e+00, 1.6251e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [1.0000e+00, 6.6280e-05],\n",
      "         [8.6719e-01, 1.3379e-01],\n",
      "         [1.7822e-02, 9.8047e-01],\n",
      "         [1.8750e-01, 8.1250e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.0136e-04],\n",
      "         [9.3359e-01, 6.5430e-02],\n",
      "         [1.6968e-02, 9.8438e-01],\n",
      "         [6.0059e-02, 9.4141e-01],\n",
      "         [9.3750e-01, 6.1768e-02]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2700 to ./videos/variable_turn_tictactoe_muzero/0/episode_002700.mp4\n",
      "learning\n",
      "Started recording episode 2700 to ./videos/variable_turn_tictactoe_muzero/1/episode_002700.mp4\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "Stopped recording episode 2700. Recorded 7 frames.\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Stopped recording episode 2700. Recorded 6 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 2700 to ./videos/variable_turn_tictactoe_muzero/3/episode_002700.mp4\n",
      "Stopped recording episode 2700. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "4900\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[6, 0, 2, 5, 3],\n",
      "        [3, 4, 7, 8, 2],\n",
      "        [8, 0, 7, 0, 7],\n",
      "        [1, 0, 8, 0, 7],\n",
      "        [4, 8, 5, 3, 1],\n",
      "        [5, 3, 0, 0, 7],\n",
      "        [1, 2, 8, 7, 0],\n",
      "        [4, 1, 0, 6, 8]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9415,  0.9510,  0.9606, -0.9703, -0.9801,  0.9900],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000]])\n",
      "predicted values tensor([[[ 0.3066],\n",
      "         [-0.4766],\n",
      "         [-0.5195],\n",
      "         [ 0.4238],\n",
      "         [ 0.2910],\n",
      "         [ 0.1885]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [-0.2793],\n",
      "         [-0.1562],\n",
      "         [ 0.0031],\n",
      "         [ 0.0571],\n",
      "         [ 0.1484]],\n",
      "\n",
      "        [[ 0.1250],\n",
      "         [ 0.1631],\n",
      "         [ 0.0189],\n",
      "         [ 0.2461],\n",
      "         [-0.0493],\n",
      "         [ 0.0615]],\n",
      "\n",
      "        [[ 0.3789],\n",
      "         [ 0.1572],\n",
      "         [ 0.2354],\n",
      "         [ 0.1553],\n",
      "         [ 0.0513],\n",
      "         [ 0.1328]],\n",
      "\n",
      "        [[ 0.3086],\n",
      "         [-0.5898],\n",
      "         [-0.6289],\n",
      "         [ 0.4609],\n",
      "         [ 0.2695],\n",
      "         [ 0.1055]],\n",
      "\n",
      "        [[ 0.5586],\n",
      "         [ 0.4023],\n",
      "         [ 0.1279],\n",
      "         [-0.0284],\n",
      "         [-0.1436],\n",
      "         [ 0.1055]],\n",
      "\n",
      "        [[ 0.4434],\n",
      "         [ 0.3770],\n",
      "         [ 0.0264],\n",
      "         [ 0.1396],\n",
      "         [ 0.3926],\n",
      "         [-0.0337]],\n",
      "\n",
      "        [[ 0.3574],\n",
      "         [ 0.4609],\n",
      "         [-0.4941],\n",
      "         [-0.5586],\n",
      "         [ 0.2734],\n",
      "         [ 0.1396]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0209],\n",
      "         [-0.0170],\n",
      "         [ 0.0032],\n",
      "         [ 0.2051],\n",
      "         [ 0.3984]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0199],\n",
      "         [ 0.0225],\n",
      "         [ 0.0491],\n",
      "         [ 0.1079],\n",
      "         [ 0.0693]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2871],\n",
      "         [ 0.0461],\n",
      "         [ 0.4609],\n",
      "         [ 0.1069],\n",
      "         [ 0.1982]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.7852],\n",
      "         [ 0.1172],\n",
      "         [ 0.6914],\n",
      "         [ 0.0442],\n",
      "         [ 0.1904]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0157],\n",
      "         [ 0.0104],\n",
      "         [-0.0042],\n",
      "         [ 0.1934],\n",
      "         [ 0.1758]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0051],\n",
      "         [ 1.0547],\n",
      "         [-0.0018],\n",
      "         [-0.1079],\n",
      "         [ 0.0032]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0266],\n",
      "         [ 0.8398],\n",
      "         [ 0.1133],\n",
      "         [ 0.4844],\n",
      "         [ 0.3965]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0292],\n",
      "         [ 0.0226],\n",
      "         [-0.0070],\n",
      "         [ 0.0498],\n",
      "         [ 0.1885]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.6880e-04, 1.0000e+00],\n",
      "         [2.7847e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 3.0279e-05],\n",
      "         [1.0000e+00, 1.6689e-05],\n",
      "         [2.6758e-01, 7.3438e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.9864e-04, 1.0000e+00],\n",
      "         [1.2817e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 8.7738e-05],\n",
      "         [9.9609e-01, 1.9836e-03],\n",
      "         [3.3936e-02, 9.6484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.1182e-01, 8.8672e-01],\n",
      "         [2.8839e-03, 9.9609e-01],\n",
      "         [5.1562e-01, 4.8633e-01],\n",
      "         [9.6875e-01, 3.1494e-02],\n",
      "         [5.1953e-01, 4.7852e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.0625e-01, 9.4238e-02],\n",
      "         [4.8828e-02, 9.4922e-01],\n",
      "         [2.9492e-01, 7.0312e-01],\n",
      "         [4.2188e-01, 5.7812e-01],\n",
      "         [1.7676e-01, 8.2422e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.2697e-04, 1.0000e+00],\n",
      "         [1.0538e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.9829e-05],\n",
      "         [1.0000e+00, 2.5868e-05],\n",
      "         [2.7148e-01, 7.2656e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.7466e-04],\n",
      "         [9.4531e-01, 5.5420e-02],\n",
      "         [3.1281e-03, 9.9609e-01],\n",
      "         [3.7079e-03, 9.9609e-01],\n",
      "         [7.3828e-01, 2.6367e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.9609e-01, 3.7689e-03],\n",
      "         [8.2031e-01, 1.8066e-01],\n",
      "         [1.4709e-02, 9.8438e-01],\n",
      "         [5.2344e-01, 4.7656e-01],\n",
      "         [9.9219e-01, 8.3008e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.2643e-04],\n",
      "         [7.9346e-04, 1.0000e+00],\n",
      "         [4.8399e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.1498e-05],\n",
      "         [1.0000e+00, 4.3678e-04]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2700 to ./videos/variable_turn_tictactoe_muzero/2/episode_002700.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2700. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started recording episode 2800 to ./videos/variable_turn_tictactoe_muzero/0/episode_002800.mp4\n",
      "learning\n",
      "5000\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 0, 0, 1, 5],\n",
      "        [3, 6, 0, 1, 2],\n",
      "        [3, 1, 0, 1, 5],\n",
      "        [3, 6, 8, 0, 0],\n",
      "        [8, 0, 6, 2, 0],\n",
      "        [1, 0, 1, 1, 5],\n",
      "        [4, 0, 6, 0, 5],\n",
      "        [6, 8, 2, 5, 3]])\n",
      "target value tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.0610],\n",
      "         [ 0.3828],\n",
      "         [-0.0087],\n",
      "         [-0.1069],\n",
      "         [ 0.0913],\n",
      "         [ 0.2275]],\n",
      "\n",
      "        [[ 0.4844],\n",
      "         [-0.6250],\n",
      "         [-0.5781],\n",
      "         [ 0.7031],\n",
      "         [ 0.5625],\n",
      "         [ 0.1138]],\n",
      "\n",
      "        [[ 0.3340],\n",
      "         [ 0.2275],\n",
      "         [ 0.0432],\n",
      "         [-0.0610],\n",
      "         [ 0.0354],\n",
      "         [ 0.3027]],\n",
      "\n",
      "        [[-0.9258],\n",
      "         [-0.8242],\n",
      "         [ 0.7617],\n",
      "         [ 0.6016],\n",
      "         [-0.0354],\n",
      "         [-0.0845]],\n",
      "\n",
      "        [[-0.3184],\n",
      "         [-0.5195],\n",
      "         [ 0.6328],\n",
      "         [ 0.5469],\n",
      "         [ 0.1099],\n",
      "         [ 0.0464]],\n",
      "\n",
      "        [[ 0.1465],\n",
      "         [ 0.1152],\n",
      "         [-0.0444],\n",
      "         [ 0.2793],\n",
      "         [ 0.1904],\n",
      "         [ 0.1387]],\n",
      "\n",
      "        [[-0.2520],\n",
      "         [ 0.1045],\n",
      "         [ 0.0109],\n",
      "         [ 0.0479],\n",
      "         [-0.1768],\n",
      "         [ 0.3320]],\n",
      "\n",
      "        [[ 0.4844],\n",
      "         [-0.5195],\n",
      "         [-0.5820],\n",
      "         [ 0.7578],\n",
      "         [ 0.6953],\n",
      "         [ 0.0254]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 1.9434e-01],\n",
      "         [ 4.1211e-01],\n",
      "         [ 1.8921e-02],\n",
      "         [ 3.1250e-01],\n",
      "         [ 2.9883e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-4.2969e-02],\n",
      "         [-1.0864e-02],\n",
      "         [ 1.8433e-02],\n",
      "         [-1.1597e-02],\n",
      "         [ 5.8984e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 2.4023e-01],\n",
      "         [ 4.1016e-01],\n",
      "         [ 4.6253e-05],\n",
      "         [ 2.2559e-01],\n",
      "         [ 1.5430e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.5442e-02],\n",
      "         [ 3.1006e-02],\n",
      "         [ 3.1836e-01],\n",
      "         [ 5.8594e-01],\n",
      "         [-9.4604e-03]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.4404e-02],\n",
      "         [-3.8452e-03],\n",
      "         [ 8.2031e-02],\n",
      "         [ 7.5000e-01],\n",
      "         [ 2.4414e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.3086e-01],\n",
      "         [-4.0527e-02],\n",
      "         [ 2.1680e-01],\n",
      "         [ 2.1289e-01],\n",
      "         [ 4.3164e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 1.4587e-02],\n",
      "         [ 6.9824e-02],\n",
      "         [ 1.6016e-01],\n",
      "         [ 7.2632e-03],\n",
      "         [ 4.8340e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-4.9072e-02],\n",
      "         [-5.8365e-04],\n",
      "         [-1.5320e-02],\n",
      "         [ 1.6016e-01],\n",
      "         [ 1.1016e+00]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [8.0469e-01, 1.9434e-01],\n",
      "         [9.9609e-01, 2.9755e-03],\n",
      "         [8.2812e-01, 1.7285e-01],\n",
      "         [1.9141e-01, 8.0859e-01],\n",
      "         [2.5000e-01, 7.5000e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.5776e-04, 1.0000e+00],\n",
      "         [6.8188e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 2.8372e-05],\n",
      "         [1.0000e+00, 9.9182e-05],\n",
      "         [6.9922e-01, 3.0273e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.7656e-01, 5.2344e-01],\n",
      "         [9.9609e-01, 3.4790e-03],\n",
      "         [6.9531e-01, 3.0469e-01],\n",
      "         [8.0566e-02, 9.1797e-01],\n",
      "         [5.4688e-01, 4.5312e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.7670e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 1.6880e-04],\n",
      "         [1.0000e+00, 7.4863e-05],\n",
      "         [8.3594e-01, 1.6602e-01],\n",
      "         [6.8970e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.9550e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 4.3106e-04],\n",
      "         [1.0000e+00, 4.6492e-06],\n",
      "         [8.9844e-01, 1.0205e-01],\n",
      "         [6.2866e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.8359e-02, 9.2969e-01],\n",
      "         [1.9455e-04, 1.0000e+00],\n",
      "         [5.2734e-01, 4.7266e-01],\n",
      "         [1.0000e+00, 4.7302e-04],\n",
      "         [6.5625e-01, 3.4375e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.4400e-04],\n",
      "         [1.0000e+00, 9.1171e-04],\n",
      "         [6.7871e-02, 9.3359e-01],\n",
      "         [2.9564e-04, 1.0000e+00],\n",
      "         [8.8281e-01, 1.1621e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [2.0313e-04, 1.0000e+00],\n",
      "         [8.7738e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 5.7817e-06],\n",
      "         [1.0000e+00, 3.7253e-06],\n",
      "         [9.5703e-01, 4.1260e-02]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "Stopped recording episode 2800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2800 to ./videos/variable_turn_tictactoe_muzero/1/episode_002800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2800 to ./videos/variable_turn_tictactoe_muzero/3/episode_002800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2800. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "encoder input shape (8, 18, 3, 3)\n",
      "Testing Player 0 vs Agent random\n",
      "Player 0 prediction: (tensor([0.1600, 0.0400, 0.2000, 0.0400, 0.3200, 0.0400, 0.1200, 0.0400, 0.0400]), tensor([0.1600, 0.0400, 0.2000, 0.0400, 0.3200, 0.0400, 0.1200, 0.0400, 0.0400]), 0.5434104383427546, tensor(4), {'network_policy': tensor([0.0625, 0.0615, 0.1128, 0.0742, 0.2715, 0.0850, 0.1494, 0.0786, 0.1045],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.369140625, 'search_policy': tensor([0.1600, 0.0400, 0.2000, 0.0400, 0.3200, 0.0400, 0.1200, 0.0400, 0.0400]), 'search_value': 0.5434104383427546, 'root_children_values': tensor([0.6145, 0.2021, 0.6006, 0.2354, 0.6696, 0.2969, 0.5265, 0.0967, 0.3398])})\n",
      "action: 4\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.1200, 0.0400, 0.2000, 0.0800, 0.0000, 0.0800, 0.1600, 0.0800, 0.2400]), tensor([0.1200, 0.0400, 0.2000, 0.0800, 0.0000, 0.0800, 0.1600, 0.0800, 0.2400]), 0.6215654059776893, tensor(8), {'network_policy': tensor([0.1187, 0.0859, 0.1699, 0.1279, 0.0000, 0.1118, 0.1226, 0.1016, 0.1602],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.53515625, 'search_policy': tensor([0.1200, 0.0400, 0.2000, 0.0800, 0.0000, 0.0800, 0.1600, 0.0800, 0.2400]), 'search_value': 0.6215654059776893, 'root_children_values': tensor([-0.6875, -0.4551, -0.7266, -0.6875,  0.0000, -0.6094, -0.6432, -0.6016,\n",
      "        -0.7047])})\n",
      "action: 8\n",
      "Player 1 random action: 6\n",
      "Player 1 random action: 2\n",
      "Player 0 prediction: (tensor([0.1600, 0.1200, 0.0000, 0.2800, 0.0000, 0.3600, 0.0000, 0.0800, 0.0000]), tensor([0.1600, 0.1200, 0.0000, 0.2800, 0.0000, 0.3600, 0.0000, 0.0800, 0.0000]), 0.7089271100041318, tensor(5), {'network_policy': tensor([0.1621, 0.1196, 0.0000, 0.1777, 0.0000, 0.3438, 0.0000, 0.1973, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.47265625, 'search_policy': tensor([0.1600, 0.1200, 0.0000, 0.2800, 0.0000, 0.3600, 0.0000, 0.0800, 0.0000]), 'search_value': 0.7089271100041318, 'root_children_values': tensor([0.5520, 0.4038, 0.0000, 0.6470, 0.0000, 0.8771, 0.0000, 0.4513, 0.0000])})\n",
      "action: 5\n",
      "Player 0 prediction: (tensor([0.2400, 0.0400, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.0800, 0.0000]), tensor([0.2400, 0.0400, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.0800, 0.0000]), 0.9744283642296426, tensor(3), {'network_policy': tensor([0.1816, 0.1445, 0.0000, 0.4258, 0.0000, 0.0000, 0.0000, 0.2480, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.578125, 'search_policy': tensor([0.2400, 0.0400, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.0800, 0.0000]), 'search_value': 0.9744283642296426, 'root_children_values': tensor([0.2038, 0.1748, 0.0000, 0.1296, 0.0000, 0.0000, 0.0000, 0.2035, 0.0000])})\n",
      "action: 3\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2800 to ./videos/variable_turn_tictactoe_muzero/2/episode_002800.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2800. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 0 win percentage vs random: 100.0 and average score: 1.0\n",
      "Testing Player 1 vs Agent random\n",
      "Player 0 random action: 1\n",
      "Player 0 random action: 7\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.0800, 0.0000, 0.1200, 0.0800, 0.3200, 0.0400, 0.1200, 0.0000, 0.2400]), tensor([0.0800, 0.0000, 0.1200, 0.0800, 0.3200, 0.0400, 0.1200, 0.0000, 0.2400]), -0.015772730783315796, tensor(4), {'network_policy': tensor([0.0957, 0.0000, 0.1699, 0.1016, 0.2197, 0.1094, 0.1123, 0.0000, 0.1904],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.10888671875, 'search_policy': tensor([0.0800, 0.0000, 0.1200, 0.0800, 0.3200, 0.0400, 0.1200, 0.0000, 0.2400]), 'search_value': -0.015772730783315796, 'root_children_values': tensor([-0.0249,  0.0000, -0.0540, -0.0871,  0.0726, -0.2969, -0.0708,  0.0000,\n",
      "        -0.0501])})\n",
      "action: 4\n",
      "Player 1 prediction: (tensor([0.1200, 0.0000, 0.1600, 0.3200, 0.0000, 0.1200, 0.0800, 0.0000, 0.2000]), tensor([0.1200, 0.0000, 0.1600, 0.3200, 0.0000, 0.1200, 0.0800, 0.0000, 0.2000]), -0.04122756862229568, tensor(3), {'network_policy': tensor([0.1309, 0.0000, 0.2500, 0.1245, 0.0000, 0.1206, 0.1318, 0.0000, 0.2393],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.07470703125, 'search_policy': tensor([0.1200, 0.0000, 0.1600, 0.3200, 0.0000, 0.1200, 0.0800, 0.0000, 0.2000]), 'search_value': -0.04122756862229568, 'root_children_values': tensor([0.1250, 0.0000, 0.1131, 0.0449, 0.0000, 0.1144, 0.0830, 0.0000, 0.0138])})\n",
      "action: 3\n",
      "Player 0 random action: 0\n",
      "Player 0 random action: 5\n",
      "Player 1 prediction: (tensor([0.0000, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.1200, 0.0000, 0.2400]), tensor([0.0000, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.1200, 0.0000, 0.2400]), 0.5090486087077214, tensor(2), {'network_policy': tensor([0.0000, 0.0000, 0.4180, 0.0000, 0.0000, 0.0000, 0.2451, 0.0000, 0.3359],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.46484375, 'search_policy': tensor([0.0000, 0.0000, 0.6400, 0.0000, 0.0000, 0.0000, 0.1200, 0.0000, 0.2400]), 'search_value': 0.5090486087077214, 'root_children_values': tensor([ 0.0000,  0.0000,  0.5972,  0.0000,  0.0000,  0.0000,  0.1661,  0.0000,\n",
      "        -0.0061])})\n",
      "action: 2\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5200, 0.0000, 0.4800]), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5200, 0.0000, 0.4800]), -0.1548756912611037, tensor(6), {'network_policy': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4590, 0.0000, 0.5391],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.55078125, 'search_policy': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5200, 0.0000, 0.4800]), 'search_value': -0.1548756912611037, 'root_children_values': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5965, 0.0000, 0.7581])})\n",
      "action: 6\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "5100\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[1, 2, 3, 5, 0],\n",
      "        [8, 1, 3, 4, 7],\n",
      "        [6, 7, 2, 4, 5],\n",
      "        [8, 6, 7, 0, 5],\n",
      "        [2, 0, 1, 0, 0],\n",
      "        [1, 0, 2, 1, 0],\n",
      "        [4, 2, 3, 6, 5],\n",
      "        [1, 0, 2, 1, 0]])\n",
      "target value tensor([[-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [ 0.9227,  0.9321, -0.9415, -0.9510,  0.9606,  0.9703],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2734],\n",
      "         [ 0.0947],\n",
      "         [ 0.1836],\n",
      "         [ 0.1572],\n",
      "         [ 0.1235],\n",
      "         [-0.0476]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [ 0.4941],\n",
      "         [-0.2988],\n",
      "         [-0.4355],\n",
      "         [ 0.0664],\n",
      "         [-0.1504]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [ 0.4160],\n",
      "         [-0.3535],\n",
      "         [-0.3711],\n",
      "         [ 0.0184],\n",
      "         [ 0.2061]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [ 0.4941],\n",
      "         [-0.4707],\n",
      "         [-0.4941],\n",
      "         [ 0.6055],\n",
      "         [ 0.5234]],\n",
      "\n",
      "        [[-0.0164],\n",
      "         [-0.0101],\n",
      "         [ 0.1021],\n",
      "         [-0.0791],\n",
      "         [-0.0177],\n",
      "         [ 0.0229]],\n",
      "\n",
      "        [[ 0.2090],\n",
      "         [ 0.0097],\n",
      "         [ 0.0029],\n",
      "         [-0.0776],\n",
      "         [ 0.1289],\n",
      "         [ 0.0114]],\n",
      "\n",
      "        [[ 0.3555],\n",
      "         [ 0.6562],\n",
      "         [-0.6250],\n",
      "         [-0.7734],\n",
      "         [ 0.6289],\n",
      "         [ 0.4277]],\n",
      "\n",
      "        [[ 0.2383],\n",
      "         [ 0.0708],\n",
      "         [ 0.1758],\n",
      "         [ 0.1621],\n",
      "         [ 0.1436],\n",
      "         [-0.0564]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0342],\n",
      "         [ 0.4766],\n",
      "         [ 0.2256],\n",
      "         [ 0.7930],\n",
      "         [ 0.1128]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0383],\n",
      "         [ 0.0378],\n",
      "         [-0.0154],\n",
      "         [ 0.0099],\n",
      "         [ 0.2061]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0376],\n",
      "         [ 0.0461],\n",
      "         [ 0.0396],\n",
      "         [-0.0034],\n",
      "         [ 0.1123]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0383],\n",
      "         [ 0.0084],\n",
      "         [ 0.0034],\n",
      "         [ 0.0226],\n",
      "         [ 0.0649]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0596],\n",
      "         [ 0.3750],\n",
      "         [ 0.6445],\n",
      "         [ 0.0703],\n",
      "         [-0.0369]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4746],\n",
      "         [ 0.0422],\n",
      "         [ 0.1514],\n",
      "         [ 0.1240],\n",
      "         [ 0.0713]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0159],\n",
      "         [ 0.0461],\n",
      "         [-0.0087],\n",
      "         [ 0.0562],\n",
      "         [ 0.2676]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3848],\n",
      "         [ 0.6133],\n",
      "         [ 0.2539],\n",
      "         [ 0.6680],\n",
      "         [ 0.1187]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.6875e-01, 3.2959e-02],\n",
      "         [3.5742e-01, 6.4453e-01],\n",
      "         [2.3746e-04, 1.0000e+00],\n",
      "         [2.6172e-01, 7.3828e-01],\n",
      "         [9.8047e-01, 1.9165e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2302e-04],\n",
      "         [1.3161e-04, 1.0000e+00],\n",
      "         [2.3603e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0681e-03],\n",
      "         [1.0000e+00, 1.5354e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.3167e-05],\n",
      "         [4.3678e-04, 1.0000e+00],\n",
      "         [1.5354e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.4550e-04],\n",
      "         [1.0000e+00, 1.2054e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2302e-04],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [4.1246e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 3.1233e-05],\n",
      "         [1.0000e+00, 3.5286e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.4801e-03, 1.0000e+00],\n",
      "         [6.2891e-01, 3.7109e-01],\n",
      "         [1.0000e+00, 2.3079e-04],\n",
      "         [7.3047e-01, 2.6953e-01],\n",
      "         [4.7119e-02, 9.5312e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.8438e-01, 1.4954e-02],\n",
      "         [3.9368e-03, 9.9609e-01],\n",
      "         [8.5449e-04, 1.0000e+00],\n",
      "         [9.9609e-01, 2.3193e-03],\n",
      "         [9.5312e-01, 4.7363e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 6.7902e-04],\n",
      "         [3.3722e-03, 9.9609e-01],\n",
      "         [2.2173e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 9.9182e-05],\n",
      "         [1.0000e+00, 3.3975e-06]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.3542e-04],\n",
      "         [6.5625e-01, 3.4180e-01],\n",
      "         [5.8289e-03, 9.9609e-01],\n",
      "         [1.3281e-01, 8.6719e-01],\n",
      "         [4.5312e-01, 5.4688e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 1 win percentage vs random: 46.0 and average score: -0.02\n",
      "Results vs random: {'player_0_score': 1.0, 'player_0_win%': 1.0, 'player_1_score': -0.02, 'player_1_win%': 0.46, 'score': 0.49}\n",
      "Testing Player 0 vs Agent tictactoe_expert\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0400, 0.0400, 0.0800, 0.0400, 0.4000, 0.1600, 0.1600, 0.0400, 0.0400]), tensor([0.0400, 0.0400, 0.0800, 0.0400, 0.4000, 0.1600, 0.1600, 0.0400, 0.0400]), 0.5253939408054351, tensor(4), {'network_policy': tensor([0.0625, 0.0615, 0.1128, 0.0742, 0.2715, 0.0850, 0.1494, 0.0786, 0.1045],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.369140625, 'search_policy': tensor([0.0400, 0.0400, 0.0800, 0.0400, 0.4000, 0.1600, 0.1600, 0.0400, 0.0400]), 'search_value': 0.5253939408054351, 'root_children_values': tensor([0.4492, 0.2021, 0.5781, 0.2354, 0.6765, 0.4516, 0.5307, 0.0967, 0.3398])})\n",
      "action: 4\n",
      "Player 0 prediction: (tensor([0.4000, 0.0400, 0.1600, 0.0800, 0.0000, 0.0400, 0.0800, 0.0400, 0.1600]), tensor([0.4000, 0.0400, 0.1600, 0.0800, 0.0000, 0.0400, 0.0800, 0.0400, 0.1600]), 0.6297098921931341, tensor(0), {'network_policy': tensor([0.1187, 0.0859, 0.1699, 0.1279, 0.0000, 0.1118, 0.1226, 0.1016, 0.1602],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.53515625, 'search_policy': tensor([0.4000, 0.0400, 0.1600, 0.0800, 0.0000, 0.0400, 0.0800, 0.0400, 0.1600]), 'search_value': 0.6297098921931341, 'root_children_values': tensor([-0.6487, -0.4551, -0.7215, -0.6875,  0.0000, -0.6055, -0.6323, -0.6094,\n",
      "        -0.6729])})\n",
      "action: 0\n",
      "Player 1 tictactoe_expert action: 8\n",
      "Player 1 tictactoe_expert action: 2\n",
      "Player 0 prediction: (tensor([0.0000, 0.0400, 0.0000, 0.1600, 0.0000, 0.2000, 0.5600, 0.0400, 0.0000]), tensor([0.0000, 0.0400, 0.0000, 0.1600, 0.0000, 0.2000, 0.5600, 0.0400, 0.0000]), 0.8115922263793947, tensor(6), {'network_policy': tensor([0.0000, 0.1279, 0.0000, 0.2051, 0.0000, 0.2256, 0.3027, 0.1338, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.5234375, 'search_policy': tensor([0.0000, 0.0400, 0.0000, 0.1600, 0.0000, 0.2000, 0.5600, 0.0400, 0.0000]), 'search_value': 0.8115922263793947, 'root_children_values': tensor([0.0000, 0.3789, 0.0000, 0.7004, 0.0000, 0.7532, 0.7875, 0.2217, 0.0000])})\n",
      "action: 6\n",
      "learning\n",
      "Player 0 prediction: (tensor([0.0000, 0.1200, 0.0000, 0.4800, 0.0000, 0.0800, 0.0000, 0.3200, 0.0000]), tensor([0.0000, 0.1200, 0.0000, 0.4800, 0.0000, 0.0800, 0.0000, 0.3200, 0.0000]), 0.8137538865872895, tensor(3), {'network_policy': tensor([0.0000, 0.1768, 0.0000, 0.3105, 0.0000, 0.2910, 0.0000, 0.2217, 0.0000],\n",
      "       dtype=torch.bfloat16), 'network_value': 0.52734375, 'search_policy': tensor([0.0000, 0.1200, 0.0000, 0.4800, 0.0000, 0.0800, 0.0000, 0.3200, 0.0000]), 'search_value': 0.8137538865872895, 'root_children_values': tensor([0.0000, 0.0566, 0.0000, 0.1611, 0.0000, 0.3230, 0.0000, 0.3917, 0.0000])})\n",
      "action: 3\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2900 to ./videos/variable_turn_tictactoe_muzero/0/episode_002900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2900. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2900 to ./videos/variable_turn_tictactoe_muzero/1/episode_002900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2900. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Player 0 win percentage vs tictactoe_expert: 100.0 and average score: 1.0\n",
      "Testing Player 1 vs Agent tictactoe_expert\n",
      "Player 0 tictactoe_expert action: 2\n",
      "Player 0 tictactoe_expert action: 1\n",
      "Player 1 prediction: (tensor([0.0400, 0.0000, 0.0000, 0.2000, 0.4000, 0.1200, 0.0800, 0.0800, 0.0800]), tensor([0.0400, 0.0000, 0.0000, 0.2000, 0.4000, 0.1200, 0.0800, 0.0800, 0.0800]), -0.24012766265399635, tensor(4), {'network_policy': tensor([0.0972, 0.0000, 0.0000, 0.1318, 0.2236, 0.1089, 0.1270, 0.1445, 0.1650],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.49609375, 'search_policy': tensor([0.0400, 0.0000, 0.0000, 0.2000, 0.4000, 0.1200, 0.0800, 0.0800, 0.0800]), 'search_value': -0.24012766265399635, 'root_children_values': tensor([-0.4688,  0.0000,  0.0000, -0.3409, -0.1274, -0.3452, -0.2891, -0.2734,\n",
      "        -0.3579])})\n",
      "action: 4\n",
      "learning\n",
      "Player 1 prediction: (tensor([0.2000, 0.0000, 0.0000, 0.1200, 0.0000, 0.0800, 0.2000, 0.1600, 0.2400]), tensor([0.2000, 0.0000, 0.0000, 0.1200, 0.0000, 0.0800, 0.2000, 0.1600, 0.2400]), -0.1347289043719952, tensor(8), {'network_policy': tensor([0.1406, 0.0000, 0.0000, 0.1670, 0.0000, 0.1445, 0.1709, 0.1553, 0.2197],\n",
      "       dtype=torch.bfloat16), 'network_value': -0.361328125, 'search_policy': tensor([0.2000, 0.0000, 0.0000, 0.1200, 0.0000, 0.0800, 0.2000, 0.1600, 0.2400]), 'search_value': -0.1347289043719952, 'root_children_values': tensor([0.2026, 0.0000, 0.0000, 0.1676, 0.0000, 0.2266, 0.1762, 0.2170, 0.1117])})\n",
      "action: 8\n",
      "Player 0 tictactoe_expert action: 0\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 2900 to ./videos/variable_turn_tictactoe_muzero/3/episode_002900.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 2900. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Player 1 win percentage vs tictactoe_expert: 4.0 and average score: -0.9\n",
      "Results vs tictactoe_expert: {'player_0_score': 1.0, 'player_0_win%': 1.0, 'player_1_score': -0.9, 'player_1_win%': 0.04, 'score': 0.04999999999999999}\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 2900 to ./videos/variable_turn_tictactoe_muzero/2/episode_002900.mp4\n",
      "Stopped recording episode 2900. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "5200\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[4, 3, 0, 6, 1],\n",
      "        [7, 8, 0, 6, 8],\n",
      "        [5, 4, 0, 7, 0],\n",
      "        [6, 1, 7, 2, 4],\n",
      "        [0, 0, 7, 6, 8],\n",
      "        [6, 8, 4, 1, 3],\n",
      "        [3, 0, 2, 6, 4],\n",
      "        [7, 0, 1, 4, 6]])\n",
      "target value tensor([[-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.4395],\n",
      "         [ 0.5352],\n",
      "         [-0.4473],\n",
      "         [-0.5703],\n",
      "         [ 0.3164],\n",
      "         [ 0.1719]],\n",
      "\n",
      "        [[-0.4355],\n",
      "         [ 0.5742],\n",
      "         [ 0.4434],\n",
      "         [ 0.0942],\n",
      "         [ 0.1553],\n",
      "         [ 0.1245]],\n",
      "\n",
      "        [[-0.1855],\n",
      "         [-0.3281],\n",
      "         [ 0.1543],\n",
      "         [ 0.3086],\n",
      "         [ 0.1641],\n",
      "         [ 0.1367]],\n",
      "\n",
      "        [[ 0.4395],\n",
      "         [ 0.4082],\n",
      "         [-0.2168],\n",
      "         [-0.3359],\n",
      "         [ 0.3848],\n",
      "         [ 0.3320]],\n",
      "\n",
      "        [[ 0.3340],\n",
      "         [ 0.2305],\n",
      "         [ 0.0957],\n",
      "         [ 0.1865],\n",
      "         [ 0.1118],\n",
      "         [ 0.1069]],\n",
      "\n",
      "        [[ 0.4395],\n",
      "         [ 0.4082],\n",
      "         [-0.3828],\n",
      "         [-0.3145],\n",
      "         [ 0.1006],\n",
      "         [ 0.0540]],\n",
      "\n",
      "        [[ 0.3516],\n",
      "         [-0.2100],\n",
      "         [-0.3066],\n",
      "         [ 0.2930],\n",
      "         [ 0.2061],\n",
      "         [ 0.0762]],\n",
      "\n",
      "        [[ 0.4355],\n",
      "         [-0.2773],\n",
      "         [-0.2734],\n",
      "         [ 0.4941],\n",
      "         [ 0.3359],\n",
      "         [ 0.1357]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.0079],\n",
      "         [-0.0693],\n",
      "         [-0.0132],\n",
      "         [ 0.0593],\n",
      "         [ 0.0327]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0547],\n",
      "         [ 0.1865],\n",
      "         [-0.0334],\n",
      "         [ 0.1367],\n",
      "         [ 0.5156]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0087],\n",
      "         [ 0.0212],\n",
      "         [ 0.0128],\n",
      "         [ 0.1211],\n",
      "         [-0.0737]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0339],\n",
      "         [-0.0098],\n",
      "         [ 0.0063],\n",
      "         [-0.0067],\n",
      "         [ 0.3613]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.4277],\n",
      "         [-0.1001],\n",
      "         [ 0.1357],\n",
      "         [ 0.3281],\n",
      "         [ 0.3848]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0339],\n",
      "         [-0.0065],\n",
      "         [-0.0564],\n",
      "         [-0.0366],\n",
      "         [-0.0298]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0398],\n",
      "         [-0.0615],\n",
      "         [-0.0023],\n",
      "         [ 0.1426],\n",
      "         [ 0.7188]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0500],\n",
      "         [-0.0801],\n",
      "         [-0.0110],\n",
      "         [ 0.3711],\n",
      "         [ 0.5625]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.7820e-04],\n",
      "         [1.0452e-03, 1.0000e+00],\n",
      "         [1.7929e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.1969e-04],\n",
      "         [1.0000e+00, 1.2054e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.8229e-04],\n",
      "         [1.0000e+00, 2.0981e-04],\n",
      "         [5.6250e-01, 4.3750e-01],\n",
      "         [3.6133e-02, 9.6484e-01],\n",
      "         [3.0664e-01, 6.9141e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [3.5286e-05, 1.0000e+00],\n",
      "         [9.9609e-01, 4.4556e-03],\n",
      "         [1.0000e+00, 1.0538e-04],\n",
      "         [1.2354e-01, 8.7500e-01],\n",
      "         [2.0386e-02, 9.8047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.7537e-05],\n",
      "         [2.9564e-04, 1.0000e+00],\n",
      "         [1.8501e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.3678e-04],\n",
      "         [1.0000e+00, 1.5831e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.4062e-01, 3.5742e-01],\n",
      "         [2.7148e-01, 7.2656e-01],\n",
      "         [1.3770e-01, 8.6328e-01],\n",
      "         [5.5469e-01, 4.4727e-01],\n",
      "         [7.8125e-01, 2.1680e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 2.7537e-05],\n",
      "         [1.7357e-04, 1.0000e+00],\n",
      "         [1.8501e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.6894e-04],\n",
      "         [9.6875e-01, 2.9297e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.6675e-04, 1.0000e+00],\n",
      "         [6.6833e-03, 9.9219e-01],\n",
      "         [1.0000e+00, 4.0054e-05],\n",
      "         [1.0000e+00, 1.9455e-04],\n",
      "         [8.2031e-01, 1.7871e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.4387e-04, 1.0000e+00],\n",
      "         [4.1771e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.5613e-04],\n",
      "         [1.0000e+00, 6.5613e-04],\n",
      "         [7.5391e-01, 2.4707e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "Started recording episode 3000 to ./videos/variable_turn_tictactoe_muzero/0/episode_003000.mp4\n",
      "Stopped recording episode 3000. Recorded 7 frames.\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "Started recording episode 3000 to ./videos/variable_turn_tictactoe_muzero/1/episode_003000.mp4\n",
      "Stopped recording episode 3000. Recorded 7 frames.\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score: 0.98\n",
      "Test score {'score': 0.98, 'max_score': 1, 'min_score': -1}\n",
      "Started recording episode 3000 to ./videos/variable_turn_tictactoe_muzero/3/episode_003000.mp4\n",
      "learning\n",
      "Stopped recording episode 3000. Recorded 7 frames.\n",
      "5300\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[2, 0, 5, 7, 6],\n",
      "        [0, 8, 6, 0, 6],\n",
      "        [6, 5, 2, 8, 0],\n",
      "        [5, 7, 8, 4, 1],\n",
      "        [8, 7, 6, 0, 5],\n",
      "        [6, 7, 3, 5, 0],\n",
      "        [0, 8, 0, 7, 6],\n",
      "        [5, 7, 1, 2, 0]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9415, -0.9510,  0.9606,  0.9703, -0.9801, -0.9900],\n",
      "        [-0.9321, -0.9415,  0.9510,  0.9606, -0.9703, -0.9801],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.2031],\n",
      "         [ 0.2500],\n",
      "         [ 0.1602],\n",
      "         [ 0.1846],\n",
      "         [ 0.2793],\n",
      "         [ 0.3418]],\n",
      "\n",
      "        [[ 0.1064],\n",
      "         [ 0.0021],\n",
      "         [ 0.5078],\n",
      "         [-0.0469],\n",
      "         [-0.0928],\n",
      "         [ 0.0535]],\n",
      "\n",
      "        [[-0.5156],\n",
      "         [ 0.5547],\n",
      "         [ 0.2314],\n",
      "         [ 0.2393],\n",
      "         [ 0.1846],\n",
      "         [ 0.0811]],\n",
      "\n",
      "        [[-0.0830],\n",
      "         [ 0.0952],\n",
      "         [ 0.0569],\n",
      "         [ 0.1729],\n",
      "         [ 0.0010],\n",
      "         [ 0.0527]],\n",
      "\n",
      "        [[ 0.3691],\n",
      "         [ 0.4688],\n",
      "         [-0.3242],\n",
      "         [-0.3965],\n",
      "         [ 0.4141],\n",
      "         [ 0.2227]],\n",
      "\n",
      "        [[-0.5703],\n",
      "         [-0.4082],\n",
      "         [ 0.3281],\n",
      "         [ 0.3047],\n",
      "         [ 0.0039],\n",
      "         [ 0.1230]],\n",
      "\n",
      "        [[ 0.5977],\n",
      "         [ 0.3594],\n",
      "         [ 0.3027],\n",
      "         [ 0.0918],\n",
      "         [ 0.3574],\n",
      "         [ 0.1128]],\n",
      "\n",
      "        [[-0.6562],\n",
      "         [-0.5469],\n",
      "         [ 0.7930],\n",
      "         [ 0.6133],\n",
      "         [ 0.0728],\n",
      "         [-0.0282]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000e+00],\n",
      "         [ 1.2598e-01],\n",
      "         [ 7.8125e-02],\n",
      "         [ 6.7871e-02],\n",
      "         [ 2.1191e-01],\n",
      "         [ 1.0059e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 5.5420e-02],\n",
      "         [ 4.2578e-01],\n",
      "         [ 6.1719e-01],\n",
      "         [-9.3262e-02],\n",
      "         [-5.5420e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 5.3955e-02],\n",
      "         [ 4.7363e-02],\n",
      "         [ 3.3398e-01],\n",
      "         [ 2.4292e-02],\n",
      "         [ 3.0469e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-5.0049e-02],\n",
      "         [-9.0820e-02],\n",
      "         [ 4.7302e-03],\n",
      "         [ 3.1853e-04],\n",
      "         [-3.2806e-03]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.8433e-02],\n",
      "         [ 1.1963e-02],\n",
      "         [-4.1504e-02],\n",
      "         [-4.0527e-02],\n",
      "         [ 7.4463e-03]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-8.6060e-03],\n",
      "         [ 7.7148e-02],\n",
      "         [-1.7456e-02],\n",
      "         [ 8.5547e-01],\n",
      "         [-2.3315e-02]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-7.2937e-03],\n",
      "         [ 4.7852e-01],\n",
      "         [-7.5195e-02],\n",
      "         [ 3.3398e-01],\n",
      "         [ 4.1602e-01]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [-1.2451e-02],\n",
      "         [-3.8086e-02],\n",
      "         [ 5.3955e-02],\n",
      "         [ 4.9023e-01],\n",
      "         [-6.0059e-02]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [9.2773e-03, 9.9219e-01],\n",
      "         [3.4766e-01, 6.5234e-01],\n",
      "         [1.0000e+00, 1.2436e-03],\n",
      "         [4.0234e-01, 5.9766e-01],\n",
      "         [1.2634e-02, 9.8828e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.9531e-03, 9.9609e-01],\n",
      "         [7.7344e-01, 2.2461e-01],\n",
      "         [1.0000e+00, 1.1368e-03],\n",
      "         [6.7969e-01, 3.2031e-01],\n",
      "         [2.7588e-02, 9.7266e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.9073e-04],\n",
      "         [1.0000e+00, 6.3896e-05],\n",
      "         [2.2852e-01, 7.6953e-01],\n",
      "         [1.8387e-03, 1.0000e+00],\n",
      "         [4.7266e-01, 5.2734e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.0703e-01, 2.9492e-01],\n",
      "         [1.0000e+00, 8.7738e-05],\n",
      "         [9.9609e-01, 2.0905e-03],\n",
      "         [7.7148e-02, 9.2188e-01],\n",
      "         [1.0252e-04, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.8399e-05],\n",
      "         [1.0452e-03, 1.0000e+00],\n",
      "         [1.0252e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.3479e-06],\n",
      "         [1.0000e+00, 2.0981e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0538e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 7.2479e-05],\n",
      "         [9.9609e-01, 3.7689e-03],\n",
      "         [9.3359e-01, 6.7871e-02],\n",
      "         [7.6904e-03, 9.9219e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 8.2016e-05],\n",
      "         [4.9219e-01, 5.0781e-01],\n",
      "         [5.6458e-03, 9.9609e-01],\n",
      "         [4.7852e-01, 5.1953e-01],\n",
      "         [9.9219e-01, 6.8970e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.4550e-04],\n",
      "         [1.0000e+00, 1.3428e-03],\n",
      "         [7.8125e-01, 2.1777e-01],\n",
      "         [2.3079e-04, 1.0000e+00]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3000 to ./videos/variable_turn_tictactoe_muzero/2/episode_003000.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3000. Recorded 8 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "5400\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 0, 4, 0, 0],\n",
      "        [5, 8, 4, 0, 0],\n",
      "        [4, 2, 7, 0, 3],\n",
      "        [6, 1, 3, 0, 0],\n",
      "        [3, 5, 4, 6, 0],\n",
      "        [1, 0, 2, 0, 0],\n",
      "        [6, 4, 7, 2, 8],\n",
      "        [4, 0, 1, 7, 0]])\n",
      "target value tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9703, -0.9801,  0.9900,  1.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.8867],\n",
      "         [ 0.3477],\n",
      "         [ 0.2393],\n",
      "         [ 0.0723],\n",
      "         [-0.0415],\n",
      "         [ 0.0262]],\n",
      "\n",
      "        [[-0.5703],\n",
      "         [ 0.6484],\n",
      "         [ 0.5469],\n",
      "         [ 0.1064],\n",
      "         [-0.0085],\n",
      "         [-0.0859]],\n",
      "\n",
      "        [[ 0.3828],\n",
      "         [-0.3457],\n",
      "         [-0.5625],\n",
      "         [ 0.7891],\n",
      "         [ 0.6680],\n",
      "         [ 0.0679]],\n",
      "\n",
      "        [[-0.8047],\n",
      "         [-0.4922],\n",
      "         [ 0.7227],\n",
      "         [ 0.4629],\n",
      "         [ 0.0288],\n",
      "         [-0.1230]],\n",
      "\n",
      "        [[-0.4629],\n",
      "         [-0.4668],\n",
      "         [ 0.6094],\n",
      "         [ 0.5664],\n",
      "         [ 0.0435],\n",
      "         [-0.1250]],\n",
      "\n",
      "        [[-0.7344],\n",
      "         [-0.4473],\n",
      "         [ 0.7617],\n",
      "         [ 0.5469],\n",
      "         [ 0.0981],\n",
      "         [ 0.0031]],\n",
      "\n",
      "        [[ 0.4102],\n",
      "         [ 0.4531],\n",
      "         [-0.4609],\n",
      "         [-0.6133],\n",
      "         [ 0.7969],\n",
      "         [ 0.6367]],\n",
      "\n",
      "        [[-0.3418],\n",
      "         [-0.2617],\n",
      "         [ 0.2383],\n",
      "         [ 0.2305],\n",
      "         [ 0.2793],\n",
      "         [ 0.0952]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.8984],\n",
      "         [ 0.1299],\n",
      "         [ 0.5547],\n",
      "         [ 0.0295],\n",
      "         [-0.0820]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0103],\n",
      "         [ 0.0967],\n",
      "         [ 0.8867],\n",
      "         [ 0.0097],\n",
      "         [-0.0981]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0022],\n",
      "         [ 0.0019],\n",
      "         [-0.0649],\n",
      "         [ 0.0479],\n",
      "         [ 0.8555]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0014],\n",
      "         [-0.0283],\n",
      "         [ 0.1934],\n",
      "         [ 0.3164],\n",
      "         [-0.0325]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0165],\n",
      "         [-0.0115],\n",
      "         [ 0.1445],\n",
      "         [ 0.6875],\n",
      "         [ 0.0098]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0378],\n",
      "         [ 0.0537],\n",
      "         [ 0.2969],\n",
      "         [ 0.1904],\n",
      "         [-0.0320]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0023],\n",
      "         [-0.0593],\n",
      "         [ 0.0193],\n",
      "         [-0.0233],\n",
      "         [ 0.2178]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0082],\n",
      "         [ 0.0496],\n",
      "         [ 0.0028],\n",
      "         [ 0.4434],\n",
      "         [-0.0132]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [8.5156e-01, 1.4941e-01],\n",
      "         [1.0107e-01, 8.9844e-01],\n",
      "         [3.2031e-01, 6.7969e-01],\n",
      "         [6.8750e-01, 3.1250e-01],\n",
      "         [5.3516e-01, 4.6484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.1824e-06],\n",
      "         [1.0000e+00, 4.3511e-06],\n",
      "         [9.4141e-01, 5.7129e-02],\n",
      "         [1.3123e-02, 9.8828e-01],\n",
      "         [2.6953e-01, 7.3047e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.7852e-02, 9.5312e-01],\n",
      "         [4.9829e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 1.9073e-04],\n",
      "         [1.0000e+00, 9.2387e-06],\n",
      "         [9.4141e-01, 5.8350e-02]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.1989e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 3.8862e-05],\n",
      "         [1.0000e+00, 4.5776e-04],\n",
      "         [6.6797e-01, 3.3203e-01],\n",
      "         [1.0681e-03, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.7220e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 1.8501e-04],\n",
      "         [1.0000e+00, 1.6308e-04],\n",
      "         [8.7109e-01, 1.2695e-01],\n",
      "         [4.1199e-03, 9.9609e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.5488e-03, 1.0000e+00],\n",
      "         [1.0000e+00, 3.2043e-04],\n",
      "         [1.0000e+00, 5.4836e-05],\n",
      "         [8.5547e-01, 1.4648e-01],\n",
      "         [2.6001e-02, 9.7266e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.1861e-05],\n",
      "         [2.8839e-03, 9.9609e-01],\n",
      "         [2.7847e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 6.6280e-05],\n",
      "         [1.0000e+00, 5.1498e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.7302e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.1117e-04],\n",
      "         [9.8828e-01, 1.0193e-02],\n",
      "         [6.6016e-01, 3.3789e-01],\n",
      "         [1.9287e-02, 9.8047e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False]]) tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3100 to ./videos/variable_turn_tictactoe_muzero/0/episode_003100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3100 to ./videos/variable_turn_tictactoe_muzero/1/episode_003100.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3100. Recorded 6 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3100 to ./videos/variable_turn_tictactoe_muzero/3/episode_003100.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3100 to ./videos/variable_turn_tictactoe_muzero/2/episode_003100.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3100. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "5500\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[7, 6, 3, 8, 0],\n",
      "        [4, 8, 3, 1, 7],\n",
      "        [8, 1, 5, 0, 3],\n",
      "        [7, 6, 3, 0, 4],\n",
      "        [5, 0, 4, 0, 3],\n",
      "        [4, 7, 8, 3, 6],\n",
      "        [5, 4, 8, 3, 6],\n",
      "        [4, 2, 8, 1, 7]])\n",
      "target value tensor([[ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9801, -0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9321, -0.9415, -0.9510,  0.9606,  0.9703, -0.9801],\n",
      "        [-0.9801,  0.9900,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [-0.9510,  0.9606,  0.9703, -0.9801, -0.9900,  1.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000]])\n",
      "predicted values tensor([[[ 0.5703],\n",
      "         [-0.5352],\n",
      "         [-0.5195],\n",
      "         [ 0.4746],\n",
      "         [ 0.4707],\n",
      "         [ 0.0996]],\n",
      "\n",
      "        [[ 0.3770],\n",
      "         [ 0.5547],\n",
      "         [-0.8438],\n",
      "         [-0.7539],\n",
      "         [ 0.6484],\n",
      "         [ 0.2441]],\n",
      "\n",
      "        [[ 0.2002],\n",
      "         [ 0.0305],\n",
      "         [ 0.2734],\n",
      "         [ 0.0045],\n",
      "         [ 0.0212],\n",
      "         [ 0.1777]],\n",
      "\n",
      "        [[ 0.4375],\n",
      "         [-0.4043],\n",
      "         [-0.4414],\n",
      "         [ 0.4375],\n",
      "         [ 0.1680],\n",
      "         [ 0.1030]],\n",
      "\n",
      "        [[-0.5234],\n",
      "         [ 0.5234],\n",
      "         [ 0.2637],\n",
      "         [ 0.0297],\n",
      "         [-0.0075],\n",
      "         [ 0.1543]],\n",
      "\n",
      "        [[ 0.2754],\n",
      "         [-0.5742],\n",
      "         [-0.5508],\n",
      "         [ 0.7461],\n",
      "         [ 0.4453],\n",
      "         [ 0.0923]],\n",
      "\n",
      "        [[ 0.4375],\n",
      "         [-0.3223],\n",
      "         [-0.2490],\n",
      "         [ 0.2148],\n",
      "         [ 0.1357],\n",
      "         [ 0.3145]],\n",
      "\n",
      "        [[ 0.4766],\n",
      "         [-0.5195],\n",
      "         [-0.5703],\n",
      "         [ 0.5898],\n",
      "         [ 0.3203],\n",
      "         [ 0.1484]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [-0.0077],\n",
      "         [ 0.0034],\n",
      "         [ 0.0059],\n",
      "         [ 0.1387],\n",
      "         [ 0.2451]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0173],\n",
      "         [-0.0303],\n",
      "         [ 0.0105],\n",
      "         [-0.0064],\n",
      "         [ 0.2178]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.2402],\n",
      "         [ 0.2393],\n",
      "         [ 0.5898],\n",
      "         [-0.0776],\n",
      "         [ 0.1826]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0347],\n",
      "         [-0.0165],\n",
      "         [ 0.0383],\n",
      "         [ 0.0942],\n",
      "         [ 0.6367]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0728],\n",
      "         [ 0.0320],\n",
      "         [ 0.6406],\n",
      "         [ 0.0205],\n",
      "         [ 0.1699]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0330],\n",
      "         [-0.0161],\n",
      "         [-0.0332],\n",
      "         [ 0.0518],\n",
      "         [ 0.6328]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0079],\n",
      "         [-0.0212],\n",
      "         [-0.0033],\n",
      "         [ 0.1226],\n",
      "         [ 0.4570]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0796],\n",
      "         [-0.0123],\n",
      "         [-0.0193],\n",
      "         [ 0.0542],\n",
      "         [ 0.7695]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [6.9809e-04, 1.0000e+00],\n",
      "         [6.1989e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 3.4332e-05],\n",
      "         [1.0000e+00, 1.5354e-04],\n",
      "         [5.3516e-01, 4.6484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 7.6675e-04],\n",
      "         [1.7929e-04, 1.0000e+00],\n",
      "         [2.0981e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.2030e-04],\n",
      "         [1.0000e+00, 8.9645e-04]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [6.1035e-03, 9.9219e-01],\n",
      "         [3.3008e-01, 6.7188e-01],\n",
      "         [9.9219e-01, 6.8054e-03],\n",
      "         [7.4219e-01, 2.5586e-01],\n",
      "         [1.6504e-01, 8.3594e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [5.3406e-04, 1.0000e+00],\n",
      "         [2.3746e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.7537e-05],\n",
      "         [1.0000e+00, 3.5286e-05],\n",
      "         [4.9609e-01, 5.0391e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.4142e-04],\n",
      "         [1.0000e+00, 2.4605e-04],\n",
      "         [5.1562e-01, 4.8438e-01],\n",
      "         [5.9204e-03, 9.9219e-01],\n",
      "         [6.9141e-01, 3.0664e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.9645e-04, 1.0000e+00],\n",
      "         [1.5831e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 4.0436e-04],\n",
      "         [1.0000e+00, 3.1233e-05],\n",
      "         [4.5312e-01, 5.4688e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [2.6894e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.9325e-05],\n",
      "         [1.0000e+00, 1.0300e-03],\n",
      "         [2.8320e-01, 7.1484e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [7.3242e-04, 1.0000e+00],\n",
      "         [4.6730e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 6.1393e-06],\n",
      "         [1.0000e+00, 4.7302e-04],\n",
      "         [8.4766e-01, 1.5039e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3200 to ./videos/variable_turn_tictactoe_muzero/0/episode_003200.mp4\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3200 to ./videos/variable_turn_tictactoe_muzero/1/episode_003200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3200 to ./videos/variable_turn_tictactoe_muzero/3/episode_003200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3200. Recorded 7 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Started recording episode 3200 to ./videos/variable_turn_tictactoe_muzero/2/episode_003200.mp4\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "Stopped recording episode 3200. Recorded 10 frames.\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "plotting score\n",
      "plotting policy_loss\n",
      "plotting value_loss\n",
      "plotting reward_loss\n",
      "plotting to_play_loss\n",
      "plotting cons_loss\n",
      "plotting loss\n",
      "plotting test_score\n",
      "  subkey score\n",
      "  subkey max_score\n",
      "  subkey min_score\n",
      "plotting episode_length\n",
      "plotting root_children_values\n",
      "plotting test_score_vs_random\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting test_score_vs_tictactoe_expert\n",
      "  subkey score\n",
      "  subkey player_0_score\n",
      "  subkey player_1_score\n",
      "  subkey player_0_win%\n",
      "  subkey player_1_win%\n",
      "plotting q_loss\n",
      "plotting sigma_loss\n",
      "plotting vqvae_commitment_cost\n",
      "plotting policy_entropy\n",
      "plotting value_diff\n",
      "plotting policy_improvement\n",
      "  subkey network\n",
      "  subkey search\n",
      "plotting latent viz latent_root using umap\n",
      "  Saving latent viz to checkpoints/variable_turn_tictactoe_muzero/graphs/variable_turn_tictactoe_muzero_latent_root_umap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/.venv/lib/python3.12/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "5600\n",
      "actions shape torch.Size([8, 5])\n",
      "target value shape torch.Size([8, 6])\n",
      "predicted values shape torch.Size([8, 6, 1])\n",
      "target rewards shape torch.Size([8, 6])\n",
      "predicted rewards shape torch.Size([8, 6, 1])\n",
      "target to plays shape torch.Size([8, 6, 2])\n",
      "predicted to_plays shape torch.Size([8, 6, 2])\n",
      "masks shape torch.Size([8, 6]) torch.Size([8, 6])\n",
      "actions tensor([[3, 2, 6, 4, 0],\n",
      "        [2, 3, 7, 5, 1],\n",
      "        [6, 8, 3, 0, 1],\n",
      "        [4, 0, 3, 5, 1],\n",
      "        [5, 4, 0, 0, 1],\n",
      "        [4, 0, 7, 6, 2],\n",
      "        [8, 6, 0, 7, 2],\n",
      "        [3, 0, 2, 0, 1]])\n",
      "target value tensor([[ 0.9703, -0.9801, -0.9900,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [-0.9900,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9606, -0.9703, -0.9801,  0.9900,  1.0000,  0.0000],\n",
      "        [ 0.9510,  0.9606, -0.9703, -0.9801,  0.9900,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "predicted values tensor([[[ 2.8516e-01],\n",
      "         [ 2.6172e-01],\n",
      "         [ 1.9629e-01],\n",
      "         [ 2.8320e-01],\n",
      "         [-1.0596e-01],\n",
      "         [-4.9805e-02]],\n",
      "\n",
      "        [[ 2.7344e-01],\n",
      "         [ 3.5547e-01],\n",
      "         [ 1.9824e-01],\n",
      "         [ 2.5781e-01],\n",
      "         [ 1.9434e-01],\n",
      "         [-2.1057e-03]],\n",
      "\n",
      "        [[ 8.7891e-03],\n",
      "         [ 1.5820e-01],\n",
      "         [ 1.7773e-01],\n",
      "         [ 4.6921e-04],\n",
      "         [-2.3438e-02],\n",
      "         [ 9.3750e-02]],\n",
      "\n",
      "        [[-4.3359e-01],\n",
      "         [-3.4961e-01],\n",
      "         [ 3.8086e-01],\n",
      "         [ 2.5977e-01],\n",
      "         [ 3.6865e-02],\n",
      "         [ 3.7891e-01]],\n",
      "\n",
      "        [[-2.0410e-01],\n",
      "         [ 3.5156e-01],\n",
      "         [ 1.0742e-01],\n",
      "         [ 2.0605e-01],\n",
      "         [ 6.2988e-02],\n",
      "         [ 1.6211e-01]],\n",
      "\n",
      "        [[ 2.5195e-01],\n",
      "         [-5.7812e-01],\n",
      "         [-5.9375e-01],\n",
      "         [ 7.1875e-01],\n",
      "         [ 5.0000e-01],\n",
      "         [ 1.3672e-01]],\n",
      "\n",
      "        [[ 4.8828e-01],\n",
      "         [ 4.8633e-01],\n",
      "         [-5.3125e-01],\n",
      "         [-5.9375e-01],\n",
      "         [ 7.8516e-01],\n",
      "         [ 5.7422e-01]],\n",
      "\n",
      "        [[ 5.8984e-01],\n",
      "         [ 6.3477e-02],\n",
      "         [ 2.5391e-02],\n",
      "         [-2.2095e-02],\n",
      "         [-8.4473e-02],\n",
      "         [ 6.4941e-02]]], dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)\n",
      "target rewards tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "predicted rewards tensor([[[ 0.0000],\n",
      "         [ 0.3281],\n",
      "         [ 0.1387],\n",
      "         [ 0.5273],\n",
      "         [ 0.8164],\n",
      "         [ 0.0544]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.3301],\n",
      "         [ 0.3730],\n",
      "         [ 0.3789],\n",
      "         [ 0.7227],\n",
      "         [ 0.4961]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0591],\n",
      "         [ 0.4082],\n",
      "         [ 0.4668],\n",
      "         [ 0.0127],\n",
      "         [ 0.1680]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0237],\n",
      "         [-0.0068],\n",
      "         [ 0.1011],\n",
      "         [ 0.9648],\n",
      "         [ 0.2314]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0306],\n",
      "         [ 0.1035],\n",
      "         [ 0.3379],\n",
      "         [-0.0532],\n",
      "         [ 0.4297]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [-0.0081],\n",
      "         [ 0.0087],\n",
      "         [ 0.0420],\n",
      "         [ 0.2832],\n",
      "         [ 0.6797]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.0820],\n",
      "         [ 0.0144],\n",
      "         [ 0.0317],\n",
      "         [ 0.0491],\n",
      "         [ 0.2793]],\n",
      "\n",
      "        [[ 0.0000],\n",
      "         [ 0.9062],\n",
      "         [ 0.0649],\n",
      "         [ 0.3125],\n",
      "         [-0.0176],\n",
      "         [ 0.2236]]], grad_fn=<PermuteBackward0>)\n",
      "target to plays tensor([[[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "predicted to_plays tensor([[[0.0000e+00, 0.0000e+00],\n",
      "         [2.1094e-01, 7.8906e-01],\n",
      "         [3.4523e-04, 1.0000e+00],\n",
      "         [6.9531e-01, 3.0469e-01],\n",
      "         [9.8438e-01, 1.5442e-02],\n",
      "         [7.3438e-01, 2.6758e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 5.8746e-04],\n",
      "         [1.3867e-01, 8.5938e-01],\n",
      "         [5.9570e-02, 9.4141e-01],\n",
      "         [3.8672e-01, 6.1328e-01],\n",
      "         [9.9609e-01, 5.1270e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [4.8828e-04, 1.0000e+00],\n",
      "         [4.1992e-01, 5.8203e-01],\n",
      "         [9.9609e-01, 2.0447e-03],\n",
      "         [5.7422e-01, 4.2383e-01],\n",
      "         [4.7852e-02, 9.5312e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0252e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 2.2769e-05],\n",
      "         [1.0000e+00, 2.8229e-04],\n",
      "         [8.8672e-01, 1.1182e-01],\n",
      "         [2.6367e-02, 9.7266e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 3.5018e-06],\n",
      "         [1.0000e+00, 4.6730e-05],\n",
      "         [5.6250e-01, 4.3750e-01],\n",
      "         [4.1199e-03, 9.9609e-01],\n",
      "         [4.4727e-01, 5.5078e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.3161e-04, 1.0000e+00],\n",
      "         [3.1233e-05, 1.0000e+00],\n",
      "         [1.0000e+00, 4.2343e-04],\n",
      "         [1.0000e+00, 4.6539e-04],\n",
      "         [8.3203e-01, 1.6602e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 9.8348e-06],\n",
      "         [3.0518e-04, 1.0000e+00],\n",
      "         [1.6308e-04, 1.0000e+00],\n",
      "         [1.0000e+00, 5.7817e-06],\n",
      "         [1.0000e+00, 2.6703e-05]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [9.1797e-01, 8.1543e-02],\n",
      "         [4.5654e-02, 9.5312e-01],\n",
      "         [3.7109e-01, 6.2891e-01],\n",
      "         [9.2969e-01, 7.2266e-02],\n",
      "         [8.9062e-01, 1.0840e-01]]], grad_fn=<PermuteBackward0>)\n",
      "masks tensor([[ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False]]) tensor([[ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False]])\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Multi Turn Tic Tac Toe ---\")\n",
    "params_batched = params.copy()\n",
    "params_batched[\"search_batch_size\"] = 5 \n",
    "params_batched[\"use_virtual_mean\"] = True\n",
    "\n",
    "env_batch = VariableTurnTicTacToeConfig().make_env()\n",
    "config_batch = MuZeroConfig(config_dict=params_batched, game_config=game_config)\n",
    "config_batch.search_batch_size = 5 # Explicitly set\n",
    "\n",
    "agent_batch = MuZeroAgent(\n",
    "    env=env_batch,\n",
    "    config=config_batch,\n",
    "    name=\"variable_turn_tictactoe_muzero\",\n",
    "    device=\"cpu\",\n",
    "    test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
    ")\n",
    "agent_batch.checkpoint_interval = 100\n",
    "agent_batch.test_interval = 1000\n",
    "agent_batch.test_trials = 100\n",
    "\n",
    "start_time = time.time()\n",
    "agent_batch.train()\n",
    "end_time = time.time()\n",
    "print(f\"MuZero Batched Time: {end_time - start_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
