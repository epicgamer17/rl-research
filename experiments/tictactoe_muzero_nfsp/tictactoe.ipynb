{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77528eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# sys.path.append(\"../../\")\n",
    "\n",
    "# from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "# import dill as pickle\n",
    "# from hyperopt import hp\n",
    "# from hyperopt.pyll import scope\n",
    "# from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "# import gymnasium as gym\n",
    "# import torch\n",
    "# from muzero.action_functions import action_as_plane as action_function\n",
    "# from torch.optim import Adam, SGD\n",
    "\n",
    "# search_space = {\n",
    "#     \"kernel_initializer\": hp.choice(\n",
    "#         \"kernel_initializer\",\n",
    "#         [\n",
    "#             \"he_uniform\",\n",
    "#             \"he_normal\",\n",
    "#             \"glorot_uniform\",\n",
    "#             \"glorot_normal\",\n",
    "#             \"orthogonal\",\n",
    "#         ],\n",
    "#     ),\n",
    "#     \"optimizer\": hp.choice(\n",
    "#         \"optimizer\",\n",
    "#         [\n",
    "#             {\n",
    "#                 \"optimizer\": \"adam\",\n",
    "#                 # \"adam_epsilon\": hp.qloguniform(\n",
    "#                 #     \"adam_epsilon\", np.log(1e-8), np.log(0.5), 1e-8\n",
    "#                 # ),\n",
    "#                 \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 1, 8, 1)),\n",
    "#             },\n",
    "#             {\n",
    "#                 \"optimizer\": \"sgd\",\n",
    "#                 \"momentum\": hp.quniform(\"momentum\", 0, 1, 0.1),\n",
    "#             },\n",
    "#         ],\n",
    "#     ),\n",
    "#     \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "#     # \"learning_rate\": hp.qloguniform(\n",
    "#     #     \"learning_rate\", np.log(0.0001), np.log(0.01), 0.0001\n",
    "#     # ),\n",
    "#     \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 1, 4, 1)),\n",
    "#     \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "#     \"residual_filters\": scope.int(\n",
    "#         hp.qloguniform(\"residual_filters\", np.log(8), np.log(32), 8)\n",
    "#     ),\n",
    "#     \"residual_stacks\": scope.int(\n",
    "#         hp.qloguniform(\"residual_stacks\", np.log(1), np.log(3), 1)\n",
    "#     ),\n",
    "#     \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "#     \"actor_and_critic_conv_filters\": scope.int(\n",
    "#         hp.qloguniform(\n",
    "#             \"actor_and_critic_conv_filters\", np.log(0 + 8), np.log(32 + 8), 8\n",
    "#         )\n",
    "#         - 8  # to make 0 an option\n",
    "#     ),\n",
    "#     \"reward_conv_layers\": hp.choice(\"reward_conv_layers\", [[]]),\n",
    "#     \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "#     \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "#     \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "#     \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "#     \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "#     \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "#     \"root_dirichlet_alpha\": hp.quniform(\n",
    "#         \"root_dirichlet_alpha\", 0.1, 2.0, 0.1\n",
    "#     ),  # hp.choice(\"root_dirichlet_alpha\", [0.3, 1.0, 2.0]),\n",
    "#     \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "#     \"num_simulations\": scope.int(\n",
    "#         hp.qloguniform(\"num_simulations\", np.log(25), np.log(25) + 1e-10, 25)\n",
    "#     ),\n",
    "# \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 0, 4, 1))],\n",
    "# \"temperatures\": hp.choice(\"temperatures\", [1.0, 0.1]),\n",
    "# \"temperature_with_training_steps\": hp.choice(\n",
    "#     \"temperature_with_training_steps\", False\n",
    "# ),\n",
    "#     \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "#     \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "#     \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "#     \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "#     \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "#     \"policy_loss_function\": hp.choice(\n",
    "#         \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "#     ),\n",
    "#     \"training_steps\": scope.int(\n",
    "#         hp.qloguniform(\"training_steps\", np.log(10000), np.log(30000), 10000)\n",
    "#     ),\n",
    "#     # \"minibatch_size\": scope.int(\n",
    "#     #     hp.qloguniform(\"minibatch_size\", np.log(8), np.log(64), 8)\n",
    "#     # ),\n",
    "#     # \"min_replay_buffer_size\": scope.int(\n",
    "#     #     hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "#     # ),\n",
    "#     # \"replay_buffer_size\": scope.int(\n",
    "#     #     hp.qloguniform(\"replay_buffer_size\", np.log(10000), np.log(200000), 10000)\n",
    "#     # ),\n",
    "#     \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 6, 1))),\n",
    "#     \"min_replay_buffer_size\": scope.int(\n",
    "#         hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "#     ),\n",
    "#     \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 6, 1))),\n",
    "#     \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "#     \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "#     \"clipnorm\": scope.int(hp.quniform(\"clipnorm\", 0, 10.0, 1)),\n",
    "#     \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "#     \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "#     \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "#     \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "#     \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "#     \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "#     \"multi_process\": hp.choice(\n",
    "#         \"multi_process\",\n",
    "#         [\n",
    "#             {\n",
    "#                 \"multi_process\": True,\n",
    "#                 \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "#             },\n",
    "#             # {\n",
    "#             #     \"multi_process\": False,\n",
    "#             #     \"games_per_generation\": scope.int(\n",
    "#             #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "#             #     ),\n",
    "#             # },\n",
    "#         ],\n",
    "#     ),\n",
    "#     \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "# }\n",
    "\n",
    "# initial_best_config = []\n",
    "\n",
    "# search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New SMALLEST SEARCH SPACE, IMPROVED\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_plane as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# size = 5 * 1 * 1 * 4.0 * 3 * 2.0 * 5 * 1 * 1 = 600\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 8, 8 + 1e-8, 2)),\n",
    "                \"adam_epsilon\": hp.choice(\"adam_epsilon\", [1e-8]),\n",
    "                \"adam_learning_rate\": 10\n",
    "                ** (-hp.quniform(\"adam_learning_rate\", 3, 3 + 1e-8, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"optimizer\": \"sgd\",\n",
    "            #     \"momentum\": hp.choice(\"momentum\", [0.0, 0.9]),\n",
    "            #     \"sgd_learning_rate\": 10 ** (-hp.quniform(\"sgd_learning_rate\", 1, 3, 1)),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    \"residual_filters\": scope.int(\n",
    "        hp.qloguniform(\"residual_filters\", np.log(24), np.log(24) + 1e-8, 8)\n",
    "    ),\n",
    "    \"residual_stacks\": scope.int(\n",
    "        hp.qloguniform(\"residual_stacks\", np.log(1), np.log(4), 1)\n",
    "    ),\n",
    "    \"output_filters\": scope.int(\n",
    "        hp.qloguniform(\"output_filters\", np.log(16 + 8), np.log(16 + 8) + 1e-8, 8)\n",
    "        - 8  # to make 0 an option\n",
    "    ),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": 2 ** (hp.quniform(\"root_dirichlet_alpha\", -3, -1, 1.0)),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(50), np.log(75), 25)\n",
    "    ),\n",
    "    \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 4, 8, 1))],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(35000), np.log(45000), 10000)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 3 + 1e-8, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\n",
    "            \"min_replay_buffer_size\", np.log(5000), np.log(5000) + 1e-8, 1000\n",
    "        )\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(\n",
    "        10 ** (hp.quniform(\"replay_buffer_size\", 5, 5 + 1e-8, 1))\n",
    "    ),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "    \"clipnorm\": hp.choice(\n",
    "        # \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clip_val\", 0, 2, 1)))]\n",
    "        \"clipnorm\",\n",
    "        [0.0],\n",
    "    ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 2, 2 + 1e-8, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)\n",
    "\n",
    "\n",
    "def prep_params(params):\n",
    "    assert params[\"output_filters\"] <= params[\"residual_filters\"]\n",
    "\n",
    "    params[\"residual_layers\"] = [(params[\"residual_filters\"], 3, 1)] * params[\n",
    "        \"residual_stacks\"\n",
    "    ]\n",
    "    del params[\"residual_filters\"]\n",
    "    del params[\"residual_stacks\"]\n",
    "    if params[\"output_filters\"] != 0:\n",
    "        params[\"actor_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"critic_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"reward_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "    else:\n",
    "        params[\"actor_conv_layers\"] = []\n",
    "        params[\"critic_conv_layers\"] = []\n",
    "    del params[\"output_filters\"]\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "        params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"adam_learning_rate\"]\n",
    "        params[\"optimizer\"] = Adam\n",
    "    elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "        params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"sgd_learning_rate\"]\n",
    "        params[\"optimizer\"] = SGD\n",
    "\n",
    "    print(params[\"clipnorm\"])\n",
    "    if isinstance(params[\"clipnorm\"], dict):\n",
    "        params[\"clipnorm\"] = params[\"clipnorm\"][\"clipval\"]\n",
    "    params[\"support_range\"] = None\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALLEST SEARCH SPACE, IMPROVED\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_plane as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 8, 8 + 1e-8, 2)),\n",
    "                \"adam_epsilon\": hp.choice(\"adam_epsilon\", [1e-8]),\n",
    "                \"adam_learning_rate\": 10\n",
    "                ** (-hp.quniform(\"adam_learning_rate\", 2, 3, 1)),\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": \"sgd\",\n",
    "                \"momentum\": hp.choice(\"momentum\", [0.0, 0.9]),\n",
    "                \"sgd_learning_rate\": 10 ** (-hp.quniform(\"sgd_learning_rate\", 1, 3, 1)),\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    \"residual_filters\": scope.int(\n",
    "        hp.qloguniform(\"residual_filters\", np.log(24), np.log(24) + 1e-8, 8)\n",
    "    ),\n",
    "    \"residual_stacks\": scope.int(\n",
    "        hp.qloguniform(\"residual_stacks\", np.log(1), np.log(1) + 1e-8, 1)\n",
    "    ),\n",
    "    \"output_filters\": scope.int(\n",
    "        hp.qloguniform(\"output_filters\", np.log(16 + 8), np.log(16 + 8) + 1e-8, 8)\n",
    "        - 8  # to make 0 an option\n",
    "    ),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": 2 ** (hp.quniform(\"root_dirichlet_alpha\", -2, 1, 1.0)),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(25) + 1e-10, 25)\n",
    "    ),\n",
    "    \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 0, 8, 1))],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(35000), np.log(45000), 10000)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 5, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 7, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "    \"clipnorm\": hp.choice(\n",
    "        \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clip_val\", 0, 2, 1)))]\n",
    "    ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)\n",
    "\n",
    "\n",
    "def prep_params(params):\n",
    "    assert params[\"output_filters\"] <= params[\"residual_filters\"]\n",
    "\n",
    "    params[\"residual_layers\"] = [(params[\"residual_filters\"], 3, 1)] * params[\n",
    "        \"residual_stacks\"\n",
    "    ]\n",
    "    del params[\"residual_filters\"]\n",
    "    del params[\"residual_stacks\"]\n",
    "    if params[\"output_filters\"] != 0:\n",
    "        params[\"actor_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"critic_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"reward_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "    else:\n",
    "        params[\"actor_conv_layers\"] = []\n",
    "        params[\"critic_conv_layers\"] = []\n",
    "    del params[\"output_filters\"]\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "        params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"adam_learning_rate\"]\n",
    "        params[\"optimizer\"] = Adam\n",
    "    elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "        params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"sgd_learning_rate\"]\n",
    "        params[\"optimizer\"] = SGD\n",
    "\n",
    "    print(params[\"clipnorm\"])\n",
    "    if isinstance(params[\"clipnorm\"], dict):\n",
    "        params[\"clipnorm\"] = params[\"clipnorm\"][\"clipval\"]\n",
    "    params[\"support_range\"] = None\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIGHTLY WIDER IMPROVED SPACE\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_plane as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 8, 8 + 1e-10, 2)),\n",
    "                \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 2, 5, 1)),\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": \"sgd\",\n",
    "                \"momentum\": hp.choice(\"momentum\", [0.0, 0.9]),\n",
    "                \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 1, 3, 1)),\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    \"residual_filters\": scope.int(\n",
    "        hp.qloguniform(\"residual_filters\", np.log(8), np.log(32), 8)\n",
    "    ),\n",
    "    \"residual_stacks\": scope.int(\n",
    "        hp.qloguniform(\"residual_stacks\", np.log(1), np.log(3), 1)\n",
    "    ),\n",
    "    \"output_filters\": scope.int(\n",
    "        hp.qloguniform(\"output_filters\", np.log(0 + 8), np.log(32 + 8), 8)\n",
    "        - 8  # to make 0 an option\n",
    "    ),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": 2 ** (hp.quniform(\"root_dirichlet_alpha\", -2, 2, 1.0)),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(25) + 1e-10, 25)\n",
    "    ),\n",
    "    \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 0, 8, 1))],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(11000), np.log(33000), 11000)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 6, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 6, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "    \"clipnorm\": hp.choice(\n",
    "        \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clipnorm\", 0, 2, 1)))]\n",
    "    ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL SPACE\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_plane as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": hp.qloguniform(\n",
    "                #     \"adam_epsilon\", np.log(1e-8), np.log(0.5), 1e-8\n",
    "                # ),\n",
    "                \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 2, 8, 2)),\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": \"sgd\",\n",
    "                \"momentum\": hp.quniform(\"momentum\", 0, 0.9, 0.1),\n",
    "                # \"momentum\": hp.choice(\n",
    "                #     \"momentum\", [0.0, 0.9]\n",
    "                # ),\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 1, 4, 1)),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    \"residual_filters\": scope.int(\n",
    "        hp.qloguniform(\"residual_filters\", np.log(8), np.log(32), 8)\n",
    "    ),\n",
    "    \"residual_stacks\": scope.int(\n",
    "        hp.qloguniform(\"residual_stacks\", np.log(1), np.log(3), 1)\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"output_filters\": scope.int(\n",
    "        hp.qloguniform(\"output_filters\", np.log(0 + 8), np.log(32 + 8), 8)\n",
    "        - 8  # to make 0 an option\n",
    "    ),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": hp.quniform(\"root_dirichlet_alpha\", 0.1, 2.0, 0.1),\n",
    "    # \"root_dirichlet_alpha\": 2\n",
    "    # ** (\n",
    "    #     hp.quniform(\"root_dirichlet_alpha\", -2, 2, 1.0)\n",
    "    # ),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(25) + 1e-10, 25)\n",
    "    ),\n",
    "    \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 0, 8, 1))],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(11000), np.log(33000), 11000)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 6, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 6, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "    \"clipnorm\": scope.int(hp.quniform(\"clipnorm\", 0, 10.0, 1)),\n",
    "    # \"clipnorm\": hp.choice(\n",
    "    #     \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clipnorm\", 0, 2, 1)))]\n",
    "    # ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALL STANDARD SPACE (no picking num filters etc), should be compatible with initial\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_plane as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": hp.qloguniform(\n",
    "                #     \"adam_epsilon\", np.log(1e-8), np.log(0.5), 1e-8\n",
    "                # ),\n",
    "                \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 8.01, 8.02, 2)),\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": \"sgd\",\n",
    "                \"momentum\": hp.quniform(\"momentum\", 0.91, 0.92, 0.1),\n",
    "                # \"momentum\": hp.choice(\n",
    "                #     \"momentum\", [0.0, 0.9]\n",
    "                # ),\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"learning_rate\": 10 ** (-hp.quniform(\"learning_rate\", 1, 4, 1)),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    \"residual_filters\": scope.int(\n",
    "        hp.qloguniform(\"residual_filters\", np.log(24), np.log(24) + 1e-8, 8)\n",
    "    ),\n",
    "    \"residual_stacks\": scope.int(\n",
    "        hp.qloguniform(\"residual_stacks\", np.log(1), np.log(1) + 1e-8, 1)\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"output_filters\": scope.int(\n",
    "        hp.qloguniform(\"output_filters\", np.log(16 + 8), np.log(16 + 8) + 1e-8, 8)\n",
    "        - 8  # to make 0 an option\n",
    "    ),\n",
    "    \"actor_dense_layer_widths\": hp.choice(\"actor_dense_layer_widths\", [[]]),\n",
    "    \"critic_dense_layer_widths\": hp.choice(\"critic_dense_layer_widths\", [[]]),\n",
    "    \"reward_dense_layer_widths\": hp.choice(\"reward_dense_layer_widths\", [[]]),\n",
    "    \"dense_layer_widths\": hp.choice(\"dense_layer_widths\", [[]]),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": hp.quniform(\"root_dirichlet_alpha\", 0.1, 2.0, 0.1),\n",
    "    # \"root_dirichlet_alpha\": 2\n",
    "    # ** (\n",
    "    #     hp.quniform(\"root_dirichlet_alpha\", -2, 2, 1.0)\n",
    "    # ),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        hp.qloguniform(\"num_simulations\", np.log(25), np.log(25) + 1e-10, 25)\n",
    "    ),\n",
    "    \"temperature_updates\": [scope.int(hp.quniform(\"temperature_updates\", 0, 8, 1))],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(11000), np.log(33000), 11000)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 6, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        hp.qloguniform(\"min_replay_buffer_size\", np.log(1000), np.log(10000), 1000)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(10 ** (hp.quniform(\"replay_buffer_size\", 4, 6, 1))),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [9]),\n",
    "    \"clipnorm\": scope.int(hp.quniform(\"clipnorm\", 0, 10.0, 1)),\n",
    "    # \"clipnorm\": hp.choice(\n",
    "    #     \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clipnorm\", 0, 2, 1)))]\n",
    "    # ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.choice(\"per_alpha\", [0.0]),\n",
    "    \"per_beta\": hp.choice(\"per_beta\", [0.0]),\n",
    "    \"per_beta_final\": hp.choice(\"per_beta_final\", [0.0]),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 1, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\")]),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_params(params):\n",
    "    assert params[\"output_filters\"] <= params[\"residual_filters\"]\n",
    "\n",
    "    params[\"residual_layers\"] = [(params[\"residual_filters\"], 3, 1)] * params[\n",
    "        \"residual_stacks\"\n",
    "    ]\n",
    "    del params[\"residual_filters\"]\n",
    "    del params[\"residual_stacks\"]\n",
    "    if params[\"output_filters\"] != 0:\n",
    "        params[\"actor_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"critic_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "        params[\"reward_conv_layers\"] = [(params[\"output_filters\"], 1, 1)]\n",
    "    else:\n",
    "        params[\"actor_conv_layers\"] = []\n",
    "        params[\"critic_conv_layers\"] = []\n",
    "    del params[\"output_filters\"]\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "        params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "        params[\"optimizer\"] = Adam\n",
    "    elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "        params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "        params[\"optimizer\"] = SGD\n",
    "\n",
    "    params[\"support_range\"] = None\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd34594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import dill as pickle\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from elo.elo import StandingsTable\n",
    "\n",
    "games_per_pair = 10\n",
    "try:\n",
    "    players = pickle.load(open(\"./tictactoe_players.pkl\", \"rb\"))\n",
    "    table = pickle.load(open(\"./tictactoe_table.pkl\", \"rb\"))\n",
    "    print(table.bayes_elo())\n",
    "    print(table.get_win_table())\n",
    "    print(table.get_draw_table())\n",
    "except:\n",
    "    players = []\n",
    "    table = StandingsTable([], start_elo=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48758b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_configs.tictactoe_config import TicTacToeConfig\n",
    "import torch\n",
    "\n",
    "from pettingzoo.classic import tictactoe_v3\n",
    "\n",
    "\n",
    "def play_game(player1, player2):\n",
    "\n",
    "    env = TicTacToeConfig().make_env()\n",
    "    with torch.no_grad():  # No gradient computation during testing\n",
    "        # Reset environment\n",
    "        env.reset()\n",
    "        state, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "        agent_id = env.agent_selection\n",
    "        current_player = env.agents.index(agent_id)\n",
    "        # state, info = process_petting_zoo_obs(state, info, current_player)\n",
    "        agent_names = env.agents.copy()\n",
    "\n",
    "        episode_length = 0\n",
    "        while not done and episode_length < 1000:  # Safety limit\n",
    "            # Get current agent and player\n",
    "            episode_length += 1\n",
    "\n",
    "            if current_player == 0:\n",
    "                prediction = player1.predict(state, info, env=env)\n",
    "                action = player1.select_actions(prediction, info).item()\n",
    "            else:\n",
    "                prediction = player2.predict(state, info, env=env)\n",
    "                action = player2.select_actions(prediction, info).item()\n",
    "\n",
    "            # Step environment\n",
    "            env.step(action)\n",
    "            state, reward, termination, truncation, info = env.last()\n",
    "            agent_id = env.agent_selection\n",
    "            current_player = env.agents.index(agent_id)\n",
    "            # state, info = process_petting_zoo_obs(state, info, current_player)\n",
    "            done = termination or truncation\n",
    "        print(env.rewards)\n",
    "        return env.rewards[\"player_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0235f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 144\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 145\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 146\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 147\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 148\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 149\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 150\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 151\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 152\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 153\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 154\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 155\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 156\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 157\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 158\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 159\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 160\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 161\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 162\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 163\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 164\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 165\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 166\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 167\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 168\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 169\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 170\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 171\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 172\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 173\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 174\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 175\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 176\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 177\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 178\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 179\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 180\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 181\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 182\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 183\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 184\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 185\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 186\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 187\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 188\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 189\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 190\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 191\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 192\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 193\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 194\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 195\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 196\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 197\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 198\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 199\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 200\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 201\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 202\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 203\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 204\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 205\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 206\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 207\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 208\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 209\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 210\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 211\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 212\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 213\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 214\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 215\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 216\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 217\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 218\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 219\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 220\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 221\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 222\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 223\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 224\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 225\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 226\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 227\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 228\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 229\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 230\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 231\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 232\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 233\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 234\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 235\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 236\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 237\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 238\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 239\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 240\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 241\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 242\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 243\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 244\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 245\n",
      "{'player_0': -1, 'player_1': 1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 246\n",
      "{'player_0': 1, 'player_1': -1}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 247\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 248\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 249\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "Playing tictactoe_expert vs tictactoe_muzero_42 game 250\n",
      "{'player_0': 0, 'player_1': 0}\n",
      "{'Elo table':                       Elo Games  Score  Draws\n",
      "tictactoe_expert     1410   500  0.505  0.318\n",
      "tictactoe_muzero_42  1389   500  0.495  0.318, 'eloAdvantage': -731.2508605220805, 'eloDraw': 2131.2281166108937}\n",
      "                      Elo Games  Score  Draws\n",
      "tictactoe_expert     1410   500  0.505  0.318\n",
      "tictactoe_muzero_42  1389   500  0.495  0.318\n",
      "Elo: 2758.0\n",
      "parallel programs done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:8: RuntimeWarning: overflow encountered in power\n",
      "  return 1.0 / (1 + np.power(10, D / 400))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  l += winTable[i][j] * np.log(f(elos[i] - elos[j] - eloAdvantage + eloDraw))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:15: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  l += winTable[i][j] * np.log(f(elos[i] - elos[j] - eloAdvantage + eloDraw))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  +0.5 * drawTable[i][j] * np.log(\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  +0.5 * drawTable[i][j] * np.log(\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: invalid value encountered in log\n",
      "  +0.5 * drawTable[i][j] * np.log(\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:8: RuntimeWarning: overflow encountered in power\n",
      "  return 1.0 / (1 + np.power(10, D / 400))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  l += winTable[i][j] * np.log(f(elos[i] - elos[j] - eloAdvantage + eloDraw))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:15: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  l += winTable[i][j] * np.log(f(elos[i] - elos[j] - eloAdvantage + eloDraw))\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  +0.5 * drawTable[i][j] * np.log(\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  +0.5 * drawTable[i][j] * np.log(\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../elo/elo.py:16: RuntimeWarning: invalid value encountered in log\n",
      "  +0.5 * drawTable[i][j] * np.log(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:  {'action_function': <function action_as_plane at 0x147de4160>, 'actor_dense_layer_widths': (), 'clip_low_prob': 0.0, 'clipnorm': 0.0, 'conv_layers': (), 'critic_dense_layer_widths': (), 'dense_layer_widths': (), 'kernel_initializer': 'he_uniform', 'known_bounds': (-1, 1), 'lr_ratio': inf, 'min_replay_buffer_size': 5000, 'minibatch_size': 8, 'multi_process': {'multi_process': True, 'num_workers': 2}, 'n_step': 9, 'noisy_sigma': 0.0, 'num_simulations': 75, 'optimizer': {'adam_epsilon': 1e-08, 'adam_learning_rate': 0.001, 'optimizer': 'adam'}, 'output_filters': 16, 'pb_c_base': 19652, 'pb_c_init': 1.25, 'per_alpha': 0.0, 'per_beta': 0.0, 'per_beta_final': 0.0, 'per_epsilon': 0.0001, 'policy_loss_function': <utils.utils.CategoricalCrossentropyLoss object at 0x30de48130>, 'replay_buffer_size': 100000, 'residual_filters': 24, 'residual_stacks': 4, 'reward_dense_layer_widths': (), 'reward_loss_function': <utils.utils.MSELoss object at 0x30de1bfa0>, 'root_dirichlet_alpha': 0.125, 'root_exploration_fraction': 0.25, 'temperature_updates': (8,), 'temperature_with_training_steps': False, 'temperatures': (1.0, 0.1), 'training_steps': 40000, 'unroll_steps': 5, 'value_loss_factor': 1.0, 'value_loss_function': <utils.utils.MSELoss object at 0x30de1be50>, 'weight_decay': 0.0001}\n",
      "Making environments\n",
      "0.0\n",
      "Using default save_intermediate_weights     : False\n",
      "Using         training_steps                : 40000\n",
      "Using         adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.001\n",
      "Using         clipnorm                      : 0.0\n",
      "Using         optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using         weight_decay                  : 0.0001\n",
      "Using default loss_function                 : <class 'utils.utils.MSELoss'>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : he_uniform\n",
      "Using         minibatch_size                : 8\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 5000\n",
      "Using default num_minibatches               : 1\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "Using         known_bounds                  : (-1, 1)\n",
      "Using         residual_layers               : [(24, 3, 1), (24, 3, 1), (24, 3, 1), (24, 3, 1)]\n",
      "Using         conv_layers                   : ()\n",
      "Using         dense_layer_widths            : ()\n",
      "Using default representation_residual_layers: [(24, 3, 1), (24, 3, 1), (24, 3, 1), (24, 3, 1)]\n",
      "Using default representation_conv_layers    : ()\n",
      "Using default representation_dense_layer_widths: []\n",
      "Using default dynamics_residual_layers      : [(24, 3, 1), (24, 3, 1), (24, 3, 1), (24, 3, 1)]\n",
      "Using default dynamics_conv_layers          : ()\n",
      "Using default dynamics_dense_layer_widths   : []\n",
      "Using         reward_conv_layers            : [(16, 1, 1)]\n",
      "Using         reward_dense_layer_widths     : ()\n",
      "Using         critic_conv_layers            : [(16, 1, 1)]\n",
      "Using         critic_dense_layer_widths     : ()\n",
      "Using         actor_conv_layers             : [(16, 1, 1)]\n",
      "Using         actor_dense_layer_widths      : ()\n",
      "Using         noisy_sigma                   : 0.0\n",
      "Using default games_per_generation          : 100\n",
      "Using         value_loss_factor             : 1.0\n",
      "Using         weight_decay                  : 0.0001\n",
      "Using         root_dirichlet_alpha          : 0.125\n",
      "Using         root_exploration_fraction     : 0.25\n",
      "Using         num_simulations               : 75\n",
      "Using         temperatures                  : (1.0, 0.1)\n",
      "Using         temperature_updates           : (8,)\n",
      "Using         temperature_with_training_steps: False\n",
      "Using         clip_low_prob                 : 0.0\n",
      "Using         pb_c_base                     : 19652\n",
      "Using         pb_c_init                     : 1.25\n",
      "Using         value_loss_function           : <utils.utils.MSELoss object at 0x30de1be50>\n",
      "Using         reward_loss_function          : <utils.utils.MSELoss object at 0x30de1bfa0>\n",
      "Using         policy_loss_function          : <utils.utils.CategoricalCrossentropyLoss object at 0x30de48130>\n",
      "Using         action_function               : <function action_as_plane at 0x147de4160>\n",
      "Using         n_step                        : 9\n",
      "Using default discount_factor               : 1.0\n",
      "Using         unroll_steps                  : 5\n",
      "Using         per_alpha                     : 0.0\n",
      "Using         per_beta                      : 0.0\n",
      "Using         per_beta_final                : 0.0\n",
      "Using         per_epsilon                   : 0.0001\n",
      "Using default per_use_batch_weights         : False\n",
      "Using default per_initial_priority_max      : False\n",
      "Using         support_range                 : None\n",
      "Using         multi_process                 : True\n",
      "Using         num_workers                   : 2\n",
      "Using         lr_ratio                      : inf\n",
      "Using device: cpu\n",
      "making test env\n",
      "Test env with record video\n",
      "env render mode rgb_array\n",
      "petting zoo env\n",
      "Test env: RecordVideo<ChannelLastToFirstWrapper<TwoPlayerPlayerPlaneWrapper<FrameStackWrapper<ActionMaskInInfoWrapper<tictactoe_v3>>>>>\n",
      "<class 'method'>\n",
      "petting zoo\n",
      "Observation dimensions: (9, 3, 3)\n",
      "Observation dtype: int8\n",
      "num_actions:  9 <class 'int'>\n",
      "Test agents: [<agents.random.RandomAgent object at 0x30e556da0>, <agents.tictactoe_expert.TicTacToeBestAgent object at 0x323a77d00>]\n",
      "9\n",
      "24\n",
      "24\n",
      "24\n",
      "Hidden state shape: (8, 24, 3, 3)\n",
      "Action function output shape: torch.Size([1, 3, 3])\n",
      "torch.Size([8, 25, 3, 3])\n",
      "dynamics input shape torch.Size([8, 25, 3, 3])\n",
      "25\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "Layer weights:\n",
      "representation.residual_layers.residual_layers.0.conv1.weight:\n",
      "tensor([[[[ 0.0968, -0.0463,  0.0494],\n",
      "          [ 0.0423,  0.0507, -0.0679],\n",
      "          [ 0.0926,  0.0096, -0.0976]],\n",
      "\n",
      "         [[ 0.0200, -0.0924, -0.0424],\n",
      "          [-0.0239, -0.0479,  0.0058],\n",
      "          [ 0.0462, -0.0893,  0.0894]],\n",
      "\n",
      "         [[-0.1008,  0.1085,  0.0549],\n",
      "          [ 0.0722,  0.0339,  0.0533],\n",
      "          [-0.0348, -0.0935,  0.0624]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0026, -0.0950,  0.0200],\n",
      "          [-0.0410,  0.0758,  0.0632],\n",
      "          [ 0.0740,  0.0035, -0.0985]],\n",
      "\n",
      "         [[-0.0627, -0.0010, -0.0530],\n",
      "          [-0.0035,  0.0031, -0.0158],\n",
      "          [ 0.0109,  0.0347,  0.1066]],\n",
      "\n",
      "         [[-0.0118,  0.0361, -0.0435],\n",
      "          [-0.0458, -0.0604, -0.0446],\n",
      "          [ 0.1080, -0.0738,  0.0270]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0938, -0.0873, -0.0308],\n",
      "          [ 0.0104, -0.0330,  0.0922],\n",
      "          [ 0.1029, -0.0820, -0.0599]],\n",
      "\n",
      "         [[-0.0716, -0.0298, -0.0309],\n",
      "          [-0.0900,  0.0906,  0.1023],\n",
      "          [-0.0655, -0.0489, -0.0873]],\n",
      "\n",
      "         [[-0.0844, -0.0478,  0.0665],\n",
      "          [-0.0733,  0.0790,  0.0417],\n",
      "          [-0.0637, -0.0788, -0.0860]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0267, -0.0183,  0.0468],\n",
      "          [-0.1042, -0.0877, -0.0283],\n",
      "          [-0.0384, -0.0899,  0.0562]],\n",
      "\n",
      "         [[-0.0157, -0.0169, -0.0690],\n",
      "          [-0.0928, -0.0667,  0.0555],\n",
      "          [-0.0647,  0.1037,  0.1004]],\n",
      "\n",
      "         [[-0.1105, -0.0420, -0.0237],\n",
      "          [ 0.0593, -0.0791, -0.0334],\n",
      "          [ 0.1042, -0.0774, -0.0449]]],\n",
      "\n",
      "\n",
      "        [[[-0.0855, -0.0677,  0.0249],\n",
      "          [-0.0763,  0.0465, -0.0020],\n",
      "          [ 0.0816,  0.0444, -0.0836]],\n",
      "\n",
      "         [[ 0.0420,  0.0918, -0.0793],\n",
      "          [ 0.1024, -0.0860, -0.0215],\n",
      "          [ 0.0170, -0.0380,  0.1044]],\n",
      "\n",
      "         [[-0.0643,  0.0461, -0.0176],\n",
      "          [ 0.0730, -0.0146, -0.0326],\n",
      "          [-0.0181,  0.0971,  0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0610, -0.0082,  0.0189],\n",
      "          [ 0.0705, -0.0460,  0.0325],\n",
      "          [ 0.0739,  0.0278,  0.0371]],\n",
      "\n",
      "         [[ 0.0701,  0.0870, -0.0524],\n",
      "          [ 0.1053, -0.0823, -0.0469],\n",
      "          [ 0.0117, -0.0333,  0.0411]],\n",
      "\n",
      "         [[-0.0353, -0.0237, -0.0566],\n",
      "          [ 0.0850, -0.0747, -0.0390],\n",
      "          [-0.0172, -0.0746,  0.0065]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0002,  0.0404, -0.0672],\n",
      "          [ 0.0540, -0.0720, -0.0797],\n",
      "          [-0.0052,  0.0974, -0.0850]],\n",
      "\n",
      "         [[-0.0379, -0.1019,  0.0945],\n",
      "          [ 0.0894,  0.0992,  0.0053],\n",
      "          [-0.0193, -0.0606,  0.0779]],\n",
      "\n",
      "         [[ 0.0500, -0.0177,  0.0395],\n",
      "          [ 0.0129,  0.0124, -0.0279],\n",
      "          [-0.0929,  0.0287, -0.0616]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0900, -0.0944, -0.0437],\n",
      "          [ 0.0133, -0.0105, -0.0126],\n",
      "          [-0.0350, -0.0843,  0.0304]],\n",
      "\n",
      "         [[ 0.0925, -0.0664, -0.0207],\n",
      "          [-0.1099, -0.0244, -0.0891],\n",
      "          [-0.1056,  0.0408,  0.0656]],\n",
      "\n",
      "         [[ 0.0081,  0.0233, -0.0396],\n",
      "          [-0.0081,  0.0814,  0.0653],\n",
      "          [ 0.0579,  0.0290,  0.0943]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1092, -0.0060,  0.0200],\n",
      "          [ 0.0332,  0.0159, -0.0158],\n",
      "          [ 0.0471, -0.0946,  0.1090]],\n",
      "\n",
      "         [[-0.0656, -0.0734, -0.0532],\n",
      "          [-0.0577,  0.0002,  0.0436],\n",
      "          [-0.0925,  0.0737,  0.0086]],\n",
      "\n",
      "         [[ 0.0521, -0.0256,  0.0386],\n",
      "          [-0.0867,  0.0913, -0.0246],\n",
      "          [ 0.0582, -0.0918, -0.1051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0037,  0.0592,  0.0951],\n",
      "          [ 0.1104,  0.1042, -0.0087],\n",
      "          [ 0.0947,  0.0617,  0.0901]],\n",
      "\n",
      "         [[-0.0323, -0.0167,  0.0260],\n",
      "          [ 0.0561, -0.0450, -0.0348],\n",
      "          [ 0.0707,  0.0211, -0.0109]],\n",
      "\n",
      "         [[ 0.0586,  0.0850, -0.0496],\n",
      "          [ 0.0093, -0.0393, -0.0500],\n",
      "          [-0.0101, -0.0988,  0.0125]]],\n",
      "\n",
      "\n",
      "        [[[-0.0859,  0.0444, -0.0610],\n",
      "          [-0.0331, -0.0921, -0.0875],\n",
      "          [ 0.0962, -0.0486,  0.0596]],\n",
      "\n",
      "         [[-0.1006, -0.1014,  0.0457],\n",
      "          [ 0.0770,  0.1075,  0.0291],\n",
      "          [ 0.0656, -0.1111, -0.0264]],\n",
      "\n",
      "         [[ 0.0155, -0.0719, -0.1063],\n",
      "          [-0.0262,  0.0336,  0.0728],\n",
      "          [-0.0880, -0.0227, -0.0930]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0462, -0.0828, -0.1017],\n",
      "          [-0.0058, -0.0351, -0.0438],\n",
      "          [ 0.0060, -0.0401,  0.0522]],\n",
      "\n",
      "         [[ 0.0958,  0.0679,  0.0150],\n",
      "          [ 0.0237,  0.0983,  0.0668],\n",
      "          [ 0.0829, -0.1052,  0.0593]],\n",
      "\n",
      "         [[ 0.0316, -0.0573,  0.0257],\n",
      "          [ 0.0952,  0.0886, -0.0696],\n",
      "          [ 0.0952, -0.0778, -0.0523]]]])\n",
      "Shape: torch.Size([24, 9, 3, 3]), std: 0.0643, mean: -0.0007\n",
      "\n",
      "representation.residual_layers.residual_layers.0.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.0.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.0.conv2.weight:\n",
      "tensor([[[[-0.0247, -0.0172,  0.0122],\n",
      "          [-0.0660, -0.0504,  0.0328],\n",
      "          [ 0.0211,  0.0241, -0.0439]],\n",
      "\n",
      "         [[-0.0528,  0.0526,  0.0654],\n",
      "          [ 0.0112, -0.0343, -0.0517],\n",
      "          [ 0.0525,  0.0129, -0.0580]],\n",
      "\n",
      "         [[ 0.0144, -0.0172, -0.0362],\n",
      "          [-0.0336, -0.0509,  0.0085],\n",
      "          [ 0.0501, -0.0110,  0.0178]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0402, -0.0098,  0.0464],\n",
      "          [ 0.0190,  0.0596,  0.0226],\n",
      "          [-0.0452, -0.0025, -0.0135]],\n",
      "\n",
      "         [[ 0.0584,  0.0135,  0.0055],\n",
      "          [ 0.0481,  0.0113,  0.0522],\n",
      "          [-0.0675, -0.0041,  0.0347]],\n",
      "\n",
      "         [[ 0.0426,  0.0403, -0.0119],\n",
      "          [-0.0563, -0.0290, -0.0522],\n",
      "          [ 0.0304,  0.0602, -0.0540]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0607, -0.0540,  0.0382],\n",
      "          [ 0.0289,  0.0196,  0.0097],\n",
      "          [ 0.0149, -0.0355,  0.0358]],\n",
      "\n",
      "         [[ 0.0345,  0.0207,  0.0469],\n",
      "          [-0.0162, -0.0467, -0.0380],\n",
      "          [-0.0303, -0.0141,  0.0563]],\n",
      "\n",
      "         [[-0.0530, -0.0656,  0.0199],\n",
      "          [ 0.0568,  0.0269,  0.0524],\n",
      "          [-0.0247,  0.0062, -0.0619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0524,  0.0680, -0.0103],\n",
      "          [ 0.0573,  0.0422, -0.0500],\n",
      "          [-0.0625,  0.0489, -0.0296]],\n",
      "\n",
      "         [[-0.0230,  0.0317, -0.0378],\n",
      "          [ 0.0642, -0.0668,  0.0674],\n",
      "          [ 0.0649, -0.0447,  0.0261]],\n",
      "\n",
      "         [[-0.0671,  0.0366, -0.0664],\n",
      "          [-0.0679,  0.0151, -0.0110],\n",
      "          [ 0.0409, -0.0003,  0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0452, -0.0640, -0.0385],\n",
      "          [ 0.0123, -0.0298, -0.0272],\n",
      "          [-0.0108, -0.0003, -0.0570]],\n",
      "\n",
      "         [[-0.0537, -0.0427,  0.0626],\n",
      "          [-0.0451, -0.0169,  0.0429],\n",
      "          [-0.0547, -0.0262, -0.0458]],\n",
      "\n",
      "         [[-0.0030,  0.0081, -0.0404],\n",
      "          [ 0.0591,  0.0087,  0.0042],\n",
      "          [ 0.0226, -0.0432,  0.0421]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0669,  0.0546,  0.0349],\n",
      "          [-0.0037, -0.0308, -0.0608],\n",
      "          [-0.0212,  0.0356, -0.0451]],\n",
      "\n",
      "         [[ 0.0607, -0.0149,  0.0008],\n",
      "          [ 0.0093, -0.0059,  0.0397],\n",
      "          [-0.0582,  0.0354,  0.0283]],\n",
      "\n",
      "         [[ 0.0563, -0.0226,  0.0226],\n",
      "          [ 0.0118,  0.0432,  0.0531],\n",
      "          [ 0.0178, -0.0128,  0.0629]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0422, -0.0564, -0.0092],\n",
      "          [-0.0440,  0.0049, -0.0355],\n",
      "          [-0.0031,  0.0611, -0.0542]],\n",
      "\n",
      "         [[-0.0450,  0.0046, -0.0484],\n",
      "          [ 0.0064, -0.0612,  0.0153],\n",
      "          [-0.0618, -0.0003, -0.0135]],\n",
      "\n",
      "         [[-0.0157,  0.0196, -0.0605],\n",
      "          [-0.0059, -0.0586,  0.0035],\n",
      "          [-0.0652, -0.0423, -0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0016,  0.0140,  0.0133],\n",
      "          [-0.0143, -0.0604, -0.0159],\n",
      "          [-0.0409,  0.0006, -0.0568]],\n",
      "\n",
      "         [[ 0.0254,  0.0304, -0.0292],\n",
      "          [ 0.0118,  0.0417,  0.0192],\n",
      "          [-0.0380,  0.0400,  0.0509]],\n",
      "\n",
      "         [[ 0.0331,  0.0126,  0.0079],\n",
      "          [-0.0395, -0.0387,  0.0566],\n",
      "          [-0.0251, -0.0447, -0.0467]]],\n",
      "\n",
      "\n",
      "        [[[-0.0480, -0.0280, -0.0672],\n",
      "          [-0.0478,  0.0626,  0.0495],\n",
      "          [ 0.0128, -0.0626, -0.0223]],\n",
      "\n",
      "         [[-0.0248, -0.0444,  0.0567],\n",
      "          [ 0.0379, -0.0517,  0.0209],\n",
      "          [ 0.0559,  0.0408,  0.0661]],\n",
      "\n",
      "         [[-0.0551,  0.0321, -0.0281],\n",
      "          [-0.0539, -0.0653,  0.0608],\n",
      "          [ 0.0360, -0.0210, -0.0481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0584,  0.0388, -0.0528],\n",
      "          [-0.0594,  0.0197, -0.0099],\n",
      "          [-0.0098,  0.0402, -0.0528]],\n",
      "\n",
      "         [[-0.0413,  0.0043,  0.0557],\n",
      "          [ 0.0052,  0.0376, -0.0006],\n",
      "          [ 0.0045,  0.0248,  0.0475]],\n",
      "\n",
      "         [[ 0.0354,  0.0158, -0.0226],\n",
      "          [ 0.0364, -0.0160, -0.0115],\n",
      "          [-0.0065,  0.0126, -0.0498]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.0365,  0.0320],\n",
      "          [ 0.0238,  0.0032,  0.0600],\n",
      "          [-0.0239, -0.0298, -0.0644]],\n",
      "\n",
      "         [[-0.0603, -0.0583,  0.0640],\n",
      "          [ 0.0284, -0.0350,  0.0045],\n",
      "          [-0.0127, -0.0537,  0.0595]],\n",
      "\n",
      "         [[ 0.0460, -0.0123,  0.0076],\n",
      "          [ 0.0136, -0.0213, -0.0550],\n",
      "          [-0.0645, -0.0029, -0.0613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0200, -0.0149, -0.0581],\n",
      "          [-0.0139,  0.0088,  0.0100],\n",
      "          [-0.0154,  0.0483,  0.0643]],\n",
      "\n",
      "         [[-0.0153,  0.0275,  0.0264],\n",
      "          [ 0.0032, -0.0259, -0.0134],\n",
      "          [-0.0196, -0.0491,  0.0357]],\n",
      "\n",
      "         [[-0.0293, -0.0233,  0.0393],\n",
      "          [ 0.0483, -0.0373,  0.0130],\n",
      "          [ 0.0337, -0.0358, -0.0525]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0390, mean: -0.0001\n",
      "\n",
      "representation.residual_layers.residual_layers.0.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.0.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.0.downsample.0.weight:\n",
      "tensor([[[[ 0.0581, -0.0106, -0.0268],\n",
      "          [ 0.0916,  0.0823, -0.0615],\n",
      "          [-0.1071,  0.0467,  0.0059]],\n",
      "\n",
      "         [[ 0.0040, -0.0418,  0.0934],\n",
      "          [-0.0244, -0.0095, -0.0719],\n",
      "          [-0.0087,  0.0802, -0.0844]],\n",
      "\n",
      "         [[-0.0321,  0.0317,  0.1027],\n",
      "          [ 0.0494, -0.0554,  0.0714],\n",
      "          [-0.1018,  0.0356,  0.1080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0686,  0.0429,  0.0292],\n",
      "          [ 0.0070, -0.0995,  0.0328],\n",
      "          [-0.1081, -0.0617, -0.1092]],\n",
      "\n",
      "         [[-0.0219, -0.0614, -0.0059],\n",
      "          [-0.0012, -0.0539,  0.0345],\n",
      "          [ 0.0803, -0.0739,  0.0739]],\n",
      "\n",
      "         [[ 0.0685, -0.1063,  0.0552],\n",
      "          [-0.0416,  0.0981, -0.0674],\n",
      "          [ 0.0555,  0.0784, -0.0447]]],\n",
      "\n",
      "\n",
      "        [[[-0.0187, -0.0229,  0.0157],\n",
      "          [-0.0684, -0.0599, -0.0280],\n",
      "          [-0.0304,  0.0818,  0.0662]],\n",
      "\n",
      "         [[ 0.0387, -0.1090, -0.0419],\n",
      "          [-0.0409, -0.1031,  0.0576],\n",
      "          [-0.0729,  0.0823,  0.0498]],\n",
      "\n",
      "         [[-0.0704,  0.0450, -0.0905],\n",
      "          [-0.0825, -0.0666, -0.0352],\n",
      "          [-0.1085,  0.1096,  0.0844]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0123, -0.0382,  0.0093],\n",
      "          [-0.0126,  0.0019, -0.0336],\n",
      "          [ 0.0358,  0.0740,  0.0278]],\n",
      "\n",
      "         [[-0.0527,  0.0019,  0.0480],\n",
      "          [-0.1107, -0.1042, -0.0346],\n",
      "          [ 0.0211, -0.0485, -0.0125]],\n",
      "\n",
      "         [[-0.0061, -0.0551,  0.0204],\n",
      "          [-0.1101, -0.0135,  0.0536],\n",
      "          [-0.0833, -0.0383,  0.0381]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0594, -0.1004,  0.0855],\n",
      "          [-0.0527,  0.0020,  0.0151],\n",
      "          [-0.0730,  0.0588,  0.0814]],\n",
      "\n",
      "         [[ 0.0418,  0.0699, -0.0927],\n",
      "          [-0.0880,  0.0614,  0.0902],\n",
      "          [-0.0931, -0.0083, -0.0360]],\n",
      "\n",
      "         [[-0.0440,  0.0220, -0.1056],\n",
      "          [ 0.0519, -0.0663, -0.0868],\n",
      "          [ 0.0633, -0.0492,  0.0817]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0953,  0.0468,  0.0637],\n",
      "          [ 0.0014, -0.1093, -0.0823],\n",
      "          [ 0.0106, -0.0278,  0.1061]],\n",
      "\n",
      "         [[-0.0514,  0.0286,  0.0849],\n",
      "          [-0.0257,  0.0344,  0.0640],\n",
      "          [ 0.1073, -0.0338,  0.0757]],\n",
      "\n",
      "         [[ 0.0002, -0.0900, -0.1107],\n",
      "          [-0.0233,  0.0781, -0.0762],\n",
      "          [ 0.0988,  0.1081, -0.0394]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0800,  0.0715,  0.0752],\n",
      "          [-0.0385,  0.1067,  0.0022],\n",
      "          [-0.0020,  0.0590,  0.0882]],\n",
      "\n",
      "         [[ 0.0590,  0.0681,  0.0615],\n",
      "          [-0.0300, -0.0671,  0.0481],\n",
      "          [ 0.1000,  0.0662, -0.0055]],\n",
      "\n",
      "         [[-0.0147,  0.0782,  0.1055],\n",
      "          [-0.0783, -0.0203, -0.0483],\n",
      "          [ 0.0959, -0.0913,  0.0912]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0099, -0.0465,  0.0069],\n",
      "          [ 0.0693, -0.0704, -0.0951],\n",
      "          [-0.0813, -0.0401, -0.0198]],\n",
      "\n",
      "         [[-0.0430, -0.0893, -0.0390],\n",
      "          [-0.1006, -0.0641,  0.0552],\n",
      "          [ 0.0488, -0.1007,  0.0487]],\n",
      "\n",
      "         [[ 0.0801,  0.1045, -0.0495],\n",
      "          [-0.0080,  0.0517, -0.0341],\n",
      "          [ 0.0208,  0.1055, -0.0245]]],\n",
      "\n",
      "\n",
      "        [[[-0.0185, -0.0206, -0.0183],\n",
      "          [-0.0957, -0.0169, -0.0373],\n",
      "          [ 0.0668, -0.1062,  0.0314]],\n",
      "\n",
      "         [[-0.0986, -0.0318,  0.0544],\n",
      "          [ 0.0626,  0.0435,  0.1105],\n",
      "          [-0.0224, -0.0518,  0.1031]],\n",
      "\n",
      "         [[-0.0595,  0.0835,  0.1050],\n",
      "          [-0.0684,  0.0515, -0.0471],\n",
      "          [-0.1077,  0.0661,  0.0316]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0933, -0.0854, -0.0378],\n",
      "          [-0.0605, -0.0388,  0.0820],\n",
      "          [ 0.0147,  0.0912, -0.0937]],\n",
      "\n",
      "         [[-0.0835,  0.0703,  0.0707],\n",
      "          [ 0.0079,  0.0181, -0.0272],\n",
      "          [-0.0694, -0.0795,  0.0023]],\n",
      "\n",
      "         [[-0.0680, -0.0715, -0.0770],\n",
      "          [-0.0780, -0.0836,  0.0268],\n",
      "          [-0.0781, -0.0327, -0.0834]]],\n",
      "\n",
      "\n",
      "        [[[-0.0998,  0.1023, -0.0273],\n",
      "          [-0.0881, -0.0252, -0.0949],\n",
      "          [-0.0977,  0.0250, -0.0539]],\n",
      "\n",
      "         [[ 0.0310, -0.0465, -0.0784],\n",
      "          [-0.0719, -0.0905, -0.0016],\n",
      "          [ 0.0085, -0.0235,  0.0850]],\n",
      "\n",
      "         [[-0.0853,  0.0484, -0.0474],\n",
      "          [ 0.1079,  0.0887,  0.1100],\n",
      "          [ 0.0747, -0.0313, -0.0227]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0883, -0.0312, -0.0473],\n",
      "          [-0.0722,  0.0215,  0.1010],\n",
      "          [ 0.0837,  0.0827, -0.0895]],\n",
      "\n",
      "         [[ 0.0280, -0.0560,  0.0557],\n",
      "          [ 0.0687,  0.0634,  0.0478],\n",
      "          [-0.0114, -0.0465,  0.0953]],\n",
      "\n",
      "         [[-0.0807,  0.0734,  0.0692],\n",
      "          [-0.0230, -0.0244, -0.0709],\n",
      "          [-0.0766, -0.0927, -0.0427]]]])\n",
      "Shape: torch.Size([24, 9, 3, 3]), std: 0.0652, mean: -0.0022\n",
      "\n",
      "representation.residual_layers.residual_layers.0.downsample.1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.0.downsample.1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.1.conv1.weight:\n",
      "tensor([[[[ 0.0544, -0.0667,  0.0253],\n",
      "          [-0.0206,  0.0206,  0.0413],\n",
      "          [ 0.0520, -0.0506, -0.0226]],\n",
      "\n",
      "         [[-0.0516, -0.0158,  0.0596],\n",
      "          [-0.0228,  0.0617,  0.0309],\n",
      "          [-0.0269,  0.0269,  0.0157]],\n",
      "\n",
      "         [[ 0.0467,  0.0058, -0.0659],\n",
      "          [ 0.0037, -0.0544,  0.0492],\n",
      "          [ 0.0662,  0.0254, -0.0148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0571,  0.0281,  0.0446],\n",
      "          [-0.0504,  0.0571,  0.0333],\n",
      "          [-0.0491,  0.0566, -0.0254]],\n",
      "\n",
      "         [[ 0.0157, -0.0545, -0.0638],\n",
      "          [ 0.0186, -0.0467,  0.0219],\n",
      "          [ 0.0563,  0.0577,  0.0536]],\n",
      "\n",
      "         [[-0.0351,  0.0263,  0.0673],\n",
      "          [ 0.0570,  0.0369,  0.0465],\n",
      "          [-0.0249, -0.0533,  0.0310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0545, -0.0055,  0.0047],\n",
      "          [ 0.0418,  0.0458, -0.0219],\n",
      "          [-0.0238, -0.0599, -0.0677]],\n",
      "\n",
      "         [[ 0.0371, -0.0659, -0.0338],\n",
      "          [-0.0266, -0.0414,  0.0186],\n",
      "          [ 0.0341, -0.0257, -0.0323]],\n",
      "\n",
      "         [[ 0.0121, -0.0641, -0.0478],\n",
      "          [ 0.0436, -0.0550, -0.0155],\n",
      "          [-0.0274,  0.0164,  0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0598, -0.0099,  0.0036],\n",
      "          [ 0.0395, -0.0152, -0.0433],\n",
      "          [ 0.0061,  0.0080,  0.0447]],\n",
      "\n",
      "         [[ 0.0026, -0.0538,  0.0200],\n",
      "          [ 0.0524,  0.0173, -0.0568],\n",
      "          [ 0.0239,  0.0601, -0.0117]],\n",
      "\n",
      "         [[ 0.0008, -0.0266, -0.0248],\n",
      "          [-0.0631,  0.0133,  0.0497],\n",
      "          [ 0.0271,  0.0047,  0.0599]]],\n",
      "\n",
      "\n",
      "        [[[-0.0061, -0.0493,  0.0272],\n",
      "          [ 0.0477,  0.0161, -0.0037],\n",
      "          [ 0.0536, -0.0465,  0.0068]],\n",
      "\n",
      "         [[-0.0033, -0.0288,  0.0430],\n",
      "          [ 0.0271,  0.0073, -0.0588],\n",
      "          [ 0.0341, -0.0073,  0.0538]],\n",
      "\n",
      "         [[-0.0416,  0.0063, -0.0368],\n",
      "          [ 0.0631, -0.0157, -0.0219],\n",
      "          [-0.0343, -0.0024, -0.0442]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0234, -0.0577,  0.0336],\n",
      "          [ 0.0503,  0.0320,  0.0441],\n",
      "          [-0.0592,  0.0513,  0.0575]],\n",
      "\n",
      "         [[-0.0665, -0.0471,  0.0035],\n",
      "          [ 0.0411,  0.0101, -0.0133],\n",
      "          [-0.0279,  0.0569, -0.0515]],\n",
      "\n",
      "         [[-0.0180, -0.0440, -0.0436],\n",
      "          [ 0.0070, -0.0212,  0.0103],\n",
      "          [ 0.0324,  0.0129, -0.0500]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0523,  0.0517,  0.0674],\n",
      "          [ 0.0316,  0.0449,  0.0149],\n",
      "          [-0.0028, -0.0259,  0.0067]],\n",
      "\n",
      "         [[ 0.0194,  0.0518,  0.0643],\n",
      "          [ 0.0110,  0.0239,  0.0549],\n",
      "          [ 0.0131,  0.0092,  0.0291]],\n",
      "\n",
      "         [[ 0.0219, -0.0269,  0.0458],\n",
      "          [ 0.0238,  0.0171, -0.0336],\n",
      "          [-0.0148,  0.0007,  0.0630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0186,  0.0313,  0.0102],\n",
      "          [-0.0068, -0.0377,  0.0236],\n",
      "          [ 0.0604,  0.0008,  0.0089]],\n",
      "\n",
      "         [[ 0.0446, -0.0023,  0.0554],\n",
      "          [-0.0567, -0.0622, -0.0059],\n",
      "          [ 0.0057, -0.0329, -0.0261]],\n",
      "\n",
      "         [[-0.0193,  0.0076, -0.0510],\n",
      "          [ 0.0586,  0.0257,  0.0478],\n",
      "          [-0.0577,  0.0198, -0.0493]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0105, -0.0065, -0.0312],\n",
      "          [-0.0500,  0.0536, -0.0374],\n",
      "          [-0.0235, -0.0252,  0.0216]],\n",
      "\n",
      "         [[-0.0558,  0.0321, -0.0104],\n",
      "          [-0.0202,  0.0082, -0.0070],\n",
      "          [-0.0554,  0.0574,  0.0528]],\n",
      "\n",
      "         [[-0.0339,  0.0028,  0.0247],\n",
      "          [ 0.0470, -0.0342, -0.0251],\n",
      "          [-0.0390, -0.0589, -0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0151,  0.0561,  0.0268],\n",
      "          [-0.0597,  0.0109, -0.0105],\n",
      "          [-0.0606,  0.0649, -0.0538]],\n",
      "\n",
      "         [[ 0.0454, -0.0252, -0.0472],\n",
      "          [ 0.0569,  0.0163,  0.0025],\n",
      "          [-0.0224, -0.0277, -0.0480]],\n",
      "\n",
      "         [[ 0.0054,  0.0358, -0.0077],\n",
      "          [-0.0386,  0.0406, -0.0604],\n",
      "          [-0.0195, -0.0324, -0.0602]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114,  0.0530,  0.0002],\n",
      "          [-0.0521,  0.0194,  0.0475],\n",
      "          [-0.0402, -0.0585, -0.0015]],\n",
      "\n",
      "         [[ 0.0460, -0.0204,  0.0679],\n",
      "          [-0.0094,  0.0507,  0.0309],\n",
      "          [-0.0461, -0.0163,  0.0154]],\n",
      "\n",
      "         [[-0.0491, -0.0075,  0.0401],\n",
      "          [-0.0382,  0.0450,  0.0420],\n",
      "          [-0.0077,  0.0361, -0.0148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0014,  0.0586,  0.0512],\n",
      "          [-0.0015, -0.0456,  0.0655],\n",
      "          [ 0.0675, -0.0419,  0.0164]],\n",
      "\n",
      "         [[ 0.0506,  0.0594, -0.0632],\n",
      "          [-0.0649,  0.0448, -0.0061],\n",
      "          [ 0.0549,  0.0604,  0.0666]],\n",
      "\n",
      "         [[-0.0055,  0.0110,  0.0446],\n",
      "          [-0.0417,  0.0263,  0.0018],\n",
      "          [ 0.0404,  0.0587,  0.0087]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0394, mean: -0.0001\n",
      "\n",
      "representation.residual_layers.residual_layers.1.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.1.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.1.conv2.weight:\n",
      "tensor([[[[ 0.0184,  0.0162, -0.0396],\n",
      "          [-0.0149, -0.0474,  0.0340],\n",
      "          [ 0.0356, -0.0329,  0.0079]],\n",
      "\n",
      "         [[ 0.0220,  0.0450, -0.0193],\n",
      "          [ 0.0446,  0.0444,  0.0437],\n",
      "          [ 0.0291,  0.0573, -0.0145]],\n",
      "\n",
      "         [[-0.0316,  0.0150,  0.0317],\n",
      "          [-0.0387,  0.0642, -0.0590],\n",
      "          [-0.0453,  0.0289,  0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0131,  0.0173,  0.0623],\n",
      "          [-0.0344, -0.0434, -0.0381],\n",
      "          [ 0.0129,  0.0543, -0.0366]],\n",
      "\n",
      "         [[ 0.0131,  0.0679, -0.0559],\n",
      "          [-0.0654, -0.0661,  0.0397],\n",
      "          [ 0.0605,  0.0659,  0.0349]],\n",
      "\n",
      "         [[-0.0220, -0.0404, -0.0265],\n",
      "          [ 0.0441,  0.0541,  0.0312],\n",
      "          [-0.0218, -0.0248, -0.0677]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0291,  0.0275, -0.0475],\n",
      "          [ 0.0279,  0.0044, -0.0148],\n",
      "          [-0.0312, -0.0266,  0.0320]],\n",
      "\n",
      "         [[ 0.0279, -0.0414,  0.0203],\n",
      "          [ 0.0643, -0.0541,  0.0214],\n",
      "          [ 0.0581,  0.0300,  0.0230]],\n",
      "\n",
      "         [[ 0.0007,  0.0192, -0.0394],\n",
      "          [-0.0255,  0.0081, -0.0577],\n",
      "          [ 0.0325, -0.0175, -0.0580]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0499,  0.0312, -0.0165],\n",
      "          [-0.0414, -0.0416, -0.0440],\n",
      "          [-0.0520,  0.0275, -0.0025]],\n",
      "\n",
      "         [[-0.0322, -0.0560,  0.0588],\n",
      "          [-0.0472, -0.0025,  0.0119],\n",
      "          [-0.0293,  0.0494,  0.0237]],\n",
      "\n",
      "         [[-0.0572, -0.0338, -0.0659],\n",
      "          [ 0.0243,  0.0037, -0.0023],\n",
      "          [ 0.0342,  0.0578,  0.0539]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0546,  0.0097,  0.0415],\n",
      "          [-0.0229, -0.0243,  0.0107],\n",
      "          [ 0.0186, -0.0380,  0.0168]],\n",
      "\n",
      "         [[ 0.0661, -0.0622, -0.0403],\n",
      "          [-0.0116, -0.0080,  0.0149],\n",
      "          [ 0.0503, -0.0210,  0.0071]],\n",
      "\n",
      "         [[-0.0333, -0.0671,  0.0051],\n",
      "          [-0.0578, -0.0672,  0.0263],\n",
      "          [-0.0288,  0.0608, -0.0631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0143,  0.0210,  0.0349],\n",
      "          [-0.0142,  0.0005,  0.0427],\n",
      "          [-0.0068, -0.0579,  0.0205]],\n",
      "\n",
      "         [[-0.0072,  0.0515, -0.0545],\n",
      "          [ 0.0155,  0.0295, -0.0529],\n",
      "          [ 0.0078, -0.0319,  0.0299]],\n",
      "\n",
      "         [[ 0.0105, -0.0079, -0.0343],\n",
      "          [-0.0400, -0.0540,  0.0127],\n",
      "          [-0.0547, -0.0430,  0.0090]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0279,  0.0249,  0.0112],\n",
      "          [ 0.0676,  0.0144,  0.0649],\n",
      "          [-0.0145, -0.0456,  0.0079]],\n",
      "\n",
      "         [[-0.0207,  0.0643,  0.0192],\n",
      "          [-0.0202, -0.0320,  0.0544],\n",
      "          [ 0.0479,  0.0387, -0.0249]],\n",
      "\n",
      "         [[ 0.0580,  0.0514,  0.0236],\n",
      "          [ 0.0070, -0.0628,  0.0492],\n",
      "          [-0.0199,  0.0492, -0.0190]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219, -0.0234,  0.0316],\n",
      "          [ 0.0565,  0.0293,  0.0021],\n",
      "          [-0.0037,  0.0633,  0.0656]],\n",
      "\n",
      "         [[-0.0522,  0.0206, -0.0324],\n",
      "          [-0.0162, -0.0159,  0.0440],\n",
      "          [ 0.0608, -0.0510, -0.0546]],\n",
      "\n",
      "         [[ 0.0432,  0.0107, -0.0434],\n",
      "          [ 0.0205,  0.0057, -0.0322],\n",
      "          [-0.0194,  0.0617, -0.0437]]],\n",
      "\n",
      "\n",
      "        [[[-0.0439, -0.0657, -0.0538],\n",
      "          [-0.0248, -0.0096, -0.0404],\n",
      "          [-0.0178,  0.0510,  0.0015]],\n",
      "\n",
      "         [[ 0.0470, -0.0392,  0.0628],\n",
      "          [-0.0488,  0.0645,  0.0387],\n",
      "          [-0.0436,  0.0151,  0.0205]],\n",
      "\n",
      "         [[ 0.0558,  0.0630,  0.0571],\n",
      "          [-0.0258,  0.0024, -0.0442],\n",
      "          [-0.0395, -0.0661,  0.0404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0635, -0.0145, -0.0121],\n",
      "          [ 0.0142,  0.0467, -0.0447],\n",
      "          [-0.0492,  0.0023,  0.0582]],\n",
      "\n",
      "         [[ 0.0116, -0.0084,  0.0543],\n",
      "          [-0.0420, -0.0042, -0.0018],\n",
      "          [-0.0427, -0.0588,  0.0670]],\n",
      "\n",
      "         [[ 0.0609,  0.0060, -0.0469],\n",
      "          [-0.0660,  0.0145,  0.0314],\n",
      "          [ 0.0661, -0.0567,  0.0035]]],\n",
      "\n",
      "\n",
      "        [[[-0.0576, -0.0124, -0.0034],\n",
      "          [ 0.0613, -0.0529,  0.0228],\n",
      "          [-0.0341, -0.0230,  0.0078]],\n",
      "\n",
      "         [[-0.0102, -0.0152,  0.0179],\n",
      "          [-0.0482,  0.0644,  0.0243],\n",
      "          [-0.0212,  0.0622,  0.0539]],\n",
      "\n",
      "         [[-0.0311,  0.0361, -0.0612],\n",
      "          [ 0.0651,  0.0298, -0.0495],\n",
      "          [ 0.0195, -0.0218, -0.0569]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0615,  0.0102,  0.0207],\n",
      "          [-0.0001, -0.0540,  0.0438],\n",
      "          [-0.0579, -0.0257,  0.0005]],\n",
      "\n",
      "         [[-0.0492,  0.0157, -0.0553],\n",
      "          [ 0.0364,  0.0285,  0.0037],\n",
      "          [-0.0074, -0.0072, -0.0205]],\n",
      "\n",
      "         [[ 0.0211, -0.0515, -0.0417],\n",
      "          [-0.0359, -0.0225, -0.0135],\n",
      "          [ 0.0277, -0.0415, -0.0580]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0395, mean: 0.0007\n",
      "\n",
      "representation.residual_layers.residual_layers.1.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.1.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.2.conv1.weight:\n",
      "tensor([[[[ 0.0673, -0.0651, -0.0382],\n",
      "          [-0.0675, -0.0341,  0.0190],\n",
      "          [-0.0278, -0.0037,  0.0007]],\n",
      "\n",
      "         [[ 0.0228,  0.0331,  0.0174],\n",
      "          [ 0.0115,  0.0013,  0.0053],\n",
      "          [ 0.0010, -0.0159,  0.0656]],\n",
      "\n",
      "         [[-0.0484, -0.0069, -0.0615],\n",
      "          [-0.0665,  0.0664,  0.0006],\n",
      "          [-0.0234, -0.0290,  0.0193]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0565,  0.0110,  0.0136],\n",
      "          [ 0.0387, -0.0130, -0.0641],\n",
      "          [-0.0462,  0.0300, -0.0085]],\n",
      "\n",
      "         [[-0.0077,  0.0353,  0.0523],\n",
      "          [ 0.0074, -0.0080,  0.0541],\n",
      "          [-0.0261, -0.0227,  0.0172]],\n",
      "\n",
      "         [[-0.0503,  0.0175,  0.0145],\n",
      "          [ 0.0295, -0.0377, -0.0171],\n",
      "          [-0.0207,  0.0496, -0.0152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0393,  0.0059, -0.0452],\n",
      "          [ 0.0664,  0.0147, -0.0664],\n",
      "          [-0.0272,  0.0015,  0.0051]],\n",
      "\n",
      "         [[-0.0148,  0.0146, -0.0169],\n",
      "          [-0.0516, -0.0256, -0.0383],\n",
      "          [-0.0021,  0.0245,  0.0273]],\n",
      "\n",
      "         [[-0.0103, -0.0264,  0.0342],\n",
      "          [-0.0622,  0.0063, -0.0419],\n",
      "          [ 0.0272,  0.0170, -0.0197]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036,  0.0064, -0.0035],\n",
      "          [-0.0197,  0.0040,  0.0632],\n",
      "          [ 0.0228, -0.0159, -0.0127]],\n",
      "\n",
      "         [[-0.0384,  0.0175, -0.0085],\n",
      "          [ 0.0062, -0.0453, -0.0268],\n",
      "          [ 0.0222, -0.0636,  0.0277]],\n",
      "\n",
      "         [[ 0.0615, -0.0387,  0.0474],\n",
      "          [-0.0275,  0.0052,  0.0530],\n",
      "          [-0.0009,  0.0051,  0.0165]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0385, -0.0520, -0.0510],\n",
      "          [-0.0171, -0.0623,  0.0486],\n",
      "          [ 0.0363,  0.0342,  0.0185]],\n",
      "\n",
      "         [[-0.0005,  0.0137,  0.0639],\n",
      "          [ 0.0121,  0.0431, -0.0537],\n",
      "          [ 0.0409,  0.0456,  0.0193]],\n",
      "\n",
      "         [[-0.0361, -0.0367,  0.0011],\n",
      "          [-0.0144, -0.0548, -0.0254],\n",
      "          [ 0.0247,  0.0503,  0.0119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0057, -0.0221,  0.0246],\n",
      "          [-0.0563, -0.0086, -0.0500],\n",
      "          [ 0.0306, -0.0502, -0.0413]],\n",
      "\n",
      "         [[ 0.0315,  0.0015, -0.0662],\n",
      "          [ 0.0322,  0.0553,  0.0182],\n",
      "          [-0.0232, -0.0511,  0.0079]],\n",
      "\n",
      "         [[ 0.0502, -0.0370, -0.0601],\n",
      "          [-0.0467,  0.0006,  0.0657],\n",
      "          [ 0.0171, -0.0611,  0.0495]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0122, -0.0606,  0.0638],\n",
      "          [ 0.0605, -0.0645, -0.0495],\n",
      "          [ 0.0664,  0.0616,  0.0301]],\n",
      "\n",
      "         [[ 0.0487, -0.0426, -0.0211],\n",
      "          [ 0.0370, -0.0453, -0.0522],\n",
      "          [ 0.0334, -0.0059,  0.0118]],\n",
      "\n",
      "         [[-0.0131, -0.0188,  0.0583],\n",
      "          [-0.0413,  0.0420,  0.0576],\n",
      "          [ 0.0560, -0.0537,  0.0477]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078,  0.0347, -0.0060],\n",
      "          [ 0.0260, -0.0068, -0.0266],\n",
      "          [-0.0128, -0.0284,  0.0119]],\n",
      "\n",
      "         [[ 0.0086, -0.0002, -0.0499],\n",
      "          [-0.0461, -0.0430, -0.0551],\n",
      "          [-0.0430, -0.0427,  0.0220]],\n",
      "\n",
      "         [[ 0.0649, -0.0360, -0.0176],\n",
      "          [-0.0244, -0.0529,  0.0574],\n",
      "          [-0.0311, -0.0414,  0.0158]]],\n",
      "\n",
      "\n",
      "        [[[-0.0465, -0.0246,  0.0007],\n",
      "          [-0.0668, -0.0455,  0.0144],\n",
      "          [-0.0209,  0.0121, -0.0323]],\n",
      "\n",
      "         [[-0.0132, -0.0667,  0.0407],\n",
      "          [ 0.0581, -0.0106,  0.0522],\n",
      "          [-0.0469,  0.0190, -0.0602]],\n",
      "\n",
      "         [[-0.0472, -0.0379,  0.0628],\n",
      "          [ 0.0548, -0.0291,  0.0372],\n",
      "          [ 0.0587,  0.0404,  0.0019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0376,  0.0428, -0.0243],\n",
      "          [ 0.0303, -0.0057,  0.0448],\n",
      "          [ 0.0158,  0.0502, -0.0047]],\n",
      "\n",
      "         [[ 0.0330,  0.0483, -0.0114],\n",
      "          [-0.0594, -0.0488, -0.0350],\n",
      "          [-0.0253,  0.0260, -0.0381]],\n",
      "\n",
      "         [[ 0.0041,  0.0007,  0.0647],\n",
      "          [ 0.0054,  0.0381,  0.0299],\n",
      "          [-0.0163, -0.0091,  0.0567]]],\n",
      "\n",
      "\n",
      "        [[[-0.0524, -0.0172, -0.0107],\n",
      "          [-0.0001, -0.0408,  0.0619],\n",
      "          [ 0.0117,  0.0217, -0.0118]],\n",
      "\n",
      "         [[ 0.0190,  0.0270,  0.0121],\n",
      "          [-0.0547, -0.0506, -0.0267],\n",
      "          [ 0.0293, -0.0334, -0.0680]],\n",
      "\n",
      "         [[ 0.0250,  0.0020, -0.0533],\n",
      "          [-0.0672, -0.0469,  0.0439],\n",
      "          [-0.0444,  0.0277, -0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0349, -0.0110,  0.0501],\n",
      "          [ 0.0322, -0.0236,  0.0022],\n",
      "          [ 0.0679, -0.0338,  0.0376]],\n",
      "\n",
      "         [[ 0.0146, -0.0516,  0.0264],\n",
      "          [-0.0489,  0.0255, -0.0352],\n",
      "          [-0.0035,  0.0381, -0.0460]],\n",
      "\n",
      "         [[ 0.0166, -0.0239, -0.0649],\n",
      "          [-0.0506, -0.0520, -0.0479],\n",
      "          [ 0.0513, -0.0202,  0.0441]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0387, mean: 0.0001\n",
      "\n",
      "representation.residual_layers.residual_layers.2.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.2.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.2.conv2.weight:\n",
      "tensor([[[[ 4.9690e-02, -3.9487e-04, -5.8816e-02],\n",
      "          [-6.7253e-02,  4.2618e-02, -2.6194e-02],\n",
      "          [ 1.5500e-02, -3.7063e-02, -2.9183e-02]],\n",
      "\n",
      "         [[-4.2018e-02,  4.0649e-03, -1.7496e-02],\n",
      "          [ 3.8719e-02, -1.3649e-02,  1.0441e-02],\n",
      "          [-2.1177e-02,  1.0874e-02, -1.1765e-02]],\n",
      "\n",
      "         [[ 3.5585e-02, -5.7718e-02,  4.6296e-02],\n",
      "          [-3.4648e-02, -3.3169e-02, -6.7851e-02],\n",
      "          [ 3.4059e-03, -3.4691e-02, -6.7173e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8876e-02,  3.6712e-02, -3.6921e-02],\n",
      "          [-4.1267e-02,  3.1269e-02,  2.0131e-02],\n",
      "          [ 4.7624e-02,  7.2148e-03, -1.5337e-02]],\n",
      "\n",
      "         [[-3.9131e-02,  3.3850e-02, -4.9358e-02],\n",
      "          [-2.1867e-02,  5.2489e-02, -3.8055e-02],\n",
      "          [ 2.1250e-02, -2.1586e-02,  3.8787e-02]],\n",
      "\n",
      "         [[-9.8783e-03,  1.7089e-02,  3.3640e-02],\n",
      "          [ 7.2038e-04, -1.7647e-02, -1.0879e-02],\n",
      "          [-1.3378e-02,  2.0525e-02,  3.9073e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2654e-02, -4.1641e-02, -4.5290e-02],\n",
      "          [-5.8577e-02, -2.7457e-02,  6.1972e-02],\n",
      "          [ 3.6922e-02, -5.8704e-02, -3.2891e-02]],\n",
      "\n",
      "         [[-5.5521e-02, -4.7481e-02, -2.9303e-02],\n",
      "          [ 5.2824e-02, -6.3580e-02,  5.8083e-02],\n",
      "          [-5.8755e-02, -2.7815e-02,  3.1609e-02]],\n",
      "\n",
      "         [[-4.9794e-02,  2.0419e-02, -2.6983e-02],\n",
      "          [ 6.3855e-02,  8.1641e-03,  4.7150e-02],\n",
      "          [ 4.7088e-02, -5.9118e-02,  1.5801e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1209e-02,  1.8569e-02, -5.8075e-02],\n",
      "          [ 1.8388e-02,  4.1648e-02, -1.5816e-02],\n",
      "          [ 5.0258e-02,  5.3706e-02, -4.1837e-03]],\n",
      "\n",
      "         [[ 3.1199e-02,  4.0735e-02,  9.2854e-03],\n",
      "          [ 3.7708e-03,  6.0421e-02,  1.9611e-02],\n",
      "          [-5.0583e-02, -1.9193e-02, -4.5744e-02]],\n",
      "\n",
      "         [[ 1.1402e-02,  3.7924e-02,  2.0822e-02],\n",
      "          [-5.9787e-02,  9.2859e-03,  6.7528e-02],\n",
      "          [-2.0432e-02,  6.2722e-02, -1.6215e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8087e-02, -2.3455e-02,  1.3112e-02],\n",
      "          [-2.0113e-02, -3.0702e-02,  5.7660e-02],\n",
      "          [ 6.4994e-02, -4.1127e-02, -3.0037e-02]],\n",
      "\n",
      "         [[ 3.0036e-02, -2.4935e-02, -4.3508e-02],\n",
      "          [ 5.3800e-02,  2.3515e-02, -2.4059e-02],\n",
      "          [ 5.1465e-02,  1.7753e-02,  5.2521e-02]],\n",
      "\n",
      "         [[-3.1821e-02,  3.0411e-02,  3.2680e-02],\n",
      "          [ 1.9849e-02,  1.0460e-02, -6.5226e-02],\n",
      "          [ 1.0463e-02, -4.3762e-02,  3.6214e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4713e-03, -2.8723e-02, -4.2683e-02],\n",
      "          [-1.1998e-02, -1.4336e-02,  3.6926e-03],\n",
      "          [ 5.4669e-03,  2.5198e-02,  7.9643e-03]],\n",
      "\n",
      "         [[ 4.7660e-02,  1.4810e-02, -5.0562e-02],\n",
      "          [-4.9541e-02,  1.1586e-02, -1.4135e-02],\n",
      "          [ 4.9533e-02, -4.6884e-02,  3.0895e-02]],\n",
      "\n",
      "         [[ 4.7874e-02, -2.1295e-02, -2.6790e-02],\n",
      "          [ 2.0296e-02, -3.8514e-03, -4.3269e-02],\n",
      "          [ 1.7763e-02, -6.7442e-02, -6.1252e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9259e-02, -4.8717e-02,  4.7173e-02],\n",
      "          [ 3.8560e-02, -6.5349e-02,  1.7747e-02],\n",
      "          [ 1.4500e-02,  2.9050e-02, -2.1036e-02]],\n",
      "\n",
      "         [[ 3.0028e-02, -5.0456e-02, -4.8785e-02],\n",
      "          [-3.8506e-02, -5.4331e-02,  3.8818e-02],\n",
      "          [-2.3752e-02, -2.6398e-02, -4.2382e-02]],\n",
      "\n",
      "         [[-6.2394e-02, -3.5212e-02,  2.5417e-02],\n",
      "          [ 4.8053e-02,  1.7637e-03, -5.7228e-02],\n",
      "          [ 4.0512e-02,  9.2056e-03, -5.0060e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8162e-02, -6.0281e-02, -5.7711e-02],\n",
      "          [ 5.8893e-02,  2.2795e-02, -1.7971e-02],\n",
      "          [ 5.5089e-02, -5.5743e-03, -3.0628e-02]],\n",
      "\n",
      "         [[ 6.2914e-02,  6.5910e-02,  6.1055e-02],\n",
      "          [ 4.8200e-02, -4.7207e-02,  4.4938e-02],\n",
      "          [ 4.8071e-03, -5.6310e-02,  4.1065e-02]],\n",
      "\n",
      "         [[-1.1478e-02,  2.3806e-02,  6.1867e-02],\n",
      "          [ 2.0271e-02,  6.0875e-02, -3.8379e-02],\n",
      "          [ 5.5310e-02,  2.5180e-02, -2.4477e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.4132e-02, -7.8946e-03, -4.1248e-02],\n",
      "          [-4.9738e-02,  4.2409e-02, -1.9935e-02],\n",
      "          [-3.6909e-02,  5.3706e-02, -5.8341e-02]],\n",
      "\n",
      "         [[ 2.3818e-02,  5.1604e-02,  2.0779e-02],\n",
      "          [-4.3661e-02,  1.1904e-02,  4.2870e-02],\n",
      "          [-6.4719e-02, -3.2135e-02, -3.2511e-02]],\n",
      "\n",
      "         [[-1.7570e-02,  5.5014e-02,  6.5886e-03],\n",
      "          [-3.3893e-02,  6.4531e-03,  1.4002e-02],\n",
      "          [ 5.4738e-02,  1.8315e-02, -3.2943e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8973e-03, -5.3671e-02, -2.0375e-03],\n",
      "          [-7.6308e-03, -4.9715e-02,  4.7501e-03],\n",
      "          [ 3.7148e-03, -5.0679e-02, -5.0193e-02]],\n",
      "\n",
      "         [[-5.4192e-02,  1.3027e-02,  3.6807e-02],\n",
      "          [-1.2276e-02, -4.4423e-02,  1.7175e-02],\n",
      "          [ 3.7006e-02, -1.9322e-02,  5.7774e-02]],\n",
      "\n",
      "         [[-3.8641e-02,  2.4262e-03,  6.4042e-02],\n",
      "          [-2.9427e-02,  1.6718e-02, -4.7655e-02],\n",
      "          [ 9.1722e-03, -4.0043e-02,  3.5622e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.7871e-02,  2.8685e-02, -5.3023e-02],\n",
      "          [-1.1486e-02,  2.6691e-02,  5.2104e-03],\n",
      "          [-5.2386e-02, -4.1180e-02, -3.6510e-02]],\n",
      "\n",
      "         [[-5.2762e-03, -7.5833e-03,  4.4130e-02],\n",
      "          [ 9.1338e-03,  5.5315e-02,  6.6824e-02],\n",
      "          [-6.2973e-03, -3.7130e-02, -5.4136e-02]],\n",
      "\n",
      "         [[ 3.2216e-02, -6.4516e-03,  5.0374e-02],\n",
      "          [ 1.6852e-02,  5.2503e-02, -3.3307e-02],\n",
      "          [ 3.2031e-03, -3.5583e-02, -2.2308e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7658e-02, -5.6645e-02, -6.2219e-02],\n",
      "          [ 6.4034e-02, -2.9412e-02,  2.8579e-02],\n",
      "          [ 1.0191e-02, -1.9009e-02, -6.0992e-02]],\n",
      "\n",
      "         [[ 8.8473e-03,  6.5231e-02, -5.4493e-02],\n",
      "          [ 6.5109e-02, -1.5715e-02,  4.6370e-04],\n",
      "          [ 2.9864e-02, -3.0698e-02, -3.1020e-02]],\n",
      "\n",
      "         [[ 6.4590e-02, -3.1502e-02, -4.4794e-02],\n",
      "          [-4.6147e-02, -2.0897e-02, -6.4262e-02],\n",
      "          [ 1.2821e-04, -4.9092e-02,  5.2280e-03]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0395, mean: -0.0001\n",
      "\n",
      "representation.residual_layers.residual_layers.2.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.2.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.3.conv1.weight:\n",
      "tensor([[[[-0.0207, -0.0304,  0.0218],\n",
      "          [-0.0664, -0.0075, -0.0326],\n",
      "          [ 0.0029,  0.0006,  0.0426]],\n",
      "\n",
      "         [[ 0.0306, -0.0523, -0.0657],\n",
      "          [ 0.0581, -0.0334,  0.0120],\n",
      "          [ 0.0092,  0.0122, -0.0383]],\n",
      "\n",
      "         [[ 0.0235, -0.0277,  0.0547],\n",
      "          [-0.0437, -0.0108, -0.0376],\n",
      "          [-0.0658, -0.0306,  0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0412, -0.0351, -0.0211],\n",
      "          [ 0.0533,  0.0580, -0.0460],\n",
      "          [-0.0045,  0.0083,  0.0669]],\n",
      "\n",
      "         [[-0.0105,  0.0062,  0.0042],\n",
      "          [-0.0446, -0.0347,  0.0013],\n",
      "          [ 0.0225,  0.0202, -0.0211]],\n",
      "\n",
      "         [[-0.0560,  0.0573, -0.0328],\n",
      "          [ 0.0272, -0.0258, -0.0481],\n",
      "          [-0.0396,  0.0459, -0.0547]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0665,  0.0586,  0.0580],\n",
      "          [-0.0238, -0.0172,  0.0411],\n",
      "          [-0.0374,  0.0541, -0.0513]],\n",
      "\n",
      "         [[-0.0272,  0.0430, -0.0311],\n",
      "          [-0.0037,  0.0111, -0.0187],\n",
      "          [ 0.0322,  0.0319, -0.0514]],\n",
      "\n",
      "         [[-0.0266,  0.0201,  0.0457],\n",
      "          [-0.0419,  0.0659,  0.0643],\n",
      "          [ 0.0508, -0.0652, -0.0129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0583, -0.0496,  0.0515],\n",
      "          [ 0.0034,  0.0369,  0.0092],\n",
      "          [ 0.0496, -0.0602,  0.0047]],\n",
      "\n",
      "         [[-0.0421,  0.0677,  0.0581],\n",
      "          [-0.0118,  0.0483,  0.0319],\n",
      "          [-0.0179, -0.0178, -0.0607]],\n",
      "\n",
      "         [[ 0.0181, -0.0541, -0.0229],\n",
      "          [ 0.0131,  0.0602,  0.0435],\n",
      "          [-0.0357,  0.0472,  0.0090]]],\n",
      "\n",
      "\n",
      "        [[[-0.0407,  0.0490,  0.0228],\n",
      "          [ 0.0067, -0.0537, -0.0468],\n",
      "          [ 0.0243,  0.0445, -0.0593]],\n",
      "\n",
      "         [[ 0.0102, -0.0531,  0.0033],\n",
      "          [ 0.0073,  0.0256,  0.0270],\n",
      "          [ 0.0033, -0.0251, -0.0429]],\n",
      "\n",
      "         [[ 0.0229,  0.0456,  0.0577],\n",
      "          [-0.0385,  0.0310, -0.0133],\n",
      "          [-0.0630, -0.0182, -0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0516, -0.0295, -0.0179],\n",
      "          [-0.0629, -0.0329,  0.0385],\n",
      "          [ 0.0396, -0.0226,  0.0391]],\n",
      "\n",
      "         [[ 0.0416,  0.0477,  0.0429],\n",
      "          [ 0.0212,  0.0400, -0.0136],\n",
      "          [ 0.0404,  0.0505, -0.0438]],\n",
      "\n",
      "         [[-0.0017, -0.0402,  0.0363],\n",
      "          [ 0.0168, -0.0297, -0.0316],\n",
      "          [ 0.0531, -0.0375,  0.0640]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0351, -0.0433, -0.0204],\n",
      "          [-0.0291, -0.0619, -0.0197],\n",
      "          [-0.0271,  0.0664,  0.0090]],\n",
      "\n",
      "         [[ 0.0309,  0.0097,  0.0155],\n",
      "          [-0.0249,  0.0261, -0.0049],\n",
      "          [ 0.0373, -0.0424, -0.0058]],\n",
      "\n",
      "         [[ 0.0093,  0.0220, -0.0566],\n",
      "          [ 0.0283,  0.0546, -0.0292],\n",
      "          [-0.0358, -0.0287,  0.0160]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0589, -0.0183,  0.0430],\n",
      "          [ 0.0575,  0.0646, -0.0558],\n",
      "          [-0.0405,  0.0231,  0.0640]],\n",
      "\n",
      "         [[ 0.0593, -0.0207,  0.0044],\n",
      "          [-0.0015,  0.0142, -0.0127],\n",
      "          [-0.0380,  0.0510,  0.0121]],\n",
      "\n",
      "         [[-0.0085,  0.0128, -0.0276],\n",
      "          [ 0.0119,  0.0136, -0.0595],\n",
      "          [ 0.0349,  0.0594,  0.0486]]],\n",
      "\n",
      "\n",
      "        [[[-0.0466,  0.0298,  0.0353],\n",
      "          [-0.0446,  0.0472,  0.0048],\n",
      "          [ 0.0517,  0.0469,  0.0407]],\n",
      "\n",
      "         [[ 0.0168, -0.0131, -0.0544],\n",
      "          [ 0.0203,  0.0407, -0.0408],\n",
      "          [ 0.0004,  0.0561, -0.0430]],\n",
      "\n",
      "         [[ 0.0460, -0.0098,  0.0042],\n",
      "          [-0.0521, -0.0395,  0.0430],\n",
      "          [-0.0559, -0.0242,  0.0249]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0294, -0.0654, -0.0531],\n",
      "          [ 0.0343,  0.0070, -0.0433],\n",
      "          [ 0.0409, -0.0302,  0.0256]],\n",
      "\n",
      "         [[-0.0120, -0.0173, -0.0349],\n",
      "          [-0.0341, -0.0655,  0.0185],\n",
      "          [-0.0590,  0.0296, -0.0654]],\n",
      "\n",
      "         [[-0.0147,  0.0675,  0.0680],\n",
      "          [-0.0600, -0.0487, -0.0447],\n",
      "          [ 0.0472, -0.0549,  0.0237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0520, -0.0136,  0.0069],\n",
      "          [ 0.0003, -0.0564, -0.0519],\n",
      "          [ 0.0502, -0.0148,  0.0617]],\n",
      "\n",
      "         [[-0.0083, -0.0012,  0.0026],\n",
      "          [-0.0676,  0.0395, -0.0488],\n",
      "          [-0.0130,  0.0444,  0.0541]],\n",
      "\n",
      "         [[ 0.0215,  0.0415,  0.0225],\n",
      "          [ 0.0264,  0.0549,  0.0075],\n",
      "          [-0.0453, -0.0421,  0.0481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0080, -0.0408,  0.0534],\n",
      "          [-0.0538, -0.0049, -0.0573],\n",
      "          [-0.0516,  0.0551, -0.0680]],\n",
      "\n",
      "         [[ 0.0231,  0.0400, -0.0185],\n",
      "          [ 0.0203,  0.0053, -0.0039],\n",
      "          [-0.0597,  0.0136,  0.0395]],\n",
      "\n",
      "         [[-0.0003,  0.0658, -0.0591],\n",
      "          [-0.0117,  0.0332, -0.0099],\n",
      "          [-0.0060,  0.0084,  0.0121]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0396, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.3.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.3.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.3.conv2.weight:\n",
      "tensor([[[[-2.0020e-02,  1.8871e-03, -2.7486e-04],\n",
      "          [-2.0727e-02, -1.0709e-02,  4.8308e-02],\n",
      "          [ 3.2750e-02, -4.4768e-02, -4.5944e-02]],\n",
      "\n",
      "         [[ 1.4782e-02,  9.7942e-03,  4.5230e-02],\n",
      "          [-1.8874e-02,  3.9398e-02,  5.0039e-02],\n",
      "          [-6.1132e-02,  1.3374e-02,  2.6567e-02]],\n",
      "\n",
      "         [[ 4.6139e-02, -4.6527e-02, -3.7627e-02],\n",
      "          [-3.7545e-02,  4.9334e-02, -1.2290e-02],\n",
      "          [ 3.9337e-02, -5.6703e-02,  5.9355e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2021e-02, -3.7956e-02,  5.9324e-02],\n",
      "          [-8.6600e-03, -9.6891e-03,  6.3744e-02],\n",
      "          [ 5.1426e-02,  1.6827e-02,  5.6101e-02]],\n",
      "\n",
      "         [[-3.5424e-03, -2.5635e-02,  2.2113e-02],\n",
      "          [-6.2817e-02, -6.5578e-02,  2.2091e-02],\n",
      "          [-4.4752e-02,  2.0233e-02,  6.2438e-02]],\n",
      "\n",
      "         [[-3.3473e-02,  2.2302e-02,  7.6807e-03],\n",
      "          [ 4.4470e-02, -1.7117e-03, -3.1760e-02],\n",
      "          [-2.0219e-02,  8.9648e-03,  6.5029e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2136e-02,  2.8477e-02,  2.5994e-02],\n",
      "          [ 1.0468e-03,  1.0586e-02,  3.3937e-02],\n",
      "          [-5.7118e-02,  4.6974e-02,  1.3527e-02]],\n",
      "\n",
      "         [[-1.4991e-02, -2.7500e-02, -6.1715e-02],\n",
      "          [-2.6741e-02, -2.0959e-02,  4.4035e-02],\n",
      "          [ 6.6208e-02,  4.9857e-02, -2.0055e-02]],\n",
      "\n",
      "         [[ 5.4627e-02, -1.3517e-02,  4.6714e-02],\n",
      "          [-3.1227e-03,  6.6240e-02, -2.1138e-02],\n",
      "          [-1.8854e-02, -5.0986e-02,  5.1641e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2233e-02,  4.0794e-02,  2.4381e-02],\n",
      "          [ 5.4564e-02, -3.8108e-02,  6.1933e-02],\n",
      "          [-5.9528e-02,  2.6818e-02, -4.9015e-03]],\n",
      "\n",
      "         [[ 6.3500e-03, -7.0597e-04,  1.2442e-02],\n",
      "          [-5.5932e-02,  3.5387e-02,  4.6741e-02],\n",
      "          [-4.7226e-02,  1.0458e-02, -7.9662e-04]],\n",
      "\n",
      "         [[-1.5727e-02,  3.5441e-02,  5.3435e-02],\n",
      "          [ 4.7176e-02,  6.5945e-02,  5.1880e-03],\n",
      "          [-1.6947e-02,  3.0786e-02, -6.4438e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8682e-02, -3.4125e-02, -1.6987e-02],\n",
      "          [ 2.3008e-02,  1.5800e-03, -6.3200e-03],\n",
      "          [ 1.0243e-02,  1.9452e-02,  2.4515e-02]],\n",
      "\n",
      "         [[-4.2637e-02,  1.7963e-02,  5.2819e-02],\n",
      "          [ 5.8061e-02,  3.1380e-03, -2.2338e-02],\n",
      "          [ 4.5655e-02, -6.3310e-02, -4.2267e-02]],\n",
      "\n",
      "         [[-5.9546e-03, -3.4594e-02,  4.0040e-02],\n",
      "          [ 2.6564e-02, -5.0665e-02,  6.1748e-03],\n",
      "          [-1.4467e-02, -3.4132e-03,  1.4789e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1754e-02, -6.5363e-02, -2.1763e-02],\n",
      "          [-3.9538e-02,  1.8151e-02,  5.0563e-04],\n",
      "          [-6.1548e-02, -4.9256e-02, -6.7208e-02]],\n",
      "\n",
      "         [[ 8.0765e-03,  5.6451e-02, -5.8423e-02],\n",
      "          [-4.2637e-02, -5.2878e-02,  5.9605e-02],\n",
      "          [-1.7417e-02, -4.1705e-02, -3.7724e-02]],\n",
      "\n",
      "         [[-1.5351e-02, -2.6213e-02, -5.7333e-02],\n",
      "          [-9.3911e-03, -5.4127e-02, -6.8015e-02],\n",
      "          [-2.6424e-02,  3.4703e-02,  3.0676e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.4841e-03, -3.2104e-02,  4.2670e-02],\n",
      "          [ 5.5716e-02, -2.9039e-02, -4.9612e-03],\n",
      "          [ 1.5809e-02, -7.2169e-03,  4.8726e-02]],\n",
      "\n",
      "         [[-4.5141e-02, -3.2342e-02,  5.9360e-02],\n",
      "          [-4.7655e-02, -1.1956e-02,  2.2594e-02],\n",
      "          [-5.9695e-02, -2.0326e-02,  3.0281e-02]],\n",
      "\n",
      "         [[-3.6121e-02, -4.4441e-02, -2.1973e-02],\n",
      "          [ 4.7100e-02, -3.3128e-02, -4.7603e-02],\n",
      "          [ 1.9350e-02, -3.1770e-02,  6.4693e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7051e-02, -5.3867e-03, -5.4656e-02],\n",
      "          [-4.8127e-02,  3.1632e-02,  4.5664e-02],\n",
      "          [-2.0055e-02, -1.0690e-02,  2.3267e-02]],\n",
      "\n",
      "         [[-2.4457e-02, -6.1130e-03,  2.0437e-02],\n",
      "          [-6.5326e-02,  7.5185e-03, -1.5504e-02],\n",
      "          [-5.5109e-02, -4.0743e-02,  2.7782e-03]],\n",
      "\n",
      "         [[ 4.6416e-02, -1.6860e-03, -3.2913e-03],\n",
      "          [-2.2074e-02,  6.5188e-02, -2.0774e-02],\n",
      "          [ 5.8433e-02, -1.8161e-02, -2.5166e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6067e-02,  1.1126e-02,  3.6395e-02],\n",
      "          [ 3.0748e-02,  6.4391e-02, -6.4167e-02],\n",
      "          [-4.2539e-02, -3.9484e-02, -4.2544e-02]],\n",
      "\n",
      "         [[ 2.5027e-02,  2.6687e-02,  2.2349e-03],\n",
      "          [-4.8069e-02,  3.9877e-02,  6.2397e-02],\n",
      "          [-5.7445e-02, -1.9066e-02, -3.8529e-02]],\n",
      "\n",
      "         [[-1.0815e-02,  3.4158e-03,  5.5530e-02],\n",
      "          [-3.1162e-02,  4.5028e-02,  6.0839e-02],\n",
      "          [ 6.6151e-02, -5.6906e-02,  9.0642e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2205e-02, -1.4613e-02, -1.9733e-02],\n",
      "          [-3.4074e-03, -2.8094e-02, -6.0157e-02],\n",
      "          [ 4.9811e-02,  3.1445e-02, -1.4308e-02]],\n",
      "\n",
      "         [[-3.4761e-02, -2.2283e-02,  4.1693e-02],\n",
      "          [ 4.2025e-02,  5.5441e-02, -5.0736e-02],\n",
      "          [-5.2615e-02,  6.4072e-02, -5.7412e-02]],\n",
      "\n",
      "         [[ 4.1557e-02,  7.6731e-03, -1.2838e-02],\n",
      "          [ 1.5596e-02, -2.2873e-03,  5.3822e-02],\n",
      "          [ 5.7748e-02,  6.3342e-02,  6.1850e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2136e-02, -6.4570e-02, -6.2149e-02],\n",
      "          [-3.9868e-03,  5.3213e-02,  3.5998e-02],\n",
      "          [-4.6709e-02, -2.0525e-02, -3.7315e-02]],\n",
      "\n",
      "         [[-3.4906e-02,  8.1332e-03, -9.2802e-03],\n",
      "          [ 1.9942e-02, -1.2146e-02, -2.4998e-02],\n",
      "          [-8.2078e-03, -5.1336e-02,  5.5914e-02]],\n",
      "\n",
      "         [[-1.3808e-03, -2.8220e-02, -5.3090e-02],\n",
      "          [-7.5320e-03,  3.2298e-02, -4.6142e-02],\n",
      "          [-1.1148e-02, -2.8600e-02,  3.4791e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7980e-02, -4.1963e-02, -4.5583e-02],\n",
      "          [ 1.9393e-02, -3.1704e-02,  5.8494e-02],\n",
      "          [-5.8740e-02,  4.4647e-02, -3.6365e-02]],\n",
      "\n",
      "         [[ 3.2562e-02,  4.7335e-03,  1.6910e-02],\n",
      "          [ 2.3693e-02, -6.6382e-02, -2.9500e-02],\n",
      "          [ 1.6574e-02, -6.7657e-02, -6.3106e-02]],\n",
      "\n",
      "         [[ 5.4921e-02, -1.8784e-02, -4.0369e-02],\n",
      "          [-5.0164e-02, -5.9447e-02,  5.7537e-02],\n",
      "          [ 5.8097e-02,  1.7092e-02, -1.3351e-02]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0390, mean: -0.0009\n",
      "\n",
      "representation.residual_layers.residual_layers.3.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "representation.residual_layers.residual_layers.3.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.conv1.weight:\n",
      "tensor([[[[ 1.6376e-02,  2.4401e-02,  5.4768e-02],\n",
      "          [ 3.3107e-02,  4.5028e-02,  3.4415e-02],\n",
      "          [ 9.1716e-04, -3.3884e-03, -4.8214e-02]],\n",
      "\n",
      "         [[-3.6636e-02,  4.1812e-02,  4.5514e-02],\n",
      "          [-6.3601e-02, -3.3154e-02,  4.5051e-02],\n",
      "          [ 6.5479e-02, -6.3403e-02, -6.3032e-02]],\n",
      "\n",
      "         [[-5.5139e-02, -5.7914e-02,  3.0790e-02],\n",
      "          [-3.2040e-02,  5.7752e-02,  6.0575e-02],\n",
      "          [-5.0748e-02,  3.9440e-02,  6.9849e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1353e-02, -3.4373e-02,  6.0939e-02],\n",
      "          [ 5.8105e-02, -4.9860e-02, -1.4867e-02],\n",
      "          [ 6.1632e-02, -3.6315e-02,  2.9725e-02]],\n",
      "\n",
      "         [[ 2.6510e-02,  5.6282e-02,  5.1398e-02],\n",
      "          [ 4.8632e-02, -2.5217e-02,  7.3454e-03],\n",
      "          [-4.7498e-02,  1.2775e-02, -2.0451e-02]],\n",
      "\n",
      "         [[ 6.4010e-02,  4.1337e-03,  6.6619e-02],\n",
      "          [-2.9255e-02,  4.5533e-02,  1.5389e-02],\n",
      "          [-3.3823e-02, -3.5952e-02,  3.1748e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7506e-02,  1.2244e-04,  2.0822e-02],\n",
      "          [ 5.1974e-02,  4.6513e-02,  1.8976e-02],\n",
      "          [-3.1605e-02, -6.2547e-02,  3.9608e-02]],\n",
      "\n",
      "         [[-2.8438e-02,  2.9088e-02,  6.4227e-02],\n",
      "          [ 6.6320e-02,  6.5855e-02, -3.3273e-02],\n",
      "          [-2.2325e-02, -2.3559e-02, -2.0578e-03]],\n",
      "\n",
      "         [[ 5.1872e-02,  4.3204e-02, -7.3272e-03],\n",
      "          [-1.8488e-02,  3.4701e-02, -4.2459e-03],\n",
      "          [ 2.7552e-02, -3.8722e-02, -2.1252e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2690e-02,  1.9649e-02,  7.2962e-03],\n",
      "          [-4.0567e-02, -3.0526e-02, -2.5247e-02],\n",
      "          [ 1.8478e-02, -6.3150e-03,  4.6558e-02]],\n",
      "\n",
      "         [[-4.9724e-02, -3.6563e-02,  4.1947e-02],\n",
      "          [ 6.1410e-02,  3.0820e-02,  2.3808e-02],\n",
      "          [-5.8566e-02, -5.5912e-02, -4.0535e-02]],\n",
      "\n",
      "         [[ 1.6841e-02, -7.5571e-03, -1.1764e-02],\n",
      "          [ 6.3472e-03, -2.8791e-02,  5.7015e-02],\n",
      "          [ 1.9615e-02,  6.0288e-02,  2.3622e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2066e-02, -1.2280e-02, -1.0523e-02],\n",
      "          [-5.2509e-02,  5.7001e-02,  2.6629e-02],\n",
      "          [ 6.5216e-02,  6.5681e-02, -4.8917e-02]],\n",
      "\n",
      "         [[ 6.3568e-02, -5.0963e-02,  1.0872e-02],\n",
      "          [ 4.1309e-02, -5.0742e-03, -5.0614e-02],\n",
      "          [-6.3610e-02, -3.1989e-02,  4.6158e-02]],\n",
      "\n",
      "         [[-1.9165e-02, -7.0601e-04,  4.5332e-02],\n",
      "          [-5.7935e-02,  4.0133e-02, -1.8348e-02],\n",
      "          [-5.0850e-02,  5.2870e-02, -6.1669e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7903e-02, -5.9889e-02, -1.8027e-02],\n",
      "          [ 6.4662e-02, -6.0271e-02,  6.2088e-02],\n",
      "          [ 1.9604e-02, -6.5852e-02,  3.4483e-02]],\n",
      "\n",
      "         [[ 5.4362e-02, -2.6189e-02,  3.0811e-02],\n",
      "          [-4.9741e-02, -1.4623e-02, -6.0233e-02],\n",
      "          [-2.7502e-03,  2.1280e-02, -3.4677e-02]],\n",
      "\n",
      "         [[-1.0773e-02, -6.3049e-02,  3.9453e-02],\n",
      "          [-5.0885e-02, -5.8742e-02,  8.9524e-03],\n",
      "          [-5.0906e-02, -4.2377e-02,  4.9539e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1096e-02, -3.4169e-02,  5.9126e-02],\n",
      "          [ 4.9921e-02, -3.9534e-02,  1.1736e-02],\n",
      "          [ 3.8709e-02, -4.0536e-02, -3.4385e-02]],\n",
      "\n",
      "         [[-4.7520e-02, -4.3593e-02, -2.0692e-03],\n",
      "          [ 1.1834e-02,  5.0224e-02,  2.2388e-02],\n",
      "          [-4.4696e-03, -3.8507e-02, -1.0255e-02]],\n",
      "\n",
      "         [[-6.0215e-02,  3.3558e-02,  8.0988e-03],\n",
      "          [-4.6751e-02,  3.2624e-02,  2.9229e-03],\n",
      "          [ 3.1962e-02,  1.0203e-02,  5.6148e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7950e-02,  7.9908e-03, -6.4340e-02],\n",
      "          [ 6.9298e-03, -1.7578e-02,  4.0970e-02],\n",
      "          [ 1.1468e-02,  2.0161e-02,  4.4729e-02]],\n",
      "\n",
      "         [[-1.1611e-02,  5.7589e-04,  4.3680e-02],\n",
      "          [-5.1009e-02,  9.0171e-03, -2.8332e-02],\n",
      "          [-3.9966e-02,  3.6801e-02, -1.9126e-02]],\n",
      "\n",
      "         [[-7.8622e-03, -3.6081e-06,  1.9262e-03],\n",
      "          [ 3.0012e-02,  1.1721e-03, -3.0045e-03],\n",
      "          [-3.5541e-02, -5.6087e-02, -4.0611e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1275e-04,  2.9128e-02,  1.2621e-02],\n",
      "          [ 2.1275e-02,  3.5412e-02, -5.9505e-03],\n",
      "          [ 3.3148e-02,  2.9493e-03,  3.5659e-02]],\n",
      "\n",
      "         [[ 3.9287e-02, -2.6287e-02,  4.0527e-02],\n",
      "          [ 2.7222e-02,  5.5318e-02,  7.7438e-04],\n",
      "          [-6.3866e-02,  4.4216e-03,  4.4109e-02]],\n",
      "\n",
      "         [[-8.7162e-03,  3.1053e-02, -1.8194e-02],\n",
      "          [-3.8527e-02, -5.3273e-02,  6.5850e-02],\n",
      "          [ 4.9873e-02,  7.7961e-04, -6.5428e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9401e-02, -2.4458e-02,  4.1477e-02],\n",
      "          [ 1.3118e-02, -3.1641e-02, -6.2936e-02],\n",
      "          [ 1.7277e-02, -4.3141e-02, -4.5274e-02]],\n",
      "\n",
      "         [[ 1.4959e-03,  4.0811e-02, -1.8090e-02],\n",
      "          [-1.4774e-02,  5.7006e-02, -2.5379e-02],\n",
      "          [-4.3742e-02, -4.8423e-02, -3.2312e-02]],\n",
      "\n",
      "         [[ 1.1505e-02,  5.4559e-02,  3.0690e-02],\n",
      "          [ 9.8636e-04,  2.4664e-02,  5.2401e-02],\n",
      "          [-5.6807e-02,  8.3303e-03,  5.1960e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2127e-02, -4.1168e-02, -1.9997e-02],\n",
      "          [-2.3611e-03, -1.1545e-02,  1.0091e-02],\n",
      "          [-1.7102e-02,  5.8319e-02, -5.9293e-02]],\n",
      "\n",
      "         [[-4.6793e-02,  4.2170e-02,  1.0578e-02],\n",
      "          [-4.7368e-02,  3.7115e-02, -1.0977e-02],\n",
      "          [ 2.6909e-02,  4.3992e-02, -6.5921e-02]],\n",
      "\n",
      "         [[-4.8350e-02, -7.7994e-03, -5.5875e-03],\n",
      "          [-1.0482e-02, -5.2799e-02,  4.5445e-02],\n",
      "          [ 3.0298e-03, -1.2155e-02, -4.6323e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5895e-02, -2.0413e-02, -4.3212e-02],\n",
      "          [ 6.0781e-02, -1.3936e-02,  4.5070e-02],\n",
      "          [-3.4097e-02, -7.5754e-03,  5.2829e-02]],\n",
      "\n",
      "         [[-3.5866e-02,  4.9993e-02,  1.4463e-02],\n",
      "          [-3.3811e-02,  1.5167e-02,  7.7829e-03],\n",
      "          [-3.5829e-02, -3.3756e-02,  6.5295e-02]],\n",
      "\n",
      "         [[ 3.7010e-02, -7.8607e-03,  6.5559e-02],\n",
      "          [-2.1029e-02, -6.5074e-02, -1.5230e-02],\n",
      "          [ 1.8711e-02,  6.1848e-02, -5.4505e-02]]]])\n",
      "Shape: torch.Size([24, 25, 3, 3]), std: 0.0387, mean: 0.0006\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.conv2.weight:\n",
      "tensor([[[[ 0.0230, -0.0489, -0.0097],\n",
      "          [-0.0308,  0.0261, -0.0509],\n",
      "          [ 0.0271, -0.0200, -0.0102]],\n",
      "\n",
      "         [[-0.0321, -0.0095,  0.0261],\n",
      "          [ 0.0172,  0.0605,  0.0053],\n",
      "          [-0.0528,  0.0673,  0.0421]],\n",
      "\n",
      "         [[ 0.0521, -0.0659,  0.0197],\n",
      "          [-0.0266,  0.0379,  0.0100],\n",
      "          [ 0.0349, -0.0402,  0.0606]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0309,  0.0322,  0.0503],\n",
      "          [ 0.0636,  0.0205, -0.0597],\n",
      "          [-0.0305, -0.0284, -0.0369]],\n",
      "\n",
      "         [[-0.0448, -0.0535, -0.0615],\n",
      "          [ 0.0528,  0.0675, -0.0249],\n",
      "          [-0.0045, -0.0283,  0.0022]],\n",
      "\n",
      "         [[ 0.0366, -0.0348, -0.0140],\n",
      "          [-0.0137,  0.0289, -0.0282],\n",
      "          [ 0.0296,  0.0078, -0.0278]]],\n",
      "\n",
      "\n",
      "        [[[-0.0257, -0.0146, -0.0027],\n",
      "          [ 0.0250,  0.0555,  0.0124],\n",
      "          [ 0.0242,  0.0029,  0.0555]],\n",
      "\n",
      "         [[ 0.0081, -0.0625, -0.0556],\n",
      "          [-0.0342,  0.0331,  0.0560],\n",
      "          [-0.0399,  0.0269, -0.0457]],\n",
      "\n",
      "         [[-0.0185,  0.0010,  0.0110],\n",
      "          [-0.0143, -0.0299,  0.0420],\n",
      "          [ 0.0580,  0.0568,  0.0450]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0512,  0.0197, -0.0222],\n",
      "          [ 0.0019, -0.0110,  0.0091],\n",
      "          [-0.0033,  0.0284, -0.0234]],\n",
      "\n",
      "         [[-0.0672,  0.0248,  0.0253],\n",
      "          [ 0.0252, -0.0237,  0.0520],\n",
      "          [ 0.0229, -0.0440,  0.0483]],\n",
      "\n",
      "         [[ 0.0625, -0.0399,  0.0189],\n",
      "          [ 0.0474,  0.0224,  0.0096],\n",
      "          [ 0.0568,  0.0571,  0.0624]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0344, -0.0179,  0.0209],\n",
      "          [ 0.0394, -0.0677,  0.0026],\n",
      "          [ 0.0533, -0.0247,  0.0006]],\n",
      "\n",
      "         [[ 0.0327,  0.0662, -0.0136],\n",
      "          [ 0.0033,  0.0270,  0.0162],\n",
      "          [-0.0579, -0.0485, -0.0617]],\n",
      "\n",
      "         [[ 0.0089, -0.0278,  0.0090],\n",
      "          [-0.0641,  0.0208, -0.0309],\n",
      "          [-0.0151, -0.0110, -0.0216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0298, -0.0663,  0.0189],\n",
      "          [ 0.0233,  0.0357,  0.0078],\n",
      "          [ 0.0611,  0.0561,  0.0570]],\n",
      "\n",
      "         [[-0.0025, -0.0096,  0.0043],\n",
      "          [ 0.0612,  0.0043,  0.0335],\n",
      "          [-0.0517, -0.0153,  0.0295]],\n",
      "\n",
      "         [[ 0.0517, -0.0640, -0.0316],\n",
      "          [ 0.0333, -0.0308,  0.0333],\n",
      "          [-0.0507, -0.0367, -0.0315]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0188,  0.0017, -0.0328],\n",
      "          [ 0.0625,  0.0667, -0.0444],\n",
      "          [-0.0564, -0.0035, -0.0676]],\n",
      "\n",
      "         [[ 0.0454,  0.0110,  0.0032],\n",
      "          [-0.0493, -0.0249, -0.0612],\n",
      "          [-0.0651, -0.0064, -0.0415]],\n",
      "\n",
      "         [[ 0.0374, -0.0608, -0.0519],\n",
      "          [-0.0314, -0.0448,  0.0157],\n",
      "          [-0.0091,  0.0287,  0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0398, -0.0306,  0.0492],\n",
      "          [-0.0222, -0.0364,  0.0082],\n",
      "          [-0.0236,  0.0177, -0.0049]],\n",
      "\n",
      "         [[ 0.0201,  0.0587,  0.0217],\n",
      "          [-0.0490,  0.0573, -0.0204],\n",
      "          [-0.0219, -0.0678, -0.0460]],\n",
      "\n",
      "         [[-0.0390,  0.0006,  0.0366],\n",
      "          [-0.0482,  0.0024, -0.0356],\n",
      "          [-0.0029, -0.0249,  0.0159]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0414, -0.0349,  0.0450],\n",
      "          [ 0.0427, -0.0564, -0.0058],\n",
      "          [-0.0294,  0.0464,  0.0100]],\n",
      "\n",
      "         [[-0.0488,  0.0075,  0.0137],\n",
      "          [ 0.0616,  0.0140,  0.0048],\n",
      "          [-0.0612, -0.0329,  0.0494]],\n",
      "\n",
      "         [[-0.0263,  0.0362, -0.0222],\n",
      "          [ 0.0119,  0.0502,  0.0459],\n",
      "          [-0.0110,  0.0479,  0.0348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0256, -0.0621, -0.0433],\n",
      "          [ 0.0407,  0.0594,  0.0354],\n",
      "          [-0.0673, -0.0169,  0.0668]],\n",
      "\n",
      "         [[-0.0375, -0.0321,  0.0149],\n",
      "          [-0.0178,  0.0298,  0.0064],\n",
      "          [ 0.0560,  0.0580,  0.0179]],\n",
      "\n",
      "         [[-0.0509,  0.0107, -0.0182],\n",
      "          [ 0.0440, -0.0486, -0.0039],\n",
      "          [-0.0509, -0.0605,  0.0395]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0144, -0.0442, -0.0568],\n",
      "          [-0.0145, -0.0450,  0.0552],\n",
      "          [-0.0527,  0.0532, -0.0147]],\n",
      "\n",
      "         [[ 0.0614,  0.0234,  0.0427],\n",
      "          [-0.0156,  0.0317,  0.0513],\n",
      "          [ 0.0595, -0.0351, -0.0175]],\n",
      "\n",
      "         [[-0.0083, -0.0029, -0.0154],\n",
      "          [-0.0402,  0.0394, -0.0617],\n",
      "          [-0.0100,  0.0567,  0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0544, -0.0531,  0.0364],\n",
      "          [ 0.0249,  0.0077,  0.0510],\n",
      "          [ 0.0296, -0.0400, -0.0279]],\n",
      "\n",
      "         [[-0.0469, -0.0443, -0.0222],\n",
      "          [ 0.0072, -0.0638,  0.0529],\n",
      "          [ 0.0316, -0.0504,  0.0419]],\n",
      "\n",
      "         [[ 0.0404, -0.0551,  0.0267],\n",
      "          [-0.0258, -0.0315, -0.0334],\n",
      "          [ 0.0178, -0.0482, -0.0592]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0391, mean: 0.0005\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.downsample.0.weight:\n",
      "tensor([[[[ 0.0138,  0.0620,  0.0292],\n",
      "          [ 0.0017,  0.0608, -0.0071],\n",
      "          [-0.0407,  0.0240, -0.0105]],\n",
      "\n",
      "         [[ 0.0479, -0.0203,  0.0341],\n",
      "          [ 0.0614,  0.0256,  0.0457],\n",
      "          [ 0.0134, -0.0451,  0.0158]],\n",
      "\n",
      "         [[-0.0029, -0.0663, -0.0657],\n",
      "          [-0.0544,  0.0653,  0.0308],\n",
      "          [-0.0228,  0.0368, -0.0271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0067,  0.0543, -0.0244],\n",
      "          [-0.0191, -0.0656,  0.0535],\n",
      "          [-0.0552,  0.0101, -0.0467]],\n",
      "\n",
      "         [[ 0.0465, -0.0321,  0.0095],\n",
      "          [ 0.0457, -0.0249, -0.0540],\n",
      "          [ 0.0008, -0.0230,  0.0116]],\n",
      "\n",
      "         [[-0.0015, -0.0614, -0.0478],\n",
      "          [ 0.0095,  0.0561, -0.0282],\n",
      "          [-0.0008,  0.0093, -0.0635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470,  0.0549,  0.0113],\n",
      "          [ 0.0516,  0.0093,  0.0037],\n",
      "          [-0.0163, -0.0062,  0.0379]],\n",
      "\n",
      "         [[ 0.0523, -0.0655, -0.0502],\n",
      "          [-0.0514,  0.0529,  0.0380],\n",
      "          [ 0.0544,  0.0625,  0.0493]],\n",
      "\n",
      "         [[ 0.0520, -0.0135,  0.0266],\n",
      "          [ 0.0370,  0.0517,  0.0626],\n",
      "          [-0.0369,  0.0032, -0.0637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0030,  0.0510, -0.0352],\n",
      "          [ 0.0396, -0.0666, -0.0027],\n",
      "          [-0.0386, -0.0320, -0.0085]],\n",
      "\n",
      "         [[ 0.0325, -0.0113, -0.0358],\n",
      "          [ 0.0138,  0.0432,  0.0417],\n",
      "          [-0.0004, -0.0377, -0.0590]],\n",
      "\n",
      "         [[ 0.0424, -0.0419, -0.0523],\n",
      "          [-0.0332, -0.0397, -0.0396],\n",
      "          [-0.0513,  0.0360,  0.0585]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0471,  0.0399,  0.0098],\n",
      "          [-0.0520, -0.0085, -0.0420],\n",
      "          [ 0.0159,  0.0447,  0.0429]],\n",
      "\n",
      "         [[-0.0050,  0.0013,  0.0074],\n",
      "          [ 0.0305,  0.0404,  0.0259],\n",
      "          [ 0.0209, -0.0534, -0.0002]],\n",
      "\n",
      "         [[ 0.0562, -0.0413,  0.0431],\n",
      "          [ 0.0277,  0.0183, -0.0248],\n",
      "          [ 0.0016,  0.0191,  0.0588]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0282, -0.0412, -0.0171],\n",
      "          [-0.0257,  0.0423, -0.0125],\n",
      "          [-0.0659,  0.0266, -0.0220]],\n",
      "\n",
      "         [[ 0.0362, -0.0021,  0.0577],\n",
      "          [-0.0439,  0.0372, -0.0358],\n",
      "          [-0.0016,  0.0484,  0.0333]],\n",
      "\n",
      "         [[-0.0374,  0.0380, -0.0620],\n",
      "          [ 0.0518, -0.0394,  0.0447],\n",
      "          [ 0.0112,  0.0102,  0.0513]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0289, -0.0625,  0.0491],\n",
      "          [-0.0496, -0.0159, -0.0619],\n",
      "          [-0.0482,  0.0038, -0.0127]],\n",
      "\n",
      "         [[ 0.0578,  0.0112, -0.0500],\n",
      "          [-0.0389, -0.0629, -0.0362],\n",
      "          [ 0.0048, -0.0038,  0.0052]],\n",
      "\n",
      "         [[-0.0217, -0.0488, -0.0242],\n",
      "          [ 0.0515,  0.0194,  0.0373],\n",
      "          [-0.0314,  0.0581,  0.0047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0500,  0.0090,  0.0068],\n",
      "          [ 0.0422,  0.0492, -0.0425],\n",
      "          [ 0.0214,  0.0172,  0.0118]],\n",
      "\n",
      "         [[ 0.0048, -0.0530,  0.0625],\n",
      "          [-0.0065, -0.0602, -0.0287],\n",
      "          [ 0.0104, -0.0235, -0.0650]],\n",
      "\n",
      "         [[-0.0449, -0.0278,  0.0388],\n",
      "          [ 0.0464,  0.0356, -0.0142],\n",
      "          [ 0.0011, -0.0338,  0.0465]]],\n",
      "\n",
      "\n",
      "        [[[-0.0248,  0.0658,  0.0655],\n",
      "          [ 0.0475, -0.0244, -0.0311],\n",
      "          [ 0.0520,  0.0339,  0.0413]],\n",
      "\n",
      "         [[ 0.0242,  0.0226,  0.0613],\n",
      "          [ 0.0144,  0.0465,  0.0350],\n",
      "          [-0.0153, -0.0119,  0.0170]],\n",
      "\n",
      "         [[-0.0394, -0.0389, -0.0018],\n",
      "          [ 0.0517,  0.0214, -0.0361],\n",
      "          [ 0.0496,  0.0574,  0.0333]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0254,  0.0444, -0.0423],\n",
      "          [-0.0551, -0.0273, -0.0055],\n",
      "          [ 0.0031, -0.0576,  0.0440]],\n",
      "\n",
      "         [[-0.0093, -0.0407,  0.0275],\n",
      "          [-0.0034,  0.0148,  0.0551],\n",
      "          [-0.0469, -0.0244,  0.0476]],\n",
      "\n",
      "         [[ 0.0434, -0.0355,  0.0236],\n",
      "          [ 0.0192, -0.0164,  0.0565],\n",
      "          [-0.0031, -0.0167, -0.0410]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0213, -0.0348, -0.0202],\n",
      "          [ 0.0118, -0.0382, -0.0521],\n",
      "          [ 0.0517, -0.0119,  0.0586]],\n",
      "\n",
      "         [[-0.0435,  0.0034,  0.0586],\n",
      "          [-0.0591,  0.0484,  0.0281],\n",
      "          [-0.0613,  0.0308,  0.0170]],\n",
      "\n",
      "         [[ 0.0217,  0.0216,  0.0081],\n",
      "          [-0.0425,  0.0279, -0.0368],\n",
      "          [-0.0463, -0.0292, -0.0253]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0421,  0.0432,  0.0341],\n",
      "          [-0.0151,  0.0172,  0.0068],\n",
      "          [-0.0221, -0.0005, -0.0462]],\n",
      "\n",
      "         [[-0.0478,  0.0542,  0.0621],\n",
      "          [-0.0187,  0.0070, -0.0384],\n",
      "          [-0.0471,  0.0374,  0.0529]],\n",
      "\n",
      "         [[ 0.0606,  0.0069,  0.0199],\n",
      "          [ 0.0412,  0.0038,  0.0167],\n",
      "          [-0.0657,  0.0188, -0.0196]]]])\n",
      "Shape: torch.Size([24, 25, 3, 3]), std: 0.0384, mean: -0.0004\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.downsample.1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.0.downsample.1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.conv1.weight:\n",
      "tensor([[[[-2.6594e-02, -2.0271e-03,  1.9558e-02],\n",
      "          [ 1.5918e-03,  2.5692e-02, -3.8367e-02],\n",
      "          [-3.9684e-02, -6.5453e-02,  5.8665e-03]],\n",
      "\n",
      "         [[ 1.8172e-03, -2.6835e-02,  2.1419e-02],\n",
      "          [ 6.7271e-02,  2.2991e-02, -6.7972e-02],\n",
      "          [ 6.1312e-02,  2.3333e-02, -6.1790e-02]],\n",
      "\n",
      "         [[-4.9579e-02, -4.2555e-02, -1.2036e-02],\n",
      "          [ 4.9195e-02, -1.8562e-02,  3.1927e-02],\n",
      "          [ 4.8300e-02,  3.6040e-04,  2.3844e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5572e-02,  4.6763e-02, -6.7609e-02],\n",
      "          [-3.1160e-03, -6.6998e-02, -3.7766e-03],\n",
      "          [ 6.4024e-02, -4.8707e-02, -5.7162e-02]],\n",
      "\n",
      "         [[-6.5249e-02,  2.2610e-02, -4.2290e-02],\n",
      "          [-1.8865e-02,  4.9496e-02, -6.6294e-02],\n",
      "          [ 1.7250e-02, -3.9952e-03,  3.4800e-02]],\n",
      "\n",
      "         [[-1.7672e-02, -2.2965e-02,  4.1898e-02],\n",
      "          [ 4.5425e-02, -2.9296e-02,  3.6717e-02],\n",
      "          [ 3.0860e-02,  5.3907e-05,  3.2491e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8206e-02,  5.4817e-02,  5.5601e-02],\n",
      "          [ 1.5801e-02,  5.5526e-02,  2.0463e-02],\n",
      "          [-6.6477e-02, -5.9785e-02,  5.9748e-02]],\n",
      "\n",
      "         [[-1.8014e-02,  2.1875e-02,  5.4669e-02],\n",
      "          [ 6.5630e-02, -4.4081e-02,  5.0737e-02],\n",
      "          [-1.6597e-02,  4.0729e-02, -4.5505e-02]],\n",
      "\n",
      "         [[-6.0074e-02, -2.3710e-03,  4.1243e-02],\n",
      "          [-3.8373e-02,  2.1276e-02,  5.0366e-02],\n",
      "          [-3.2460e-02, -2.6886e-02,  6.2041e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4917e-02,  1.5198e-02,  4.0752e-02],\n",
      "          [-5.3768e-02, -5.1508e-02, -3.6797e-02],\n",
      "          [-5.7970e-02, -4.8916e-02,  5.0550e-02]],\n",
      "\n",
      "         [[-2.7717e-02, -2.6846e-02, -6.0981e-02],\n",
      "          [-1.0537e-02, -1.9969e-02, -3.6185e-02],\n",
      "          [-1.3419e-02, -3.6869e-02, -2.1765e-02]],\n",
      "\n",
      "         [[ 2.1155e-02,  6.3243e-02,  9.4793e-03],\n",
      "          [-2.7004e-02, -2.0104e-02, -3.9224e-02],\n",
      "          [-3.8280e-02, -3.5861e-02,  1.5378e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.9152e-02,  1.2712e-02, -2.0883e-02],\n",
      "          [-3.2837e-02,  5.3048e-03,  9.2894e-03],\n",
      "          [ 3.5282e-02,  3.7745e-02, -6.5641e-02]],\n",
      "\n",
      "         [[ 5.1780e-02,  2.2971e-02,  2.4986e-02],\n",
      "          [ 4.2028e-02,  4.2716e-02,  4.5956e-02],\n",
      "          [ 5.4384e-02,  6.7990e-02, -3.3209e-02]],\n",
      "\n",
      "         [[ 2.2442e-02,  2.8719e-02,  1.5758e-02],\n",
      "          [-2.5595e-02, -6.6061e-02, -3.3545e-02],\n",
      "          [ 5.6572e-02, -6.0263e-02,  4.9309e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2371e-02, -1.8055e-02,  4.3303e-02],\n",
      "          [ 1.6409e-02, -5.0608e-02,  5.5919e-02],\n",
      "          [ 1.9484e-02,  4.1479e-02, -6.6598e-02]],\n",
      "\n",
      "         [[-2.5296e-02,  4.2505e-02, -2.8642e-02],\n",
      "          [-3.0599e-02, -5.7225e-02,  5.5432e-02],\n",
      "          [-4.3663e-02,  1.9606e-02, -7.0622e-03]],\n",
      "\n",
      "         [[ 5.9059e-02,  6.4067e-02, -4.5690e-02],\n",
      "          [ 5.6651e-02,  2.6582e-02,  6.1954e-02],\n",
      "          [ 2.3108e-02,  6.3813e-02,  3.0061e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.3032e-02,  2.7697e-02, -5.3262e-03],\n",
      "          [ 3.7061e-02,  4.2370e-03, -6.2613e-02],\n",
      "          [ 2.8912e-02, -6.2369e-02, -5.3090e-02]],\n",
      "\n",
      "         [[-4.8430e-02,  1.9035e-02, -4.6421e-02],\n",
      "          [-6.5571e-02, -6.1843e-02,  1.1322e-02],\n",
      "          [-2.0214e-02,  6.1931e-02, -1.2411e-02]],\n",
      "\n",
      "         [[ 1.4285e-02, -6.8785e-04, -5.0254e-02],\n",
      "          [ 1.8163e-02, -4.7159e-02, -5.3381e-02],\n",
      "          [ 3.5467e-04, -3.9122e-02, -2.2145e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0230e-02, -3.4137e-02,  1.5486e-02],\n",
      "          [-5.0680e-02, -3.9127e-02,  7.7141e-03],\n",
      "          [-4.2083e-02,  2.3785e-02, -2.8063e-02]],\n",
      "\n",
      "         [[-3.7395e-02, -8.8176e-03,  2.4382e-02],\n",
      "          [-3.3395e-02, -2.0670e-02,  8.0343e-03],\n",
      "          [-4.1780e-02,  1.8414e-02, -4.8270e-02]],\n",
      "\n",
      "         [[-1.2358e-02,  1.2617e-02,  7.1921e-03],\n",
      "          [ 3.9774e-02, -3.6240e-02, -2.7849e-02],\n",
      "          [ 1.7592e-02,  3.0101e-02, -5.4238e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3491e-02,  7.0772e-03,  9.0208e-03],\n",
      "          [ 1.5691e-02,  1.3228e-02, -1.7810e-02],\n",
      "          [ 1.2474e-02, -1.3759e-02,  1.4091e-02]],\n",
      "\n",
      "         [[-4.8972e-02,  2.0365e-02,  1.5735e-02],\n",
      "          [ 2.3311e-02, -4.9890e-02,  6.7305e-02],\n",
      "          [-4.3129e-02,  6.4116e-02,  2.4944e-02]],\n",
      "\n",
      "         [[ 4.3754e-02,  4.9869e-02,  2.0279e-02],\n",
      "          [-5.8359e-02,  3.6577e-02, -3.5759e-02],\n",
      "          [ 1.6756e-02,  2.4904e-02,  4.0270e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0116e-02,  5.4894e-02,  2.8139e-02],\n",
      "          [-2.0095e-02,  4.0946e-03, -5.6690e-03],\n",
      "          [ 2.8135e-02, -2.8388e-02,  1.9101e-02]],\n",
      "\n",
      "         [[ 3.7207e-02, -5.4932e-02, -4.2689e-02],\n",
      "          [-6.0981e-02,  5.4725e-02,  2.4135e-02],\n",
      "          [ 4.8201e-02,  4.0576e-02, -2.7891e-02]],\n",
      "\n",
      "         [[-5.6650e-02, -3.3391e-02,  4.2691e-02],\n",
      "          [-6.3555e-02,  3.9224e-02,  9.2803e-03],\n",
      "          [-3.5794e-02,  2.7700e-02, -2.7016e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7141e-02, -4.2593e-02,  1.4302e-02],\n",
      "          [ 2.0468e-02,  5.7099e-04, -6.6085e-02],\n",
      "          [ 4.4298e-02,  4.7853e-03, -5.2854e-02]],\n",
      "\n",
      "         [[-4.8190e-02,  6.0197e-03,  1.9571e-02],\n",
      "          [ 3.4299e-02,  2.6620e-02,  4.4847e-02],\n",
      "          [ 3.0890e-02, -4.4715e-02, -5.1290e-02]],\n",
      "\n",
      "         [[-8.2721e-03,  4.5396e-02,  6.5841e-02],\n",
      "          [ 1.0151e-02,  2.6054e-02,  3.3405e-02],\n",
      "          [-1.6806e-02,  1.3826e-02,  3.6280e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7220e-02, -1.2109e-02,  1.2627e-02],\n",
      "          [-5.8147e-02, -6.9610e-03,  6.5945e-02],\n",
      "          [-1.2046e-02, -3.0043e-02, -6.1598e-02]],\n",
      "\n",
      "         [[ 3.7681e-02, -6.6286e-02, -1.8277e-02],\n",
      "          [ 1.8598e-02, -5.9439e-02, -4.0522e-02],\n",
      "          [-5.8101e-03, -6.1733e-02,  4.6638e-02]],\n",
      "\n",
      "         [[ 2.6848e-02, -1.3354e-02, -1.2570e-02],\n",
      "          [ 3.7025e-02,  1.7819e-02, -1.4373e-02],\n",
      "          [-5.1349e-02, -5.0661e-02,  4.4899e-02]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0394, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.conv2.weight:\n",
      "tensor([[[[ 2.3060e-02,  3.3495e-03, -3.1114e-02],\n",
      "          [ 1.0177e-02,  2.1423e-02, -6.6626e-04],\n",
      "          [ 3.2108e-03,  1.4738e-02,  6.7082e-02]],\n",
      "\n",
      "         [[-1.0216e-02, -1.8626e-02, -1.2669e-02],\n",
      "          [-5.7525e-02,  6.2534e-02,  3.9577e-03],\n",
      "          [-2.4062e-02, -3.2816e-02,  3.5516e-02]],\n",
      "\n",
      "         [[ 6.5555e-02,  5.8223e-02, -1.2096e-03],\n",
      "          [ 4.1406e-02, -5.7814e-02,  6.1543e-02],\n",
      "          [ 5.5997e-02, -4.5475e-02, -5.9026e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8748e-02,  2.6211e-02, -6.7602e-02],\n",
      "          [-4.0591e-02,  5.6200e-03,  6.5008e-03],\n",
      "          [ 2.6488e-02, -3.8183e-02, -3.7709e-02]],\n",
      "\n",
      "         [[ 4.8470e-02,  4.0792e-02, -4.7136e-02],\n",
      "          [ 5.6364e-02, -5.7484e-02, -6.1611e-02],\n",
      "          [-6.7765e-03, -1.2581e-02, -2.3342e-02]],\n",
      "\n",
      "         [[ 4.6514e-02,  1.9497e-02, -3.7419e-02],\n",
      "          [-4.0567e-02,  4.7826e-02,  1.6667e-02],\n",
      "          [-6.6149e-02, -3.3010e-02, -2.9295e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0495e-02, -4.3271e-02,  6.1998e-02],\n",
      "          [ 5.6626e-02, -7.8147e-03,  5.2332e-02],\n",
      "          [-4.9656e-02,  4.7467e-02,  1.0631e-02]],\n",
      "\n",
      "         [[ 3.9932e-02,  3.9732e-02, -1.6544e-02],\n",
      "          [-1.2870e-02, -3.6701e-03, -4.0992e-02],\n",
      "          [ 2.0434e-02, -1.3328e-02,  3.0870e-03]],\n",
      "\n",
      "         [[-1.3190e-02,  4.3742e-02, -5.7847e-02],\n",
      "          [ 5.6770e-02,  6.0606e-02,  3.1890e-02],\n",
      "          [ 3.0910e-02, -1.0155e-02, -6.3842e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4610e-02,  6.4889e-02, -3.8914e-02],\n",
      "          [ 1.9211e-02,  5.2234e-02, -1.1697e-02],\n",
      "          [-3.5026e-02,  2.3870e-02,  3.5356e-02]],\n",
      "\n",
      "         [[-4.6397e-02, -4.2466e-02,  6.1299e-02],\n",
      "          [-5.4705e-02,  6.6768e-02, -5.9591e-02],\n",
      "          [-6.7106e-02,  4.0890e-02, -2.8948e-02]],\n",
      "\n",
      "         [[ 1.9233e-02, -4.5838e-02, -6.4594e-02],\n",
      "          [ 4.9542e-02,  6.5171e-02,  1.5176e-02],\n",
      "          [ 6.0978e-02, -4.8512e-02,  2.3121e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9899e-04, -8.6533e-03,  4.2841e-02],\n",
      "          [-3.7811e-02, -2.1660e-02, -2.2680e-02],\n",
      "          [-5.5634e-02,  5.1611e-02, -1.6986e-02]],\n",
      "\n",
      "         [[-1.1731e-02,  4.1866e-02, -9.7236e-03],\n",
      "          [ 5.1053e-02,  2.3681e-02, -5.4753e-02],\n",
      "          [ 1.7431e-02, -5.4817e-02, -5.6105e-02]],\n",
      "\n",
      "         [[-6.4969e-02, -3.5174e-02,  3.1574e-02],\n",
      "          [-2.7281e-02,  1.1284e-02,  9.8186e-04],\n",
      "          [-2.9006e-02, -6.1196e-02, -1.6903e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3791e-02,  3.7190e-02,  2.0193e-02],\n",
      "          [ 3.7943e-02, -5.9923e-02,  2.2595e-02],\n",
      "          [ 1.6387e-02, -1.9295e-03, -1.5085e-02]],\n",
      "\n",
      "         [[-3.1732e-02, -1.8682e-02,  4.2853e-02],\n",
      "          [-4.2334e-02,  3.9092e-02,  5.2391e-02],\n",
      "          [ 2.7651e-02,  5.5535e-02, -5.5280e-02]],\n",
      "\n",
      "         [[ 1.4840e-02, -6.1910e-02,  6.3672e-02],\n",
      "          [-4.3651e-02,  4.7855e-02, -6.2563e-02],\n",
      "          [ 1.4193e-02,  1.0174e-02, -3.5575e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1787e-02,  3.1276e-02,  4.9796e-02],\n",
      "          [ 5.0339e-02, -4.6576e-02,  1.4537e-03],\n",
      "          [ 5.8510e-02, -3.5086e-02, -6.3741e-02]],\n",
      "\n",
      "         [[ 1.9272e-03, -1.0966e-02,  1.6373e-02],\n",
      "          [-2.9320e-02, -5.6666e-02, -6.1760e-02],\n",
      "          [-2.3461e-02, -3.5118e-02,  9.8794e-03]],\n",
      "\n",
      "         [[ 7.0191e-04, -2.4909e-02,  3.5817e-02],\n",
      "          [ 4.6361e-02, -4.9411e-02, -4.4155e-02],\n",
      "          [ 3.6049e-02,  1.5572e-02,  5.0820e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2656e-02,  1.8920e-02,  1.4960e-02],\n",
      "          [-1.1667e-02, -1.9955e-02,  6.2651e-02],\n",
      "          [-3.9158e-02,  5.8963e-02,  6.6235e-02]],\n",
      "\n",
      "         [[ 3.4040e-04, -7.9980e-03,  2.5210e-03],\n",
      "          [-9.8972e-03, -1.6191e-02,  4.9136e-03],\n",
      "          [ 4.8536e-02,  6.5178e-02,  4.6678e-02]],\n",
      "\n",
      "         [[ 2.5260e-02, -3.0586e-02,  6.7076e-02],\n",
      "          [-1.2567e-02,  8.4231e-03,  3.5428e-02],\n",
      "          [ 3.2776e-02, -5.3258e-02,  3.3775e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5836e-02, -5.7313e-03, -1.1738e-03],\n",
      "          [-4.5607e-02,  6.2793e-02, -6.5892e-02],\n",
      "          [ 5.4932e-02,  5.0341e-02,  2.1213e-02]],\n",
      "\n",
      "         [[ 5.8552e-02,  1.0012e-02,  5.6531e-02],\n",
      "          [ 2.3568e-02,  1.9941e-02,  4.8214e-02],\n",
      "          [-1.5606e-02,  4.5602e-03, -6.6016e-02]],\n",
      "\n",
      "         [[-1.2450e-02, -1.1124e-02,  3.4024e-02],\n",
      "          [ 6.1801e-03,  4.6143e-02,  2.7246e-02],\n",
      "          [ 2.7817e-02, -6.7434e-02,  2.2990e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.7018e-02,  5.4149e-02, -1.1056e-02],\n",
      "          [-1.0929e-02, -2.2506e-02, -5.8577e-02],\n",
      "          [ 2.0034e-02,  9.4617e-05, -5.9722e-02]],\n",
      "\n",
      "         [[-3.8831e-02, -8.1889e-03,  2.6512e-03],\n",
      "          [ 5.4875e-02,  2.5671e-02,  2.8152e-02],\n",
      "          [-6.6292e-02,  2.5880e-02, -6.7151e-02]],\n",
      "\n",
      "         [[-2.2944e-02, -2.5303e-02, -2.8697e-03],\n",
      "          [-3.6012e-02,  2.7842e-02,  6.6957e-02],\n",
      "          [-6.3784e-02,  6.7852e-02, -4.1719e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2197e-02, -3.0142e-02, -5.3892e-02],\n",
      "          [ 1.2521e-02, -3.1744e-02, -6.5462e-02],\n",
      "          [ 6.0800e-02,  1.1667e-02, -6.5054e-02]],\n",
      "\n",
      "         [[-1.9756e-02,  3.8776e-02,  3.4305e-02],\n",
      "          [ 1.5730e-02, -2.6508e-02,  1.9821e-02],\n",
      "          [ 1.7148e-03,  5.8011e-02,  2.2848e-02]],\n",
      "\n",
      "         [[-5.9846e-02,  6.7407e-02, -2.0570e-02],\n",
      "          [-2.4333e-02,  2.2856e-02,  1.0989e-04],\n",
      "          [ 1.8116e-02,  5.1673e-02, -4.0783e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5752e-02, -3.1192e-02, -6.7609e-02],\n",
      "          [ 5.2227e-02, -4.1502e-02,  7.8421e-03],\n",
      "          [-2.0399e-02, -4.4590e-02, -2.3541e-02]],\n",
      "\n",
      "         [[ 3.6488e-02,  3.0358e-02,  3.0254e-02],\n",
      "          [-7.3526e-04,  5.6936e-02,  6.0901e-02],\n",
      "          [-6.0035e-02,  3.7715e-02,  4.9395e-02]],\n",
      "\n",
      "         [[-2.9551e-02, -1.3410e-02,  4.8956e-02],\n",
      "          [-5.7896e-02,  5.0523e-02, -1.9989e-02],\n",
      "          [-4.0372e-02,  3.5817e-02, -5.3573e-03]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0392, mean: 0.0002\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.1.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.conv1.weight:\n",
      "tensor([[[[-0.0385, -0.0052,  0.0299],\n",
      "          [-0.0291,  0.0230, -0.0640],\n",
      "          [ 0.0596, -0.0216, -0.0652]],\n",
      "\n",
      "         [[-0.0351,  0.0396,  0.0484],\n",
      "          [-0.0357,  0.0139,  0.0221],\n",
      "          [ 0.0543, -0.0466, -0.0168]],\n",
      "\n",
      "         [[ 0.0142, -0.0464,  0.0259],\n",
      "          [ 0.0469, -0.0121,  0.0600],\n",
      "          [ 0.0352,  0.0268, -0.0493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0186,  0.0258,  0.0474],\n",
      "          [-0.0240, -0.0680, -0.0135],\n",
      "          [ 0.0459,  0.0528, -0.0548]],\n",
      "\n",
      "         [[-0.0677,  0.0432,  0.0520],\n",
      "          [ 0.0224, -0.0180, -0.0584],\n",
      "          [ 0.0290, -0.0023, -0.0247]],\n",
      "\n",
      "         [[-0.0231, -0.0022,  0.0099],\n",
      "          [ 0.0197, -0.0551,  0.0348],\n",
      "          [-0.0475, -0.0154,  0.0459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0105,  0.0103, -0.0555],\n",
      "          [-0.0393,  0.0100,  0.0564],\n",
      "          [ 0.0626,  0.0193,  0.0378]],\n",
      "\n",
      "         [[-0.0591,  0.0354, -0.0358],\n",
      "          [-0.0394, -0.0662, -0.0541],\n",
      "          [-0.0463, -0.0439, -0.0569]],\n",
      "\n",
      "         [[ 0.0094, -0.0184,  0.0679],\n",
      "          [-0.0055,  0.0676,  0.0356],\n",
      "          [ 0.0570, -0.0542, -0.0483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0581,  0.0561, -0.0345],\n",
      "          [-0.0275, -0.0007,  0.0351],\n",
      "          [ 0.0556,  0.0494, -0.0627]],\n",
      "\n",
      "         [[-0.0556,  0.0245,  0.0630],\n",
      "          [-0.0279,  0.0472, -0.0613],\n",
      "          [-0.0173, -0.0636,  0.0277]],\n",
      "\n",
      "         [[ 0.0333,  0.0314, -0.0174],\n",
      "          [-0.0581, -0.0009,  0.0116],\n",
      "          [-0.0183,  0.0442,  0.0093]]],\n",
      "\n",
      "\n",
      "        [[[-0.0610,  0.0449, -0.0666],\n",
      "          [-0.0033,  0.0178, -0.0387],\n",
      "          [-0.0470, -0.0491,  0.0085]],\n",
      "\n",
      "         [[ 0.0354, -0.0109, -0.0039],\n",
      "          [-0.0663,  0.0043,  0.0011],\n",
      "          [-0.0431,  0.0200, -0.0366]],\n",
      "\n",
      "         [[-0.0275,  0.0294, -0.0514],\n",
      "          [ 0.0472, -0.0023,  0.0205],\n",
      "          [ 0.0659, -0.0015,  0.0304]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0357,  0.0168, -0.0397],\n",
      "          [-0.0529,  0.0523, -0.0344],\n",
      "          [-0.0407,  0.0426, -0.0287]],\n",
      "\n",
      "         [[-0.0293,  0.0528,  0.0272],\n",
      "          [-0.0511, -0.0344,  0.0149],\n",
      "          [ 0.0298,  0.0380, -0.0616]],\n",
      "\n",
      "         [[ 0.0025, -0.0069,  0.0559],\n",
      "          [-0.0313,  0.0061, -0.0110],\n",
      "          [-0.0644,  0.0227, -0.0267]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0617, -0.0585, -0.0176],\n",
      "          [ 0.0006, -0.0535,  0.0091],\n",
      "          [ 0.0157, -0.0187, -0.0189]],\n",
      "\n",
      "         [[ 0.0333, -0.0409,  0.0068],\n",
      "          [-0.0615, -0.0506, -0.0322],\n",
      "          [ 0.0443, -0.0638, -0.0411]],\n",
      "\n",
      "         [[-0.0568, -0.0622,  0.0406],\n",
      "          [-0.0556, -0.0112, -0.0206],\n",
      "          [-0.0343, -0.0481, -0.0554]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0200, -0.0048,  0.0123],\n",
      "          [-0.0603, -0.0307, -0.0518],\n",
      "          [-0.0566, -0.0271,  0.0490]],\n",
      "\n",
      "         [[-0.0409,  0.0387,  0.0210],\n",
      "          [ 0.0455,  0.0563, -0.0254],\n",
      "          [-0.0261,  0.0021,  0.0326]],\n",
      "\n",
      "         [[-0.0244,  0.0637, -0.0064],\n",
      "          [-0.0165, -0.0179,  0.0386],\n",
      "          [ 0.0618,  0.0550, -0.0504]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0485, -0.0512, -0.0552],\n",
      "          [-0.0011, -0.0047, -0.0052],\n",
      "          [-0.0464, -0.0568, -0.0419]],\n",
      "\n",
      "         [[ 0.0175,  0.0641, -0.0601],\n",
      "          [-0.0143,  0.0179,  0.0303],\n",
      "          [ 0.0270, -0.0315, -0.0257]],\n",
      "\n",
      "         [[-0.0437,  0.0241, -0.0531],\n",
      "          [-0.0242,  0.0340,  0.0492],\n",
      "          [-0.0122, -0.0075, -0.0309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0408, -0.0390, -0.0432],\n",
      "          [-0.0373, -0.0449,  0.0166],\n",
      "          [-0.0027, -0.0512,  0.0402]],\n",
      "\n",
      "         [[ 0.0008,  0.0075, -0.0260],\n",
      "          [-0.0137, -0.0348,  0.0214],\n",
      "          [ 0.0227, -0.0310, -0.0499]],\n",
      "\n",
      "         [[-0.0151,  0.0228, -0.0153],\n",
      "          [ 0.0585, -0.0434, -0.0034],\n",
      "          [ 0.0354, -0.0017, -0.0627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0251, -0.0192, -0.0016],\n",
      "          [ 0.0115,  0.0344,  0.0310],\n",
      "          [-0.0110, -0.0504, -0.0319]],\n",
      "\n",
      "         [[ 0.0573,  0.0030,  0.0307],\n",
      "          [-0.0399,  0.0477,  0.0623],\n",
      "          [-0.0247, -0.0393,  0.0602]],\n",
      "\n",
      "         [[ 0.0189,  0.0220,  0.0482],\n",
      "          [ 0.0632,  0.0194, -0.0548],\n",
      "          [-0.0277, -0.0567, -0.0404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0196, -0.0650, -0.0673],\n",
      "          [-0.0370, -0.0083, -0.0659],\n",
      "          [ 0.0144,  0.0559, -0.0344]],\n",
      "\n",
      "         [[ 0.0481,  0.0002,  0.0677],\n",
      "          [ 0.0386,  0.0455,  0.0213],\n",
      "          [ 0.0182, -0.0436, -0.0590]],\n",
      "\n",
      "         [[ 0.0348, -0.0328,  0.0192],\n",
      "          [-0.0251, -0.0256, -0.0222],\n",
      "          [ 0.0454, -0.0187, -0.0602]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0392, mean: -0.0004\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.conv2.weight:\n",
      "tensor([[[[-0.0400, -0.0273, -0.0572],\n",
      "          [ 0.0226,  0.0500, -0.0047],\n",
      "          [-0.0078, -0.0236,  0.0141]],\n",
      "\n",
      "         [[ 0.0587, -0.0409, -0.0116],\n",
      "          [ 0.0360,  0.0616, -0.0667],\n",
      "          [ 0.0103, -0.0260, -0.0202]],\n",
      "\n",
      "         [[ 0.0647,  0.0304,  0.0458],\n",
      "          [ 0.0150, -0.0577, -0.0583],\n",
      "          [ 0.0675, -0.0182, -0.0548]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0568, -0.0461,  0.0657],\n",
      "          [-0.0049,  0.0097,  0.0181],\n",
      "          [-0.0301, -0.0406, -0.0634]],\n",
      "\n",
      "         [[ 0.0503, -0.0312, -0.0128],\n",
      "          [-0.0576, -0.0075,  0.0215],\n",
      "          [ 0.0339, -0.0584, -0.0366]],\n",
      "\n",
      "         [[ 0.0047,  0.0391, -0.0594],\n",
      "          [-0.0175, -0.0512,  0.0410],\n",
      "          [ 0.0410,  0.0485,  0.0501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0179,  0.0320, -0.0141],\n",
      "          [-0.0183,  0.0117, -0.0494],\n",
      "          [ 0.0338,  0.0243,  0.0464]],\n",
      "\n",
      "         [[-0.0056, -0.0084, -0.0565],\n",
      "          [ 0.0575,  0.0424, -0.0379],\n",
      "          [-0.0202,  0.0516, -0.0372]],\n",
      "\n",
      "         [[-0.0622,  0.0103, -0.0203],\n",
      "          [ 0.0583,  0.0203,  0.0313],\n",
      "          [ 0.0482,  0.0058,  0.0104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0483,  0.0445,  0.0635],\n",
      "          [-0.0648,  0.0488,  0.0238],\n",
      "          [ 0.0260,  0.0382,  0.0124]],\n",
      "\n",
      "         [[-0.0292, -0.0598, -0.0637],\n",
      "          [-0.0353,  0.0365,  0.0065],\n",
      "          [ 0.0419, -0.0600, -0.0435]],\n",
      "\n",
      "         [[ 0.0503,  0.0184,  0.0296],\n",
      "          [ 0.0415, -0.0348,  0.0312],\n",
      "          [ 0.0134, -0.0090,  0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0415, -0.0073, -0.0222],\n",
      "          [ 0.0336,  0.0405,  0.0038],\n",
      "          [-0.0440, -0.0579,  0.0474]],\n",
      "\n",
      "         [[-0.0508,  0.0128, -0.0419],\n",
      "          [-0.0499, -0.0635, -0.0470],\n",
      "          [ 0.0049, -0.0003, -0.0603]],\n",
      "\n",
      "         [[-0.0417, -0.0010,  0.0305],\n",
      "          [ 0.0245,  0.0168,  0.0387],\n",
      "          [ 0.0449, -0.0486, -0.0031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0662, -0.0484,  0.0364],\n",
      "          [-0.0061, -0.0506,  0.0149],\n",
      "          [-0.0423, -0.0177,  0.0657]],\n",
      "\n",
      "         [[ 0.0258,  0.0061,  0.0488],\n",
      "          [-0.0231,  0.0069,  0.0244],\n",
      "          [ 0.0564,  0.0012,  0.0498]],\n",
      "\n",
      "         [[-0.0485, -0.0517,  0.0190],\n",
      "          [ 0.0025, -0.0661,  0.0034],\n",
      "          [ 0.0244, -0.0646,  0.0264]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0448, -0.0100, -0.0023],\n",
      "          [ 0.0137,  0.0458,  0.0461],\n",
      "          [ 0.0368,  0.0226,  0.0522]],\n",
      "\n",
      "         [[-0.0576,  0.0247,  0.0288],\n",
      "          [-0.0542,  0.0123, -0.0549],\n",
      "          [ 0.0295, -0.0395,  0.0169]],\n",
      "\n",
      "         [[-0.0029, -0.0222, -0.0309],\n",
      "          [-0.0341,  0.0406, -0.0069],\n",
      "          [ 0.0209, -0.0581, -0.0196]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0610, -0.0327,  0.0342],\n",
      "          [-0.0031, -0.0499,  0.0491],\n",
      "          [ 0.0478, -0.0026,  0.0254]],\n",
      "\n",
      "         [[-0.0193, -0.0390, -0.0243],\n",
      "          [-0.0017,  0.0040,  0.0108],\n",
      "          [ 0.0474,  0.0461,  0.0148]],\n",
      "\n",
      "         [[ 0.0540,  0.0258,  0.0269],\n",
      "          [-0.0353,  0.0285,  0.0424],\n",
      "          [-0.0670,  0.0474, -0.0077]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0364,  0.0032,  0.0670],\n",
      "          [-0.0033, -0.0302, -0.0030],\n",
      "          [ 0.0334, -0.0205,  0.0368]],\n",
      "\n",
      "         [[-0.0290, -0.0334,  0.0081],\n",
      "          [-0.0428, -0.0011,  0.0063],\n",
      "          [-0.0561,  0.0019,  0.0501]],\n",
      "\n",
      "         [[ 0.0033, -0.0071, -0.0587],\n",
      "          [ 0.0469,  0.0176, -0.0387],\n",
      "          [-0.0430,  0.0646,  0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0522, -0.0337, -0.0064],\n",
      "          [-0.0262,  0.0600,  0.0567],\n",
      "          [ 0.0211,  0.0068,  0.0655]],\n",
      "\n",
      "         [[ 0.0528, -0.0470, -0.0195],\n",
      "          [ 0.0343,  0.0528, -0.0087],\n",
      "          [ 0.0209,  0.0605, -0.0630]],\n",
      "\n",
      "         [[-0.0344,  0.0596,  0.0104],\n",
      "          [ 0.0103, -0.0174, -0.0093],\n",
      "          [ 0.0377,  0.0019, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[-0.0378, -0.0589,  0.0315],\n",
      "          [-0.0315, -0.0564, -0.0665],\n",
      "          [ 0.0582,  0.0083, -0.0504]],\n",
      "\n",
      "         [[-0.0115, -0.0574,  0.0581],\n",
      "          [ 0.0383, -0.0466, -0.0480],\n",
      "          [-0.0309, -0.0123, -0.0367]],\n",
      "\n",
      "         [[-0.0507,  0.0278, -0.0091],\n",
      "          [-0.0641, -0.0358, -0.0348],\n",
      "          [ 0.0151, -0.0148,  0.0676]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0310,  0.0386,  0.0361],\n",
      "          [ 0.0215, -0.0463,  0.0179],\n",
      "          [-0.0168,  0.0654, -0.0052]],\n",
      "\n",
      "         [[-0.0258, -0.0668, -0.0441],\n",
      "          [-0.0494,  0.0338, -0.0168],\n",
      "          [ 0.0302, -0.0609, -0.0628]],\n",
      "\n",
      "         [[ 0.0323, -0.0668,  0.0518],\n",
      "          [-0.0674,  0.0403, -0.0036],\n",
      "          [-0.0157, -0.0310,  0.0211]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0394, mean: -0.0001\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.2.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.conv1.weight:\n",
      "tensor([[[[-0.0619, -0.0184, -0.0145],\n",
      "          [ 0.0654,  0.0623, -0.0387],\n",
      "          [ 0.0563, -0.0558, -0.0212]],\n",
      "\n",
      "         [[-0.0074, -0.0663, -0.0224],\n",
      "          [ 0.0132, -0.0417, -0.0192],\n",
      "          [ 0.0117, -0.0157,  0.0134]],\n",
      "\n",
      "         [[ 0.0618,  0.0612, -0.0093],\n",
      "          [ 0.0376, -0.0444,  0.0629],\n",
      "          [-0.0028, -0.0357, -0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0154, -0.0677, -0.0635],\n",
      "          [ 0.0436, -0.0479,  0.0275],\n",
      "          [ 0.0660,  0.0450, -0.0011]],\n",
      "\n",
      "         [[ 0.0286,  0.0102,  0.0055],\n",
      "          [-0.0229, -0.0098,  0.0430],\n",
      "          [-0.0186,  0.0297, -0.0201]],\n",
      "\n",
      "         [[-0.0568, -0.0573, -0.0403],\n",
      "          [-0.0077, -0.0629, -0.0100],\n",
      "          [ 0.0104,  0.0340,  0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0190, -0.0180, -0.0301],\n",
      "          [ 0.0183,  0.0240, -0.0323],\n",
      "          [-0.0575,  0.0426, -0.0606]],\n",
      "\n",
      "         [[-0.0219, -0.0441, -0.0474],\n",
      "          [-0.0242,  0.0365,  0.0027],\n",
      "          [ 0.0581,  0.0470, -0.0561]],\n",
      "\n",
      "         [[-0.0172, -0.0019,  0.0257],\n",
      "          [-0.0102,  0.0293,  0.0658],\n",
      "          [-0.0225,  0.0304,  0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0610,  0.0514, -0.0243],\n",
      "          [-0.0291,  0.0383,  0.0218],\n",
      "          [-0.0034,  0.0299, -0.0287]],\n",
      "\n",
      "         [[-0.0668, -0.0552, -0.0445],\n",
      "          [-0.0185,  0.0414,  0.0598],\n",
      "          [-0.0206,  0.0531, -0.0346]],\n",
      "\n",
      "         [[ 0.0074, -0.0388, -0.0354],\n",
      "          [-0.0006, -0.0336, -0.0070],\n",
      "          [-0.0498, -0.0631,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0260,  0.0534,  0.0025],\n",
      "          [ 0.0533,  0.0518,  0.0440],\n",
      "          [-0.0017, -0.0244, -0.0185]],\n",
      "\n",
      "         [[-0.0639, -0.0257, -0.0342],\n",
      "          [ 0.0379,  0.0294, -0.0044],\n",
      "          [ 0.0033,  0.0300, -0.0264]],\n",
      "\n",
      "         [[-0.0293,  0.0300, -0.0531],\n",
      "          [-0.0043, -0.0666, -0.0521],\n",
      "          [ 0.0459, -0.0517, -0.0267]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0058, -0.0055,  0.0671],\n",
      "          [-0.0076,  0.0406,  0.0229],\n",
      "          [-0.0357, -0.0626,  0.0655]],\n",
      "\n",
      "         [[-0.0480, -0.0661,  0.0236],\n",
      "          [-0.0023, -0.0121,  0.0150],\n",
      "          [ 0.0394, -0.0499, -0.0118]],\n",
      "\n",
      "         [[ 0.0066,  0.0393,  0.0295],\n",
      "          [-0.0165,  0.0247, -0.0471],\n",
      "          [ 0.0438,  0.0105,  0.0372]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0304, -0.0270, -0.0239],\n",
      "          [-0.0445,  0.0104, -0.0292],\n",
      "          [ 0.0517, -0.0565, -0.0565]],\n",
      "\n",
      "         [[ 0.0294,  0.0039,  0.0465],\n",
      "          [-0.0198, -0.0516, -0.0106],\n",
      "          [ 0.0553,  0.0481, -0.0147]],\n",
      "\n",
      "         [[ 0.0395, -0.0609,  0.0252],\n",
      "          [-0.0371, -0.0543,  0.0250],\n",
      "          [ 0.0492,  0.0086,  0.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0475, -0.0065, -0.0518],\n",
      "          [-0.0334, -0.0112, -0.0027],\n",
      "          [-0.0653,  0.0318,  0.0566]],\n",
      "\n",
      "         [[ 0.0300,  0.0042,  0.0302],\n",
      "          [-0.0537,  0.0607,  0.0191],\n",
      "          [ 0.0423,  0.0371, -0.0020]],\n",
      "\n",
      "         [[ 0.0103,  0.0263,  0.0521],\n",
      "          [ 0.0468, -0.0362,  0.0148],\n",
      "          [ 0.0227, -0.0672,  0.0160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0377,  0.0187, -0.0052],\n",
      "          [-0.0215,  0.0036,  0.0552],\n",
      "          [ 0.0281,  0.0648,  0.0528]],\n",
      "\n",
      "         [[-0.0356,  0.0621, -0.0518],\n",
      "          [ 0.0174, -0.0133,  0.0304],\n",
      "          [-0.0638,  0.0519, -0.0665]],\n",
      "\n",
      "         [[-0.0508,  0.0011,  0.0299],\n",
      "          [-0.0582, -0.0153, -0.0274],\n",
      "          [ 0.0229, -0.0299, -0.0271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0574,  0.0552, -0.0259],\n",
      "          [-0.0242, -0.0334,  0.0473],\n",
      "          [ 0.0661,  0.0158,  0.0657]],\n",
      "\n",
      "         [[ 0.0416,  0.0307,  0.0031],\n",
      "          [-0.0453,  0.0545,  0.0244],\n",
      "          [-0.0227, -0.0627, -0.0077]],\n",
      "\n",
      "         [[ 0.0660, -0.0315,  0.0151],\n",
      "          [-0.0476, -0.0679,  0.0012],\n",
      "          [ 0.0505,  0.0033,  0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0093,  0.0546, -0.0536],\n",
      "          [-0.0606, -0.0455,  0.0195],\n",
      "          [ 0.0442,  0.0166, -0.0127]],\n",
      "\n",
      "         [[-0.0668,  0.0313,  0.0262],\n",
      "          [ 0.0223,  0.0494,  0.0190],\n",
      "          [ 0.0673, -0.0185, -0.0175]],\n",
      "\n",
      "         [[ 0.0079,  0.0184,  0.0078],\n",
      "          [ 0.0598,  0.0573, -0.0203],\n",
      "          [-0.0206, -0.0252,  0.0660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0680,  0.0476, -0.0465],\n",
      "          [ 0.0151,  0.0356,  0.0207],\n",
      "          [ 0.0133, -0.0237, -0.0252]],\n",
      "\n",
      "         [[ 0.0319,  0.0374,  0.0304],\n",
      "          [ 0.0154,  0.0535, -0.0205],\n",
      "          [-0.0326,  0.0341,  0.0405]],\n",
      "\n",
      "         [[-0.0103,  0.0387, -0.0421],\n",
      "          [ 0.0421,  0.0510, -0.0531],\n",
      "          [-0.0519, -0.0252,  0.0176]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0396, mean: 0.0007\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.conv2.weight:\n",
      "tensor([[[[ 3.5664e-02, -1.8051e-02, -1.3887e-02],\n",
      "          [ 1.8983e-02, -2.2986e-02, -3.7916e-02],\n",
      "          [-2.8278e-02,  2.6419e-02,  4.1391e-03]],\n",
      "\n",
      "         [[-4.2870e-02, -1.8636e-02,  6.5631e-02],\n",
      "          [-5.6396e-02,  4.9207e-02,  4.4288e-02],\n",
      "          [ 1.8421e-02, -3.1417e-02, -5.6685e-02]],\n",
      "\n",
      "         [[ 3.3505e-02,  5.9515e-02, -9.3564e-03],\n",
      "          [ 3.2216e-02,  1.3469e-02,  4.3734e-02],\n",
      "          [-3.4022e-02,  3.8718e-02,  3.3107e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5440e-02,  2.3135e-02,  4.7914e-02],\n",
      "          [ 1.2776e-02, -1.0468e-02, -3.5729e-02],\n",
      "          [-1.1497e-03, -5.0645e-02, -4.2667e-02]],\n",
      "\n",
      "         [[ 6.5243e-02, -5.4171e-04, -2.8479e-02],\n",
      "          [ 5.3940e-02, -6.4086e-02, -1.0587e-02],\n",
      "          [-4.7444e-02,  3.6366e-02,  1.7182e-03]],\n",
      "\n",
      "         [[ 6.4026e-02,  2.3035e-02,  3.7335e-02],\n",
      "          [-7.4022e-05,  4.7140e-02, -4.4978e-02],\n",
      "          [ 2.0207e-02,  6.3350e-03, -3.0575e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4184e-02, -6.0786e-02, -3.9919e-02],\n",
      "          [ 1.4029e-02, -7.5038e-03, -6.7790e-02],\n",
      "          [ 3.9242e-02, -5.0745e-02,  5.5402e-02]],\n",
      "\n",
      "         [[ 5.3673e-02, -9.5829e-03, -5.5043e-02],\n",
      "          [ 1.3867e-02,  6.5949e-03, -5.4373e-03],\n",
      "          [ 1.3130e-02, -1.5686e-03,  1.8267e-02]],\n",
      "\n",
      "         [[-2.8535e-03,  5.6693e-02,  2.4012e-02],\n",
      "          [ 1.2954e-02,  9.8575e-03, -6.7575e-02],\n",
      "          [ 4.1501e-02,  5.4739e-02, -1.4396e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1165e-02, -6.2479e-02,  1.5825e-02],\n",
      "          [-6.2680e-02, -2.1276e-02, -1.5141e-02],\n",
      "          [-5.3841e-03,  2.1633e-02, -2.2926e-02]],\n",
      "\n",
      "         [[-3.9700e-02,  4.1212e-02,  7.1562e-03],\n",
      "          [ 6.4163e-04, -1.7625e-02,  3.9895e-03],\n",
      "          [-5.5866e-02, -7.7820e-03,  4.9109e-02]],\n",
      "\n",
      "         [[-6.4686e-02, -3.4560e-02,  5.7734e-02],\n",
      "          [-4.7328e-02,  6.7728e-02,  1.9946e-02],\n",
      "          [ 3.2401e-03, -7.0168e-03,  1.8624e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0474e-03, -4.4862e-02, -5.5208e-02],\n",
      "          [ 1.1851e-02, -6.1054e-02, -3.7242e-02],\n",
      "          [-5.4879e-03, -6.5846e-02,  3.8006e-02]],\n",
      "\n",
      "         [[-4.4205e-02, -3.7742e-02,  6.0415e-02],\n",
      "          [-8.0830e-03, -5.3897e-02,  4.1093e-02],\n",
      "          [ 1.8992e-02,  6.5474e-02, -6.1556e-03]],\n",
      "\n",
      "         [[-1.6644e-02,  6.8294e-03,  3.7786e-02],\n",
      "          [-3.0552e-02, -1.9109e-02,  6.4562e-02],\n",
      "          [ 4.2469e-02,  4.8788e-02,  3.1534e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3788e-02,  2.5660e-02,  3.1985e-02],\n",
      "          [ 5.8850e-02, -6.1570e-02,  8.4244e-03],\n",
      "          [ 2.7191e-02,  2.9581e-02, -3.8030e-02]],\n",
      "\n",
      "         [[ 5.0187e-02, -1.2649e-02, -6.3274e-02],\n",
      "          [-1.8090e-02, -5.7105e-02,  3.2277e-02],\n",
      "          [ 5.8333e-02, -4.9827e-02, -2.2741e-02]],\n",
      "\n",
      "         [[-2.7861e-02, -3.4061e-02, -7.6543e-03],\n",
      "          [ 6.2869e-03,  4.7982e-02, -1.0397e-02],\n",
      "          [-4.5068e-02,  2.4035e-02, -5.7613e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.0778e-02, -2.8176e-02, -6.0031e-02],\n",
      "          [-1.7153e-02, -2.4447e-02,  5.2663e-02],\n",
      "          [ 4.5513e-03,  1.0655e-02, -6.7162e-02]],\n",
      "\n",
      "         [[ 2.9394e-03, -6.7724e-02, -2.2588e-02],\n",
      "          [ 2.4334e-02, -5.5175e-04, -6.7917e-02],\n",
      "          [ 4.3653e-02,  1.4129e-02,  6.4904e-02]],\n",
      "\n",
      "         [[ 4.7627e-02,  5.0126e-02, -3.9758e-02],\n",
      "          [ 5.4705e-02, -4.7179e-02,  2.5392e-02],\n",
      "          [ 3.8863e-02, -2.6733e-02, -1.6558e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8655e-02,  2.9427e-02, -4.0078e-03],\n",
      "          [ 5.1063e-02,  7.9800e-03, -1.8399e-02],\n",
      "          [ 1.6130e-02, -2.5502e-02, -3.4148e-02]],\n",
      "\n",
      "         [[ 6.0946e-02,  5.9914e-02, -4.1045e-02],\n",
      "          [ 1.7917e-02,  1.9719e-02,  5.1455e-02],\n",
      "          [-7.2895e-03, -4.4285e-02,  4.5574e-03]],\n",
      "\n",
      "         [[-4.0233e-02,  6.0477e-02, -1.4778e-02],\n",
      "          [-2.5280e-02,  5.0888e-02, -6.0020e-02],\n",
      "          [ 1.2714e-02,  5.9841e-02, -1.3448e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7450e-02, -2.4136e-03, -4.3858e-02],\n",
      "          [-2.7332e-02, -4.1572e-02,  1.9231e-02],\n",
      "          [ 1.9844e-02,  2.1688e-02, -5.2352e-02]],\n",
      "\n",
      "         [[ 1.3161e-02,  6.4900e-02, -4.6835e-02],\n",
      "          [ 1.8285e-02, -3.9230e-02, -4.1999e-02],\n",
      "          [ 1.7247e-02, -3.1149e-02, -6.1860e-02]],\n",
      "\n",
      "         [[ 2.7697e-02,  4.2039e-02,  1.2763e-02],\n",
      "          [ 5.9930e-03, -5.5101e-02, -3.7425e-02],\n",
      "          [ 1.3335e-02,  5.7304e-02,  2.9187e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2165e-02,  2.5393e-02,  2.8659e-02],\n",
      "          [ 2.8091e-02, -1.8685e-02,  5.5781e-02],\n",
      "          [-1.8707e-02,  8.3242e-03,  6.6709e-02]],\n",
      "\n",
      "         [[ 1.1400e-03, -8.9084e-03, -1.5202e-02],\n",
      "          [ 3.5180e-02, -8.7261e-03, -1.3341e-02],\n",
      "          [-2.9188e-02, -3.6551e-02, -2.1842e-02]],\n",
      "\n",
      "         [[ 3.1124e-02,  6.4497e-02, -1.4539e-02],\n",
      "          [-8.7087e-03, -6.2270e-02, -1.3464e-02],\n",
      "          [-1.2086e-02, -1.4738e-02, -4.4851e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5950e-02, -9.7136e-03,  2.1570e-02],\n",
      "          [ 1.2358e-02,  2.3010e-03,  2.8414e-02],\n",
      "          [ 6.3963e-02, -3.9739e-02,  1.4272e-02]],\n",
      "\n",
      "         [[ 1.1949e-02, -2.3549e-02, -2.2758e-02],\n",
      "          [ 2.0539e-02, -4.4794e-02,  2.5662e-02],\n",
      "          [ 6.5029e-02,  4.9326e-02,  6.7583e-02]],\n",
      "\n",
      "         [[-6.2171e-02,  5.9125e-02,  5.3167e-02],\n",
      "          [-6.0045e-02, -3.5394e-02, -3.0971e-02],\n",
      "          [-1.1535e-02, -6.6549e-02,  1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1072e-02,  6.4783e-02,  4.0600e-02],\n",
      "          [-4.6061e-02,  2.9230e-02,  1.2925e-02],\n",
      "          [-5.5606e-02,  6.0259e-02, -5.5298e-02]],\n",
      "\n",
      "         [[ 1.7341e-02, -3.0339e-02, -1.1655e-02],\n",
      "          [ 5.9486e-02,  4.0744e-02, -5.4964e-02],\n",
      "          [-4.3321e-02,  6.1452e-02,  8.7383e-03]],\n",
      "\n",
      "         [[-2.0253e-02, -1.9017e-02,  3.4473e-02],\n",
      "          [ 2.8873e-02,  2.1021e-02, -5.1078e-02],\n",
      "          [-2.3242e-02, -6.2397e-02, -6.0902e-02]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0392, mean: -0.0001\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "dynamics.residual_layers.residual_layers.3.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "dynamics.reward_conv_layers.conv_layers.0.weight:\n",
      "tensor([[[[ 0.1472]],\n",
      "\n",
      "         [[-0.1050]],\n",
      "\n",
      "         [[-0.0779]],\n",
      "\n",
      "         [[ 0.0046]],\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         [[-0.0087]],\n",
      "\n",
      "         [[-0.1401]],\n",
      "\n",
      "         [[ 0.0710]],\n",
      "\n",
      "         [[ 0.0196]],\n",
      "\n",
      "         [[-0.0836]],\n",
      "\n",
      "         [[ 0.1969]],\n",
      "\n",
      "         [[ 0.1891]],\n",
      "\n",
      "         [[ 0.1094]],\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.1425]],\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         [[-0.1139]],\n",
      "\n",
      "         [[-0.1498]],\n",
      "\n",
      "         [[ 0.0549]],\n",
      "\n",
      "         [[ 0.0919]],\n",
      "\n",
      "         [[ 0.1704]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[-0.1372]],\n",
      "\n",
      "         [[-0.0340]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045]],\n",
      "\n",
      "         [[ 0.1036]],\n",
      "\n",
      "         [[ 0.0606]],\n",
      "\n",
      "         [[ 0.1750]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[-0.1911]],\n",
      "\n",
      "         [[ 0.1612]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[ 0.1263]],\n",
      "\n",
      "         [[ 0.0151]],\n",
      "\n",
      "         [[-0.0592]],\n",
      "\n",
      "         [[ 0.1669]],\n",
      "\n",
      "         [[ 0.0984]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[-0.0421]],\n",
      "\n",
      "         [[ 0.1173]],\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[ 0.0488]],\n",
      "\n",
      "         [[ 0.1651]],\n",
      "\n",
      "         [[-0.0850]],\n",
      "\n",
      "         [[ 0.1415]],\n",
      "\n",
      "         [[-0.1684]],\n",
      "\n",
      "         [[ 0.0650]]],\n",
      "\n",
      "\n",
      "        [[[-0.0334]],\n",
      "\n",
      "         [[-0.1834]],\n",
      "\n",
      "         [[-0.0332]],\n",
      "\n",
      "         [[ 0.1901]],\n",
      "\n",
      "         [[ 0.1574]],\n",
      "\n",
      "         [[-0.1021]],\n",
      "\n",
      "         [[-0.1961]],\n",
      "\n",
      "         [[ 0.0433]],\n",
      "\n",
      "         [[-0.1958]],\n",
      "\n",
      "         [[ 0.0940]],\n",
      "\n",
      "         [[-0.0290]],\n",
      "\n",
      "         [[-0.1231]],\n",
      "\n",
      "         [[ 0.1942]],\n",
      "\n",
      "         [[-0.1558]],\n",
      "\n",
      "         [[ 0.2015]],\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.1029]],\n",
      "\n",
      "         [[ 0.1084]],\n",
      "\n",
      "         [[-0.1146]],\n",
      "\n",
      "         [[ 0.1042]],\n",
      "\n",
      "         [[-0.1245]],\n",
      "\n",
      "         [[-0.1271]],\n",
      "\n",
      "         [[ 0.0347]],\n",
      "\n",
      "         [[ 0.0678]]],\n",
      "\n",
      "\n",
      "        [[[-0.0914]],\n",
      "\n",
      "         [[-0.0571]],\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[-0.0382]],\n",
      "\n",
      "         [[ 0.1719]],\n",
      "\n",
      "         [[ 0.1374]],\n",
      "\n",
      "         [[ 0.1898]],\n",
      "\n",
      "         [[ 0.1131]],\n",
      "\n",
      "         [[ 0.1155]],\n",
      "\n",
      "         [[ 0.0672]],\n",
      "\n",
      "         [[-0.1108]],\n",
      "\n",
      "         [[-0.1004]],\n",
      "\n",
      "         [[ 0.2015]],\n",
      "\n",
      "         [[ 0.1857]],\n",
      "\n",
      "         [[-0.0317]],\n",
      "\n",
      "         [[ 0.0941]],\n",
      "\n",
      "         [[ 0.0235]],\n",
      "\n",
      "         [[ 0.2038]],\n",
      "\n",
      "         [[ 0.1269]],\n",
      "\n",
      "         [[-0.0325]],\n",
      "\n",
      "         [[-0.1398]],\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[-0.1069]],\n",
      "\n",
      "         [[-0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0827]],\n",
      "\n",
      "         [[ 0.1306]],\n",
      "\n",
      "         [[ 0.0467]],\n",
      "\n",
      "         [[-0.0160]],\n",
      "\n",
      "         [[-0.1316]],\n",
      "\n",
      "         [[ 0.1225]],\n",
      "\n",
      "         [[ 0.1190]],\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[-0.0365]],\n",
      "\n",
      "         [[-0.1371]],\n",
      "\n",
      "         [[-0.1543]],\n",
      "\n",
      "         [[ 0.1824]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[ 0.1454]],\n",
      "\n",
      "         [[-0.1317]],\n",
      "\n",
      "         [[ 0.1057]],\n",
      "\n",
      "         [[-0.0771]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         [[ 0.1150]],\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         [[ 0.1943]],\n",
      "\n",
      "         [[ 0.1329]],\n",
      "\n",
      "         [[-0.0071]],\n",
      "\n",
      "         [[-0.0105]]],\n",
      "\n",
      "\n",
      "        [[[-0.0212]],\n",
      "\n",
      "         [[-0.1815]],\n",
      "\n",
      "         [[-0.1565]],\n",
      "\n",
      "         [[ 0.1346]],\n",
      "\n",
      "         [[ 0.0913]],\n",
      "\n",
      "         [[ 0.0168]],\n",
      "\n",
      "         [[ 0.1221]],\n",
      "\n",
      "         [[ 0.1110]],\n",
      "\n",
      "         [[ 0.0708]],\n",
      "\n",
      "         [[-0.1605]],\n",
      "\n",
      "         [[-0.1520]],\n",
      "\n",
      "         [[ 0.1842]],\n",
      "\n",
      "         [[-0.1180]],\n",
      "\n",
      "         [[ 0.2011]],\n",
      "\n",
      "         [[-0.0484]],\n",
      "\n",
      "         [[-0.1817]],\n",
      "\n",
      "         [[-0.0998]],\n",
      "\n",
      "         [[-0.2003]],\n",
      "\n",
      "         [[-0.0233]],\n",
      "\n",
      "         [[-0.0928]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[-0.1856]],\n",
      "\n",
      "         [[ 0.0331]],\n",
      "\n",
      "         [[ 0.0701]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1449]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[-0.1642]],\n",
      "\n",
      "         [[-0.1915]],\n",
      "\n",
      "         [[ 0.1073]],\n",
      "\n",
      "         [[-0.1683]],\n",
      "\n",
      "         [[-0.2014]],\n",
      "\n",
      "         [[-0.1616]],\n",
      "\n",
      "         [[-0.1184]],\n",
      "\n",
      "         [[-0.1460]],\n",
      "\n",
      "         [[ 0.1993]],\n",
      "\n",
      "         [[ 0.0970]],\n",
      "\n",
      "         [[ 0.0343]],\n",
      "\n",
      "         [[ 0.1293]],\n",
      "\n",
      "         [[ 0.0060]],\n",
      "\n",
      "         [[-0.1894]],\n",
      "\n",
      "         [[-0.1139]],\n",
      "\n",
      "         [[ 0.1934]],\n",
      "\n",
      "         [[ 0.1190]],\n",
      "\n",
      "         [[ 0.0036]],\n",
      "\n",
      "         [[ 0.0260]],\n",
      "\n",
      "         [[-0.1446]],\n",
      "\n",
      "         [[-0.0778]],\n",
      "\n",
      "         [[ 0.1559]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0251]],\n",
      "\n",
      "         [[-0.0955]],\n",
      "\n",
      "         [[-0.1931]],\n",
      "\n",
      "         [[ 0.1263]],\n",
      "\n",
      "         [[ 0.0240]],\n",
      "\n",
      "         [[ 0.1426]],\n",
      "\n",
      "         [[ 0.0581]],\n",
      "\n",
      "         [[ 0.0433]],\n",
      "\n",
      "         [[ 0.1621]],\n",
      "\n",
      "         [[ 0.1372]],\n",
      "\n",
      "         [[ 0.0313]],\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[ 0.1918]],\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[ 0.1941]],\n",
      "\n",
      "         [[ 0.1444]],\n",
      "\n",
      "         [[-0.1508]],\n",
      "\n",
      "         [[ 0.1821]],\n",
      "\n",
      "         [[ 0.1663]],\n",
      "\n",
      "         [[-0.1792]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         [[ 0.0245]],\n",
      "\n",
      "         [[-0.0894]],\n",
      "\n",
      "         [[-0.0978]]],\n",
      "\n",
      "\n",
      "        [[[-0.1899]],\n",
      "\n",
      "         [[-0.1035]],\n",
      "\n",
      "         [[-0.0640]],\n",
      "\n",
      "         [[-0.1112]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         [[ 0.0660]],\n",
      "\n",
      "         [[-0.1745]],\n",
      "\n",
      "         [[ 0.0535]],\n",
      "\n",
      "         [[ 0.0596]],\n",
      "\n",
      "         [[ 0.1553]],\n",
      "\n",
      "         [[ 0.0657]],\n",
      "\n",
      "         [[ 0.1820]],\n",
      "\n",
      "         [[-0.1744]],\n",
      "\n",
      "         [[ 0.1334]],\n",
      "\n",
      "         [[-0.0965]],\n",
      "\n",
      "         [[-0.0795]],\n",
      "\n",
      "         [[ 0.2012]],\n",
      "\n",
      "         [[ 0.1174]],\n",
      "\n",
      "         [[ 0.1199]],\n",
      "\n",
      "         [[ 0.0936]],\n",
      "\n",
      "         [[ 0.1329]],\n",
      "\n",
      "         [[ 0.2017]],\n",
      "\n",
      "         [[-0.0115]],\n",
      "\n",
      "         [[-0.0879]]],\n",
      "\n",
      "\n",
      "        [[[-0.1785]],\n",
      "\n",
      "         [[-0.1995]],\n",
      "\n",
      "         [[ 0.1923]],\n",
      "\n",
      "         [[ 0.0985]],\n",
      "\n",
      "         [[-0.1695]],\n",
      "\n",
      "         [[-0.1739]],\n",
      "\n",
      "         [[-0.1565]],\n",
      "\n",
      "         [[ 0.0913]],\n",
      "\n",
      "         [[ 0.1736]],\n",
      "\n",
      "         [[-0.1449]],\n",
      "\n",
      "         [[-0.1859]],\n",
      "\n",
      "         [[ 0.1013]],\n",
      "\n",
      "         [[-0.0720]],\n",
      "\n",
      "         [[ 0.0958]],\n",
      "\n",
      "         [[-0.1709]],\n",
      "\n",
      "         [[ 0.0152]],\n",
      "\n",
      "         [[ 0.1769]],\n",
      "\n",
      "         [[-0.1128]],\n",
      "\n",
      "         [[-0.0539]],\n",
      "\n",
      "         [[ 0.1560]],\n",
      "\n",
      "         [[ 0.0332]],\n",
      "\n",
      "         [[ 0.0432]],\n",
      "\n",
      "         [[ 0.0564]],\n",
      "\n",
      "         [[-0.0745]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1712]],\n",
      "\n",
      "         [[-0.1987]],\n",
      "\n",
      "         [[-0.0225]],\n",
      "\n",
      "         [[ 0.1223]],\n",
      "\n",
      "         [[-0.1668]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[-0.0069]],\n",
      "\n",
      "         [[ 0.1196]],\n",
      "\n",
      "         [[ 0.1844]],\n",
      "\n",
      "         [[-0.0842]],\n",
      "\n",
      "         [[ 0.0766]],\n",
      "\n",
      "         [[-0.0546]],\n",
      "\n",
      "         [[-0.0631]],\n",
      "\n",
      "         [[ 0.1675]],\n",
      "\n",
      "         [[ 0.1457]],\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[ 0.0862]],\n",
      "\n",
      "         [[-0.0995]],\n",
      "\n",
      "         [[ 0.1856]],\n",
      "\n",
      "         [[ 0.0196]],\n",
      "\n",
      "         [[ 0.0333]],\n",
      "\n",
      "         [[-0.1050]],\n",
      "\n",
      "         [[-0.1669]],\n",
      "\n",
      "         [[-0.0041]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1895]],\n",
      "\n",
      "         [[-0.0505]],\n",
      "\n",
      "         [[ 0.1199]],\n",
      "\n",
      "         [[-0.1943]],\n",
      "\n",
      "         [[-0.2014]],\n",
      "\n",
      "         [[-0.0664]],\n",
      "\n",
      "         [[-0.0149]],\n",
      "\n",
      "         [[ 0.1876]],\n",
      "\n",
      "         [[ 0.0275]],\n",
      "\n",
      "         [[ 0.0253]],\n",
      "\n",
      "         [[-0.1828]],\n",
      "\n",
      "         [[ 0.0739]],\n",
      "\n",
      "         [[-0.1535]],\n",
      "\n",
      "         [[ 0.1628]],\n",
      "\n",
      "         [[-0.0921]],\n",
      "\n",
      "         [[ 0.0843]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         [[-0.1033]],\n",
      "\n",
      "         [[ 0.0927]],\n",
      "\n",
      "         [[ 0.1783]],\n",
      "\n",
      "         [[-0.0792]],\n",
      "\n",
      "         [[-0.1105]],\n",
      "\n",
      "         [[ 0.0279]]],\n",
      "\n",
      "\n",
      "        [[[-0.0811]],\n",
      "\n",
      "         [[-0.0398]],\n",
      "\n",
      "         [[ 0.0987]],\n",
      "\n",
      "         [[-0.1667]],\n",
      "\n",
      "         [[ 0.0717]],\n",
      "\n",
      "         [[-0.0369]],\n",
      "\n",
      "         [[-0.0334]],\n",
      "\n",
      "         [[-0.0642]],\n",
      "\n",
      "         [[-0.0858]],\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         [[-0.0533]],\n",
      "\n",
      "         [[ 0.1548]],\n",
      "\n",
      "         [[ 0.1612]],\n",
      "\n",
      "         [[-0.1885]],\n",
      "\n",
      "         [[ 0.0750]],\n",
      "\n",
      "         [[ 0.1988]],\n",
      "\n",
      "         [[ 0.1452]],\n",
      "\n",
      "         [[ 0.2007]],\n",
      "\n",
      "         [[-0.1871]],\n",
      "\n",
      "         [[ 0.2011]],\n",
      "\n",
      "         [[ 0.1823]],\n",
      "\n",
      "         [[ 0.0109]],\n",
      "\n",
      "         [[ 0.1198]],\n",
      "\n",
      "         [[ 0.0165]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0339]],\n",
      "\n",
      "         [[-0.1321]],\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         [[ 0.1561]],\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[-0.1833]],\n",
      "\n",
      "         [[-0.1015]],\n",
      "\n",
      "         [[-0.1969]],\n",
      "\n",
      "         [[ 0.0620]],\n",
      "\n",
      "         [[ 0.1309]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[-0.0321]],\n",
      "\n",
      "         [[ 0.1863]],\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[ 0.0888]],\n",
      "\n",
      "         [[ 0.0725]],\n",
      "\n",
      "         [[-0.1408]],\n",
      "\n",
      "         [[ 0.2003]],\n",
      "\n",
      "         [[-0.0325]],\n",
      "\n",
      "         [[-0.0669]],\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[ 0.0149]],\n",
      "\n",
      "         [[ 0.0759]]],\n",
      "\n",
      "\n",
      "        [[[-0.0211]],\n",
      "\n",
      "         [[ 0.0416]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[-0.0161]],\n",
      "\n",
      "         [[ 0.0794]],\n",
      "\n",
      "         [[ 0.1506]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         [[-0.0973]],\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[ 0.0135]],\n",
      "\n",
      "         [[ 0.1060]],\n",
      "\n",
      "         [[-0.1374]],\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[ 0.1365]],\n",
      "\n",
      "         [[-0.0127]],\n",
      "\n",
      "         [[-0.1004]],\n",
      "\n",
      "         [[ 0.1709]],\n",
      "\n",
      "         [[-0.0585]],\n",
      "\n",
      "         [[ 0.1684]],\n",
      "\n",
      "         [[-0.1937]],\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[-0.1026]],\n",
      "\n",
      "         [[ 0.2018]],\n",
      "\n",
      "         [[ 0.1762]]],\n",
      "\n",
      "\n",
      "        [[[-0.0533]],\n",
      "\n",
      "         [[ 0.0487]],\n",
      "\n",
      "         [[-0.0952]],\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[-0.1761]],\n",
      "\n",
      "         [[-0.1607]],\n",
      "\n",
      "         [[-0.1409]],\n",
      "\n",
      "         [[-0.1691]],\n",
      "\n",
      "         [[-0.1077]],\n",
      "\n",
      "         [[ 0.1774]],\n",
      "\n",
      "         [[ 0.0889]],\n",
      "\n",
      "         [[-0.0866]],\n",
      "\n",
      "         [[-0.1201]],\n",
      "\n",
      "         [[-0.1110]],\n",
      "\n",
      "         [[ 0.1077]],\n",
      "\n",
      "         [[-0.1620]],\n",
      "\n",
      "         [[ 0.0770]],\n",
      "\n",
      "         [[ 0.0171]],\n",
      "\n",
      "         [[-0.0511]],\n",
      "\n",
      "         [[ 0.0319]],\n",
      "\n",
      "         [[-0.0204]],\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         [[-0.0272]],\n",
      "\n",
      "         [[-0.0601]]]])\n",
      "Shape: torch.Size([16, 24, 1, 1]), std: 0.1196, mean: 0.0079\n",
      "\n",
      "dynamics.reward_conv_layers.conv_layers.0.bias:\n",
      "tensor([ 0.1170, -0.1951, -0.0210,  0.0131,  0.0414,  0.1039,  0.0136, -0.1592,\n",
      "        -0.0498, -0.1061,  0.0612, -0.0488, -0.1687, -0.2010,  0.1589,  0.1161])\n",
      "Shape: torch.Size([16]), std: 0.1187, mean: -0.0203\n",
      "\n",
      "dynamics.reward.layer.weight:\n",
      "tensor([[ 0.0450, -0.0554,  0.0133,  0.0360,  0.0042, -0.0526, -0.0594, -0.0351,\n",
      "         -0.0211, -0.0494, -0.0701, -0.0687,  0.0733, -0.0742, -0.0674,  0.0040,\n",
      "          0.0656, -0.0139, -0.0733,  0.0190, -0.0827,  0.0540, -0.0234,  0.0402,\n",
      "          0.0734,  0.0521, -0.0823, -0.0052, -0.0099, -0.0707,  0.0199,  0.0627,\n",
      "          0.0211,  0.0723, -0.0543,  0.0818,  0.0693,  0.0523,  0.0091, -0.0578,\n",
      "          0.0099, -0.0426, -0.0425, -0.0131,  0.0592, -0.0617,  0.0330,  0.0698,\n",
      "         -0.0357, -0.0678,  0.0453,  0.0454, -0.0582, -0.0585, -0.0214, -0.0244,\n",
      "          0.0269, -0.0360, -0.0031,  0.0232,  0.0497, -0.0145, -0.0282,  0.0810,\n",
      "          0.0143,  0.0326,  0.0079,  0.0401,  0.0495, -0.0171,  0.0735, -0.0529,\n",
      "          0.0281,  0.0247, -0.0510, -0.0381,  0.0750,  0.0247, -0.0765, -0.0350,\n",
      "         -0.0117,  0.0756,  0.0460,  0.0461, -0.0298,  0.0033,  0.0759, -0.0148,\n",
      "          0.0080, -0.0012, -0.0636,  0.0159, -0.0092, -0.0535,  0.0796,  0.0106,\n",
      "         -0.0430, -0.0669, -0.0027,  0.0467, -0.0632,  0.0576, -0.0591, -0.0003,\n",
      "          0.0273, -0.0735,  0.0576, -0.0529, -0.0506, -0.0514,  0.0665, -0.0452,\n",
      "         -0.0335, -0.0819,  0.0007,  0.0523,  0.0227,  0.0714,  0.0179, -0.0422,\n",
      "          0.0056, -0.0295,  0.0566,  0.0690,  0.0591,  0.0720,  0.0509,  0.0480,\n",
      "         -0.0663,  0.0325, -0.0240,  0.0550, -0.0143, -0.0216,  0.0385,  0.0261,\n",
      "         -0.0618, -0.0434, -0.0405, -0.0322,  0.0055,  0.0674, -0.0242,  0.0280]])\n",
      "Shape: torch.Size([1, 144]), std: 0.0485, mean: 0.0005\n",
      "\n",
      "dynamics.reward.layer.bias:\n",
      "tensor([0.0722])\n",
      "Shape: torch.Size([1]), std: nan, mean: 0.0722\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.conv1.weight:\n",
      "tensor([[[[ 0.0239,  0.0531,  0.0340],\n",
      "          [-0.0124, -0.0377, -0.0035],\n",
      "          [ 0.0489,  0.0017,  0.0028]],\n",
      "\n",
      "         [[ 0.0049,  0.0576, -0.0089],\n",
      "          [ 0.0089,  0.0068,  0.0642],\n",
      "          [ 0.0134,  0.0561, -0.0565]],\n",
      "\n",
      "         [[-0.0536,  0.0564, -0.0227],\n",
      "          [-0.0276,  0.0530,  0.0608],\n",
      "          [-0.0071,  0.0293, -0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0231, -0.0220, -0.0032],\n",
      "          [ 0.0095, -0.0185, -0.0272],\n",
      "          [-0.0130, -0.0438, -0.0580]],\n",
      "\n",
      "         [[ 0.0346, -0.0157, -0.0249],\n",
      "          [-0.0678,  0.0591,  0.0237],\n",
      "          [-0.0608,  0.0621,  0.0368]],\n",
      "\n",
      "         [[-0.0274, -0.0316,  0.0167],\n",
      "          [ 0.0287,  0.0349, -0.0360],\n",
      "          [-0.0245, -0.0462,  0.0552]]],\n",
      "\n",
      "\n",
      "        [[[-0.0087, -0.0481, -0.0130],\n",
      "          [-0.0603,  0.0658, -0.0530],\n",
      "          [-0.0048,  0.0338, -0.0067]],\n",
      "\n",
      "         [[ 0.0163, -0.0669,  0.0540],\n",
      "          [-0.0399,  0.0629,  0.0228],\n",
      "          [ 0.0505,  0.0182,  0.0419]],\n",
      "\n",
      "         [[ 0.0152, -0.0640,  0.0570],\n",
      "          [ 0.0672, -0.0675, -0.0619],\n",
      "          [-0.0082,  0.0176, -0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0105, -0.0290, -0.0389],\n",
      "          [ 0.0390, -0.0324,  0.0453],\n",
      "          [ 0.0273,  0.0025, -0.0567]],\n",
      "\n",
      "         [[-0.0290,  0.0396,  0.0305],\n",
      "          [-0.0523,  0.0673,  0.0602],\n",
      "          [ 0.0534,  0.0155,  0.0452]],\n",
      "\n",
      "         [[ 0.0360, -0.0588,  0.0245],\n",
      "          [-0.0342, -0.0130,  0.0659],\n",
      "          [-0.0001,  0.0429,  0.0330]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0155,  0.0639,  0.0247],\n",
      "          [-0.0266, -0.0330, -0.0475],\n",
      "          [-0.0361, -0.0448, -0.0036]],\n",
      "\n",
      "         [[-0.0261, -0.0041, -0.0341],\n",
      "          [-0.0348, -0.0507, -0.0264],\n",
      "          [-0.0117, -0.0441, -0.0237]],\n",
      "\n",
      "         [[-0.0630, -0.0017, -0.0139],\n",
      "          [-0.0416,  0.0080,  0.0021],\n",
      "          [-0.0179,  0.0436, -0.0471]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0339, -0.0620,  0.0518],\n",
      "          [ 0.0312,  0.0041, -0.0311],\n",
      "          [-0.0345, -0.0386, -0.0641]],\n",
      "\n",
      "         [[-0.0032,  0.0470, -0.0269],\n",
      "          [-0.0038, -0.0319, -0.0124],\n",
      "          [-0.0447,  0.0501, -0.0253]],\n",
      "\n",
      "         [[ 0.0662, -0.0575,  0.0521],\n",
      "          [-0.0555,  0.0208,  0.0595],\n",
      "          [-0.0272, -0.0432, -0.0333]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0063,  0.0087,  0.0307],\n",
      "          [ 0.0677, -0.0522,  0.0323],\n",
      "          [-0.0509, -0.0161,  0.0175]],\n",
      "\n",
      "         [[-0.0591, -0.0273, -0.0534],\n",
      "          [-0.0103, -0.0137, -0.0275],\n",
      "          [-0.0190, -0.0401, -0.0339]],\n",
      "\n",
      "         [[ 0.0130,  0.0376, -0.0488],\n",
      "          [-0.0436,  0.0543,  0.0516],\n",
      "          [ 0.0222, -0.0342, -0.0019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0036, -0.0567, -0.0394],\n",
      "          [-0.0428, -0.0463, -0.0546],\n",
      "          [ 0.0602, -0.0621,  0.0465]],\n",
      "\n",
      "         [[ 0.0335, -0.0215, -0.0668],\n",
      "          [-0.0630, -0.0009, -0.0012],\n",
      "          [-0.0394, -0.0060,  0.0542]],\n",
      "\n",
      "         [[ 0.0091, -0.0610,  0.0576],\n",
      "          [-0.0161,  0.0247, -0.0625],\n",
      "          [-0.0546,  0.0238, -0.0650]]],\n",
      "\n",
      "\n",
      "        [[[-0.0315, -0.0594,  0.0306],\n",
      "          [-0.0064, -0.0021,  0.0159],\n",
      "          [ 0.0369,  0.0022,  0.0548]],\n",
      "\n",
      "         [[ 0.0518,  0.0539,  0.0268],\n",
      "          [ 0.0313,  0.0585,  0.0233],\n",
      "          [-0.0046,  0.0388,  0.0007]],\n",
      "\n",
      "         [[ 0.0662, -0.0137,  0.0657],\n",
      "          [-0.0384, -0.0617, -0.0092],\n",
      "          [-0.0424,  0.0298,  0.0489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0576,  0.0550, -0.0304],\n",
      "          [ 0.0221,  0.0503, -0.0463],\n",
      "          [ 0.0649, -0.0407,  0.0622]],\n",
      "\n",
      "         [[ 0.0516, -0.0370,  0.0387],\n",
      "          [ 0.0313,  0.0677, -0.0021],\n",
      "          [ 0.0404, -0.0207, -0.0235]],\n",
      "\n",
      "         [[-0.0672, -0.0164, -0.0406],\n",
      "          [ 0.0200, -0.0163, -0.0420],\n",
      "          [-0.0512,  0.0674,  0.0630]]],\n",
      "\n",
      "\n",
      "        [[[-0.0380, -0.0471,  0.0390],\n",
      "          [ 0.0468, -0.0592,  0.0126],\n",
      "          [ 0.0226, -0.0207, -0.0172]],\n",
      "\n",
      "         [[-0.0645, -0.0669,  0.0082],\n",
      "          [ 0.0415,  0.0223, -0.0507],\n",
      "          [-0.0568,  0.0264,  0.0362]],\n",
      "\n",
      "         [[ 0.0456, -0.0488,  0.0578],\n",
      "          [-0.0555,  0.0462, -0.0368],\n",
      "          [-0.0141, -0.0678,  0.0208]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0242, -0.0385, -0.0016],\n",
      "          [ 0.0650, -0.0619, -0.0500],\n",
      "          [ 0.0637, -0.0167,  0.0315]],\n",
      "\n",
      "         [[ 0.0393, -0.0675, -0.0132],\n",
      "          [-0.0205, -0.0362, -0.0445],\n",
      "          [ 0.0424,  0.0328, -0.0278]],\n",
      "\n",
      "         [[ 0.0368,  0.0185,  0.0018],\n",
      "          [-0.0405,  0.0501,  0.0319],\n",
      "          [-0.0161,  0.0133,  0.0556]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0394, mean: -0.0004\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.conv2.weight:\n",
      "tensor([[[[-0.0075, -0.0048,  0.0271],\n",
      "          [ 0.0662, -0.0478, -0.0663],\n",
      "          [ 0.0213, -0.0341,  0.0523]],\n",
      "\n",
      "         [[ 0.0447,  0.0433, -0.0516],\n",
      "          [ 0.0226,  0.0677,  0.0517],\n",
      "          [ 0.0344, -0.0011, -0.0423]],\n",
      "\n",
      "         [[-0.0422,  0.0464, -0.0639],\n",
      "          [-0.0059,  0.0348,  0.0254],\n",
      "          [-0.0509,  0.0641, -0.0629]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0260,  0.0438, -0.0058],\n",
      "          [-0.0326,  0.0185,  0.0154],\n",
      "          [-0.0655,  0.0441,  0.0065]],\n",
      "\n",
      "         [[ 0.0341, -0.0314, -0.0663],\n",
      "          [ 0.0124, -0.0156,  0.0418],\n",
      "          [-0.0050, -0.0011,  0.0236]],\n",
      "\n",
      "         [[ 0.0454, -0.0137, -0.0666],\n",
      "          [ 0.0465,  0.0567,  0.0060],\n",
      "          [-0.0534,  0.0427, -0.0317]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0528, -0.0514, -0.0400],\n",
      "          [ 0.0027,  0.0369, -0.0486],\n",
      "          [-0.0307, -0.0652, -0.0284]],\n",
      "\n",
      "         [[-0.0199, -0.0489, -0.0178],\n",
      "          [ 0.0072,  0.0658,  0.0051],\n",
      "          [ 0.0125,  0.0189, -0.0567]],\n",
      "\n",
      "         [[-0.0220,  0.0455, -0.0676],\n",
      "          [-0.0663, -0.0531,  0.0453],\n",
      "          [ 0.0390,  0.0420,  0.0372]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0591, -0.0294, -0.0323],\n",
      "          [-0.0673, -0.0106, -0.0258],\n",
      "          [-0.0235, -0.0037,  0.0516]],\n",
      "\n",
      "         [[-0.0072,  0.0401,  0.0571],\n",
      "          [-0.0303, -0.0318, -0.0113],\n",
      "          [ 0.0378,  0.0130,  0.0529]],\n",
      "\n",
      "         [[ 0.0420, -0.0262, -0.0368],\n",
      "          [-0.0463, -0.0365, -0.0055],\n",
      "          [ 0.0147,  0.0098, -0.0031]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0439, -0.0600,  0.0131],\n",
      "          [ 0.0203,  0.0126,  0.0343],\n",
      "          [ 0.0305,  0.0309, -0.0445]],\n",
      "\n",
      "         [[ 0.0443, -0.0536, -0.0625],\n",
      "          [ 0.0098,  0.0015, -0.0297],\n",
      "          [ 0.0335,  0.0563, -0.0431]],\n",
      "\n",
      "         [[ 0.0003, -0.0666,  0.0087],\n",
      "          [-0.0031,  0.0329,  0.0591],\n",
      "          [-0.0214, -0.0310, -0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0069, -0.0222,  0.0117],\n",
      "          [-0.0162, -0.0015,  0.0292],\n",
      "          [-0.0593, -0.0449, -0.0149]],\n",
      "\n",
      "         [[ 0.0531, -0.0575, -0.0408],\n",
      "          [ 0.0142,  0.0542,  0.0352],\n",
      "          [-0.0215,  0.0370, -0.0319]],\n",
      "\n",
      "         [[-0.0633,  0.0592, -0.0411],\n",
      "          [-0.0633, -0.0016, -0.0128],\n",
      "          [ 0.0106, -0.0565, -0.0141]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0022,  0.0282, -0.0050],\n",
      "          [ 0.0166,  0.0362,  0.0472],\n",
      "          [-0.0225,  0.0436, -0.0439]],\n",
      "\n",
      "         [[-0.0125,  0.0196,  0.0663],\n",
      "          [ 0.0315, -0.0673,  0.0005],\n",
      "          [ 0.0174, -0.0213,  0.0576]],\n",
      "\n",
      "         [[ 0.0232, -0.0223,  0.0093],\n",
      "          [ 0.0423, -0.0266,  0.0177],\n",
      "          [-0.0022, -0.0059,  0.0262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0253,  0.0109, -0.0621],\n",
      "          [ 0.0539,  0.0076, -0.0528],\n",
      "          [-0.0392, -0.0064,  0.0472]],\n",
      "\n",
      "         [[ 0.0176,  0.0620, -0.0072],\n",
      "          [ 0.0202,  0.0328,  0.0476],\n",
      "          [-0.0018, -0.0458,  0.0487]],\n",
      "\n",
      "         [[-0.0053, -0.0249, -0.0634],\n",
      "          [-0.0070,  0.0276, -0.0227],\n",
      "          [-0.0153,  0.0023,  0.0355]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0393, -0.0312, -0.0045],\n",
      "          [-0.0414, -0.0363,  0.0139],\n",
      "          [ 0.0534, -0.0291,  0.0108]],\n",
      "\n",
      "         [[-0.0077,  0.0261,  0.0523],\n",
      "          [-0.0320, -0.0502, -0.0304],\n",
      "          [ 0.0335, -0.0088,  0.0441]],\n",
      "\n",
      "         [[ 0.0135, -0.0501, -0.0430],\n",
      "          [-0.0677,  0.0496,  0.0636],\n",
      "          [ 0.0139,  0.0583,  0.0282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0302, -0.0390,  0.0397],\n",
      "          [ 0.0222,  0.0139,  0.0286],\n",
      "          [-0.0549,  0.0401,  0.0056]],\n",
      "\n",
      "         [[ 0.0611, -0.0285, -0.0173],\n",
      "          [ 0.0180,  0.0403,  0.0170],\n",
      "          [ 0.0159, -0.0416, -0.0578]],\n",
      "\n",
      "         [[ 0.0601,  0.0382, -0.0519],\n",
      "          [-0.0141, -0.0181,  0.0477],\n",
      "          [ 0.0496,  0.0470, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.0551,  0.0395, -0.0301],\n",
      "          [-0.0199,  0.0016,  0.0088],\n",
      "          [ 0.0208,  0.0382,  0.0115]],\n",
      "\n",
      "         [[ 0.0301,  0.0620, -0.0349],\n",
      "          [ 0.0305, -0.0671,  0.0002],\n",
      "          [-0.0657,  0.0270,  0.0380]],\n",
      "\n",
      "         [[-0.0414,  0.0158, -0.0188],\n",
      "          [-0.0071,  0.0240,  0.0318],\n",
      "          [ 0.0089,  0.0136,  0.0332]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0533,  0.0204,  0.0391],\n",
      "          [-0.0134, -0.0049,  0.0414],\n",
      "          [ 0.0333, -0.0420, -0.0055]],\n",
      "\n",
      "         [[-0.0448,  0.0191,  0.0445],\n",
      "          [ 0.0088, -0.0328,  0.0665],\n",
      "          [ 0.0589,  0.0591,  0.0367]],\n",
      "\n",
      "         [[-0.0480,  0.0556, -0.0310],\n",
      "          [-0.0630,  0.0165,  0.0027],\n",
      "          [-0.0054,  0.0456,  0.0438]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0389, mean: 0.0002\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.0.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.conv1.weight:\n",
      "tensor([[[[-6.3210e-02,  1.6442e-02,  6.3073e-02],\n",
      "          [-3.8070e-02,  6.6721e-02,  3.0004e-02],\n",
      "          [-3.6183e-02,  2.5575e-02, -5.4193e-03]],\n",
      "\n",
      "         [[ 1.8532e-03, -5.0089e-02, -1.3623e-02],\n",
      "          [-2.2684e-02,  2.7509e-02, -3.8994e-02],\n",
      "          [ 3.4437e-02,  4.6597e-02, -3.9464e-02]],\n",
      "\n",
      "         [[-3.1100e-02,  3.9301e-02,  2.0073e-02],\n",
      "          [ 3.6173e-02, -3.5950e-02, -4.9257e-02],\n",
      "          [-5.7737e-02,  1.1165e-02, -4.7536e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2975e-02, -3.2377e-02, -4.5767e-04],\n",
      "          [-3.2379e-02,  4.7131e-02, -1.8314e-02],\n",
      "          [ 6.4196e-02,  3.7004e-02,  5.9655e-02]],\n",
      "\n",
      "         [[ 4.8775e-02, -2.3079e-03, -1.3148e-02],\n",
      "          [-1.5123e-03, -4.0326e-02, -5.0124e-02],\n",
      "          [ 1.5397e-02, -4.6918e-02,  2.5342e-02]],\n",
      "\n",
      "         [[ 3.4300e-02,  3.9894e-03,  3.9634e-02],\n",
      "          [-2.9066e-02, -5.4461e-02, -1.4714e-02],\n",
      "          [ 4.5458e-02, -4.2993e-02, -4.2701e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3958e-02, -2.5983e-02,  2.4660e-02],\n",
      "          [ 6.6816e-02,  1.1534e-02, -8.8679e-03],\n",
      "          [-2.7984e-02, -3.9620e-03,  3.2491e-02]],\n",
      "\n",
      "         [[ 6.7821e-02, -4.0670e-02,  2.4891e-02],\n",
      "          [ 5.5098e-02,  1.7898e-02, -5.6346e-02],\n",
      "          [ 2.3058e-04,  2.2623e-02, -5.7593e-03]],\n",
      "\n",
      "         [[-5.0159e-02, -5.7720e-02,  1.1310e-02],\n",
      "          [-5.9051e-02,  8.3130e-03, -1.8951e-02],\n",
      "          [ 6.3775e-02, -1.3083e-02, -5.3682e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9509e-02,  1.7613e-04,  1.1631e-02],\n",
      "          [-3.6953e-02, -1.9022e-02,  2.7136e-02],\n",
      "          [-4.6737e-02,  2.2989e-02,  6.2396e-02]],\n",
      "\n",
      "         [[ 2.3022e-02, -5.2884e-02,  3.5808e-02],\n",
      "          [-4.7542e-02, -5.1751e-02, -5.1415e-03],\n",
      "          [-5.0833e-02,  1.1276e-02, -8.0131e-04]],\n",
      "\n",
      "         [[ 4.6759e-04,  8.2702e-03, -3.2570e-02],\n",
      "          [ 4.7929e-02,  3.9926e-04, -2.8790e-03],\n",
      "          [ 6.2777e-02, -4.4576e-02, -3.0306e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6476e-02,  3.1259e-02, -3.6020e-02],\n",
      "          [-2.9193e-02, -6.8004e-02, -2.3910e-02],\n",
      "          [-2.6230e-02,  1.4946e-02, -5.8010e-02]],\n",
      "\n",
      "         [[ 3.0022e-02, -6.5216e-02, -5.2238e-02],\n",
      "          [-3.9655e-02, -4.5740e-02,  3.2186e-02],\n",
      "          [-4.3243e-02, -1.7234e-02,  6.5723e-02]],\n",
      "\n",
      "         [[ 2.2229e-02,  2.6871e-02, -4.3044e-02],\n",
      "          [-2.6146e-02, -2.8546e-02, -2.2174e-02],\n",
      "          [ 2.3486e-02, -3.0321e-02, -3.3751e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2769e-02, -5.0162e-02,  5.8344e-02],\n",
      "          [-5.0459e-03, -1.7343e-02, -1.2660e-02],\n",
      "          [ 1.0029e-02, -3.5205e-02,  6.4215e-02]],\n",
      "\n",
      "         [[ 1.7371e-04,  3.2178e-02,  3.0016e-02],\n",
      "          [-6.2812e-02, -6.0144e-02, -4.6892e-04],\n",
      "          [ 5.1820e-02,  2.1446e-02, -2.5689e-02]],\n",
      "\n",
      "         [[ 4.9717e-02, -4.6367e-02,  4.3927e-02],\n",
      "          [ 6.4023e-02, -5.3862e-02,  3.2786e-02],\n",
      "          [-6.7437e-02,  6.7359e-02, -3.0012e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.2622e-02,  3.2848e-03, -1.4298e-02],\n",
      "          [-3.8020e-02,  5.9329e-02,  3.6745e-02],\n",
      "          [ 4.4442e-02,  1.9186e-02,  1.8703e-02]],\n",
      "\n",
      "         [[-1.4702e-02, -4.1894e-02, -4.7088e-02],\n",
      "          [ 6.7939e-02, -2.4893e-02, -6.3583e-02],\n",
      "          [-6.7732e-02,  3.4348e-02, -6.3181e-02]],\n",
      "\n",
      "         [[-5.8264e-02,  3.8220e-02, -3.5381e-02],\n",
      "          [ 4.6850e-02, -4.3063e-03,  3.0901e-02],\n",
      "          [-2.2215e-02,  1.9776e-02, -4.1154e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0410e-02, -6.3952e-02,  3.2296e-02],\n",
      "          [-5.6861e-02,  3.0844e-04,  2.3995e-02],\n",
      "          [ 6.0278e-02, -3.8474e-02,  4.1381e-02]],\n",
      "\n",
      "         [[ 3.6320e-02,  1.2978e-02,  4.5115e-02],\n",
      "          [-6.4204e-02,  7.6781e-03, -1.5509e-02],\n",
      "          [ 6.2910e-03, -5.1115e-02, -4.1102e-02]],\n",
      "\n",
      "         [[-6.6669e-02,  2.0449e-03, -1.2063e-02],\n",
      "          [ 5.1703e-02, -1.9838e-02, -3.8884e-02],\n",
      "          [ 7.9744e-03,  5.5741e-02,  3.7159e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0172e-02,  2.2057e-02,  1.9021e-02],\n",
      "          [-1.8235e-02,  6.4716e-02,  6.0752e-03],\n",
      "          [-1.0323e-02, -5.1166e-02, -8.6235e-03]],\n",
      "\n",
      "         [[ 1.1111e-02, -6.1789e-02, -1.8043e-02],\n",
      "          [ 5.2908e-02, -5.3537e-02,  1.2891e-02],\n",
      "          [ 4.5554e-02, -2.7240e-02,  1.4272e-02]],\n",
      "\n",
      "         [[ 1.9331e-02, -5.2893e-02, -5.4038e-02],\n",
      "          [-3.1603e-02,  2.0062e-02, -6.3700e-02],\n",
      "          [ 2.9033e-02,  3.5788e-02, -1.3779e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4286e-02,  4.6107e-02, -4.6884e-02],\n",
      "          [-6.5895e-02,  4.3655e-02, -6.4803e-02],\n",
      "          [ 1.6658e-02,  2.9581e-02,  5.8287e-02]],\n",
      "\n",
      "         [[ 6.6480e-02,  3.6803e-02, -4.5874e-02],\n",
      "          [ 6.7751e-02,  4.8323e-02,  5.3766e-02],\n",
      "          [-7.2251e-03, -2.1410e-02, -5.8311e-02]],\n",
      "\n",
      "         [[ 6.4688e-02, -3.7231e-02,  2.7761e-02],\n",
      "          [ 3.9657e-02, -3.4620e-02, -2.8145e-02],\n",
      "          [ 4.2784e-02, -2.2779e-02, -1.8779e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0113e-02,  2.6364e-02,  8.6583e-03],\n",
      "          [ 6.3907e-02,  3.5608e-03,  2.2151e-02],\n",
      "          [ 5.1031e-02, -1.5730e-02,  5.8906e-02]],\n",
      "\n",
      "         [[-1.0771e-02,  3.5438e-02,  6.1661e-02],\n",
      "          [ 2.8359e-02,  4.3769e-02,  3.6797e-02],\n",
      "          [ 5.3725e-02,  6.2075e-02,  6.1875e-02]],\n",
      "\n",
      "         [[-2.7848e-02,  5.9038e-03, -1.7716e-02],\n",
      "          [-1.4039e-02,  1.4113e-02,  5.8095e-02],\n",
      "          [-5.7400e-02,  1.0268e-03,  1.2181e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6360e-02,  4.8093e-02, -6.9124e-03],\n",
      "          [-5.1859e-02,  4.6391e-02, -1.4085e-02],\n",
      "          [ 5.5486e-02, -4.2498e-04, -4.2489e-02]],\n",
      "\n",
      "         [[ 6.1768e-02,  5.0679e-02,  6.2899e-02],\n",
      "          [-3.9647e-02,  1.9777e-02,  5.4307e-02],\n",
      "          [-6.4405e-02, -3.1268e-02,  5.0007e-02]],\n",
      "\n",
      "         [[ 7.8757e-03, -2.3103e-02, -2.7746e-02],\n",
      "          [ 6.0023e-06,  4.6213e-02,  6.5799e-02],\n",
      "          [ 1.3723e-02,  5.5483e-03, -6.4454e-02]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0391, mean: 0.0012\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.conv2.weight:\n",
      "tensor([[[[-3.6429e-02,  6.7373e-02,  1.6512e-02],\n",
      "          [ 5.7434e-02,  1.0512e-02,  1.9241e-02],\n",
      "          [ 5.6087e-02, -6.0866e-02, -2.8965e-02]],\n",
      "\n",
      "         [[-6.1104e-02, -6.8147e-03,  4.6877e-03],\n",
      "          [ 9.4609e-03,  4.0069e-02, -3.7523e-02],\n",
      "          [-5.8575e-02,  3.7045e-02, -6.6942e-02]],\n",
      "\n",
      "         [[ 5.7337e-02,  5.9573e-02, -5.3875e-02],\n",
      "          [ 4.5135e-02, -8.6779e-03,  3.2875e-02],\n",
      "          [-6.0495e-02,  2.6930e-02,  5.4143e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6942e-02, -1.5463e-02, -4.9389e-02],\n",
      "          [-5.4639e-02, -9.9510e-03, -5.2315e-03],\n",
      "          [-8.5687e-03,  3.8111e-02, -2.7504e-02]],\n",
      "\n",
      "         [[ 6.3981e-02, -5.5784e-03,  3.8481e-02],\n",
      "          [-6.4449e-02,  6.3077e-02,  3.2127e-02],\n",
      "          [-1.8239e-02,  3.1041e-03, -5.3171e-02]],\n",
      "\n",
      "         [[ 5.1495e-02,  8.1258e-05, -3.5650e-02],\n",
      "          [-4.8158e-02,  2.0455e-02, -7.3451e-04],\n",
      "          [ 6.7485e-03, -4.6506e-02,  5.2441e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8957e-02,  6.7450e-02,  5.9779e-02],\n",
      "          [ 5.2882e-02,  3.1341e-02,  2.2709e-02],\n",
      "          [ 6.2231e-02, -3.4684e-02, -2.7180e-02]],\n",
      "\n",
      "         [[-5.6291e-02,  6.5581e-02, -3.1284e-02],\n",
      "          [-3.5677e-02, -1.1627e-02, -6.1178e-02],\n",
      "          [ 4.3155e-03, -5.1632e-02,  6.0037e-02]],\n",
      "\n",
      "         [[ 3.1497e-02, -1.3412e-02, -2.9898e-02],\n",
      "          [-3.7573e-02, -4.8630e-02, -3.6794e-02],\n",
      "          [ 1.1317e-02,  3.6164e-02, -4.6663e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.2897e-02, -5.1013e-02, -6.6845e-02],\n",
      "          [-2.6119e-03, -5.2303e-02,  2.0710e-02],\n",
      "          [-4.6016e-02,  6.3978e-02,  4.3340e-02]],\n",
      "\n",
      "         [[ 3.8805e-02,  3.4002e-02,  1.3314e-02],\n",
      "          [ 3.7409e-02,  4.4915e-02, -2.7176e-02],\n",
      "          [-5.9616e-02,  5.3449e-02,  9.7902e-03]],\n",
      "\n",
      "         [[-6.3583e-02,  5.0631e-02, -3.7726e-02],\n",
      "          [-5.8081e-02, -6.7392e-02,  8.8678e-03],\n",
      "          [ 3.6481e-02,  4.3019e-02,  2.9570e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0371e-02, -6.0814e-02, -2.0035e-02],\n",
      "          [ 2.5179e-02, -4.4277e-03,  4.7333e-02],\n",
      "          [ 3.3859e-03, -3.3511e-02,  5.4987e-02]],\n",
      "\n",
      "         [[-3.0813e-02,  6.4849e-02,  6.7557e-02],\n",
      "          [ 2.5350e-02,  6.2764e-02,  6.3449e-02],\n",
      "          [ 6.3947e-02,  2.2469e-02, -1.1844e-02]],\n",
      "\n",
      "         [[-6.6988e-02,  3.4324e-03, -5.9439e-02],\n",
      "          [-4.0684e-02,  2.5078e-02,  2.8983e-02],\n",
      "          [-2.7411e-02,  4.0211e-03,  1.2524e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2242e-03,  2.2013e-02,  5.3798e-02],\n",
      "          [ 5.0442e-02,  3.2214e-02, -1.5991e-02],\n",
      "          [ 6.0643e-02,  5.9396e-02,  5.9903e-02]],\n",
      "\n",
      "         [[-1.3611e-02, -3.4317e-02,  1.0853e-02],\n",
      "          [-1.9232e-02, -6.6111e-02,  4.5912e-02],\n",
      "          [ 5.3545e-02, -5.4498e-02, -4.6780e-02]],\n",
      "\n",
      "         [[ 2.2264e-03, -6.0289e-02, -3.9348e-02],\n",
      "          [ 5.1748e-03, -3.6389e-02,  1.6147e-02],\n",
      "          [ 4.7368e-02, -8.2495e-03,  6.1789e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2274e-02, -4.2138e-02,  5.1167e-02],\n",
      "          [ 8.2773e-03, -4.4947e-03,  6.5352e-02],\n",
      "          [-6.7738e-02, -3.4579e-02,  4.7389e-02]],\n",
      "\n",
      "         [[ 3.5894e-02, -6.1260e-02,  2.8541e-02],\n",
      "          [-3.3877e-02, -6.1705e-02,  2.9240e-04],\n",
      "          [-7.0886e-03, -9.1027e-03, -2.7182e-02]],\n",
      "\n",
      "         [[ 6.3365e-02,  1.5532e-02, -5.7243e-02],\n",
      "          [-3.4208e-03,  5.1233e-02,  9.9491e-03],\n",
      "          [ 1.2005e-02,  2.9759e-02,  4.5737e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6951e-02,  2.6788e-02, -1.0107e-02],\n",
      "          [-5.5017e-02,  4.7989e-03, -2.6466e-02],\n",
      "          [ 6.7478e-02,  4.8907e-02,  3.4609e-02]],\n",
      "\n",
      "         [[ 1.8781e-02,  1.5759e-03, -2.1414e-02],\n",
      "          [ 1.3171e-02, -6.3770e-02, -2.9187e-02],\n",
      "          [-5.4859e-02, -6.6276e-02, -1.6163e-02]],\n",
      "\n",
      "         [[-6.0866e-02,  1.1094e-02,  7.7635e-03],\n",
      "          [ 5.4039e-02, -2.9342e-02,  1.5847e-02],\n",
      "          [-3.0947e-02,  3.3969e-02, -6.1507e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1902e-02,  6.5285e-02,  1.9116e-02],\n",
      "          [-4.0492e-02,  2.2820e-02, -3.8209e-02],\n",
      "          [ 3.3491e-02,  5.0096e-03, -4.1623e-02]],\n",
      "\n",
      "         [[ 8.2408e-03, -1.4867e-02,  5.0679e-03],\n",
      "          [-1.9037e-02, -2.6483e-02,  5.6679e-03],\n",
      "          [-6.1970e-02,  6.4033e-02,  2.3335e-02]],\n",
      "\n",
      "         [[-2.5775e-02,  3.0086e-02,  3.9159e-02],\n",
      "          [-9.4804e-03,  3.9653e-02, -4.7572e-05],\n",
      "          [ 2.1741e-02,  5.5922e-02, -5.7589e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5880e-02,  1.6379e-02,  5.1264e-02],\n",
      "          [-2.5788e-02, -5.5798e-02, -1.8800e-02],\n",
      "          [-3.3223e-02, -5.6879e-02,  5.6497e-02]],\n",
      "\n",
      "         [[-5.8305e-02, -4.1008e-02, -3.2544e-02],\n",
      "          [-4.5231e-02, -2.5725e-02, -3.3259e-02],\n",
      "          [-2.1176e-03,  6.2998e-02,  2.9874e-02]],\n",
      "\n",
      "         [[ 1.5061e-02, -2.9975e-02,  3.8445e-02],\n",
      "          [ 1.5317e-02,  4.6296e-02,  7.1878e-03],\n",
      "          [ 4.9877e-02,  4.7449e-02, -2.6007e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1151e-02,  4.2901e-02,  3.4834e-03],\n",
      "          [-3.8250e-02, -4.9289e-02, -3.1605e-02],\n",
      "          [ 6.0298e-02, -5.4360e-02,  4.7672e-02]],\n",
      "\n",
      "         [[-6.4034e-02,  5.5773e-02, -3.1478e-02],\n",
      "          [-3.7421e-02,  2.6713e-02, -1.7036e-02],\n",
      "          [-3.6179e-02,  4.1822e-02,  4.8816e-02]],\n",
      "\n",
      "         [[-8.0816e-03,  2.4614e-02,  3.9962e-02],\n",
      "          [-2.2195e-02,  2.9726e-02,  3.9362e-02],\n",
      "          [ 2.9946e-02,  2.5512e-02,  1.2076e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8397e-03, -6.4838e-03, -2.3839e-02],\n",
      "          [ 9.7233e-03,  2.3610e-02,  4.8679e-02],\n",
      "          [ 5.4554e-03,  1.1238e-02,  6.3180e-02]],\n",
      "\n",
      "         [[-5.5879e-04, -2.9633e-02, -4.1067e-02],\n",
      "          [ 3.8751e-02,  3.3456e-02, -6.2033e-03],\n",
      "          [ 2.3479e-02, -5.9009e-02,  5.6125e-02]],\n",
      "\n",
      "         [[-3.5173e-02,  5.1181e-02, -6.1594e-02],\n",
      "          [ 2.0333e-02,  3.3531e-02, -6.0560e-02],\n",
      "          [ 3.9293e-02,  3.8496e-02,  1.3282e-02]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0390, mean: 0.0002\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.1.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.conv1.weight:\n",
      "tensor([[[[ 0.0269, -0.0551, -0.0022],\n",
      "          [-0.0065, -0.0326, -0.0119],\n",
      "          [ 0.0625,  0.0313, -0.0533]],\n",
      "\n",
      "         [[-0.0017,  0.0650, -0.0111],\n",
      "          [ 0.0081, -0.0312,  0.0156],\n",
      "          [-0.0450,  0.0184,  0.0557]],\n",
      "\n",
      "         [[ 0.0300, -0.0470, -0.0204],\n",
      "          [ 0.0020,  0.0439,  0.0662],\n",
      "          [-0.0515,  0.0209, -0.0521]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0292,  0.0474,  0.0457],\n",
      "          [ 0.0156, -0.0153,  0.0653],\n",
      "          [ 0.0036,  0.0476, -0.0609]],\n",
      "\n",
      "         [[-0.0350,  0.0211,  0.0121],\n",
      "          [ 0.0211, -0.0620, -0.0468],\n",
      "          [-0.0238, -0.0331,  0.0009]],\n",
      "\n",
      "         [[-0.0680,  0.0507, -0.0270],\n",
      "          [ 0.0025,  0.0008,  0.0456],\n",
      "          [-0.0462,  0.0533, -0.0037]]],\n",
      "\n",
      "\n",
      "        [[[-0.0160,  0.0452, -0.0347],\n",
      "          [ 0.0070, -0.0265, -0.0543],\n",
      "          [-0.0218,  0.0661, -0.0201]],\n",
      "\n",
      "         [[-0.0507,  0.0219, -0.0138],\n",
      "          [-0.0052, -0.0537, -0.0511],\n",
      "          [-0.0516, -0.0009, -0.0596]],\n",
      "\n",
      "         [[ 0.0497, -0.0321, -0.0248],\n",
      "          [-0.0573,  0.0389, -0.0057],\n",
      "          [-0.0586,  0.0483,  0.0673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0128, -0.0064,  0.0610],\n",
      "          [ 0.0401,  0.0623,  0.0055],\n",
      "          [-0.0550,  0.0372,  0.0592]],\n",
      "\n",
      "         [[-0.0191, -0.0559,  0.0646],\n",
      "          [ 0.0364, -0.0162,  0.0448],\n",
      "          [ 0.0653, -0.0192, -0.0672]],\n",
      "\n",
      "         [[-0.0372, -0.0500, -0.0559],\n",
      "          [ 0.0114, -0.0545, -0.0373],\n",
      "          [ 0.0617, -0.0457, -0.0432]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0059,  0.0406,  0.0274],\n",
      "          [ 0.0039, -0.0631,  0.0526],\n",
      "          [ 0.0519,  0.0013, -0.0456]],\n",
      "\n",
      "         [[-0.0316, -0.0163, -0.0605],\n",
      "          [-0.0078,  0.0568,  0.0340],\n",
      "          [ 0.0488,  0.0542, -0.0542]],\n",
      "\n",
      "         [[-0.0471, -0.0207, -0.0582],\n",
      "          [ 0.0356,  0.0009,  0.0475],\n",
      "          [ 0.0504, -0.0360,  0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0290,  0.0587,  0.0381],\n",
      "          [-0.0317,  0.0240,  0.0619],\n",
      "          [ 0.0035,  0.0340, -0.0521]],\n",
      "\n",
      "         [[-0.0240, -0.0149, -0.0585],\n",
      "          [ 0.0525, -0.0639, -0.0023],\n",
      "          [ 0.0135, -0.0030, -0.0354]],\n",
      "\n",
      "         [[-0.0400,  0.0569,  0.0031],\n",
      "          [ 0.0301, -0.0046, -0.0618],\n",
      "          [-0.0657, -0.0519, -0.0663]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0402, -0.0421,  0.0013],\n",
      "          [ 0.0546, -0.0191, -0.0424],\n",
      "          [-0.0584,  0.0331,  0.0035]],\n",
      "\n",
      "         [[ 0.0584, -0.0533,  0.0165],\n",
      "          [-0.0246, -0.0582,  0.0065],\n",
      "          [ 0.0629, -0.0140,  0.0610]],\n",
      "\n",
      "         [[ 0.0418,  0.0560,  0.0551],\n",
      "          [-0.0452, -0.0228, -0.0338],\n",
      "          [-0.0024,  0.0589, -0.0406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0227, -0.0255,  0.0101],\n",
      "          [-0.0260,  0.0179,  0.0670],\n",
      "          [ 0.0491, -0.0230,  0.0210]],\n",
      "\n",
      "         [[-0.0506,  0.0650,  0.0007],\n",
      "          [-0.0192, -0.0090,  0.0600],\n",
      "          [ 0.0417, -0.0381,  0.0257]],\n",
      "\n",
      "         [[-0.0632, -0.0494,  0.0573],\n",
      "          [ 0.0070, -0.0474, -0.0280],\n",
      "          [-0.0599, -0.0421,  0.0535]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0050,  0.0164,  0.0394],\n",
      "          [-0.0551,  0.0113,  0.0609],\n",
      "          [-0.0160, -0.0371,  0.0485]],\n",
      "\n",
      "         [[-0.0409,  0.0515, -0.0581],\n",
      "          [ 0.0201, -0.0577, -0.0101],\n",
      "          [ 0.0358, -0.0134, -0.0373]],\n",
      "\n",
      "         [[-0.0476,  0.0534, -0.0560],\n",
      "          [-0.0357, -0.0259, -0.0308],\n",
      "          [ 0.0648,  0.0488,  0.0039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0584, -0.0571,  0.0450],\n",
      "          [ 0.0178,  0.0605,  0.0249],\n",
      "          [-0.0136,  0.0327, -0.0629]],\n",
      "\n",
      "         [[-0.0219,  0.0662, -0.0554],\n",
      "          [-0.0298,  0.0036,  0.0008],\n",
      "          [ 0.0261, -0.0091, -0.0064]],\n",
      "\n",
      "         [[-0.0042,  0.0094,  0.0457],\n",
      "          [-0.0034, -0.0058,  0.0409],\n",
      "          [-0.0153,  0.0318, -0.0269]]],\n",
      "\n",
      "\n",
      "        [[[-0.0579,  0.0204,  0.0511],\n",
      "          [ 0.0064, -0.0129, -0.0646],\n",
      "          [ 0.0473, -0.0145,  0.0669]],\n",
      "\n",
      "         [[-0.0099,  0.0028,  0.0571],\n",
      "          [-0.0628, -0.0289,  0.0383],\n",
      "          [-0.0652, -0.0039,  0.0535]],\n",
      "\n",
      "         [[ 0.0613, -0.0075, -0.0095],\n",
      "          [ 0.0152, -0.0532, -0.0644],\n",
      "          [-0.0401,  0.0007,  0.0637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0591, -0.0593, -0.0443],\n",
      "          [-0.0305,  0.0497, -0.0038],\n",
      "          [-0.0107,  0.0559,  0.0277]],\n",
      "\n",
      "         [[ 0.0455, -0.0403, -0.0115],\n",
      "          [ 0.0535, -0.0032,  0.0410],\n",
      "          [ 0.0006, -0.0557,  0.0284]],\n",
      "\n",
      "         [[-0.0560, -0.0035, -0.0380],\n",
      "          [-0.0333,  0.0657,  0.0165],\n",
      "          [ 0.0644, -0.0383, -0.0584]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0396, mean: -0.0003\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.conv2.weight:\n",
      "tensor([[[[ 0.0573, -0.0655, -0.0441],\n",
      "          [ 0.0474,  0.0270, -0.0233],\n",
      "          [-0.0357, -0.0586,  0.0239]],\n",
      "\n",
      "         [[-0.0392,  0.0154, -0.0118],\n",
      "          [ 0.0101, -0.0394, -0.0648],\n",
      "          [-0.0556,  0.0376,  0.0298]],\n",
      "\n",
      "         [[ 0.0662,  0.0052, -0.0240],\n",
      "          [-0.0087, -0.0258, -0.0280],\n",
      "          [-0.0134, -0.0200, -0.0402]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0658, -0.0600,  0.0291],\n",
      "          [-0.0126, -0.0057,  0.0406],\n",
      "          [ 0.0607, -0.0464, -0.0365]],\n",
      "\n",
      "         [[ 0.0123, -0.0444, -0.0165],\n",
      "          [ 0.0190, -0.0212,  0.0424],\n",
      "          [ 0.0628,  0.0599, -0.0678]],\n",
      "\n",
      "         [[ 0.0589, -0.0196,  0.0407],\n",
      "          [-0.0220, -0.0439,  0.0084],\n",
      "          [-0.0468,  0.0066, -0.0645]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0458, -0.0661,  0.0440],\n",
      "          [ 0.0535,  0.0460,  0.0660],\n",
      "          [ 0.0285,  0.0302, -0.0626]],\n",
      "\n",
      "         [[ 0.0499,  0.0586,  0.0453],\n",
      "          [-0.0107, -0.0439, -0.0248],\n",
      "          [-0.0469,  0.0466,  0.0602]],\n",
      "\n",
      "         [[-0.0125, -0.0224,  0.0287],\n",
      "          [ 0.0533, -0.0191,  0.0282],\n",
      "          [ 0.0273,  0.0574,  0.0109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0113, -0.0415, -0.0186],\n",
      "          [ 0.0111, -0.0060, -0.0312],\n",
      "          [-0.0461,  0.0036,  0.0575]],\n",
      "\n",
      "         [[ 0.0326,  0.0196, -0.0271],\n",
      "          [ 0.0283,  0.0134, -0.0592],\n",
      "          [ 0.0017,  0.0304, -0.0192]],\n",
      "\n",
      "         [[ 0.0366, -0.0008, -0.0366],\n",
      "          [ 0.0405, -0.0658,  0.0488],\n",
      "          [ 0.0198, -0.0182,  0.0041]]],\n",
      "\n",
      "\n",
      "        [[[-0.0254, -0.0187, -0.0313],\n",
      "          [-0.0376, -0.0236,  0.0215],\n",
      "          [-0.0299, -0.0380,  0.0047]],\n",
      "\n",
      "         [[ 0.0214,  0.0181,  0.0222],\n",
      "          [ 0.0355,  0.0161, -0.0318],\n",
      "          [ 0.0230, -0.0184,  0.0122]],\n",
      "\n",
      "         [[-0.0361,  0.0367,  0.0033],\n",
      "          [ 0.0532, -0.0612,  0.0070],\n",
      "          [ 0.0524, -0.0362,  0.0022]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0563, -0.0358,  0.0384],\n",
      "          [ 0.0041, -0.0541, -0.0225],\n",
      "          [ 0.0516,  0.0280, -0.0314]],\n",
      "\n",
      "         [[-0.0338,  0.0143,  0.0648],\n",
      "          [-0.0338, -0.0247,  0.0640],\n",
      "          [-0.0026,  0.0324, -0.0406]],\n",
      "\n",
      "         [[ 0.0005, -0.0410, -0.0230],\n",
      "          [-0.0182,  0.0348, -0.0429],\n",
      "          [-0.0187,  0.0657, -0.0287]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0024, -0.0326,  0.0046],\n",
      "          [-0.0355, -0.0502,  0.0640],\n",
      "          [-0.0044,  0.0189, -0.0214]],\n",
      "\n",
      "         [[ 0.0074,  0.0439,  0.0507],\n",
      "          [ 0.0540, -0.0440, -0.0403],\n",
      "          [ 0.0563, -0.0027,  0.0602]],\n",
      "\n",
      "         [[ 0.0653, -0.0509, -0.0138],\n",
      "          [ 0.0170,  0.0652,  0.0423],\n",
      "          [ 0.0369,  0.0056,  0.0626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0115,  0.0633,  0.0555],\n",
      "          [ 0.0107,  0.0503, -0.0372],\n",
      "          [-0.0392, -0.0095,  0.0574]],\n",
      "\n",
      "         [[ 0.0012, -0.0256, -0.0314],\n",
      "          [ 0.0085, -0.0625,  0.0213],\n",
      "          [ 0.0489, -0.0380, -0.0502]],\n",
      "\n",
      "         [[-0.0202,  0.0435,  0.0578],\n",
      "          [ 0.0488, -0.0222,  0.0354],\n",
      "          [-0.0482,  0.0367, -0.0099]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0271,  0.0497,  0.0300],\n",
      "          [ 0.0383, -0.0365, -0.0020],\n",
      "          [-0.0670,  0.0300,  0.0092]],\n",
      "\n",
      "         [[-0.0111, -0.0378, -0.0646],\n",
      "          [ 0.0521,  0.0383, -0.0350],\n",
      "          [ 0.0666, -0.0172,  0.0251]],\n",
      "\n",
      "         [[ 0.0184, -0.0265, -0.0371],\n",
      "          [-0.0670, -0.0623, -0.0048],\n",
      "          [-0.0091, -0.0520,  0.0513]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0566, -0.0242, -0.0083],\n",
      "          [-0.0050,  0.0484, -0.0341],\n",
      "          [-0.0371, -0.0511, -0.0035]],\n",
      "\n",
      "         [[-0.0507, -0.0202, -0.0662],\n",
      "          [-0.0017,  0.0438,  0.0616],\n",
      "          [-0.0484, -0.0465, -0.0260]],\n",
      "\n",
      "         [[ 0.0063, -0.0486, -0.0604],\n",
      "          [ 0.0207, -0.0598,  0.0202],\n",
      "          [ 0.0680,  0.0550, -0.0332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0342,  0.0274,  0.0109],\n",
      "          [ 0.0238,  0.0559,  0.0326],\n",
      "          [-0.0441, -0.0609,  0.0133]],\n",
      "\n",
      "         [[-0.0608,  0.0336,  0.0675],\n",
      "          [-0.0489, -0.0101,  0.0277],\n",
      "          [ 0.0289,  0.0392, -0.0627]],\n",
      "\n",
      "         [[ 0.0216,  0.0584, -0.0241],\n",
      "          [-0.0374, -0.0501, -0.0281],\n",
      "          [ 0.0283,  0.0193,  0.0669]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0088,  0.0323, -0.0254],\n",
      "          [ 0.0458, -0.0393, -0.0605],\n",
      "          [ 0.0409, -0.0106, -0.0488]],\n",
      "\n",
      "         [[ 0.0471,  0.0343, -0.0172],\n",
      "          [-0.0424, -0.0248, -0.0131],\n",
      "          [-0.0543,  0.0265,  0.0511]],\n",
      "\n",
      "         [[ 0.0029,  0.0445, -0.0565],\n",
      "          [-0.0192,  0.0278,  0.0618],\n",
      "          [-0.0251, -0.0256,  0.0089]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0391, mean: 0.0005\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.2.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.conv1.weight:\n",
      "tensor([[[[-0.0579,  0.0063,  0.0025],\n",
      "          [ 0.0376,  0.0291,  0.0378],\n",
      "          [-0.0211,  0.0493, -0.0068]],\n",
      "\n",
      "         [[-0.0444,  0.0360, -0.0424],\n",
      "          [ 0.0431,  0.0585, -0.0075],\n",
      "          [ 0.0111, -0.0648,  0.0292]],\n",
      "\n",
      "         [[ 0.0310, -0.0010, -0.0064],\n",
      "          [ 0.0551, -0.0502, -0.0442],\n",
      "          [ 0.0340,  0.0254,  0.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0373, -0.0010,  0.0259],\n",
      "          [ 0.0442, -0.0048,  0.0680],\n",
      "          [ 0.0495,  0.0613, -0.0128]],\n",
      "\n",
      "         [[-0.0643, -0.0093,  0.0311],\n",
      "          [ 0.0218,  0.0276,  0.0044],\n",
      "          [-0.0377, -0.0013, -0.0442]],\n",
      "\n",
      "         [[-0.0085,  0.0461,  0.0409],\n",
      "          [-0.0406,  0.0526,  0.0178],\n",
      "          [-0.0680,  0.0297,  0.0272]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0292,  0.0371, -0.0153],\n",
      "          [ 0.0389,  0.0014, -0.0446],\n",
      "          [ 0.0468, -0.0527, -0.0223]],\n",
      "\n",
      "         [[-0.0580, -0.0469,  0.0049],\n",
      "          [-0.0089,  0.0077,  0.0647],\n",
      "          [ 0.0393,  0.0668, -0.0502]],\n",
      "\n",
      "         [[ 0.0534, -0.0571, -0.0352],\n",
      "          [ 0.0098, -0.0321, -0.0666],\n",
      "          [-0.0605,  0.0482, -0.0630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0548, -0.0257,  0.0507],\n",
      "          [-0.0508,  0.0037,  0.0268],\n",
      "          [-0.0150, -0.0549, -0.0429]],\n",
      "\n",
      "         [[-0.0624, -0.0493, -0.0564],\n",
      "          [ 0.0596,  0.0614, -0.0320],\n",
      "          [-0.0293,  0.0475,  0.0419]],\n",
      "\n",
      "         [[-0.0031, -0.0482, -0.0014],\n",
      "          [ 0.0221,  0.0605,  0.0608],\n",
      "          [-0.0008,  0.0007,  0.0379]]],\n",
      "\n",
      "\n",
      "        [[[-0.0148,  0.0215,  0.0531],\n",
      "          [ 0.0313, -0.0591, -0.0426],\n",
      "          [ 0.0671,  0.0266,  0.0529]],\n",
      "\n",
      "         [[ 0.0167, -0.0366,  0.0192],\n",
      "          [-0.0453, -0.0070,  0.0672],\n",
      "          [-0.0230,  0.0267,  0.0145]],\n",
      "\n",
      "         [[ 0.0272, -0.0083, -0.0005],\n",
      "          [ 0.0457,  0.0590,  0.0470],\n",
      "          [ 0.0082, -0.0527,  0.0477]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0549, -0.0029,  0.0457],\n",
      "          [-0.0255,  0.0326, -0.0155],\n",
      "          [ 0.0285,  0.0110, -0.0243]],\n",
      "\n",
      "         [[ 0.0195, -0.0079,  0.0412],\n",
      "          [ 0.0522,  0.0618,  0.0477],\n",
      "          [ 0.0644,  0.0621,  0.0567]],\n",
      "\n",
      "         [[ 0.0349, -0.0509, -0.0636],\n",
      "          [ 0.0497, -0.0536, -0.0236],\n",
      "          [-0.0595,  0.0178, -0.0499]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0337, -0.0616,  0.0279],\n",
      "          [ 0.0356, -0.0327,  0.0445],\n",
      "          [ 0.0277, -0.0227,  0.0243]],\n",
      "\n",
      "         [[-0.0269, -0.0147, -0.0341],\n",
      "          [ 0.0165,  0.0390, -0.0573],\n",
      "          [ 0.0184,  0.0617, -0.0330]],\n",
      "\n",
      "         [[ 0.0349, -0.0585, -0.0223],\n",
      "          [-0.0615, -0.0677,  0.0042],\n",
      "          [-0.0410, -0.0598, -0.0372]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0596,  0.0447,  0.0084],\n",
      "          [-0.0423,  0.0298, -0.0376],\n",
      "          [-0.0190, -0.0608,  0.0119]],\n",
      "\n",
      "         [[ 0.0527, -0.0332, -0.0088],\n",
      "          [-0.0676,  0.0397,  0.0147],\n",
      "          [ 0.0017, -0.0548,  0.0527]],\n",
      "\n",
      "         [[ 0.0186, -0.0083,  0.0097],\n",
      "          [ 0.0090, -0.0168,  0.0279],\n",
      "          [ 0.0353, -0.0527,  0.0571]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0429,  0.0630,  0.0473],\n",
      "          [ 0.0397, -0.0226,  0.0257],\n",
      "          [ 0.0660, -0.0014,  0.0554]],\n",
      "\n",
      "         [[-0.0584, -0.0042,  0.0590],\n",
      "          [-0.0584,  0.0287, -0.0271],\n",
      "          [ 0.0218, -0.0516, -0.0225]],\n",
      "\n",
      "         [[ 0.0084, -0.0663, -0.0309],\n",
      "          [ 0.0651, -0.0646,  0.0052],\n",
      "          [ 0.0648, -0.0307,  0.0579]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0484, -0.0205,  0.0287],\n",
      "          [-0.0639,  0.0280,  0.0441],\n",
      "          [ 0.0634, -0.0466,  0.0610]],\n",
      "\n",
      "         [[ 0.0557,  0.0304,  0.0468],\n",
      "          [ 0.0228,  0.0257,  0.0254],\n",
      "          [-0.0213,  0.0125,  0.0162]],\n",
      "\n",
      "         [[-0.0372,  0.0145,  0.0071],\n",
      "          [ 0.0497,  0.0013,  0.0327],\n",
      "          [-0.0188,  0.0220, -0.0309]]],\n",
      "\n",
      "\n",
      "        [[[-0.0105,  0.0608, -0.0119],\n",
      "          [-0.0126,  0.0503, -0.0073],\n",
      "          [-0.0462, -0.0242,  0.0582]],\n",
      "\n",
      "         [[-0.0457,  0.0669, -0.0169],\n",
      "          [-0.0230, -0.0578, -0.0644],\n",
      "          [-0.0223,  0.0401, -0.0533]],\n",
      "\n",
      "         [[-0.0663,  0.0362, -0.0133],\n",
      "          [ 0.0661, -0.0215,  0.0660],\n",
      "          [-0.0306,  0.0008, -0.0245]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0645, -0.0246, -0.0648],\n",
      "          [ 0.0157, -0.0676,  0.0472],\n",
      "          [ 0.0412,  0.0650,  0.0487]],\n",
      "\n",
      "         [[-0.0363, -0.0400, -0.0551],\n",
      "          [ 0.0680,  0.0266,  0.0559],\n",
      "          [ 0.0108,  0.0623, -0.0094]],\n",
      "\n",
      "         [[ 0.0348,  0.0385,  0.0528],\n",
      "          [-0.0220, -0.0227,  0.0398],\n",
      "          [-0.0498, -0.0198, -0.0492]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0395, mean: 0.0003\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.bn1.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.bn1.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.conv2.weight:\n",
      "tensor([[[[-0.0338, -0.0347,  0.0276],\n",
      "          [ 0.0563, -0.0122, -0.0294],\n",
      "          [ 0.0126, -0.0305,  0.0088]],\n",
      "\n",
      "         [[ 0.0172, -0.0616, -0.0588],\n",
      "          [-0.0242,  0.0186,  0.0264],\n",
      "          [-0.0227,  0.0388, -0.0305]],\n",
      "\n",
      "         [[-0.0281, -0.0291,  0.0194],\n",
      "          [-0.0218,  0.0586,  0.0505],\n",
      "          [-0.0673, -0.0484, -0.0562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0374,  0.0051,  0.0581],\n",
      "          [-0.0004, -0.0195, -0.0477],\n",
      "          [ 0.0364,  0.0329,  0.0453]],\n",
      "\n",
      "         [[-0.0037,  0.0658, -0.0057],\n",
      "          [-0.0311,  0.0039, -0.0612],\n",
      "          [-0.0356,  0.0412,  0.0420]],\n",
      "\n",
      "         [[ 0.0438, -0.0534, -0.0059],\n",
      "          [ 0.0069, -0.0023, -0.0047],\n",
      "          [-0.0283, -0.0254, -0.0582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0204, -0.0235, -0.0390],\n",
      "          [-0.0672, -0.0547,  0.0003],\n",
      "          [ 0.0409, -0.0038, -0.0247]],\n",
      "\n",
      "         [[-0.0130, -0.0530,  0.0125],\n",
      "          [-0.0575,  0.0469,  0.0346],\n",
      "          [-0.0132,  0.0079,  0.0619]],\n",
      "\n",
      "         [[ 0.0112,  0.0660, -0.0548],\n",
      "          [-0.0599,  0.0129, -0.0160],\n",
      "          [-0.0478, -0.0058, -0.0209]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047,  0.0550, -0.0560],\n",
      "          [ 0.0485, -0.0331, -0.0676],\n",
      "          [-0.0209,  0.0160, -0.0655]],\n",
      "\n",
      "         [[ 0.0103,  0.0177, -0.0625],\n",
      "          [-0.0504,  0.0552,  0.0311],\n",
      "          [-0.0604, -0.0604, -0.0446]],\n",
      "\n",
      "         [[ 0.0543,  0.0612,  0.0554],\n",
      "          [-0.0177, -0.0608, -0.0636],\n",
      "          [-0.0638, -0.0585, -0.0588]]],\n",
      "\n",
      "\n",
      "        [[[-0.0296,  0.0429, -0.0412],\n",
      "          [-0.0206,  0.0398, -0.0316],\n",
      "          [ 0.0434, -0.0507, -0.0094]],\n",
      "\n",
      "         [[-0.0552, -0.0275,  0.0457],\n",
      "          [-0.0588, -0.0157,  0.0620],\n",
      "          [ 0.0057,  0.0302, -0.0092]],\n",
      "\n",
      "         [[-0.0299,  0.0404, -0.0023],\n",
      "          [-0.0565, -0.0638,  0.0628],\n",
      "          [ 0.0596,  0.0183,  0.0090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0089, -0.0347,  0.0187],\n",
      "          [ 0.0606,  0.0270,  0.0593],\n",
      "          [ 0.0642,  0.0361, -0.0069]],\n",
      "\n",
      "         [[ 0.0388, -0.0567,  0.0620],\n",
      "          [ 0.0134, -0.0248,  0.0263],\n",
      "          [ 0.0316, -0.0307,  0.0247]],\n",
      "\n",
      "         [[-0.0038,  0.0299,  0.0323],\n",
      "          [ 0.0358,  0.0517, -0.0383],\n",
      "          [ 0.0635,  0.0294,  0.0149]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0287,  0.0425,  0.0095],\n",
      "          [ 0.0192,  0.0645,  0.0148],\n",
      "          [ 0.0507,  0.0469, -0.0269]],\n",
      "\n",
      "         [[-0.0228,  0.0555, -0.0202],\n",
      "          [-0.0460,  0.0232, -0.0434],\n",
      "          [ 0.0500, -0.0444, -0.0117]],\n",
      "\n",
      "         [[ 0.0157,  0.0251, -0.0258],\n",
      "          [ 0.0309,  0.0078,  0.0369],\n",
      "          [-0.0026,  0.0542,  0.0004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0192, -0.0473, -0.0460],\n",
      "          [ 0.0424, -0.0286, -0.0579],\n",
      "          [ 0.0448,  0.0053, -0.0029]],\n",
      "\n",
      "         [[-0.0126, -0.0256,  0.0471],\n",
      "          [ 0.0012,  0.0331,  0.0670],\n",
      "          [ 0.0226,  0.0501,  0.0266]],\n",
      "\n",
      "         [[ 0.0246,  0.0038,  0.0263],\n",
      "          [ 0.0637,  0.0600,  0.0442],\n",
      "          [ 0.0140, -0.0437,  0.0072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0454,  0.0049,  0.0163],\n",
      "          [-0.0352, -0.0039, -0.0428],\n",
      "          [-0.0661, -0.0195, -0.0277]],\n",
      "\n",
      "         [[ 0.0551, -0.0678, -0.0321],\n",
      "          [ 0.0063,  0.0025,  0.0430],\n",
      "          [ 0.0056, -0.0611, -0.0300]],\n",
      "\n",
      "         [[-0.0252,  0.0228, -0.0589],\n",
      "          [ 0.0335,  0.0313,  0.0127],\n",
      "          [-0.0101,  0.0319, -0.0085]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0664, -0.0126,  0.0276],\n",
      "          [-0.0198, -0.0124,  0.0349],\n",
      "          [-0.0400,  0.0609, -0.0664]],\n",
      "\n",
      "         [[-0.0117, -0.0447, -0.0561],\n",
      "          [ 0.0462, -0.0202, -0.0444],\n",
      "          [-0.0555,  0.0237,  0.0633]],\n",
      "\n",
      "         [[-0.0342, -0.0277,  0.0178],\n",
      "          [-0.0198, -0.0324, -0.0307],\n",
      "          [-0.0114, -0.0160, -0.0563]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0183, -0.0556,  0.0614],\n",
      "          [ 0.0615, -0.0180,  0.0472],\n",
      "          [-0.0586,  0.0099, -0.0065]],\n",
      "\n",
      "         [[ 0.0042, -0.0565, -0.0668],\n",
      "          [-0.0237, -0.0657,  0.0635],\n",
      "          [ 0.0391,  0.0425,  0.0373]],\n",
      "\n",
      "         [[ 0.0305, -0.0600,  0.0099],\n",
      "          [ 0.0678, -0.0287, -0.0559],\n",
      "          [ 0.0241,  0.0230,  0.0252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0316,  0.0138,  0.0397],\n",
      "          [-0.0133, -0.0032,  0.0473],\n",
      "          [ 0.0136, -0.0229, -0.0449]],\n",
      "\n",
      "         [[-0.0330,  0.0256, -0.0340],\n",
      "          [-0.0029,  0.0192,  0.0388],\n",
      "          [-0.0436, -0.0388,  0.0329]],\n",
      "\n",
      "         [[-0.0387, -0.0140, -0.0561],\n",
      "          [-0.0198,  0.0284,  0.0627],\n",
      "          [-0.0594, -0.0482, -0.0378]]]])\n",
      "Shape: torch.Size([24, 24, 3, 3]), std: 0.0394, mean: -0.0007\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.bn2.weight:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 1.0000\n",
      "\n",
      "prediction.residual_layers.residual_layers.3.bn2.bias:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Shape: torch.Size([24]), std: 0.0000, mean: 0.0000\n",
      "\n",
      "prediction.critic.conv_layers.conv_layers.0.weight:\n",
      "tensor([[[[ 3.3206e-02]],\n",
      "\n",
      "         [[ 1.4586e-01]],\n",
      "\n",
      "         [[ 1.4730e-01]],\n",
      "\n",
      "         [[-1.9633e-01]],\n",
      "\n",
      "         [[ 2.8268e-02]],\n",
      "\n",
      "         [[-1.4858e-01]],\n",
      "\n",
      "         [[ 9.8549e-02]],\n",
      "\n",
      "         [[ 1.2052e-01]],\n",
      "\n",
      "         [[ 1.9452e-01]],\n",
      "\n",
      "         [[ 1.1961e-01]],\n",
      "\n",
      "         [[ 1.3132e-02]],\n",
      "\n",
      "         [[ 5.2588e-02]],\n",
      "\n",
      "         [[-6.8976e-03]],\n",
      "\n",
      "         [[-7.2495e-02]],\n",
      "\n",
      "         [[-7.3525e-03]],\n",
      "\n",
      "         [[ 9.5029e-02]],\n",
      "\n",
      "         [[ 9.5018e-02]],\n",
      "\n",
      "         [[-1.3205e-01]],\n",
      "\n",
      "         [[ 1.1177e-01]],\n",
      "\n",
      "         [[-1.2496e-01]],\n",
      "\n",
      "         [[-1.6238e-01]],\n",
      "\n",
      "         [[-1.9557e-01]],\n",
      "\n",
      "         [[ 8.7252e-02]],\n",
      "\n",
      "         [[-2.0402e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2479e-02]],\n",
      "\n",
      "         [[ 7.7814e-02]],\n",
      "\n",
      "         [[-1.0868e-01]],\n",
      "\n",
      "         [[-1.0382e-01]],\n",
      "\n",
      "         [[ 1.9688e-01]],\n",
      "\n",
      "         [[ 2.8888e-02]],\n",
      "\n",
      "         [[-5.8165e-02]],\n",
      "\n",
      "         [[ 4.4204e-02]],\n",
      "\n",
      "         [[-9.2293e-02]],\n",
      "\n",
      "         [[ 3.5700e-02]],\n",
      "\n",
      "         [[-6.7203e-02]],\n",
      "\n",
      "         [[-5.2910e-02]],\n",
      "\n",
      "         [[-1.2246e-01]],\n",
      "\n",
      "         [[-1.4551e-01]],\n",
      "\n",
      "         [[ 1.4009e-04]],\n",
      "\n",
      "         [[ 1.0576e-01]],\n",
      "\n",
      "         [[ 5.8247e-02]],\n",
      "\n",
      "         [[-1.7226e-01]],\n",
      "\n",
      "         [[-2.8393e-02]],\n",
      "\n",
      "         [[ 5.5593e-02]],\n",
      "\n",
      "         [[-1.5093e-01]],\n",
      "\n",
      "         [[ 1.9259e-01]],\n",
      "\n",
      "         [[-1.6233e-01]],\n",
      "\n",
      "         [[-2.0234e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2227e-01]],\n",
      "\n",
      "         [[ 1.9953e-01]],\n",
      "\n",
      "         [[ 6.6821e-02]],\n",
      "\n",
      "         [[ 2.5223e-03]],\n",
      "\n",
      "         [[-1.7352e-01]],\n",
      "\n",
      "         [[ 7.2447e-02]],\n",
      "\n",
      "         [[-1.8734e-01]],\n",
      "\n",
      "         [[ 7.4266e-02]],\n",
      "\n",
      "         [[ 1.6842e-01]],\n",
      "\n",
      "         [[-1.3945e-01]],\n",
      "\n",
      "         [[ 1.9456e-01]],\n",
      "\n",
      "         [[-1.2677e-01]],\n",
      "\n",
      "         [[ 4.6573e-02]],\n",
      "\n",
      "         [[-1.6883e-01]],\n",
      "\n",
      "         [[ 9.5788e-02]],\n",
      "\n",
      "         [[ 1.7094e-01]],\n",
      "\n",
      "         [[ 1.6805e-01]],\n",
      "\n",
      "         [[ 4.3569e-02]],\n",
      "\n",
      "         [[-1.0388e-01]],\n",
      "\n",
      "         [[ 2.9483e-03]],\n",
      "\n",
      "         [[ 1.5622e-02]],\n",
      "\n",
      "         [[-1.5996e-02]],\n",
      "\n",
      "         [[ 5.6718e-02]],\n",
      "\n",
      "         [[-3.0935e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5040e-01]],\n",
      "\n",
      "         [[ 1.2539e-01]],\n",
      "\n",
      "         [[ 1.5465e-01]],\n",
      "\n",
      "         [[ 1.7324e-01]],\n",
      "\n",
      "         [[-1.3033e-02]],\n",
      "\n",
      "         [[ 1.6645e-02]],\n",
      "\n",
      "         [[-6.5414e-02]],\n",
      "\n",
      "         [[-1.0847e-01]],\n",
      "\n",
      "         [[ 1.5024e-01]],\n",
      "\n",
      "         [[-1.0536e-01]],\n",
      "\n",
      "         [[-1.6409e-01]],\n",
      "\n",
      "         [[-1.1416e-01]],\n",
      "\n",
      "         [[-1.0821e-01]],\n",
      "\n",
      "         [[-5.2888e-02]],\n",
      "\n",
      "         [[-2.3460e-02]],\n",
      "\n",
      "         [[ 1.9899e-02]],\n",
      "\n",
      "         [[ 6.5163e-02]],\n",
      "\n",
      "         [[ 1.8716e-01]],\n",
      "\n",
      "         [[ 1.7844e-01]],\n",
      "\n",
      "         [[-1.4475e-01]],\n",
      "\n",
      "         [[ 7.2797e-02]],\n",
      "\n",
      "         [[ 1.8834e-01]],\n",
      "\n",
      "         [[ 1.3091e-01]],\n",
      "\n",
      "         [[ 1.6101e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0769e-01]],\n",
      "\n",
      "         [[-9.1374e-02]],\n",
      "\n",
      "         [[ 6.2172e-02]],\n",
      "\n",
      "         [[ 5.9493e-02]],\n",
      "\n",
      "         [[-1.5539e-01]],\n",
      "\n",
      "         [[-9.2175e-02]],\n",
      "\n",
      "         [[ 1.2629e-01]],\n",
      "\n",
      "         [[-4.5141e-02]],\n",
      "\n",
      "         [[-2.0315e-02]],\n",
      "\n",
      "         [[ 6.8917e-02]],\n",
      "\n",
      "         [[-1.1544e-01]],\n",
      "\n",
      "         [[ 8.2687e-02]],\n",
      "\n",
      "         [[-2.0168e-01]],\n",
      "\n",
      "         [[-8.6052e-02]],\n",
      "\n",
      "         [[-7.4616e-02]],\n",
      "\n",
      "         [[-2.2947e-02]],\n",
      "\n",
      "         [[ 1.0231e-01]],\n",
      "\n",
      "         [[-2.3905e-02]],\n",
      "\n",
      "         [[-1.2304e-01]],\n",
      "\n",
      "         [[ 9.3891e-03]],\n",
      "\n",
      "         [[ 1.5020e-01]],\n",
      "\n",
      "         [[-7.1818e-02]],\n",
      "\n",
      "         [[-1.2202e-01]],\n",
      "\n",
      "         [[ 1.3177e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7477e-01]],\n",
      "\n",
      "         [[ 1.3249e-01]],\n",
      "\n",
      "         [[ 1.2954e-01]],\n",
      "\n",
      "         [[ 3.2329e-02]],\n",
      "\n",
      "         [[ 7.1379e-02]],\n",
      "\n",
      "         [[ 2.0662e-02]],\n",
      "\n",
      "         [[-2.8075e-02]],\n",
      "\n",
      "         [[-7.8404e-02]],\n",
      "\n",
      "         [[-1.4842e-01]],\n",
      "\n",
      "         [[-8.0005e-02]],\n",
      "\n",
      "         [[ 1.4844e-01]],\n",
      "\n",
      "         [[ 8.0409e-02]],\n",
      "\n",
      "         [[ 6.9844e-02]],\n",
      "\n",
      "         [[-8.1526e-02]],\n",
      "\n",
      "         [[ 3.4264e-03]],\n",
      "\n",
      "         [[ 4.1598e-02]],\n",
      "\n",
      "         [[-7.1140e-02]],\n",
      "\n",
      "         [[-1.3856e-01]],\n",
      "\n",
      "         [[-1.9157e-01]],\n",
      "\n",
      "         [[ 2.0122e-01]],\n",
      "\n",
      "         [[ 1.8629e-02]],\n",
      "\n",
      "         [[-1.5708e-01]],\n",
      "\n",
      "         [[ 5.0176e-02]],\n",
      "\n",
      "         [[-3.4622e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0099e-01]],\n",
      "\n",
      "         [[-1.5829e-01]],\n",
      "\n",
      "         [[ 8.3893e-02]],\n",
      "\n",
      "         [[-1.5174e-01]],\n",
      "\n",
      "         [[-1.4841e-01]],\n",
      "\n",
      "         [[ 1.2693e-01]],\n",
      "\n",
      "         [[ 3.3852e-02]],\n",
      "\n",
      "         [[-1.4749e-01]],\n",
      "\n",
      "         [[ 2.6012e-02]],\n",
      "\n",
      "         [[ 1.5169e-01]],\n",
      "\n",
      "         [[ 1.3317e-01]],\n",
      "\n",
      "         [[-8.7142e-02]],\n",
      "\n",
      "         [[-3.6491e-02]],\n",
      "\n",
      "         [[-1.2440e-01]],\n",
      "\n",
      "         [[ 7.2109e-02]],\n",
      "\n",
      "         [[ 1.9193e-01]],\n",
      "\n",
      "         [[ 1.1588e-01]],\n",
      "\n",
      "         [[ 6.2321e-02]],\n",
      "\n",
      "         [[ 7.2452e-02]],\n",
      "\n",
      "         [[-1.0225e-01]],\n",
      "\n",
      "         [[ 4.0971e-02]],\n",
      "\n",
      "         [[ 9.5298e-02]],\n",
      "\n",
      "         [[ 1.7092e-01]],\n",
      "\n",
      "         [[ 7.3937e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.7226e-02]],\n",
      "\n",
      "         [[-1.3617e-01]],\n",
      "\n",
      "         [[-1.3446e-01]],\n",
      "\n",
      "         [[-7.9394e-02]],\n",
      "\n",
      "         [[ 2.0086e-01]],\n",
      "\n",
      "         [[ 1.0053e-01]],\n",
      "\n",
      "         [[ 1.6764e-01]],\n",
      "\n",
      "         [[-1.3762e-01]],\n",
      "\n",
      "         [[ 1.9818e-01]],\n",
      "\n",
      "         [[ 1.0349e-01]],\n",
      "\n",
      "         [[ 1.2706e-01]],\n",
      "\n",
      "         [[-1.1532e-01]],\n",
      "\n",
      "         [[-7.8103e-02]],\n",
      "\n",
      "         [[-6.4883e-03]],\n",
      "\n",
      "         [[-6.4905e-02]],\n",
      "\n",
      "         [[ 8.9137e-02]],\n",
      "\n",
      "         [[ 3.3849e-02]],\n",
      "\n",
      "         [[-1.3362e-01]],\n",
      "\n",
      "         [[-9.8804e-02]],\n",
      "\n",
      "         [[ 7.4277e-02]],\n",
      "\n",
      "         [[-1.5854e-01]],\n",
      "\n",
      "         [[-7.3359e-02]],\n",
      "\n",
      "         [[-1.4223e-01]],\n",
      "\n",
      "         [[-1.3022e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4172e-01]],\n",
      "\n",
      "         [[ 1.5101e-01]],\n",
      "\n",
      "         [[ 1.5352e-01]],\n",
      "\n",
      "         [[ 1.0569e-01]],\n",
      "\n",
      "         [[ 1.3566e-02]],\n",
      "\n",
      "         [[ 1.3395e-01]],\n",
      "\n",
      "         [[ 9.3610e-02]],\n",
      "\n",
      "         [[ 1.1719e-01]],\n",
      "\n",
      "         [[ 6.8716e-02]],\n",
      "\n",
      "         [[-1.5764e-01]],\n",
      "\n",
      "         [[-1.6078e-01]],\n",
      "\n",
      "         [[-7.3668e-02]],\n",
      "\n",
      "         [[-2.8226e-02]],\n",
      "\n",
      "         [[-1.3817e-01]],\n",
      "\n",
      "         [[ 5.5261e-02]],\n",
      "\n",
      "         [[-7.1453e-02]],\n",
      "\n",
      "         [[ 1.6579e-01]],\n",
      "\n",
      "         [[ 1.8849e-01]],\n",
      "\n",
      "         [[ 1.2661e-01]],\n",
      "\n",
      "         [[ 1.2077e-01]],\n",
      "\n",
      "         [[ 1.3242e-01]],\n",
      "\n",
      "         [[ 3.0680e-02]],\n",
      "\n",
      "         [[ 2.4421e-02]],\n",
      "\n",
      "         [[ 1.0507e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6846e-01]],\n",
      "\n",
      "         [[-2.5114e-03]],\n",
      "\n",
      "         [[ 1.1126e-01]],\n",
      "\n",
      "         [[ 1.4521e-01]],\n",
      "\n",
      "         [[ 1.9772e-01]],\n",
      "\n",
      "         [[-8.1195e-02]],\n",
      "\n",
      "         [[-1.8329e-01]],\n",
      "\n",
      "         [[-8.5495e-02]],\n",
      "\n",
      "         [[ 7.0332e-02]],\n",
      "\n",
      "         [[ 1.5195e-01]],\n",
      "\n",
      "         [[-2.5280e-02]],\n",
      "\n",
      "         [[-1.4934e-01]],\n",
      "\n",
      "         [[ 5.3231e-02]],\n",
      "\n",
      "         [[ 1.4785e-01]],\n",
      "\n",
      "         [[-7.7007e-02]],\n",
      "\n",
      "         [[ 2.1269e-02]],\n",
      "\n",
      "         [[-6.3518e-02]],\n",
      "\n",
      "         [[-3.0126e-02]],\n",
      "\n",
      "         [[ 1.6637e-01]],\n",
      "\n",
      "         [[-1.5066e-01]],\n",
      "\n",
      "         [[-1.7935e-01]],\n",
      "\n",
      "         [[ 1.9763e-01]],\n",
      "\n",
      "         [[-1.1697e-01]],\n",
      "\n",
      "         [[-3.8314e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9376e-01]],\n",
      "\n",
      "         [[ 8.9301e-02]],\n",
      "\n",
      "         [[-2.3959e-02]],\n",
      "\n",
      "         [[ 6.3351e-02]],\n",
      "\n",
      "         [[-1.9747e-01]],\n",
      "\n",
      "         [[ 9.9611e-02]],\n",
      "\n",
      "         [[ 1.7311e-01]],\n",
      "\n",
      "         [[ 1.4031e-01]],\n",
      "\n",
      "         [[-1.9468e-01]],\n",
      "\n",
      "         [[-1.2508e-01]],\n",
      "\n",
      "         [[-6.6888e-02]],\n",
      "\n",
      "         [[ 1.9471e-01]],\n",
      "\n",
      "         [[-4.9076e-02]],\n",
      "\n",
      "         [[-1.9159e-01]],\n",
      "\n",
      "         [[ 1.1882e-02]],\n",
      "\n",
      "         [[ 1.6892e-01]],\n",
      "\n",
      "         [[-1.6385e-01]],\n",
      "\n",
      "         [[-1.3179e-01]],\n",
      "\n",
      "         [[ 3.4961e-02]],\n",
      "\n",
      "         [[ 8.9001e-02]],\n",
      "\n",
      "         [[-3.0549e-02]],\n",
      "\n",
      "         [[ 1.7735e-01]],\n",
      "\n",
      "         [[-1.6414e-01]],\n",
      "\n",
      "         [[ 1.1665e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2640e-01]],\n",
      "\n",
      "         [[ 5.0565e-02]],\n",
      "\n",
      "         [[ 1.5293e-01]],\n",
      "\n",
      "         [[-2.6703e-02]],\n",
      "\n",
      "         [[-6.2498e-02]],\n",
      "\n",
      "         [[-1.2526e-01]],\n",
      "\n",
      "         [[-8.7396e-02]],\n",
      "\n",
      "         [[ 7.4444e-02]],\n",
      "\n",
      "         [[ 7.8349e-02]],\n",
      "\n",
      "         [[ 1.8705e-01]],\n",
      "\n",
      "         [[ 1.1709e-02]],\n",
      "\n",
      "         [[-1.7838e-01]],\n",
      "\n",
      "         [[-1.3882e-01]],\n",
      "\n",
      "         [[-9.4618e-02]],\n",
      "\n",
      "         [[-8.5297e-02]],\n",
      "\n",
      "         [[-2.0283e-01]],\n",
      "\n",
      "         [[ 1.2926e-02]],\n",
      "\n",
      "         [[ 1.3731e-01]],\n",
      "\n",
      "         [[ 1.1439e-01]],\n",
      "\n",
      "         [[-1.5972e-01]],\n",
      "\n",
      "         [[ 6.7774e-02]],\n",
      "\n",
      "         [[-1.7313e-01]],\n",
      "\n",
      "         [[ 1.5271e-02]],\n",
      "\n",
      "         [[ 1.8214e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9270e-02]],\n",
      "\n",
      "         [[ 4.4087e-02]],\n",
      "\n",
      "         [[ 1.3633e-01]],\n",
      "\n",
      "         [[-1.7450e-01]],\n",
      "\n",
      "         [[-1.0189e-01]],\n",
      "\n",
      "         [[-8.5397e-02]],\n",
      "\n",
      "         [[ 7.2323e-02]],\n",
      "\n",
      "         [[-7.5996e-02]],\n",
      "\n",
      "         [[-1.8029e-01]],\n",
      "\n",
      "         [[ 8.6935e-02]],\n",
      "\n",
      "         [[ 1.8856e-01]],\n",
      "\n",
      "         [[ 5.1325e-02]],\n",
      "\n",
      "         [[ 1.2391e-01]],\n",
      "\n",
      "         [[-1.7909e-01]],\n",
      "\n",
      "         [[-4.3489e-02]],\n",
      "\n",
      "         [[ 4.4116e-02]],\n",
      "\n",
      "         [[-2.8073e-02]],\n",
      "\n",
      "         [[-1.9047e-01]],\n",
      "\n",
      "         [[-3.8508e-02]],\n",
      "\n",
      "         [[-8.8658e-03]],\n",
      "\n",
      "         [[ 1.9847e-01]],\n",
      "\n",
      "         [[ 8.3517e-02]],\n",
      "\n",
      "         [[-1.0842e-01]],\n",
      "\n",
      "         [[ 1.8327e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9146e-01]],\n",
      "\n",
      "         [[ 1.7566e-01]],\n",
      "\n",
      "         [[ 1.4390e-01]],\n",
      "\n",
      "         [[-1.7143e-01]],\n",
      "\n",
      "         [[-1.5220e-01]],\n",
      "\n",
      "         [[ 1.6096e-02]],\n",
      "\n",
      "         [[-3.4754e-02]],\n",
      "\n",
      "         [[-1.9926e-01]],\n",
      "\n",
      "         [[-3.4814e-02]],\n",
      "\n",
      "         [[-1.9707e-01]],\n",
      "\n",
      "         [[ 1.3655e-01]],\n",
      "\n",
      "         [[-1.8221e-01]],\n",
      "\n",
      "         [[-4.6484e-02]],\n",
      "\n",
      "         [[ 1.9841e-01]],\n",
      "\n",
      "         [[-1.7605e-01]],\n",
      "\n",
      "         [[ 2.0064e-01]],\n",
      "\n",
      "         [[ 3.8975e-02]],\n",
      "\n",
      "         [[ 1.3181e-01]],\n",
      "\n",
      "         [[-9.2593e-03]],\n",
      "\n",
      "         [[-1.0585e-01]],\n",
      "\n",
      "         [[ 9.8224e-02]],\n",
      "\n",
      "         [[-1.3241e-01]],\n",
      "\n",
      "         [[-1.5886e-01]],\n",
      "\n",
      "         [[-4.2268e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6329e-01]],\n",
      "\n",
      "         [[-1.8643e-01]],\n",
      "\n",
      "         [[-1.8230e-01]],\n",
      "\n",
      "         [[-1.6476e-01]],\n",
      "\n",
      "         [[-5.0401e-02]],\n",
      "\n",
      "         [[-4.6840e-02]],\n",
      "\n",
      "         [[-6.8513e-03]],\n",
      "\n",
      "         [[ 1.8856e-01]],\n",
      "\n",
      "         [[-7.8069e-02]],\n",
      "\n",
      "         [[ 1.8669e-01]],\n",
      "\n",
      "         [[ 5.0339e-02]],\n",
      "\n",
      "         [[ 5.9359e-02]],\n",
      "\n",
      "         [[ 1.3981e-01]],\n",
      "\n",
      "         [[-4.1828e-02]],\n",
      "\n",
      "         [[ 7.4195e-02]],\n",
      "\n",
      "         [[ 1.3544e-01]],\n",
      "\n",
      "         [[-1.6067e-01]],\n",
      "\n",
      "         [[-1.4331e-01]],\n",
      "\n",
      "         [[-1.3927e-01]],\n",
      "\n",
      "         [[ 2.4604e-02]],\n",
      "\n",
      "         [[-9.9148e-02]],\n",
      "\n",
      "         [[ 1.4487e-01]],\n",
      "\n",
      "         [[ 1.0625e-01]],\n",
      "\n",
      "         [[ 1.0565e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4881e-01]],\n",
      "\n",
      "         [[-1.8334e-01]],\n",
      "\n",
      "         [[-1.0060e-01]],\n",
      "\n",
      "         [[-1.1945e-01]],\n",
      "\n",
      "         [[-1.6794e-01]],\n",
      "\n",
      "         [[-3.4891e-02]],\n",
      "\n",
      "         [[-1.9823e-01]],\n",
      "\n",
      "         [[-6.0000e-02]],\n",
      "\n",
      "         [[-5.5630e-02]],\n",
      "\n",
      "         [[ 1.3377e-02]],\n",
      "\n",
      "         [[ 1.4605e-01]],\n",
      "\n",
      "         [[-1.9346e-01]],\n",
      "\n",
      "         [[ 6.7937e-04]],\n",
      "\n",
      "         [[-1.7105e-01]],\n",
      "\n",
      "         [[-2.0329e-01]],\n",
      "\n",
      "         [[ 5.2467e-02]],\n",
      "\n",
      "         [[-1.4349e-01]],\n",
      "\n",
      "         [[-6.5232e-02]],\n",
      "\n",
      "         [[-4.7069e-02]],\n",
      "\n",
      "         [[ 4.0522e-02]],\n",
      "\n",
      "         [[ 2.0273e-02]],\n",
      "\n",
      "         [[-1.0501e-01]],\n",
      "\n",
      "         [[ 7.2637e-02]],\n",
      "\n",
      "         [[ 6.7424e-02]]]])\n",
      "Shape: torch.Size([16, 24, 1, 1]), std: 0.1212, mean: -0.0012\n",
      "\n",
      "prediction.critic.conv_layers.conv_layers.0.bias:\n",
      "tensor([ 0.0419,  0.0476,  0.1832, -0.0356,  0.1025, -0.1097,  0.1838, -0.1540,\n",
      "         0.0794, -0.1333,  0.1597, -0.1487,  0.1303,  0.0842, -0.1687, -0.1235])\n",
      "Shape: torch.Size([16]), std: 0.1309, mean: 0.0087\n",
      "\n",
      "prediction.critic.value.layer.weight:\n",
      "tensor([[ 0.0290, -0.0749,  0.0756, -0.0267,  0.0766, -0.0347,  0.0498,  0.0267,\n",
      "         -0.0545,  0.0596, -0.0073,  0.0598, -0.0646,  0.0266,  0.0541,  0.0113,\n",
      "          0.0175, -0.0324, -0.0806,  0.0444, -0.0791, -0.0675, -0.0081, -0.0612,\n",
      "          0.0324,  0.0334,  0.0770,  0.0137, -0.0542,  0.0032, -0.0107, -0.0176,\n",
      "         -0.0390, -0.0645,  0.0490,  0.0030, -0.0452, -0.0072,  0.0084,  0.0627,\n",
      "          0.0599,  0.0755, -0.0487, -0.0701, -0.0793,  0.0072, -0.0824, -0.0756,\n",
      "         -0.0559,  0.0459, -0.0202, -0.0675, -0.0466, -0.0188, -0.0787,  0.0006,\n",
      "         -0.0073, -0.0766, -0.0349,  0.0609, -0.0676,  0.0040, -0.0198,  0.0675,\n",
      "          0.0683, -0.0617, -0.0104,  0.0226,  0.0673, -0.0697,  0.0644, -0.0165,\n",
      "         -0.0343,  0.0749, -0.0469,  0.0367,  0.0116,  0.0438, -0.0001, -0.0074,\n",
      "          0.0134, -0.0457, -0.0591,  0.0802, -0.0673, -0.0098,  0.0434, -0.0351,\n",
      "         -0.0341, -0.0290, -0.0748, -0.0547, -0.0003,  0.0196, -0.0482, -0.0308,\n",
      "          0.0749, -0.0496, -0.0780,  0.0472, -0.0606,  0.0610,  0.0426,  0.0354,\n",
      "         -0.0744, -0.0329,  0.0815,  0.0278, -0.0367,  0.0578,  0.0369, -0.0579,\n",
      "          0.0030, -0.0078,  0.0492, -0.0586,  0.0175,  0.0728,  0.0712,  0.0546,\n",
      "          0.0198, -0.0500,  0.0738, -0.0374,  0.0778,  0.0557,  0.0148, -0.0288,\n",
      "         -0.0379, -0.0406, -0.0208, -0.0082,  0.0515, -0.0169, -0.0452, -0.0775,\n",
      "          0.0738,  0.0566,  0.0727,  0.0001,  0.0318,  0.0646, -0.0271,  0.0227]])\n",
      "Shape: torch.Size([1, 144]), std: 0.0502, mean: -0.0016\n",
      "\n",
      "prediction.critic.value.layer.bias:\n",
      "tensor([0.0542])\n",
      "Shape: torch.Size([1]), std: nan, mean: 0.0542\n",
      "\n",
      "prediction.actor.conv_layers.conv_layers.0.weight:\n",
      "tensor([[[[ 0.0802]],\n",
      "\n",
      "         [[-0.2018]],\n",
      "\n",
      "         [[-0.1339]],\n",
      "\n",
      "         [[ 0.0017]],\n",
      "\n",
      "         [[-0.0835]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         [[-0.0968]],\n",
      "\n",
      "         [[ 0.1101]],\n",
      "\n",
      "         [[-0.0255]],\n",
      "\n",
      "         [[ 0.0573]],\n",
      "\n",
      "         [[-0.1658]],\n",
      "\n",
      "         [[-0.0786]],\n",
      "\n",
      "         [[ 0.1097]],\n",
      "\n",
      "         [[ 0.0316]],\n",
      "\n",
      "         [[-0.1528]],\n",
      "\n",
      "         [[ 0.1310]],\n",
      "\n",
      "         [[ 0.0592]],\n",
      "\n",
      "         [[ 0.1079]],\n",
      "\n",
      "         [[ 0.1942]],\n",
      "\n",
      "         [[ 0.1251]],\n",
      "\n",
      "         [[-0.0942]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[ 0.1746]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0389]],\n",
      "\n",
      "         [[-0.1234]],\n",
      "\n",
      "         [[-0.0941]],\n",
      "\n",
      "         [[-0.1749]],\n",
      "\n",
      "         [[-0.1210]],\n",
      "\n",
      "         [[-0.0755]],\n",
      "\n",
      "         [[-0.0642]],\n",
      "\n",
      "         [[ 0.1481]],\n",
      "\n",
      "         [[ 0.1032]],\n",
      "\n",
      "         [[ 0.0928]],\n",
      "\n",
      "         [[-0.0006]],\n",
      "\n",
      "         [[ 0.0052]],\n",
      "\n",
      "         [[-0.1432]],\n",
      "\n",
      "         [[ 0.1282]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         [[-0.0518]],\n",
      "\n",
      "         [[ 0.0695]],\n",
      "\n",
      "         [[-0.1424]],\n",
      "\n",
      "         [[-0.1711]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         [[-0.1638]],\n",
      "\n",
      "         [[-0.0270]],\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         [[ 0.1230]]],\n",
      "\n",
      "\n",
      "        [[[-0.0928]],\n",
      "\n",
      "         [[ 0.0597]],\n",
      "\n",
      "         [[-0.1186]],\n",
      "\n",
      "         [[-0.0088]],\n",
      "\n",
      "         [[-0.1988]],\n",
      "\n",
      "         [[-0.1613]],\n",
      "\n",
      "         [[-0.1137]],\n",
      "\n",
      "         [[ 0.0188]],\n",
      "\n",
      "         [[-0.1229]],\n",
      "\n",
      "         [[-0.1509]],\n",
      "\n",
      "         [[ 0.0747]],\n",
      "\n",
      "         [[-0.1997]],\n",
      "\n",
      "         [[ 0.1590]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         [[-0.0295]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[ 0.0810]],\n",
      "\n",
      "         [[-0.0941]],\n",
      "\n",
      "         [[ 0.1746]],\n",
      "\n",
      "         [[-0.0358]],\n",
      "\n",
      "         [[ 0.0586]],\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[-0.1181]],\n",
      "\n",
      "         [[-0.0365]]],\n",
      "\n",
      "\n",
      "        [[[-0.0643]],\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.1389]],\n",
      "\n",
      "         [[-0.1697]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         [[-0.1873]],\n",
      "\n",
      "         [[ 0.1785]],\n",
      "\n",
      "         [[-0.1948]],\n",
      "\n",
      "         [[ 0.0714]],\n",
      "\n",
      "         [[ 0.0933]],\n",
      "\n",
      "         [[ 0.1942]],\n",
      "\n",
      "         [[ 0.0817]],\n",
      "\n",
      "         [[ 0.0375]],\n",
      "\n",
      "         [[-0.1658]],\n",
      "\n",
      "         [[ 0.1089]],\n",
      "\n",
      "         [[-0.1427]],\n",
      "\n",
      "         [[-0.1868]],\n",
      "\n",
      "         [[-0.0613]],\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[ 0.1991]],\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         [[ 0.0485]],\n",
      "\n",
      "         [[-0.0503]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2010]],\n",
      "\n",
      "         [[-0.0718]],\n",
      "\n",
      "         [[ 0.0889]],\n",
      "\n",
      "         [[ 0.0472]],\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[-0.1930]],\n",
      "\n",
      "         [[ 0.1331]],\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         [[ 0.1663]],\n",
      "\n",
      "         [[ 0.1090]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.1596]],\n",
      "\n",
      "         [[-0.0607]],\n",
      "\n",
      "         [[-0.0316]],\n",
      "\n",
      "         [[ 0.0423]],\n",
      "\n",
      "         [[-0.0512]],\n",
      "\n",
      "         [[ 0.0482]],\n",
      "\n",
      "         [[-0.1222]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[ 0.1133]],\n",
      "\n",
      "         [[-0.1429]],\n",
      "\n",
      "         [[-0.1595]],\n",
      "\n",
      "         [[ 0.1609]],\n",
      "\n",
      "         [[ 0.1097]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1042]],\n",
      "\n",
      "         [[ 0.0994]],\n",
      "\n",
      "         [[ 0.1214]],\n",
      "\n",
      "         [[-0.0402]],\n",
      "\n",
      "         [[ 0.0218]],\n",
      "\n",
      "         [[ 0.0295]],\n",
      "\n",
      "         [[-0.1436]],\n",
      "\n",
      "         [[-0.0172]],\n",
      "\n",
      "         [[ 0.0624]],\n",
      "\n",
      "         [[ 0.1200]],\n",
      "\n",
      "         [[ 0.0694]],\n",
      "\n",
      "         [[-0.1404]],\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         [[-0.1186]],\n",
      "\n",
      "         [[ 0.1939]],\n",
      "\n",
      "         [[-0.2013]],\n",
      "\n",
      "         [[-0.1199]],\n",
      "\n",
      "         [[ 0.0701]],\n",
      "\n",
      "         [[ 0.0199]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[-0.1714]],\n",
      "\n",
      "         [[-0.1816]],\n",
      "\n",
      "         [[ 0.0896]]],\n",
      "\n",
      "\n",
      "        [[[-0.0218]],\n",
      "\n",
      "         [[ 0.0211]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         [[-0.0283]],\n",
      "\n",
      "         [[ 0.0560]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         [[-0.0165]],\n",
      "\n",
      "         [[-0.1180]],\n",
      "\n",
      "         [[-0.0923]],\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.1763]],\n",
      "\n",
      "         [[-0.0978]],\n",
      "\n",
      "         [[ 0.1950]],\n",
      "\n",
      "         [[-0.0494]],\n",
      "\n",
      "         [[ 0.0674]],\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[ 0.0060]],\n",
      "\n",
      "         [[ 0.1939]],\n",
      "\n",
      "         [[ 0.0973]],\n",
      "\n",
      "         [[ 0.0595]],\n",
      "\n",
      "         [[-0.0273]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         [[-0.1063]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1266]],\n",
      "\n",
      "         [[-0.0784]],\n",
      "\n",
      "         [[-0.0879]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[ 0.0975]],\n",
      "\n",
      "         [[ 0.0571]],\n",
      "\n",
      "         [[ 0.0960]],\n",
      "\n",
      "         [[ 0.0172]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         [[-0.1766]],\n",
      "\n",
      "         [[-0.0775]],\n",
      "\n",
      "         [[-0.1150]],\n",
      "\n",
      "         [[ 0.1772]],\n",
      "\n",
      "         [[ 0.0282]],\n",
      "\n",
      "         [[ 0.1437]],\n",
      "\n",
      "         [[ 0.1244]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         [[ 0.1744]],\n",
      "\n",
      "         [[-0.0793]],\n",
      "\n",
      "         [[ 0.1283]],\n",
      "\n",
      "         [[-0.0348]],\n",
      "\n",
      "         [[ 0.1608]],\n",
      "\n",
      "         [[-0.0232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1227]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[ 0.0939]],\n",
      "\n",
      "         [[ 0.0830]],\n",
      "\n",
      "         [[ 0.1937]],\n",
      "\n",
      "         [[ 0.1522]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         [[-0.0538]],\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[ 0.0788]],\n",
      "\n",
      "         [[-0.1439]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[-0.0104]],\n",
      "\n",
      "         [[-0.1235]],\n",
      "\n",
      "         [[ 0.1180]],\n",
      "\n",
      "         [[ 0.1904]],\n",
      "\n",
      "         [[ 0.0393]],\n",
      "\n",
      "         [[-0.0407]],\n",
      "\n",
      "         [[-0.0359]],\n",
      "\n",
      "         [[-0.2024]],\n",
      "\n",
      "         [[-0.1748]],\n",
      "\n",
      "         [[-0.1709]],\n",
      "\n",
      "         [[ 0.0790]],\n",
      "\n",
      "         [[-0.1718]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1701]],\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[ 0.1825]],\n",
      "\n",
      "         [[ 0.1558]],\n",
      "\n",
      "         [[-0.0473]],\n",
      "\n",
      "         [[-0.1375]],\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[ 0.1658]],\n",
      "\n",
      "         [[-0.0506]],\n",
      "\n",
      "         [[ 0.0796]],\n",
      "\n",
      "         [[-0.1630]],\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[-0.0893]],\n",
      "\n",
      "         [[ 0.1660]],\n",
      "\n",
      "         [[-0.1127]],\n",
      "\n",
      "         [[-0.0866]],\n",
      "\n",
      "         [[ 0.1614]],\n",
      "\n",
      "         [[ 0.1349]],\n",
      "\n",
      "         [[-0.0985]],\n",
      "\n",
      "         [[ 0.1584]],\n",
      "\n",
      "         [[-0.0122]],\n",
      "\n",
      "         [[ 0.0476]],\n",
      "\n",
      "         [[ 0.1756]],\n",
      "\n",
      "         [[-0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1159]],\n",
      "\n",
      "         [[ 0.0517]],\n",
      "\n",
      "         [[ 0.0689]],\n",
      "\n",
      "         [[ 0.0712]],\n",
      "\n",
      "         [[-0.1190]],\n",
      "\n",
      "         [[-0.1986]],\n",
      "\n",
      "         [[ 0.1392]],\n",
      "\n",
      "         [[-0.0671]],\n",
      "\n",
      "         [[ 0.0802]],\n",
      "\n",
      "         [[ 0.1280]],\n",
      "\n",
      "         [[-0.1190]],\n",
      "\n",
      "         [[-0.0829]],\n",
      "\n",
      "         [[-0.1559]],\n",
      "\n",
      "         [[-0.0826]],\n",
      "\n",
      "         [[ 0.1699]],\n",
      "\n",
      "         [[-0.0725]],\n",
      "\n",
      "         [[ 0.0603]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[-0.0723]],\n",
      "\n",
      "         [[-0.0433]],\n",
      "\n",
      "         [[-0.1826]],\n",
      "\n",
      "         [[-0.0796]],\n",
      "\n",
      "         [[ 0.1544]],\n",
      "\n",
      "         [[-0.1365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0211]],\n",
      "\n",
      "         [[-0.0364]],\n",
      "\n",
      "         [[-0.1852]],\n",
      "\n",
      "         [[-0.0511]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         [[-0.1130]],\n",
      "\n",
      "         [[ 0.1788]],\n",
      "\n",
      "         [[-0.0456]],\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[-0.1982]],\n",
      "\n",
      "         [[ 0.1887]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         [[ 0.0362]],\n",
      "\n",
      "         [[ 0.0826]],\n",
      "\n",
      "         [[ 0.1765]],\n",
      "\n",
      "         [[ 0.1469]],\n",
      "\n",
      "         [[ 0.1314]],\n",
      "\n",
      "         [[ 0.1610]],\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[ 0.1498]],\n",
      "\n",
      "         [[ 0.1014]],\n",
      "\n",
      "         [[ 0.1593]],\n",
      "\n",
      "         [[-0.2027]],\n",
      "\n",
      "         [[ 0.0646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721]],\n",
      "\n",
      "         [[ 0.0640]],\n",
      "\n",
      "         [[-0.0451]],\n",
      "\n",
      "         [[ 0.0528]],\n",
      "\n",
      "         [[-0.1052]],\n",
      "\n",
      "         [[ 0.1984]],\n",
      "\n",
      "         [[ 0.1337]],\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[ 0.0516]],\n",
      "\n",
      "         [[ 0.1370]],\n",
      "\n",
      "         [[-0.1751]],\n",
      "\n",
      "         [[-0.0754]],\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[-0.0306]],\n",
      "\n",
      "         [[ 0.1452]],\n",
      "\n",
      "         [[-0.0785]],\n",
      "\n",
      "         [[-0.0757]],\n",
      "\n",
      "         [[-0.0874]],\n",
      "\n",
      "         [[ 0.1275]],\n",
      "\n",
      "         [[-0.1660]],\n",
      "\n",
      "         [[ 0.0530]],\n",
      "\n",
      "         [[-0.1597]],\n",
      "\n",
      "         [[ 0.0999]],\n",
      "\n",
      "         [[-0.1259]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1877]],\n",
      "\n",
      "         [[ 0.0748]],\n",
      "\n",
      "         [[-0.2025]],\n",
      "\n",
      "         [[-0.0677]],\n",
      "\n",
      "         [[ 0.0656]],\n",
      "\n",
      "         [[-0.0922]],\n",
      "\n",
      "         [[ 0.0434]],\n",
      "\n",
      "         [[ 0.0534]],\n",
      "\n",
      "         [[-0.0886]],\n",
      "\n",
      "         [[ 0.1632]],\n",
      "\n",
      "         [[ 0.0226]],\n",
      "\n",
      "         [[ 0.1855]],\n",
      "\n",
      "         [[ 0.1506]],\n",
      "\n",
      "         [[-0.0685]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[-0.1853]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[ 0.1127]],\n",
      "\n",
      "         [[ 0.0922]],\n",
      "\n",
      "         [[-0.1131]],\n",
      "\n",
      "         [[-0.0902]],\n",
      "\n",
      "         [[ 0.1303]],\n",
      "\n",
      "         [[-0.1316]],\n",
      "\n",
      "         [[ 0.1516]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0896]],\n",
      "\n",
      "         [[ 0.1646]],\n",
      "\n",
      "         [[ 0.1869]],\n",
      "\n",
      "         [[-0.1251]],\n",
      "\n",
      "         [[ 0.0318]],\n",
      "\n",
      "         [[-0.1489]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.1864]],\n",
      "\n",
      "         [[-0.1810]],\n",
      "\n",
      "         [[-0.1160]],\n",
      "\n",
      "         [[ 0.1360]],\n",
      "\n",
      "         [[ 0.0872]],\n",
      "\n",
      "         [[-0.0940]],\n",
      "\n",
      "         [[-0.0158]],\n",
      "\n",
      "         [[-0.1978]],\n",
      "\n",
      "         [[ 0.1012]],\n",
      "\n",
      "         [[-0.1205]],\n",
      "\n",
      "         [[ 0.0964]],\n",
      "\n",
      "         [[-0.0901]],\n",
      "\n",
      "         [[ 0.1053]],\n",
      "\n",
      "         [[-0.0737]],\n",
      "\n",
      "         [[ 0.1239]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         [[ 0.1487]]],\n",
      "\n",
      "\n",
      "        [[[-0.0139]],\n",
      "\n",
      "         [[-0.0911]],\n",
      "\n",
      "         [[-0.0560]],\n",
      "\n",
      "         [[-0.0569]],\n",
      "\n",
      "         [[ 0.0164]],\n",
      "\n",
      "         [[-0.1735]],\n",
      "\n",
      "         [[ 0.0414]],\n",
      "\n",
      "         [[ 0.1131]],\n",
      "\n",
      "         [[ 0.1758]],\n",
      "\n",
      "         [[-0.1653]],\n",
      "\n",
      "         [[ 0.1205]],\n",
      "\n",
      "         [[ 0.0970]],\n",
      "\n",
      "         [[-0.1957]],\n",
      "\n",
      "         [[-0.0995]],\n",
      "\n",
      "         [[-0.0633]],\n",
      "\n",
      "         [[-0.1991]],\n",
      "\n",
      "         [[-0.1340]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0981]],\n",
      "\n",
      "         [[ 0.0602]],\n",
      "\n",
      "         [[ 0.1704]],\n",
      "\n",
      "         [[-0.1878]],\n",
      "\n",
      "         [[ 0.1199]],\n",
      "\n",
      "         [[-0.1020]]]])\n",
      "Shape: torch.Size([16, 24, 1, 1]), std: 0.1137, mean: 0.0010\n",
      "\n",
      "prediction.actor.conv_layers.conv_layers.0.bias:\n",
      "tensor([-0.1013, -0.1253,  0.1055, -0.0411, -0.1120, -0.1417, -0.2026,  0.1803,\n",
      "        -0.1456, -0.0207,  0.1552,  0.1873,  0.0746, -0.1406,  0.0274,  0.1053])\n",
      "Shape: torch.Size([16]), std: 0.1318, mean: -0.0122\n",
      "\n",
      "prediction.actor.actions.layer.weight:\n",
      "tensor([[-0.0169,  0.0719,  0.0100,  ..., -0.0618, -0.0396, -0.0775],\n",
      "        [ 0.0539,  0.0699,  0.0507,  ..., -0.0535,  0.0769, -0.0794],\n",
      "        [-0.0681, -0.0151, -0.0533,  ...,  0.0585,  0.0176, -0.0307],\n",
      "        ...,\n",
      "        [ 0.0261,  0.0299, -0.0209,  ..., -0.0026, -0.0217,  0.0561],\n",
      "        [-0.0107,  0.0320,  0.0711,  ...,  0.0045,  0.0763, -0.0698],\n",
      "        [-0.0127,  0.0128,  0.0303,  ..., -0.0743,  0.0822, -0.0744]])\n",
      "Shape: torch.Size([9, 144]), std: 0.0481, mean: -0.0009\n",
      "\n",
      "prediction.actor.actions.layer.bias:\n",
      "tensor([ 0.0332,  0.0499,  0.0641, -0.0734,  0.0473, -0.0432,  0.0337, -0.0762,\n",
      "         0.0684])\n",
      "Shape: torch.Size([9]), std: 0.0588, mean: 0.0115\n",
      "\n",
      "Warning: for board games it is recommnded to have n_step >= game length\n",
      "Max size: 100000\n",
      "Initializing stat 'score' with subkeys None\n",
      "Initializing stat 'policy_loss' with subkeys None\n",
      "Initializing stat 'value_loss' with subkeys None\n",
      "Initializing stat 'reward_loss' with subkeys None\n",
      "Initializing stat 'loss' with subkeys None\n",
      "Initializing stat 'test_score' with subkeys ['score', 'max_score', 'min_score']\n",
      "Initializing stat 'test_score_vs_random' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
      "Initializing stat 'test_score_vs_tictactoe_expert' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
      "  f\"Shape: {param.shape}, std: {param.std():.4f}, mean: {param.mean():.4f}\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Worker 1] Starting self-play...\n",
      "[Worker 0] Starting self-play...\n",
      "Buffer size: 6\n",
      "Buffer size: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-169:\n",
      "Process Process-170:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 219, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 703, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 639, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 376, in monte_carlo_tree_search\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 48, in select_child\n",
      "    child_ucbs = [\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 49, in <listcomp>\n",
      "    self.child_ucb_score(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_mcts.py\", line 64, in child_ucb_score\n",
      "    pb_c = log((self.visits + pb_c_base + 1) / pb_c_base) + pb_c_init\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 219, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 703, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 639, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 388, in monte_carlo_tree_search\n",
      "    self.predict_single_recurrent_inference(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py\", line 625, in predict_single_recurrent_inference\n",
      "    reward, hidden_state, value, policy = self.model.recurrent_inference(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_network.py\", line 810, in recurrent_inference\n",
      "    value, policy = self.prediction(hidden_state)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_network.py\", line 533, in forward\n",
      "    S = self.residual_layers(S)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/residual.py\", line 63, in forward\n",
      "    x = self.activation(layer(x))\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../modules/residual.py\", line 153, in forward\n",
      "    x = self.conv2(x)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 548, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 543, in _conv_forward\n",
      "    return F.conv2d(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo saved Trials! Starting from scratch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarl_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Objective Function to optimize\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Hyperparameter's Search Space\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optimization algorithm (representative TPE)\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of optimization attempts\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Record the results\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# early_stop_fn=no_progress_loss(5, 1),\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_trials.p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints_to_evaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_best_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(best)\n\u001b[1;32m     73\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m space_eval(search_space, best)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../hyperparameter_optimization/hyperopt.py:193\u001b[0m, in \u001b[0;36mmarl_objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplay_buffer_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_replay_buffer_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# score = run_training([params, env, name])\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmarl_run_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    195\u001b[0m     status \u001b[38;5;241m=\u001b[39m STATUS_FAIL\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../hyperparameter_optimization/hyperopt.py:105\u001b[0m, in \u001b[0;36mmarl_run_training\u001b[0;34m(params, agent_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_interval \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtest_interval\n\u001b[1;32m    103\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_trials \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtest_trials\n\u001b[0;32m--> 105\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39meval_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elo_evaulation(agent)\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/tictactoe_muzero_nfsp/../../muzero/muzero_agent_torch.py:247\u001b[0m, in \u001b[0;36mMuZeroAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtraining_steps:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43merror_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    248\u001b[0m             err, tb \u001b[38;5;241m=\u001b[39m error_queue\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;66;03m# Stop all workers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py:129\u001b[0m, in \u001b[0;36mQueue.empty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mempty\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "from agents.random import RandomAgent\n",
    "from hyperparameter_optimization.hyperopt import (\n",
    "    marl_objective,\n",
    "    set_marl_config,\n",
    "    MarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import atpe, tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from game_configs import TicTacToeConfig\n",
    "from agents.tictactoe_expert import TicTacToeBestAgent\n",
    "\n",
    "search_space_path, initial_best_config_path = (\n",
    "    \"search_space.pkl\",\n",
    "    \"best_config.pkl\",\n",
    ")\n",
    "# search_space = pickle.load(open(search_space_path, \"rb\"))\n",
    "# initial_best_config = pickle.load(open(initial_best_config_path, \"rb\"))\n",
    "file_name = \"tictactoe_muzero\"\n",
    "max_trials = 64\n",
    "trials_step = 24  # how many additional trials to do after loading the last ones\n",
    "\n",
    "set_marl_config(\n",
    "    MarlHyperoptConfig(\n",
    "        file_name=file_name,\n",
    "        eval_method=\"test_agents_elo\",\n",
    "        best_agent=TicTacToeBestAgent(),\n",
    "        make_env=TicTacToeConfig().make_env,\n",
    "        prep_params=prep_params,\n",
    "        agent_class=MuZeroAgent,\n",
    "        agent_config=MuZeroConfig,\n",
    "        game_config=TicTacToeConfig,\n",
    "        games_per_pair=500,\n",
    "        num_opps=1,  # not used\n",
    "        table=table,  # not used\n",
    "        play_game=play_game,\n",
    "        checkpoint_interval=100,\n",
    "        test_interval=1000,\n",
    "        test_trials=200,\n",
    "        test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
    "        test_agent_weights=[1.0, 2.0],\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "try:  # try to load an already saved trials object, and increase the max\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading...\")\n",
    "    max_trials = len(trials.trials) + trials_step\n",
    "    print(\n",
    "        \"Rerunning from {} trials to {} (+{}) trials\".format(\n",
    "            len(trials.trials), max_trials, trials_step\n",
    "        )\n",
    "    )\n",
    "except:  # create a new trials object and start searching\n",
    "    print(\"No saved Trials! Starting from scratch.\")\n",
    "    trials = None\n",
    "\n",
    "best = fmin(\n",
    "    fn=marl_objective,  # Objective Function to optimize\n",
    "    space=search_space,  # Hyperparameter's Search Space\n",
    "    algo=atpe.suggest,  # Optimization algorithm (representative TPE)\n",
    "    max_evals=max_trials,  # Number of optimization attempts\n",
    "    trials=trials,  # Record the results\n",
    "    # early_stop_fn=no_progress_loss(5, 1),\n",
    "    trials_save_file=f\"./{file_name}_trials.p\",\n",
    "    points_to_evaluate=initial_best_config,\n",
    "    show_progressbar=False,\n",
    ")\n",
    "print(best)\n",
    "best_trial = space_eval(search_space, best)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f114f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparameter_optimization.hyperopt import (\n",
    "    marl_objective,\n",
    "    set_marl_config,\n",
    "    MarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from game_configs import TicTacToeConfig\n",
    "from agents.tictactoe_expert import TicTacToeBestAgent\n",
    "\n",
    "search_space_path, initial_best_config_path = (\n",
    "    \"search_space.pkl\",\n",
    "    \"best_config.pkl\",\n",
    ")\n",
    "# search_space = pickle.load(open(search_space_path, \"rb\"))\n",
    "# initial_best_config = pickle.load(open(initial_best_config_path, \"rb\"))\n",
    "file_name = \"tictactoe_muzero\"\n",
    "max_trials = 1\n",
    "trials_step = 64  # how many additional trials to do after loading the last ones\n",
    "\n",
    "set_marl_config(\n",
    "    MarlHyperoptConfig(\n",
    "        file_name=file_name,\n",
    "        eval_method=\"elo\",\n",
    "        best_agent=TicTacToeBestAgent(),\n",
    "        make_env=tictactoe_v3.env,\n",
    "        prep_params=prep_params,\n",
    "        agent_class=MuZeroAgent,\n",
    "        agent_config=MuZeroConfig,\n",
    "        game_config=TicTacToeConfig,\n",
    "        games_per_pair=100,\n",
    "        num_opps=1,  # not used\n",
    "        table=table,  # not used\n",
    "        play_game=play_game,\n",
    "        checkpoint_interval=50,\n",
    "        test_interval=250,\n",
    "        test_trials=25,\n",
    "        test_agents=[RandomAgent(), TicTacToeBestAgent()],\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "try:  # try to load an already saved trials object, and increase the max\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading...\")\n",
    "    max_trials = len(trials.trials) + 1\n",
    "    print(\n",
    "        \"Rerunning from {} trials to {} (+{}) trials\".format(\n",
    "            len(trials.trials), max_trials, trials_step\n",
    "        )\n",
    "    )\n",
    "except:  # create a new trials object and start searching\n",
    "    trials = None\n",
    "\n",
    "for i in range(trials_step):\n",
    "    try:\n",
    "        best = fmin(\n",
    "            fn=marl_objective,  # Objective Function to optimize\n",
    "            space=search_space,  # Hyperparameter's Search Space\n",
    "            algo=tpe.suggest,  # Optimization algorithm (representative TPE)\n",
    "            max_evals=max_trials,  # Number of optimization attempts\n",
    "            trials=trials,  # Record the results\n",
    "            # early_stop_fn=no_progress_loss(5, 1),\n",
    "            trials_save_file=f\"./{file_name}_trials.p\",\n",
    "            points_to_evaluate=initial_best_config,\n",
    "            show_progressbar=False,\n",
    "        )\n",
    "    except AllTrialsFailed:\n",
    "        print(\"trial failed\")\n",
    "\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading and Updating...\")\n",
    "    try:\n",
    "        elo_table = table.bayes_elo()[\"Elo table\"]\n",
    "        for trial in range(len(trials.trials)):\n",
    "            trial_elo = elo_table.iloc[trial][\"Elo\"]\n",
    "            print(f\"Trial {trials.trials[trial]['tid']} ELO: {trial_elo}\")\n",
    "            trials.trials[trial][\"result\"][\"loss\"] = -trial_elo\n",
    "            pickle.dump(trials, open(f\"./{file_name}_trials.p\", \"wb\"))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Not enough players to calculate elo.\")\n",
    "    max_trials = len(trials.trials) + 1\n",
    "    print(best)\n",
    "    best_trial = space_eval(search_space, best)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2665b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared network but not shared buffer?\n",
    "# 1 vs 2 minibatches\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dqn.NFSP.nfsp_agent_clean import NFSPDQN\n",
    "from agent_configs import NFSPDQNConfig\n",
    "from game_configs import TicTacToeConfig\n",
    "from utils import KLDivergenceLoss, CategoricalCrossentropyLoss, HuberLoss, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "config_dict = {\n",
    "    \"shared_networks_and_buffers\": False,\n",
    "    \"training_steps\": 10000,\n",
    "    \"anticipatory_param\": 0.1,\n",
    "    \"replay_interval\": 128,  #\n",
    "    \"num_minibatches\": 1,  # or 2, could be 2 minibatches per network, or 2 minibatches (1 for each network/player)\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"momentum\": 0.0,\n",
    "    \"optimizer\": SGD,\n",
    "    \"loss_function\": MSELoss(),\n",
    "    \"min_replay_buffer_size\": 128,\n",
    "    \"minibatch_size\": 128,\n",
    "    \"replay_buffer_size\": 2e5,\n",
    "    \"transfer_interval\": 300,\n",
    "    \"residual_layers\": [(128, 3, 1)] * 3,\n",
    "    \"conv_layers\": [(32, 3, 1)],\n",
    "    \"dense_layer_widths\": [],\n",
    "    \"value_hidden_layer_widths\": [],\n",
    "    \"advantage_hidden_layer_widths\": [],\n",
    "    \"noisy_sigma\": 0.0,\n",
    "    \"eg_epsilon\": 0.06,\n",
    "    # \"eg_epsilon_final\": 0.06,\n",
    "    \"eg_epsilon_decay_type\": \"inverse_sqrt\",\n",
    "    \"eg_epsilon_decay_final_step\": 0,\n",
    "    \"sl_learning_rate\": 0.005,\n",
    "    \"sl_momentum\": 0.0,\n",
    "    # \"sl_weight_decay\": 1e-9,\n",
    "    # \"sl_clipnorm\": 1.0,\n",
    "    \"sl_optimizer\": SGD,\n",
    "    \"sl_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"sl_min_replay_buffer_size\": 128,\n",
    "    \"sl_minibatch_size\": 128,\n",
    "    \"sl_replay_buffer_size\": 2000000,\n",
    "    \"sl_residual_layers\": [(128, 3, 1)] * 3,\n",
    "    \"sl_conv_layers\": [(32, 3, 1)],\n",
    "    \"sl_dense_layer_widths\": [],\n",
    "    \"sl_clip_low_prob\": 0.0,\n",
    "    \"per_alpha\": 0.0,\n",
    "    \"per_beta\": 0.0,\n",
    "    \"per_beta_final\": 0.0,\n",
    "    \"per_epsilon\": 0.00001,\n",
    "    \"n_step\": 1,\n",
    "    \"atom_size\": 1,\n",
    "    \"dueling\": False,\n",
    "    \"clipnorm\": 10.0,\n",
    "    \"sl_clipnorm\": 10.0,\n",
    "}\n",
    "config = NFSPDQNConfig(\n",
    "    config_dict=config_dict,\n",
    "    game_config=TicTacToeConfig(),\n",
    ")\n",
    "config.save_intermediate_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import tictactoe_v3\n",
    "\n",
    "env = tictactoe_v3.env(render_mode=\"rgb_array\")\n",
    "\n",
    "print(env.observation_space(\"player_0\"))\n",
    "\n",
    "agent = NFSPDQN(env, config, name=\"NFSP-TicTacToe-Standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.checkpoint_interval = 100\n",
    "agent.checkpoint_trials = 100\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443809d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared network but not shared buffer?\n",
    "# 1 vs 2 minibatches\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dqn.NFSP.nfsp_agent_clean import NFSPDQN\n",
    "from agent_configs import NFSPDQNConfig\n",
    "from game_configs import TicTacToeConfig\n",
    "from utils import KLDivergenceLoss, CategoricalCrossentropyLoss, HuberLoss, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "config_dict = {\n",
    "    \"shared_networks_and_buffers\": False,\n",
    "    \"training_steps\": 10000,\n",
    "    \"anticipatory_param\": 0.1,\n",
    "    \"replay_interval\": 128,  #\n",
    "    \"num_minibatches\": 1,  # or 2, could be 2 minibatches per network, or 2 minibatches (1 for each network/player)\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"momentum\": 0.0,\n",
    "    \"optimizer\": SGD,\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"min_replay_buffer_size\": 1000,\n",
    "    \"minibatch_size\": 128,\n",
    "    \"replay_buffer_size\": 2e5,\n",
    "    \"transfer_interval\": 300,\n",
    "    \"residual_layers\": [(128, 3, 1)] * 3,\n",
    "    \"conv_layers\": [(32, 3, 1)],\n",
    "    \"dense_layer_widths\": [],\n",
    "    \"value_hidden_layer_widths\": [],\n",
    "    \"advantage_hidden_layer_widths\": [],\n",
    "    \"noisy_sigma\": 0.06,\n",
    "    \"eg_epsilon\": 0.0,\n",
    "    # \"eg_epsilon_final\": 0.06,\n",
    "    \"eg_epsilon_decay_type\": \"inverse_sqrt\",\n",
    "    \"eg_epsilon_decay_final_step\": 0,\n",
    "    \"sl_learning_rate\": 0.005,\n",
    "    \"sl_momentum\": 0.0,\n",
    "    # \"sl_weight_decay\": 1e-9,\n",
    "    # \"sl_clipnorm\": 1.0,\n",
    "    \"sl_optimizer\": SGD,\n",
    "    \"sl_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"sl_min_replay_buffer_size\": 1000,\n",
    "    \"sl_minibatch_size\": 128,\n",
    "    \"sl_replay_buffer_size\": 2000000,\n",
    "    \"sl_residual_layers\": [(128, 3, 1)] * 3,\n",
    "    \"sl_conv_layers\": [(32, 3, 1)],\n",
    "    \"sl_dense_layer_widths\": [],\n",
    "    \"sl_clip_low_prob\": 0.0,\n",
    "    \"per_alpha\": 0.5,\n",
    "    \"per_beta\": 0.5,\n",
    "    \"per_beta_final\": 1.0,\n",
    "    \"per_epsilon\": 0.00001,\n",
    "    \"n_step\": 3,\n",
    "    \"atom_size\": 51,\n",
    "    \"dueling\": True,\n",
    "    \"clipnorm\": 10.0,\n",
    "    \"sl_clipnorm\": 10.0,\n",
    "}\n",
    "config = NFSPDQNConfig(\n",
    "    config_dict=config_dict,\n",
    "    game_config=TicTacToeConfig(),\n",
    ")\n",
    "config.save_intermediate_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import tictactoe_v3\n",
    "\n",
    "env = tictactoe_v3.env(render_mode=\"rgb_array\")\n",
    "\n",
    "print(env.observation_space(\"player_0\"))\n",
    "\n",
    "agent = NFSPDQN(env, config, name=\"NFSP-TicTacToe-Rainbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.checkpoint_interval = 100\n",
    "agent.checkpoint_trials = 100\n",
    "agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
