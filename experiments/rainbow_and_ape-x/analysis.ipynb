{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rainbow and Ape-X Expiriments \n",
    "    1. We release a set of hyper parameters for CartPole-v1 and Classic Control and Atari\n",
    "    2. We release code for Rainbow that can train X steps in Y minutes on a Mac M2 Chip\n",
    "    3. We also release a version of Ape-X as described in the original paper, and an Ape-X with rainbow\n",
    "        1. Compare results of each \n",
    "        2. Compare Ape-X with different Rainbow components added or removed\n",
    "    4. We compare the different models of DQN as seen in their papers to rainbow, the different individual components to rainbow, and rainbow with individual components removed\n",
    "    5. We graph the convergence of Hyperopt for both tensorflow and torch, we do a score/trials graph and we compare to random hyper parameters \n",
    "    6. We graph the exploration of the Hyperopt algorithm showing the difference between consecutive trials to measure when the algorithm is “confident” in its parameters\n",
    "    7. Compare search space sizes\n",
    "        1. Large all hp.choice\n",
    "        2. small/medium hp.choice\n",
    "        3. a set using hp.uniform etc \n",
    "    8. Different methods\n",
    "        1. tuning only 1 part of the system at a time and then tuning the next part, from a base set of params \n",
    "            1. DQN, then PER, then Double… \n",
    "    9. Different testing methods, like for example rolling average instead of latest test score\n",
    "    10. Compare rainbow training speeds with different levels of numerical precision and datatypes\n",
    "        1. Mixed precision using torch.amp \n",
    "        2. Lower matmul precision\n",
    "            1. comparing medium, high, and highest \n",
    "            2. https://pytorch.org/docs/master/generated/torch.set_float32_matmul_precision.html?highlight=precision#torch.set_float32_matmul_precision\n",
    "    11. Ape-X Hyper parameter sweep and sensitivities\n",
    "    12. Exploration methods for Rainbow Ape-X\n",
    "        1. Just noisy nets (same for all actors)\n",
    "        2. Noisy nets and varying epsilon \n",
    "        3. Adding a constant that changes variance of noisy nets for action selection\n",
    "        4. AlphaStar Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Parameter Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import AtariPreprocessing, FrameStack\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "from game_configs import AtariConfig, CartPoleConfig\n",
    "from agent_configs import RainbowConfig\n",
    "from utils import KLDivergence\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# env = ClipReward(AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\n",
    "# env = FrameStack(env, 4)\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "\n",
    "config_dict = {\n",
    "  \"dense_layers_widths\": [128],\n",
    "  \"value_hidden_layers_widths\": [128],\n",
    "  \"advatage_hidden_layers_widths\": [128],\n",
    "  \"adam_epsilon\": 1e-8,\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"training_steps\": 10000,\n",
    "  \"per_epsilon\": 1e-6,\n",
    "  \"per_alpha\": 0.2,\n",
    "  \"per_beta\": 0.6,\n",
    "  \"minibatch_size\": 128,\n",
    "  \"transfer_interval\": 100,\n",
    "  \"n_step\": 3,\n",
    "  \"noisy_sigma\": 0.5,\n",
    "  \"replay_interval\": 1,\n",
    "  \"kernel_initializer\": \"orthogonal\",\n",
    "  \"noisy_sigma\": 0.5,\n",
    "  \"loss_function\": KLDivergence(), # could do categorical cross entropy \n",
    "  \"clipnorm\": 10.0,\n",
    "}\n",
    "game_config = CartPoleConfig()\n",
    "config = RainbowConfig(config_dict, game_config)\n",
    "agent = RainbowAgent(env, config, name=\"baseline\")\n",
    "\n",
    "for param in agent.model.parameters():\n",
    "  print(param)\n",
    "print(\"start\")\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization of Rainbow on Cartpole-v1\n",
    "Training steps: 10,000\n",
    "Evaluation: 10 episodes from random starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt with PyTorch and TensorFlow only hp.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from hyperopt import hp\n",
    "from utils import CategoricalCrossentropy, KLDivergence, generate_layer_widths\n",
    "import gymnasium as gym \n",
    "\n",
    "width_combinations = generate_layer_widths([32, 64, 128, 256, 512, 1024], 5)\n",
    "\n",
    "search_space = {\n",
    "        \"kernel_initializer\": hp.choice(\n",
    "            \"kernel_initializer\",\n",
    "            [\n",
    "                \"he_uniform\",\n",
    "                \"he_normal\",\n",
    "                \"glorot_uniform\",\n",
    "                \"glorot_normal\",\n",
    "                \"orthogonal\",\n",
    "            ],\n",
    "        ),\n",
    "        \"learning_rate\": hp.choice(\n",
    "            \"learning_rate\", [10, 5, 2, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        ),\n",
    "        \"adam_epsilon\": hp.choice(\n",
    "            \"adam_epsilon\", [0.3125, 0.03125, 0.003125, 0.0003125]\n",
    "        ),\n",
    "        \"loss_function\": hp.choice(\n",
    "            \"loss_function\", [CategoricalCrossentropy(), KLDivergence()]\n",
    "        ),\n",
    "        # NORMALIZATION?\n",
    "        \"transfer_interval\": hp.choice(\n",
    "            \"transfer_interval\", [10, 25, 50, 100, 200, 400, 800, 1600, 2000]\n",
    "        ),\n",
    "        \"replay_interval\": hp.choice(\"replay_interval\", [1, 2, 3, 4, 5, 8, 10, 12]),\n",
    "        \"minibatch_size\": hp.choice(\n",
    "            \"minibatch_size\", [2**i for i in range(4, 8)]\n",
    "        ),  ###########\n",
    "        \"replay_buffer_size\": hp.choice(\n",
    "            \"replay_buffer_size\",\n",
    "            [2000, 3000, 5000, 7500, 10000],\n",
    "        ),  #############\n",
    "        \"min_replay_buffer_size\": hp.choice(\n",
    "            \"min_replay_buffer_size\",\n",
    "            [125, 250, 375, 500, 625, 750, 875, 1000, 1500, 2000],\n",
    "        ),  # 125, 250, 375, 500, 625, 750, 875, 1000, 1500, 2000\n",
    "        \"n_step\": hp.choice(\"n_step\", [3, 4, 5, 8, 10]),\n",
    "        \"discount_factor\": hp.choice(\"discount_factor\", [0.9, 0.99, 0.995, 0.999]),\n",
    "        \"atom_size\": hp.choice(\"atom_size\", [51, 61, 71, 81]),  #\n",
    "        \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "        \"dense_layers_widths\": hp.choice(\"dense_layers_widths\", width_combinations),\n",
    "        \"advantage_hidden_layers_widths\": hp.choice(\n",
    "            \"advantage_hidden_layers_widths\", width_combinations\n",
    "        ),  #\n",
    "        \"value_hidden_layers_widths\": hp.choice(\n",
    "            \"value_hidden_layers_widths\", width_combinations\n",
    "        ),  #\n",
    "        \"training_steps\": hp.choice(\"training_steps\", [10000]),\n",
    "        \"per_epsilon\": hp.choice(\"per_epsilon\", [0.00001, 0.0001, 0.001, 0.01, 0.1]),\n",
    "        \"per_alpha\": hp.choice(\"per_alpha\", [0.05 * i for i in range(1, 21)]),\n",
    "        \"per_beta\": hp.choice(\"per_beta\", [0.05 * i for i in range(1, 21)]),\n",
    "        \"clipnorm\": hp.choice(\"clipnorm\", [None, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]),\n",
    "    }\n",
    "\n",
    "initial_best_config = [{}]\n",
    "\n",
    "\n",
    "pickle.dump(search_space, open(\"./search_spaces/torch_choice_search_search_space.pkl\", \"wb\"))\n",
    "pickle.dump(initial_best_config, open(\"./search_spaces/torch_choice_search_initial_best_config.pkl\", \"wb\"))\n",
    "\n",
    "%run ../../dqn/rainbow/hyperparameter_optimization.py ./search_spaces/torch_choice_search_search_space.pkl ./search_spaces/torch_choice_search_initial_best_config.pkl ClassicControl-v1_search_choice ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing the trials over time\n",
    "from utils import plot_trials\n",
    "import pickle\n",
    "trials = pickle.load(open('./torch_choice_trials/CartPole-v1_trials.p', 'rb'))\n",
    "tesnorflow_trials = pickle.load(open('./tensorflow_choice_trials/CartPole-v1_trials.p', 'rb'))\n",
    "# print(trials.trials)\n",
    "%matplotlib inline\n",
    "plot_trials(trials, \"Carpole-v1_torch_trials_over_time\")\n",
    "plot_trials(tesnorflow_trials, \"Carpole-v1_tensorflow_trials_over_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt with Torch and hp.uniform, hp.loguniform, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropy, KLDivergence, generate_layer_widths\n",
    "import gymnasium as gym \n",
    "import numpy as np\n",
    "\n",
    "width_combinations = generate_layer_widths([32, 64, 128, 256, 512, 1024], 5)\n",
    "# print(width_combinations)\n",
    "\n",
    "search_space = {\n",
    "        \"kernel_initializer\": hp.choice(\n",
    "            \"kernel_initializer\",\n",
    "            [\n",
    "                \"he_uniform\",\n",
    "                \"he_normal\",\n",
    "                \"glorot_uniform\",\n",
    "                \"glorot_normal\",\n",
    "                \"orthogonal\",\n",
    "            ],\n",
    "        ),\n",
    "        \"learning_rate\": hp.qloguniform('learning_rate', np.log(0.00001), np.log(1.0), 0.00001),\n",
    "        \"adam_epsilon\": hp.qloguniform('adam_epsilon', np.log(0.0003125), np.log(0.3125), 0.0003125),\n",
    "        \"loss_function\": hp.choice(\n",
    "            \"loss_function\", [CategoricalCrossentropy(), KLDivergence()]\n",
    "        ),\n",
    "        # NORMALIZATION?\n",
    "        \"transfer_interval\": hp.qloguniform('transfer_interval', np.log(10), np.log(2000), 10),\n",
    "        \"replay_interval\": hp.uniformint('replay_interval', 1, 12),\n",
    "        \"minibatch_size\": scope.int(hp.quniform('minibatch_size', 16, 128, 16)),  ###########\n",
    "        \"replay_buffer_size\": scope.int(hp.quniform('replay_buffer_size', 2000, 10000, 1000)),  #############\n",
    "        \"min_replay_buffer_size\": scope.int(hp.quniform('min_replay_buffer_size', 125, 2000, 125)), \n",
    "        \"n_step\": hp.uniformint('n_step', 2, 10),\n",
    "        \"discount_factor\": hp.qloguniform('discount_factor', np.log(0.9), np.log(0.999), 0.001),\n",
    "        \"atom_size\": scope.int(hp.quniform('atom_size', 51, 81, 10) + 1),  #\n",
    "        \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "        \"dense_layers_widths\": hp.choice(\"dense_layers_widths\", width_combinations),\n",
    "        \"advantage_hidden_layers_widths\": hp.choice(\n",
    "            \"advantage_hidden_layers_widths\", width_combinations\n",
    "        ),  #\n",
    "        \"value_hidden_layers_widths\": hp.choice(\n",
    "            \"value_hidden_layers_widths\", width_combinations\n",
    "        ),  #\n",
    "        \"training_steps\": hp.choice(\"training_steps\", [10000]),\n",
    "        \"per_epsilon\": hp.qloguniform('per_epsilon', np.log(0.00001), np.log(0.1), 0.00001),\n",
    "        \"per_alpha\": hp.quniform('per_alpha', 0.05, 1.0, 0.05),\n",
    "        \"per_beta\": hp.quniform('per_beta', 0.05, 1.0, 0.05),\n",
    "        \"clipnorm\": hp.qloguniform('clipnorm', np.log(0.1), np.log(100.0), 0.1)\n",
    "    }\n",
    "\n",
    "initial_best_config = [{}]\n",
    "\n",
    "\n",
    "pickle.dump(search_space, open(\"./search_spaces/torch_quantized_search_search_space.pkl\", \"wb\"))\n",
    "pickle.dump(initial_best_config, open(\"./search_spaces/torch_quantized_search_initial_best_config.pkl\", \"wb\"))\n",
    "\n",
    "%run ../../dqn/rainbow/hyperparameter_optimization.py ./search_spaces/torch_quantized_search_search_space.pkl ./search_spaces/torch_quantized_search_initial_best_config.pkl ClassicControl-v1_quantized_search ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing the trials over time\n",
    "from utils import plot_trials\n",
    "import pickle\n",
    "trials = pickle.load(open('../../dqn/rainbow/CartPole-v1_trials.p', 'rb'))\n",
    "tesnorflow_trials = pickle.load(open('./tensorflow_trials/CartPole-v1_trials.p', 'rb'))\n",
    "# print(trials.trials)\n",
    "%matplotlib inline\n",
    "plot_trials(trials, \"Carpole-v1_torch_search_trials_over_time\")\n",
    "plot_trials(tesnorflow_trials, \"Carpole-v1_tensorflow_trials_over_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed of results\n",
    "# Graph of hyperparameter convergence over time for torch and tensorflow compared with random search\n",
    "# Hyperparameters importance (ape-x analysis file)\n",
    "# Hyperparameter similarity of consecutive trials as a measure of confidence\n",
    "# Search space size vs convergence speed\n",
    "# Compare results to tuning only one system at a time\n",
    "# Using rolling average as evaluation method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rainbow results on Classic Control environments\n",
    "Training steps: \n",
    "Evaluation: \n",
    "Hyperparamaters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rainbow results on (subset of) Atari games\n",
    "Training steps: \n",
    "Evaluation: \n",
    "Hyperparamaters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
