{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5607c5be",
   "metadata": {},
   "source": [
    "*** TO DO FOR CATAN: ***\n",
    "RAINBOW: \n",
    "    1. vs Random\n",
    "    2. vs Weighted Random\n",
    "    3. vs MTCS\n",
    "    4. vs Victory Point\n",
    "    5. vs AlphaBeta\n",
    "Masked PPO the same \n",
    "NFSP \n",
    "MuZero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa0589",
   "metadata": {},
   "source": [
    "MUZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d597228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default save_intermediate_weights     : False\n",
      "Using default training_steps                : 10000\n",
      "Using default adam_epsilon                  : 1e-08\n",
      "Using default momentum                      : 0.9\n",
      "Using         learning_rate                 : 0.001\n",
      "Using default clipnorm                      : 0\n",
      "Using default optimizer                     : <class 'torch.optim.adam.Adam'>\n",
      "Using default weight_decay                  : 0.0\n",
      "Using default loss_function                 : <class 'utils.utils.MSELoss'>\n",
      "Using default activation                    : relu\n",
      "Using         kernel_initializer            : None\n",
      "Using         minibatch_size                : 1024\n",
      "Using         replay_buffer_size            : 100000\n",
      "Using         min_replay_buffer_size        : 4096\n",
      "Using default num_minibatches               : 1\n",
      "Using default training_iterations           : 1\n",
      "Using default print_interval                : 100\n",
      "Using         known_bounds                  : [-1, 1]\n",
      "Using         residual_layers               : []\n",
      "Using default conv_layers                   : []\n",
      "Using         dense_layer_widths            : [128, 128, 128, 128, 128]\n",
      "Using default representation_residual_layers: []\n",
      "Using default representation_conv_layers    : []\n",
      "Using default representation_dense_layer_widths: [128, 128, 128, 128, 128]\n",
      "Using default dynamics_residual_layers      : []\n",
      "Using default dynamics_conv_layers          : []\n",
      "Using default dynamics_dense_layer_widths   : [128, 128, 128, 128, 128]\n",
      "Using         reward_conv_layers            : []\n",
      "Using         reward_dense_layer_widths     : [32]\n",
      "Using         to_play_conv_layers           : []\n",
      "Using         to_play_dense_layer_widths    : [32]\n",
      "Using         critic_conv_layers            : []\n",
      "Using         critic_dense_layer_widths     : [32]\n",
      "Using         actor_conv_layers             : []\n",
      "Using         actor_dense_layer_widths      : [32]\n",
      "Using default noisy_sigma                   : 0.0\n",
      "Using default games_per_generation          : 100\n",
      "Using default value_loss_factor             : 1.0\n",
      "Using default weight_decay                  : 0.0001\n",
      "Using         root_dirichlet_alpha          : 0.03\n",
      "Using default root_exploration_fraction     : 0.25\n",
      "Using         num_simulations               : 100\n",
      "Using default temperatures                  : [1.0, 0.1]\n",
      "Using         temperature_updates           : [500]\n",
      "Using default temperature_with_training_steps: False\n",
      "Using default clip_low_prob                 : 0.0\n",
      "Using default pb_c_base                     : 19652\n",
      "Using default pb_c_init                     : 1.25\n",
      "Using default value_loss_function           : <utils.utils.MSELoss object at 0x32270bc70>\n",
      "Using default reward_loss_function          : <utils.utils.MSELoss object at 0x32270bc40>\n",
      "Using default policy_loss_function          : <utils.utils.CategoricalCrossentropyLoss object at 0x32270bca0>\n",
      "Using default to_play_loss_function         : <utils.utils.CategoricalCrossentropyLoss object at 0x32270bd00>\n",
      "Using         action_function               : <function action_as_onehot at 0x3226fec20>\n",
      "Using         n_step                        : 1500\n",
      "Using default discount_factor               : 1.0\n",
      "Using default unroll_steps                  : 5\n",
      "Using         per_alpha                     : 0.0\n",
      "Using         per_beta                      : 0.0\n",
      "Using         per_beta_final                : 0.0\n",
      "Using default per_epsilon                   : 1e-06\n",
      "Using default per_use_batch_weights         : False\n",
      "Using default per_initial_priority_max      : False\n",
      "Using         support_range                 : None\n",
      "Using default multi_process                 : True\n",
      "Using         num_workers                   : 4\n",
      "Using         lr_ratio                      : 0.1\n",
      "Using device: cpu\n",
      "making test env\n",
      "Warning: test_env will not record videos as render_mode is not 'rgb_array'\n",
      "Test env: AppendAgentSelectionWrapper<FrameStackWrapper<ActionMaskInInfoWrapper<catanatron_v1>>>\n",
      "<class 'method'>\n",
      "petting zoo\n",
      "Observation dimensions: (2457,)\n",
      "Observation dtype: float32\n",
      "num_actions:  290 <class 'int'>\n",
      "Test agents: [<agents.catan_player_wrapper.CatanPlayerWrapper object at 0x32270bbe0>, <agents.catan_player_wrapper.CatanPlayerWrapper object at 0x32270bdf0>]\n",
      "Hidden state shape: (1024, 128)\n",
      "Action function output shape: torch.Size([290])\n",
      "torch.Size([1024, 418])\n",
      "dynamics input shape torch.Size([1024, 418])\n",
      "Layer weights:\n",
      "representation.dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[-0.0127, -0.0049, -0.0075,  ...,  0.0117,  0.0056,  0.0162],\n",
      "        [ 0.0183,  0.0148, -0.0179,  ...,  0.0198,  0.0007,  0.0192],\n",
      "        [ 0.0018,  0.0180,  0.0101,  ...,  0.0120, -0.0054,  0.0123],\n",
      "        ...,\n",
      "        [-0.0057, -0.0130, -0.0191,  ...,  0.0197,  0.0201,  0.0085],\n",
      "        [ 0.0045, -0.0095,  0.0014,  ...,  0.0166,  0.0051,  0.0120],\n",
      "        [ 0.0060, -0.0111,  0.0027,  ...,  0.0002,  0.0002, -0.0194]])\n",
      "Shape: torch.Size([128, 2457]), std: 0.0116, mean: 0.0000\n",
      "\n",
      "representation.dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([ 8.4312e-03,  9.3411e-03, -1.6618e-02,  2.6372e-03, -1.4500e-02,\n",
      "         1.7564e-03, -1.0765e-02,  2.3155e-03, -2.0135e-02, -1.1827e-02,\n",
      "        -7.7731e-03, -1.0424e-02,  1.3026e-02,  9.7139e-03,  1.5412e-02,\n",
      "        -6.1746e-03,  7.8329e-03, -1.6296e-02, -2.1494e-03, -1.0198e-03,\n",
      "        -1.4243e-02, -1.8455e-02, -6.8927e-03, -1.7876e-02,  1.3380e-02,\n",
      "         1.2814e-02, -1.7762e-02,  1.0131e-02, -5.8841e-03, -5.2162e-03,\n",
      "        -6.0437e-03,  1.1894e-02,  1.3484e-02, -6.5781e-03,  1.3634e-03,\n",
      "         7.9711e-03, -2.3211e-03,  1.1931e-02,  6.3911e-03,  1.3704e-02,\n",
      "         1.0028e-02, -1.9898e-02, -1.5019e-02, -2.3500e-03, -5.9255e-03,\n",
      "         1.5603e-02,  7.2119e-03,  5.3351e-03,  1.7143e-02, -1.0733e-02,\n",
      "         1.9460e-02,  4.7489e-03,  1.6703e-02, -5.3756e-05,  5.1584e-03,\n",
      "         1.6345e-02, -1.5653e-03, -1.0133e-02, -1.3049e-03, -1.7980e-02,\n",
      "         1.8849e-02,  1.9119e-02, -1.7981e-02,  1.0747e-02,  2.1885e-03,\n",
      "         9.7600e-03, -1.1892e-02,  1.9704e-02,  3.3656e-03,  1.4925e-02,\n",
      "        -8.1136e-03,  1.0182e-02,  7.4314e-03,  1.6365e-02,  6.5165e-04,\n",
      "         9.8459e-03, -1.2326e-02, -1.0898e-02, -1.0839e-02,  2.5448e-03,\n",
      "        -5.8350e-03, -1.2386e-02, -1.0991e-02, -1.8013e-02,  1.4763e-02,\n",
      "         6.0894e-03, -1.7408e-02,  1.8893e-02,  1.0354e-02, -2.1919e-03,\n",
      "         3.2157e-03, -1.0619e-02,  2.8832e-03,  8.4006e-03,  1.9223e-03,\n",
      "        -1.5224e-02, -3.8337e-03,  3.2506e-03,  1.8568e-02,  2.0052e-02,\n",
      "        -1.6833e-04, -8.6918e-03, -2.7442e-03, -1.4993e-02, -1.0551e-02,\n",
      "        -1.4798e-03,  1.9999e-02, -9.1689e-03,  8.2615e-03,  7.5660e-03,\n",
      "        -4.1069e-03, -6.7763e-03,  1.3000e-02, -8.0399e-03, -2.0271e-03,\n",
      "         4.8500e-03,  1.9724e-02, -3.7926e-03, -1.1321e-02,  6.7382e-03,\n",
      "        -1.8827e-02,  7.1522e-03, -1.4171e-02, -1.0656e-02,  3.1923e-03,\n",
      "         7.2757e-03,  1.7107e-02,  2.5986e-03])\n",
      "Shape: torch.Size([128]), std: 0.0115, mean: 0.0005\n",
      "\n",
      "representation.dense_layers.dense_layers.1.layer.weight:\n",
      "tensor([[ 0.0581, -0.0496, -0.0671,  ..., -0.0005, -0.0790, -0.0024],\n",
      "        [-0.0220,  0.0245, -0.0531,  ...,  0.0784, -0.0811,  0.0295],\n",
      "        [-0.0506, -0.0082,  0.0486,  ..., -0.0470, -0.0804, -0.0330],\n",
      "        ...,\n",
      "        [-0.0089,  0.0573,  0.0256,  ...,  0.0441,  0.0736,  0.0473],\n",
      "        [ 0.0275, -0.0723,  0.0415,  ..., -0.0602, -0.0440, -0.0300],\n",
      "        [-0.0676,  0.0040,  0.0008,  ...,  0.0270, -0.0260, -0.0563]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0510, mean: -0.0002\n",
      "\n",
      "representation.dense_layers.dense_layers.1.layer.bias:\n",
      "tensor([ 0.0695,  0.0270,  0.0709,  0.0447, -0.0219,  0.0334, -0.0250, -0.0474,\n",
      "         0.0810, -0.0512, -0.0107, -0.0699,  0.0385,  0.0569, -0.0547,  0.0483,\n",
      "        -0.0719, -0.0562,  0.0700, -0.0147, -0.0412, -0.0068, -0.0784,  0.0695,\n",
      "         0.0072,  0.0161, -0.0056,  0.0457, -0.0534, -0.0768,  0.0247, -0.0723,\n",
      "        -0.0567, -0.0285,  0.0198,  0.0684,  0.0640, -0.0797, -0.0769, -0.0426,\n",
      "         0.0738,  0.0276, -0.0601,  0.0163, -0.0119,  0.0555, -0.0857,  0.0496,\n",
      "        -0.0594, -0.0539, -0.0100,  0.0877, -0.0687, -0.0752, -0.0285, -0.0136,\n",
      "         0.0489,  0.0849,  0.0184, -0.0667,  0.0543, -0.0530, -0.0744, -0.0533,\n",
      "        -0.0819,  0.0879, -0.0775, -0.0724,  0.0421,  0.0172, -0.0155, -0.0597,\n",
      "         0.0251,  0.0247, -0.0474, -0.0644, -0.0228, -0.0491,  0.0862,  0.0531,\n",
      "         0.0432,  0.0192,  0.0300,  0.0422, -0.0605,  0.0626, -0.0568,  0.0265,\n",
      "         0.0215, -0.0097,  0.0124,  0.0269, -0.0193, -0.0205, -0.0854, -0.0779,\n",
      "         0.0745,  0.0537, -0.0826, -0.0798,  0.0114,  0.0558,  0.0863, -0.0294,\n",
      "        -0.0462,  0.0453,  0.0696, -0.0450,  0.0317, -0.0488, -0.0416, -0.0477,\n",
      "        -0.0540, -0.0535, -0.0461, -0.0514, -0.0614, -0.0706, -0.0418, -0.0625,\n",
      "         0.0118, -0.0051, -0.0423,  0.0421, -0.0535, -0.0178,  0.0370, -0.0404])\n",
      "Shape: torch.Size([128]), std: 0.0525, mean: -0.0085\n",
      "\n",
      "representation.dense_layers.dense_layers.2.layer.weight:\n",
      "tensor([[ 0.0274,  0.0114, -0.0605,  ..., -0.0536, -0.0390, -0.0124],\n",
      "        [ 0.0409,  0.0187, -0.0374,  ..., -0.0502,  0.0200, -0.0219],\n",
      "        [ 0.0854, -0.0125, -0.0235,  ...,  0.0530, -0.0410,  0.0135],\n",
      "        ...,\n",
      "        [ 0.0838, -0.0543,  0.0055,  ...,  0.0509,  0.0625,  0.0008],\n",
      "        [ 0.0431, -0.0259,  0.0024,  ..., -0.0224, -0.0256,  0.0775],\n",
      "        [ 0.0609, -0.0157, -0.0041,  ..., -0.0158, -0.0052, -0.0518]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0511, mean: 0.0002\n",
      "\n",
      "representation.dense_layers.dense_layers.2.layer.bias:\n",
      "tensor([-0.0337,  0.0293, -0.0713, -0.0495,  0.0032, -0.0368,  0.0733, -0.0723,\n",
      "         0.0101,  0.0528,  0.0724, -0.0827,  0.0804, -0.0876, -0.0406,  0.0846,\n",
      "         0.0806,  0.0441,  0.0725,  0.0358, -0.0467, -0.0376,  0.0220,  0.0693,\n",
      "         0.0640, -0.0737,  0.0059, -0.0447,  0.0211, -0.0292, -0.0656, -0.0568,\n",
      "         0.0129,  0.0642, -0.0361, -0.0372,  0.0347,  0.0422,  0.0195, -0.0167,\n",
      "         0.0279, -0.0312,  0.0176, -0.0641, -0.0412, -0.0688,  0.0581, -0.0358,\n",
      "        -0.0460, -0.0055,  0.0136,  0.0509,  0.0218, -0.0372,  0.0761, -0.0193,\n",
      "         0.0242,  0.0797, -0.0877, -0.0456,  0.0350,  0.0771, -0.0054, -0.0725,\n",
      "         0.0202,  0.0284, -0.0715, -0.0321,  0.0749,  0.0150,  0.0683,  0.0055,\n",
      "        -0.0132, -0.0657, -0.0562,  0.0258,  0.0679, -0.0512,  0.0182,  0.0780,\n",
      "         0.0435,  0.0730,  0.0701, -0.0039,  0.0783, -0.0820,  0.0027, -0.0740,\n",
      "         0.0587,  0.0690,  0.0374,  0.0863, -0.0835, -0.0464,  0.0822,  0.0846,\n",
      "         0.0834,  0.0725, -0.0181, -0.0746, -0.0119,  0.0081, -0.0205,  0.0515,\n",
      "         0.0312, -0.0272,  0.0607,  0.0590, -0.0562,  0.0627,  0.0018, -0.0364,\n",
      "        -0.0594, -0.0215,  0.0742, -0.0035, -0.0085, -0.0874,  0.0745,  0.0283,\n",
      "         0.0092,  0.0663, -0.0368,  0.0269, -0.0797, -0.0037,  0.0298,  0.0272])\n",
      "Shape: torch.Size([128]), std: 0.0530, mean: 0.0057\n",
      "\n",
      "representation.dense_layers.dense_layers.3.layer.weight:\n",
      "tensor([[ 0.0411,  0.0475,  0.0829,  ...,  0.0581,  0.0526,  0.0749],\n",
      "        [ 0.0108,  0.0777,  0.0577,  ..., -0.0176, -0.0167,  0.0292],\n",
      "        [ 0.0341,  0.0536, -0.0254,  ...,  0.0112,  0.0838, -0.0183],\n",
      "        ...,\n",
      "        [ 0.0163, -0.0696,  0.0223,  ..., -0.0818,  0.0800,  0.0841],\n",
      "        [ 0.0209, -0.0182, -0.0492,  ..., -0.0452,  0.0809, -0.0730],\n",
      "        [-0.0319, -0.0510, -0.0035,  ..., -0.0831, -0.0691,  0.0309]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0510, mean: -0.0002\n",
      "\n",
      "representation.dense_layers.dense_layers.3.layer.bias:\n",
      "tensor([-1.7462e-02,  2.7331e-02,  8.1012e-02,  3.5296e-02,  8.5427e-02,\n",
      "        -7.5983e-02,  2.6339e-02,  2.6614e-02,  7.7210e-03, -2.9558e-02,\n",
      "         2.0420e-02,  2.1350e-02, -2.3812e-02,  8.8085e-02,  2.2400e-02,\n",
      "         8.6677e-02, -1.4355e-02,  5.8288e-02,  6.6590e-02,  7.7783e-02,\n",
      "         3.5997e-02,  7.8046e-02, -6.5465e-02,  4.4635e-02, -3.0610e-02,\n",
      "         2.1330e-02,  5.3826e-02,  4.8049e-02, -5.6278e-02,  4.1893e-02,\n",
      "         3.3252e-02, -1.7020e-02,  4.2686e-02, -2.0888e-02, -4.7260e-02,\n",
      "         8.1807e-02, -9.5603e-03, -1.2231e-02,  3.4784e-02, -8.7321e-02,\n",
      "        -5.2755e-02, -3.2749e-02, -7.8393e-02,  3.0971e-02, -8.7143e-02,\n",
      "         8.0350e-02, -1.8784e-02,  1.1955e-02, -8.4035e-02,  1.6330e-02,\n",
      "         2.7742e-02,  6.8004e-02,  4.5864e-02, -2.7178e-02,  4.9018e-02,\n",
      "        -1.2903e-02, -4.0145e-02, -1.9637e-02,  6.5467e-02, -1.2096e-02,\n",
      "        -7.8526e-02, -4.2638e-02, -1.1577e-02, -9.4710e-03, -2.7268e-02,\n",
      "        -7.7152e-02,  1.1314e-02, -3.9339e-02,  5.4788e-02, -1.8487e-02,\n",
      "         1.8954e-02, -8.6741e-02, -5.4044e-02, -4.7814e-03, -8.2264e-02,\n",
      "         7.1345e-02, -4.8870e-02, -6.4283e-02,  7.0507e-02, -6.2598e-02,\n",
      "        -5.6872e-02,  5.3152e-02,  6.5682e-03,  2.7021e-02,  8.3056e-02,\n",
      "        -2.5283e-02, -7.0455e-02, -8.5213e-02, -1.5106e-03,  6.3298e-02,\n",
      "        -3.4685e-02,  6.9304e-02, -7.4875e-02,  8.2426e-02, -8.0227e-02,\n",
      "         8.5653e-02,  2.4509e-02, -9.4911e-03,  4.4449e-02, -6.7382e-02,\n",
      "         5.1623e-02,  7.9310e-02,  6.9775e-02,  6.1598e-02, -7.6759e-02,\n",
      "        -4.7121e-02, -3.6500e-02,  2.4460e-02,  4.1109e-02, -1.2944e-02,\n",
      "         3.6571e-02, -6.2996e-02, -2.2501e-02,  2.6177e-02,  3.4102e-02,\n",
      "         7.6649e-02, -1.5201e-02,  7.9844e-02, -4.6958e-02,  1.3673e-02,\n",
      "         2.5396e-02,  8.3965e-02,  2.6320e-02,  5.7433e-02,  4.4360e-05,\n",
      "         3.8185e-03, -1.4739e-03, -4.3770e-02])\n",
      "Shape: torch.Size([128]), std: 0.0520, mean: 0.0051\n",
      "\n",
      "representation.dense_layers.dense_layers.4.layer.weight:\n",
      "tensor([[ 0.0173, -0.0312, -0.0333,  ...,  0.0836,  0.0829, -0.0752],\n",
      "        [-0.0746, -0.0704,  0.0788,  ...,  0.0409, -0.0156, -0.0830],\n",
      "        [-0.0017, -0.0319,  0.0882,  ...,  0.0124, -0.0238, -0.0840],\n",
      "        ...,\n",
      "        [-0.0462,  0.0817,  0.0058,  ..., -0.0198, -0.0037,  0.0133],\n",
      "        [ 0.0824, -0.0049,  0.0462,  ..., -0.0399, -0.0084,  0.0678],\n",
      "        [-0.0292,  0.0185, -0.0437,  ...,  0.0636, -0.0596,  0.0359]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0510, mean: 0.0001\n",
      "\n",
      "representation.dense_layers.dense_layers.4.layer.bias:\n",
      "tensor([ 0.0307,  0.0498,  0.0028,  0.0724,  0.0244,  0.0473, -0.0094, -0.0403,\n",
      "         0.0779, -0.0533, -0.0827, -0.0757, -0.0060, -0.0546,  0.0617, -0.0593,\n",
      "        -0.0293, -0.0365, -0.0076, -0.0779, -0.0567, -0.0049, -0.0454,  0.0581,\n",
      "         0.0580,  0.0295,  0.0506, -0.0076,  0.0489, -0.0083,  0.0584, -0.0247,\n",
      "        -0.0256, -0.0187,  0.0270, -0.0484,  0.0499,  0.0749,  0.0173, -0.0722,\n",
      "        -0.0529,  0.0220,  0.0438, -0.0131,  0.0118,  0.0770,  0.0790, -0.0335,\n",
      "        -0.0761, -0.0012, -0.0060, -0.0824, -0.0578,  0.0280,  0.0571, -0.0543,\n",
      "         0.0496,  0.0855, -0.0650, -0.0372,  0.0519, -0.0323, -0.0166, -0.0365,\n",
      "         0.0584, -0.0310,  0.0142, -0.0355, -0.0039, -0.0139, -0.0264,  0.0813,\n",
      "        -0.0415, -0.0419, -0.0769,  0.0500, -0.0050, -0.0011, -0.0058,  0.0506,\n",
      "         0.0374,  0.0266, -0.0454, -0.0789,  0.0056, -0.0527, -0.0806, -0.0378,\n",
      "        -0.0157, -0.0215, -0.0750,  0.0098,  0.0499,  0.0260, -0.0263, -0.0141,\n",
      "         0.0586,  0.0353,  0.0191, -0.0464, -0.0588,  0.0763, -0.0675,  0.0412,\n",
      "        -0.0186,  0.0032, -0.0302,  0.0181, -0.0771,  0.0159, -0.0694, -0.0750,\n",
      "        -0.0220, -0.0003,  0.0484,  0.0422, -0.0665, -0.0042, -0.0111, -0.0237,\n",
      "        -0.0105,  0.0021, -0.0694,  0.0755,  0.0802,  0.0628, -0.0822, -0.0773])\n",
      "Shape: torch.Size([128]), std: 0.0483, mean: -0.0048\n",
      "\n",
      "dynamics.dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[ 0.0185, -0.0225,  0.0456,  ...,  0.0456, -0.0173, -0.0470],\n",
      "        [ 0.0066,  0.0462, -0.0022,  ..., -0.0467, -0.0107, -0.0402],\n",
      "        [-0.0276, -0.0089,  0.0328,  ...,  0.0438, -0.0094, -0.0104],\n",
      "        ...,\n",
      "        [-0.0263,  0.0058, -0.0224,  ..., -0.0240, -0.0055, -0.0086],\n",
      "        [ 0.0184,  0.0049,  0.0152,  ...,  0.0322, -0.0084, -0.0135],\n",
      "        [ 0.0484, -0.0302,  0.0344,  ...,  0.0120, -0.0012, -0.0058]])\n",
      "Shape: torch.Size([128, 418]), std: 0.0282, mean: -0.0002\n",
      "\n",
      "dynamics.dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([-4.5642e-02, -4.1384e-02, -1.5651e-02,  4.7398e-02, -2.8793e-02,\n",
      "        -1.4486e-02,  2.3419e-02, -2.4604e-02,  8.5029e-03,  1.9889e-02,\n",
      "        -1.5789e-02, -1.2200e-02,  4.4531e-03,  7.9788e-03,  2.1266e-02,\n",
      "        -3.5594e-02, -1.3312e-03, -1.2600e-02, -2.1140e-03,  4.4773e-02,\n",
      "        -1.0230e-02,  4.5047e-02, -3.1326e-02,  1.5382e-02, -3.6352e-02,\n",
      "        -4.5877e-04,  4.2754e-02,  2.2589e-03,  3.1558e-02,  1.2373e-02,\n",
      "        -1.0244e-03,  4.5512e-02,  4.5031e-02,  4.3572e-02,  1.2000e-02,\n",
      "        -4.7447e-02,  3.1290e-02,  3.3118e-02,  1.3630e-04, -7.8328e-03,\n",
      "         1.8943e-02, -1.2890e-02, -2.3686e-02,  3.7241e-02, -1.7447e-03,\n",
      "         4.1532e-02, -6.6252e-03, -1.0209e-02, -4.1233e-02, -6.7333e-03,\n",
      "        -1.9231e-03,  1.0809e-03,  3.4370e-02, -2.4682e-02,  2.3027e-02,\n",
      "         2.6019e-02,  5.5543e-03,  3.2277e-02, -6.9753e-04, -1.8796e-02,\n",
      "         2.0158e-02,  3.2513e-02,  9.4811e-03,  2.3538e-02, -1.0805e-02,\n",
      "        -2.0406e-03, -1.3923e-02,  1.3344e-02,  2.0179e-02, -2.5197e-02,\n",
      "         2.5143e-02,  4.3182e-02,  3.8093e-02,  3.9012e-02, -4.3685e-02,\n",
      "        -1.4570e-02,  1.5495e-02, -3.2655e-02,  3.9226e-02, -2.0181e-03,\n",
      "        -5.4611e-03, -2.1210e-02,  5.0055e-03,  4.2222e-02,  1.5404e-02,\n",
      "         9.2553e-03,  3.6222e-02, -3.4883e-02,  3.3664e-02, -3.4523e-02,\n",
      "         2.3215e-02, -4.8047e-02,  2.6257e-02, -3.9745e-02, -4.6674e-03,\n",
      "        -1.4240e-02,  8.1358e-03, -3.6457e-03,  4.3223e-02,  2.2752e-02,\n",
      "        -4.1382e-02, -1.2730e-02,  1.7944e-02,  2.8849e-02,  4.1693e-02,\n",
      "        -3.7940e-02, -4.0739e-02,  9.1001e-03, -1.3509e-02,  1.6302e-02,\n",
      "        -4.6936e-03, -4.1137e-02, -2.8793e-02,  4.4480e-02,  4.0097e-02,\n",
      "        -5.2069e-03,  7.5371e-04, -2.9537e-02, -2.1429e-02,  5.3345e-05,\n",
      "        -3.5237e-02,  1.7832e-02, -3.7094e-02,  4.9317e-03,  3.9194e-02,\n",
      "        -7.3191e-03,  5.7746e-04,  3.5052e-03])\n",
      "Shape: torch.Size([128]), std: 0.0267, mean: 0.0029\n",
      "\n",
      "dynamics.dense_layers.dense_layers.1.layer.weight:\n",
      "tensor([[ 0.0205,  0.0455, -0.0530,  ...,  0.0699,  0.0764, -0.0087],\n",
      "        [ 0.0768,  0.0725, -0.0033,  ..., -0.0521,  0.0088, -0.0757],\n",
      "        [-0.0030,  0.0408,  0.0465,  ...,  0.0275,  0.0483,  0.0549],\n",
      "        ...,\n",
      "        [ 0.0424,  0.0586, -0.0032,  ...,  0.0011,  0.0168,  0.0565],\n",
      "        [ 0.0313,  0.0793, -0.0759,  ..., -0.0374,  0.0872, -0.0448],\n",
      "        [-0.0686,  0.0134,  0.0494,  ..., -0.0731, -0.0010,  0.0124]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0511, mean: -0.0001\n",
      "\n",
      "dynamics.dense_layers.dense_layers.1.layer.bias:\n",
      "tensor([-0.0146, -0.0735,  0.0706,  0.0758,  0.0703, -0.0572, -0.0126, -0.0358,\n",
      "        -0.0026, -0.0074, -0.0219,  0.0215,  0.0220, -0.0578,  0.0392,  0.0284,\n",
      "         0.0810,  0.0320,  0.0740,  0.0010,  0.0363, -0.0469, -0.0074, -0.0256,\n",
      "         0.0188, -0.0613,  0.0590, -0.0282, -0.0808,  0.0018,  0.0210,  0.0087,\n",
      "        -0.0195, -0.0287,  0.0177,  0.0204, -0.0867,  0.0766, -0.0023, -0.0118,\n",
      "        -0.0356, -0.0115, -0.0716, -0.0133,  0.0190, -0.0129,  0.0349, -0.0777,\n",
      "        -0.0148, -0.0076, -0.0167,  0.0095, -0.0169,  0.0450,  0.0531, -0.0644,\n",
      "         0.0546, -0.0786, -0.0318, -0.0005,  0.0621,  0.0313,  0.0767, -0.0182,\n",
      "        -0.0378, -0.0346,  0.0235,  0.0389, -0.0123, -0.0357, -0.0420,  0.0525,\n",
      "        -0.0167,  0.0317,  0.0303, -0.0188,  0.0541, -0.0315, -0.0004, -0.0857,\n",
      "         0.0658, -0.0552,  0.0414,  0.0140, -0.0277, -0.0774, -0.0337, -0.0458,\n",
      "        -0.0790,  0.0758, -0.0636, -0.0255,  0.0831,  0.0103,  0.0337, -0.0849,\n",
      "        -0.0023,  0.0305, -0.0255, -0.0684,  0.0624,  0.0824, -0.0156, -0.0149,\n",
      "         0.0354, -0.0776,  0.0463, -0.0490, -0.0862,  0.0596,  0.0069,  0.0211,\n",
      "         0.0286, -0.0365,  0.0231,  0.0270,  0.0339, -0.0050, -0.0224, -0.0466,\n",
      "        -0.0324,  0.0473,  0.0503,  0.0433, -0.0599,  0.0359, -0.0474,  0.0009])\n",
      "Shape: torch.Size([128]), std: 0.0457, mean: -0.0016\n",
      "\n",
      "dynamics.dense_layers.dense_layers.2.layer.weight:\n",
      "tensor([[-0.0677, -0.0218,  0.0167,  ...,  0.0551, -0.0612,  0.0652],\n",
      "        [-0.0656,  0.0188, -0.0869,  ...,  0.0708,  0.0134,  0.0551],\n",
      "        [-0.0151,  0.0190, -0.0388,  ...,  0.0042, -0.0287, -0.0479],\n",
      "        ...,\n",
      "        [ 0.0597, -0.0139, -0.0254,  ...,  0.0071,  0.0079, -0.0445],\n",
      "        [ 0.0632,  0.0109, -0.0044,  ...,  0.0224, -0.0374, -0.0215],\n",
      "        [-0.0745,  0.0548,  0.0083,  ..., -0.0593,  0.0195,  0.0456]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0513, mean: 0.0005\n",
      "\n",
      "dynamics.dense_layers.dense_layers.2.layer.bias:\n",
      "tensor([-0.0064, -0.0376,  0.0294,  0.0782, -0.0609,  0.0546,  0.0283, -0.0373,\n",
      "        -0.0719, -0.0137,  0.0291,  0.0603,  0.0612, -0.0399,  0.0222, -0.0178,\n",
      "        -0.0344,  0.0087, -0.0823,  0.0690, -0.0111, -0.0171, -0.0661, -0.0884,\n",
      "         0.0030,  0.0204,  0.0515,  0.0114, -0.0727, -0.0226, -0.0306,  0.0675,\n",
      "        -0.0760,  0.0658, -0.0578, -0.0559,  0.0864,  0.0607,  0.0843, -0.0255,\n",
      "         0.0124, -0.0828,  0.0669,  0.0256,  0.0716,  0.0852,  0.0412,  0.0097,\n",
      "        -0.0500, -0.0400,  0.0844,  0.0108, -0.0153, -0.0568,  0.0343, -0.0481,\n",
      "        -0.0649,  0.0634,  0.0014, -0.0397, -0.0434,  0.0029, -0.0698,  0.0820,\n",
      "        -0.0602, -0.0259, -0.0168, -0.0559,  0.0351,  0.0833, -0.0349,  0.0570,\n",
      "         0.0438, -0.0844, -0.0705,  0.0201,  0.0164,  0.0548,  0.0601,  0.0834,\n",
      "        -0.0142,  0.0623, -0.0508, -0.0523,  0.0577, -0.0866,  0.0742,  0.0137,\n",
      "         0.0614, -0.0138,  0.0458,  0.0404,  0.0545, -0.0756,  0.0580, -0.0288,\n",
      "         0.0766, -0.0646,  0.0145, -0.0284, -0.0857, -0.0470, -0.0483,  0.0355,\n",
      "         0.0118,  0.0700,  0.0731,  0.0433, -0.0508,  0.0848, -0.0045, -0.0638,\n",
      "         0.0384,  0.0328,  0.0524,  0.0586,  0.0186, -0.0417, -0.0606, -0.0670,\n",
      "         0.0518,  0.0799,  0.0541, -0.0165,  0.0394, -0.0714,  0.0467, -0.0480])\n",
      "Shape: torch.Size([128]), std: 0.0534, mean: 0.0038\n",
      "\n",
      "dynamics.dense_layers.dense_layers.3.layer.weight:\n",
      "tensor([[-0.0813,  0.0365, -0.0083,  ...,  0.0379, -0.0336, -0.0384],\n",
      "        [-0.0668,  0.0826, -0.0611,  ...,  0.0081, -0.0048,  0.0341],\n",
      "        [ 0.0604,  0.0372, -0.0274,  ...,  0.0522,  0.0642,  0.0806],\n",
      "        ...,\n",
      "        [ 0.0427,  0.0185, -0.0117,  ..., -0.0573,  0.0776,  0.0672],\n",
      "        [-0.0341,  0.0484,  0.0794,  ..., -0.0586,  0.0672, -0.0840],\n",
      "        [ 0.0845,  0.0375,  0.0226,  ...,  0.0119, -0.0053, -0.0225]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0507, mean: 0.0006\n",
      "\n",
      "dynamics.dense_layers.dense_layers.3.layer.bias:\n",
      "tensor([-0.0700,  0.0313,  0.0304, -0.0200, -0.0610, -0.0377, -0.0461, -0.0068,\n",
      "         0.0079,  0.0481, -0.0092, -0.0235,  0.0657, -0.0811,  0.0867, -0.0043,\n",
      "        -0.0307, -0.0647, -0.0114,  0.0315,  0.0044, -0.0568, -0.0156,  0.0307,\n",
      "         0.0793, -0.0317, -0.0278, -0.0082, -0.0016,  0.0756,  0.0355, -0.0673,\n",
      "         0.0443, -0.0094,  0.0438, -0.0799, -0.0338,  0.0650,  0.0131,  0.0745,\n",
      "        -0.0845,  0.0750, -0.0331,  0.0758,  0.0658, -0.0554,  0.0696,  0.0075,\n",
      "         0.0591, -0.0718, -0.0520, -0.0073,  0.0028,  0.0349, -0.0675, -0.0493,\n",
      "         0.0052,  0.0793, -0.0051, -0.0717, -0.0532, -0.0772, -0.0661,  0.0238,\n",
      "        -0.0592, -0.0439,  0.0315, -0.0872,  0.0155,  0.0029, -0.0480,  0.0084,\n",
      "        -0.0833, -0.0526, -0.0550, -0.0666, -0.0491, -0.0383, -0.0770, -0.0161,\n",
      "         0.0402, -0.0677, -0.0656, -0.0546, -0.0520, -0.0518,  0.0245, -0.0529,\n",
      "         0.0789,  0.0104,  0.0661, -0.0158,  0.0497,  0.0558, -0.0282, -0.0620,\n",
      "        -0.0807, -0.0032, -0.0270, -0.0015,  0.0241, -0.0594, -0.0777,  0.0343,\n",
      "         0.0615, -0.0562,  0.0016, -0.0229, -0.0126, -0.0392, -0.0014, -0.0095,\n",
      "         0.0038,  0.0858,  0.0700,  0.0787,  0.0353, -0.0725, -0.0276, -0.0283,\n",
      "         0.0062,  0.0161,  0.0826,  0.0747,  0.0498, -0.0641,  0.0621, -0.0450])\n",
      "Shape: torch.Size([128]), std: 0.0506, mean: -0.0071\n",
      "\n",
      "dynamics.dense_layers.dense_layers.4.layer.weight:\n",
      "tensor([[ 0.0273,  0.0204,  0.0547,  ..., -0.0354, -0.0486, -0.0238],\n",
      "        [ 0.0269, -0.0667, -0.0118,  ..., -0.0274,  0.0070,  0.0328],\n",
      "        [-0.0766, -0.0112,  0.0589,  ...,  0.0678,  0.0062,  0.0658],\n",
      "        ...,\n",
      "        [ 0.0779,  0.0199,  0.0491,  ...,  0.0347, -0.0789,  0.0846],\n",
      "        [ 0.0285, -0.0172,  0.0342,  ...,  0.0754,  0.0144, -0.0840],\n",
      "        [ 0.0635,  0.0634,  0.0139,  ..., -0.0053,  0.0753,  0.0392]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0511, mean: 0.0005\n",
      "\n",
      "dynamics.dense_layers.dense_layers.4.layer.bias:\n",
      "tensor([ 0.0785,  0.0792, -0.0084, -0.0190, -0.0171, -0.0043,  0.0405, -0.0353,\n",
      "         0.0549,  0.0181, -0.0547,  0.0600,  0.0611,  0.0386, -0.0302,  0.0583,\n",
      "         0.0192,  0.0129,  0.0349,  0.0267, -0.0608,  0.0769, -0.0255,  0.0460,\n",
      "         0.0413, -0.0422, -0.0277,  0.0235,  0.0877,  0.0176, -0.0212, -0.0739,\n",
      "         0.0719, -0.0131,  0.0306,  0.0514,  0.0582,  0.0266, -0.0400, -0.0472,\n",
      "         0.0396, -0.0008,  0.0866,  0.0755, -0.0662, -0.0382, -0.0872, -0.0517,\n",
      "        -0.0593,  0.0786,  0.0011,  0.0201, -0.0175, -0.0613,  0.0604, -0.0609,\n",
      "         0.0582,  0.0073, -0.0848, -0.0207,  0.0472,  0.0331, -0.0398, -0.0701,\n",
      "        -0.0159, -0.0420, -0.0512,  0.0074,  0.0372, -0.0018, -0.0680, -0.0329,\n",
      "         0.0475,  0.0325,  0.0495, -0.0502, -0.0498, -0.0709, -0.0508, -0.0208,\n",
      "         0.0546, -0.0585, -0.0229, -0.0370,  0.0118, -0.0707,  0.0447,  0.0833,\n",
      "        -0.0840,  0.0637, -0.0853, -0.0708, -0.0088,  0.0167, -0.0241,  0.0158,\n",
      "        -0.0296, -0.0232, -0.0342,  0.0449,  0.0759,  0.0402, -0.0733,  0.0793,\n",
      "        -0.0521,  0.0624,  0.0840,  0.0660, -0.0166,  0.0513, -0.0653, -0.0424,\n",
      "         0.0400, -0.0232, -0.0474, -0.0167, -0.0448,  0.0215, -0.0040, -0.0858,\n",
      "        -0.0843, -0.0786, -0.0502, -0.0876,  0.0219, -0.0267, -0.0700, -0.0875])\n",
      "Shape: torch.Size([128]), std: 0.0515, mean: -0.0036\n",
      "\n",
      "dynamics.reward_dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[-0.0728,  0.0100,  0.0307,  ..., -0.0098, -0.0836, -0.0534],\n",
      "        [-0.0856, -0.0151, -0.0203,  ..., -0.0008,  0.0449, -0.0095],\n",
      "        [ 0.0351, -0.0570, -0.0730,  ...,  0.0084, -0.0434,  0.0018],\n",
      "        ...,\n",
      "        [ 0.0676,  0.0525, -0.0719,  ...,  0.0405, -0.0393, -0.0814],\n",
      "        [-0.0862, -0.0635,  0.0533,  ...,  0.0470, -0.0261, -0.0875],\n",
      "        [ 0.0304,  0.0801, -0.0071,  ..., -0.0164, -0.0109, -0.0008]])\n",
      "Shape: torch.Size([32, 128]), std: 0.0511, mean: 0.0008\n",
      "\n",
      "dynamics.reward_dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([ 0.0453,  0.0656, -0.0163,  0.0411, -0.0681, -0.0841, -0.0697,  0.0754,\n",
      "         0.0617, -0.0450,  0.0436, -0.0474, -0.0174, -0.0605, -0.0823, -0.0033,\n",
      "         0.0535, -0.0372, -0.0003,  0.0428, -0.0785,  0.0337, -0.0229,  0.0447,\n",
      "         0.0262,  0.0451, -0.0278, -0.0181,  0.0413, -0.0207, -0.0069,  0.0037])\n",
      "Shape: torch.Size([32]), std: 0.0485, mean: -0.0026\n",
      "\n",
      "dynamics.reward.layer.weight:\n",
      "tensor([[-0.1030,  0.1196,  0.1644, -0.0865,  0.0068, -0.0694,  0.1465,  0.0664,\n",
      "         -0.1381, -0.0140,  0.0592,  0.0354,  0.1532,  0.0737,  0.0210,  0.1653,\n",
      "          0.1630,  0.0519,  0.1503, -0.0860,  0.1023, -0.1039,  0.1474, -0.0218,\n",
      "          0.1735, -0.0031,  0.0560,  0.1251,  0.0905, -0.0870,  0.0500, -0.1423]])\n",
      "Shape: torch.Size([1, 32]), std: 0.1001, mean: 0.0396\n",
      "\n",
      "dynamics.reward.layer.bias:\n",
      "tensor([-0.0030])\n",
      "Shape: torch.Size([1]), std: nan, mean: -0.0030\n",
      "\n",
      "dynamics.to_play_dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[-2.4022e-03,  5.8605e-03,  8.2103e-02,  ...,  5.8478e-02,\n",
      "          4.1686e-02, -6.1186e-02],\n",
      "        [ 4.4623e-02, -6.0083e-02,  8.4542e-02,  ..., -3.2824e-02,\n",
      "         -8.3424e-02,  7.3135e-02],\n",
      "        [ 7.8623e-02,  4.5503e-02, -1.5579e-02,  ...,  5.0682e-02,\n",
      "         -2.1223e-02, -6.5283e-02],\n",
      "        ...,\n",
      "        [-2.5660e-02,  7.4234e-02, -2.1856e-03,  ..., -1.9957e-02,\n",
      "         -6.6654e-02,  3.4413e-02],\n",
      "        [ 5.3802e-02, -9.8629e-03,  2.4168e-02,  ..., -5.0281e-03,\n",
      "         -6.9117e-02,  1.2541e-02],\n",
      "        [-7.2713e-02, -7.0107e-02, -5.9766e-02,  ..., -6.0611e-02,\n",
      "         -1.7922e-02, -5.2684e-06]])\n",
      "Shape: torch.Size([32, 128]), std: 0.0511, mean: 0.0009\n",
      "\n",
      "dynamics.to_play_dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([-0.0353,  0.0836,  0.0786,  0.0145,  0.0773,  0.0360,  0.0646,  0.0871,\n",
      "        -0.0314, -0.0604,  0.0619, -0.0572, -0.0240, -0.0638, -0.0268,  0.0399,\n",
      "        -0.0710, -0.0088, -0.0494,  0.0026, -0.0386, -0.0589, -0.0682,  0.0265,\n",
      "         0.0130,  0.0243,  0.0203, -0.0294, -0.0474, -0.0849, -0.0034, -0.0425])\n",
      "Shape: torch.Size([32]), std: 0.0516, mean: -0.0053\n",
      "\n",
      "dynamics.to_play.layer.weight:\n",
      "tensor([[-0.0437,  0.1561,  0.1287,  0.0758,  0.1324, -0.1426, -0.1519,  0.1580,\n",
      "         -0.0294, -0.0156, -0.1727, -0.1635, -0.1385,  0.0728, -0.1095, -0.0482,\n",
      "          0.1657,  0.1461, -0.1654,  0.0905, -0.0352, -0.0283, -0.1221,  0.1697,\n",
      "          0.1296, -0.0245, -0.0610, -0.1519, -0.0100, -0.1157,  0.0858, -0.1029],\n",
      "        [-0.1148,  0.1136, -0.0239,  0.1497,  0.0908,  0.0483,  0.1660, -0.0992,\n",
      "          0.1119, -0.0854, -0.0464,  0.1159, -0.1528, -0.1244, -0.0970,  0.0149,\n",
      "         -0.0481,  0.1694,  0.0909,  0.1414, -0.1705,  0.1705,  0.1485,  0.1178,\n",
      "         -0.1719, -0.0630,  0.0704, -0.1391, -0.0728, -0.0739,  0.0871, -0.1319]])\n",
      "Shape: torch.Size([2, 32]), std: 0.1171, mean: -0.0020\n",
      "\n",
      "dynamics.to_play.layer.bias:\n",
      "tensor([-0.0534, -0.1090])\n",
      "Shape: torch.Size([2]), std: 0.0393, mean: -0.0812\n",
      "\n",
      "prediction.dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[-0.0172,  0.0031,  0.0834,  ..., -0.0319, -0.0788, -0.0415],\n",
      "        [ 0.0377, -0.0224,  0.0003,  ..., -0.0048, -0.0743,  0.0655],\n",
      "        [ 0.0219,  0.0017, -0.0586,  ...,  0.0050,  0.0011,  0.0380],\n",
      "        ...,\n",
      "        [-0.0412,  0.0624, -0.0730,  ..., -0.0522, -0.0264,  0.0553],\n",
      "        [ 0.0084, -0.0582,  0.0725,  ...,  0.0040, -0.0190, -0.0523],\n",
      "        [ 0.0109,  0.0483, -0.0749,  ..., -0.0501, -0.0181, -0.0724]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0510, mean: 0.0004\n",
      "\n",
      "prediction.dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([-0.0383, -0.0336,  0.0194, -0.0203,  0.0122,  0.0081, -0.0668,  0.0750,\n",
      "        -0.0151,  0.0095,  0.0105, -0.0787,  0.0581, -0.0093,  0.0381, -0.0355,\n",
      "         0.0020, -0.0443, -0.0306,  0.0697,  0.0073, -0.0200, -0.0421,  0.0287,\n",
      "         0.0814, -0.0288,  0.0013, -0.0676, -0.0023, -0.0050, -0.0361,  0.0261,\n",
      "        -0.0492, -0.0211, -0.0634,  0.0371, -0.0449, -0.0202, -0.0137, -0.0634,\n",
      "        -0.0570,  0.0337, -0.0724,  0.0639,  0.0484,  0.0613, -0.0304, -0.0281,\n",
      "        -0.0255,  0.0671, -0.0776, -0.0069,  0.0245, -0.0462,  0.0814,  0.0627,\n",
      "         0.0794, -0.0844, -0.0884, -0.0116, -0.0570, -0.0377, -0.0294,  0.0797,\n",
      "         0.0764,  0.0512, -0.0358, -0.0420, -0.0875,  0.0172,  0.0231, -0.0283,\n",
      "         0.0754, -0.0835,  0.0571,  0.0172, -0.0169, -0.0113, -0.0588,  0.0106,\n",
      "        -0.0397, -0.0225, -0.0311, -0.0691, -0.0278, -0.0863, -0.0250,  0.0107,\n",
      "        -0.0555, -0.0488,  0.0530,  0.0039, -0.0343, -0.0320, -0.0516,  0.0514,\n",
      "         0.0469, -0.0578, -0.0644, -0.0173, -0.0058, -0.0815, -0.0502, -0.0514,\n",
      "         0.0606,  0.0876,  0.0654,  0.0129, -0.0434,  0.0874,  0.0859, -0.0635,\n",
      "        -0.0057,  0.0397,  0.0297,  0.0662,  0.0825,  0.0093, -0.0167,  0.0860,\n",
      "        -0.0553,  0.0375, -0.0806, -0.0562, -0.0028,  0.0324,  0.0469,  0.0092])\n",
      "Shape: torch.Size([128]), std: 0.0497, mean: -0.0049\n",
      "\n",
      "prediction.dense_layers.dense_layers.1.layer.weight:\n",
      "tensor([[-0.0518, -0.0827,  0.0217,  ...,  0.0704,  0.0404, -0.0224],\n",
      "        [ 0.0847,  0.0348, -0.0335,  ...,  0.0782,  0.0289,  0.0245],\n",
      "        [-0.0524, -0.0836, -0.0138,  ...,  0.0472,  0.0258, -0.0467],\n",
      "        ...,\n",
      "        [-0.0138,  0.0058, -0.0080,  ...,  0.0406,  0.0647, -0.0460],\n",
      "        [ 0.0599, -0.0049, -0.0699,  ..., -0.0524, -0.0745, -0.0370],\n",
      "        [-0.0610, -0.0760, -0.0430,  ..., -0.0049,  0.0558, -0.0152]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0507, mean: 0.0006\n",
      "\n",
      "prediction.dense_layers.dense_layers.1.layer.bias:\n",
      "tensor([ 0.0122, -0.0484,  0.0386, -0.0554,  0.0859,  0.0311,  0.0084,  0.0644,\n",
      "        -0.0725, -0.0344,  0.0169,  0.0746, -0.0406, -0.0196,  0.0752,  0.0710,\n",
      "         0.0483, -0.0612,  0.0715,  0.0380, -0.0495, -0.0459, -0.0742,  0.0396,\n",
      "         0.0754,  0.0004, -0.0369, -0.0117,  0.0441,  0.0750,  0.0572, -0.0096,\n",
      "        -0.0117, -0.0063, -0.0135, -0.0261, -0.0206,  0.0218, -0.0808,  0.0042,\n",
      "         0.0882, -0.0660, -0.0653,  0.0559, -0.0706,  0.0661, -0.0863,  0.0591,\n",
      "        -0.0103, -0.0288, -0.0313,  0.0617,  0.0318,  0.0533, -0.0370, -0.0720,\n",
      "        -0.0179, -0.0262,  0.0430,  0.0831,  0.0073, -0.0794, -0.0421, -0.0724,\n",
      "        -0.0830, -0.0624, -0.0585,  0.0640,  0.0023, -0.0797,  0.0484,  0.0382,\n",
      "        -0.0502,  0.0021, -0.0205,  0.0068,  0.0059, -0.0176, -0.0564,  0.0749,\n",
      "        -0.0363,  0.0757, -0.0524, -0.0291, -0.0816, -0.0138,  0.0788,  0.0258,\n",
      "         0.0176,  0.0722,  0.0024, -0.0481, -0.0493, -0.0605, -0.0521, -0.0575,\n",
      "        -0.0486, -0.0327,  0.0276, -0.0399, -0.0051, -0.0373,  0.0216,  0.0451,\n",
      "         0.0034, -0.0479,  0.0104,  0.0219,  0.0113,  0.0463,  0.0576,  0.0252,\n",
      "         0.0454, -0.0422, -0.0464, -0.0737, -0.0541,  0.0117,  0.0778, -0.0161,\n",
      "         0.0142,  0.0127, -0.0352, -0.0392, -0.0528,  0.0102,  0.0041,  0.0392])\n",
      "Shape: torch.Size([128]), std: 0.0490, mean: -0.0031\n",
      "\n",
      "prediction.dense_layers.dense_layers.2.layer.weight:\n",
      "tensor([[-0.0080, -0.0497, -0.0561,  ...,  0.0442, -0.0780,  0.0644],\n",
      "        [ 0.0225,  0.0131,  0.0536,  ...,  0.0093, -0.0528, -0.0064],\n",
      "        [ 0.0062, -0.0842,  0.0684,  ..., -0.0068,  0.0521, -0.0221],\n",
      "        ...,\n",
      "        [-0.0036, -0.0096, -0.0713,  ...,  0.0828,  0.0222,  0.0326],\n",
      "        [ 0.0012, -0.0298, -0.0043,  ...,  0.0219,  0.0078,  0.0671],\n",
      "        [ 0.0033,  0.0445, -0.0506,  ...,  0.0099, -0.0782, -0.0337]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0509, mean: 0.0000\n",
      "\n",
      "prediction.dense_layers.dense_layers.2.layer.bias:\n",
      "tensor([ 0.0616,  0.0069,  0.0428,  0.0198,  0.0310,  0.0595, -0.0574, -0.0490,\n",
      "         0.0726,  0.0693, -0.0353,  0.0587, -0.0603,  0.0055, -0.0584,  0.0204,\n",
      "         0.0199, -0.0817, -0.0002, -0.0611,  0.0006,  0.0051, -0.0602,  0.0622,\n",
      "         0.0668,  0.0668, -0.0882, -0.0422,  0.0840, -0.0862, -0.0219,  0.0880,\n",
      "        -0.0419,  0.0008,  0.0508,  0.0454,  0.0841, -0.0832,  0.0455,  0.0153,\n",
      "        -0.0739, -0.0867,  0.0149,  0.0856, -0.0589,  0.0388, -0.0532,  0.0061,\n",
      "        -0.0583, -0.0409, -0.0296, -0.0463,  0.0154, -0.0169, -0.0751,  0.0770,\n",
      "         0.0067,  0.0338,  0.0615, -0.0693,  0.0833,  0.0858,  0.0815, -0.0515,\n",
      "        -0.0119, -0.0622,  0.0591, -0.0855,  0.0869, -0.0359, -0.0861, -0.0806,\n",
      "         0.0275,  0.0672, -0.0269,  0.0709,  0.0532, -0.0466, -0.0771,  0.0597,\n",
      "         0.0176, -0.0578, -0.0360, -0.0359, -0.0664,  0.0752, -0.0640, -0.0200,\n",
      "        -0.0261,  0.0788, -0.0635,  0.0755,  0.0495, -0.0379,  0.0074, -0.0006,\n",
      "        -0.0760,  0.0876, -0.0057,  0.0280, -0.0505,  0.0804, -0.0323,  0.0585,\n",
      "        -0.0813, -0.0475, -0.0590,  0.0767, -0.0401,  0.0670, -0.0138,  0.0483,\n",
      "        -0.0055, -0.0199, -0.0045, -0.0249, -0.0504,  0.0166, -0.0529,  0.0259,\n",
      "        -0.0629, -0.0526, -0.0183,  0.0047, -0.0456,  0.0177,  0.0495, -0.0014])\n",
      "Shape: torch.Size([128]), std: 0.0548, mean: -0.0015\n",
      "\n",
      "prediction.dense_layers.dense_layers.3.layer.weight:\n",
      "tensor([[ 0.0626,  0.0779,  0.0524,  ..., -0.0679, -0.0797,  0.0281],\n",
      "        [ 0.0159,  0.0580,  0.0614,  ...,  0.0863, -0.0037,  0.0623],\n",
      "        [-0.0367, -0.0104, -0.0836,  ...,  0.0010, -0.0644,  0.0073],\n",
      "        ...,\n",
      "        [ 0.0085, -0.0305,  0.0610,  ...,  0.0500, -0.0419, -0.0397],\n",
      "        [-0.0225, -0.0325,  0.0236,  ..., -0.0799, -0.0505,  0.0044],\n",
      "        [-0.0502, -0.0003, -0.0760,  ...,  0.0805, -0.0568,  0.0538]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0508, mean: 0.0002\n",
      "\n",
      "prediction.dense_layers.dense_layers.3.layer.bias:\n",
      "tensor([ 1.9056e-03, -3.4613e-02,  5.2637e-02, -4.3664e-02,  2.9054e-02,\n",
      "         7.5275e-02, -2.6769e-02,  7.7967e-02,  7.7957e-02, -1.4882e-03,\n",
      "        -5.3224e-02, -5.1394e-02,  7.3822e-02,  6.9054e-02,  7.7220e-02,\n",
      "         2.7665e-02, -2.4737e-02,  6.8130e-02, -9.9458e-03, -5.0495e-02,\n",
      "        -6.5807e-02, -6.2498e-02,  1.5020e-02, -8.7046e-02,  9.2357e-03,\n",
      "         8.4246e-02,  8.6025e-02,  7.4666e-02,  7.6772e-03, -7.8583e-02,\n",
      "        -1.2104e-02, -3.6060e-03,  5.8428e-02, -1.4179e-02, -2.8949e-02,\n",
      "         8.2670e-02,  5.1788e-02, -4.0072e-02,  3.8473e-02,  1.3094e-02,\n",
      "         8.3366e-02, -5.6283e-02, -2.5085e-02, -5.3442e-02,  2.0448e-02,\n",
      "        -1.2268e-02, -6.7532e-02,  4.5025e-02,  3.7622e-02, -7.0527e-02,\n",
      "        -8.3792e-02,  7.6630e-02,  6.3630e-02, -5.7166e-02, -7.0908e-02,\n",
      "         5.7384e-02, -2.8392e-02, -2.8830e-02,  8.1556e-02, -1.5493e-02,\n",
      "         3.2332e-02, -3.3051e-02, -8.4082e-02, -8.1379e-02,  8.5176e-02,\n",
      "         3.3158e-02, -7.5673e-02,  2.2429e-02, -8.5102e-02, -1.7701e-02,\n",
      "         7.7862e-03, -1.1800e-02, -4.6093e-03, -3.5750e-02,  5.2124e-02,\n",
      "        -6.9766e-02,  3.0089e-02,  8.9031e-03,  6.7214e-02, -7.3323e-02,\n",
      "         3.5561e-02,  4.6577e-02,  4.8678e-02,  2.0549e-02, -2.2511e-02,\n",
      "        -6.3784e-04,  6.8640e-02, -1.0833e-02,  4.8564e-05,  2.0270e-03,\n",
      "        -6.6366e-03,  1.2735e-02, -2.5757e-03,  2.8756e-02,  4.0762e-02,\n",
      "        -3.7753e-02,  1.1866e-02,  6.7442e-02,  8.6619e-02, -2.9507e-04,\n",
      "         6.3796e-02, -1.3129e-02,  1.4214e-02,  3.5577e-02, -3.6234e-02,\n",
      "        -2.9658e-02,  5.0631e-03, -2.6889e-02,  1.6084e-02, -7.8028e-02,\n",
      "         4.2320e-02,  1.1977e-03,  8.7727e-02, -1.8573e-02, -5.9113e-03,\n",
      "        -2.5165e-03, -6.2478e-02,  1.2860e-02,  1.9280e-02,  5.8095e-02,\n",
      "         5.5795e-02,  6.1085e-02, -2.3871e-02, -8.8258e-02, -8.6816e-02,\n",
      "        -3.4152e-02, -5.3651e-02,  3.4907e-02])\n",
      "Shape: torch.Size([128]), std: 0.0505, mean: 0.0036\n",
      "\n",
      "prediction.dense_layers.dense_layers.4.layer.weight:\n",
      "tensor([[ 0.0660, -0.0801,  0.0045,  ..., -0.0687,  0.0315, -0.0802],\n",
      "        [ 0.0287,  0.0425, -0.0148,  ...,  0.0527, -0.0822,  0.0634],\n",
      "        [-0.0727, -0.0627,  0.0058,  ..., -0.0021, -0.0796, -0.0708],\n",
      "        ...,\n",
      "        [-0.0170,  0.0802,  0.0223,  ..., -0.0115,  0.0657,  0.0690],\n",
      "        [ 0.0878,  0.0489,  0.0774,  ..., -0.0393,  0.0520,  0.0388],\n",
      "        [-0.0622, -0.0811, -0.0674,  ...,  0.0786, -0.0440,  0.0131]])\n",
      "Shape: torch.Size([128, 128]), std: 0.0512, mean: -0.0000\n",
      "\n",
      "prediction.dense_layers.dense_layers.4.layer.bias:\n",
      "tensor([ 0.0724, -0.0517, -0.0106,  0.0546, -0.0201, -0.0606,  0.0048,  0.0026,\n",
      "         0.0643,  0.0547, -0.0629,  0.0465, -0.0045,  0.0367,  0.0483,  0.0017,\n",
      "        -0.0075, -0.0113,  0.0338, -0.0144,  0.0593,  0.0266,  0.0147, -0.0312,\n",
      "         0.0743,  0.0395, -0.0796,  0.0517,  0.0326, -0.0308, -0.0196,  0.0800,\n",
      "        -0.0374, -0.0830,  0.0267, -0.0836,  0.0599,  0.0150,  0.0069,  0.0187,\n",
      "         0.0187, -0.0666, -0.0155,  0.0429, -0.0612, -0.0087, -0.0088,  0.0442,\n",
      "        -0.0623, -0.0694, -0.0152,  0.0444,  0.0238,  0.0031,  0.0152,  0.0418,\n",
      "        -0.0141, -0.0292,  0.0530,  0.0605,  0.0321,  0.0337,  0.0440, -0.0398,\n",
      "        -0.0488, -0.0772, -0.0311,  0.0212,  0.0705, -0.0265,  0.0351, -0.0335,\n",
      "        -0.0467, -0.0489, -0.0686,  0.0694,  0.0094, -0.0531, -0.0188,  0.0311,\n",
      "         0.0711, -0.0844, -0.0392,  0.0535, -0.0099,  0.0570, -0.0188,  0.0161,\n",
      "        -0.0411,  0.0836,  0.0025,  0.0407,  0.0006, -0.0174, -0.0516, -0.0530,\n",
      "         0.0784,  0.0511, -0.0464, -0.0341, -0.0451,  0.0238, -0.0033, -0.0167,\n",
      "        -0.0386, -0.0571,  0.0206,  0.0593, -0.0248, -0.0439, -0.0872,  0.0621,\n",
      "         0.0776,  0.0386, -0.0062, -0.0137, -0.0860, -0.0703, -0.0496, -0.0698,\n",
      "         0.0713, -0.0880,  0.0012,  0.0097, -0.0399,  0.0706,  0.0230,  0.0795])\n",
      "Shape: torch.Size([128]), std: 0.0476, mean: 0.0002\n",
      "\n",
      "prediction.critic.dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[ 9.0968e-03, -5.2820e-02,  1.5145e-02,  ..., -5.9754e-03,\n",
      "          8.1152e-02, -5.0977e-02],\n",
      "        [ 3.0856e-02, -4.0562e-02,  3.7682e-02,  ...,  1.0763e-02,\n",
      "          5.8807e-02, -3.6325e-02],\n",
      "        [-8.2543e-02,  6.0421e-02,  1.1450e-02,  ..., -5.8361e-02,\n",
      "          7.2534e-02,  4.7870e-02],\n",
      "        ...,\n",
      "        [ 1.6158e-02,  1.3507e-02, -3.4392e-05,  ...,  4.2775e-02,\n",
      "         -4.1894e-02, -6.1105e-02],\n",
      "        [ 1.5476e-02,  4.6212e-02,  3.3349e-02,  ..., -6.1164e-02,\n",
      "         -5.9477e-02, -8.4499e-02],\n",
      "        [ 7.8997e-02, -6.6205e-02,  3.5385e-02,  ...,  2.7642e-02,\n",
      "          3.3778e-02, -6.8438e-02]])\n",
      "Shape: torch.Size([32, 128]), std: 0.0509, mean: 0.0010\n",
      "\n",
      "prediction.critic.dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([ 0.0555,  0.0858, -0.0551, -0.0124, -0.0631, -0.0218,  0.0150,  0.0354,\n",
      "         0.0273, -0.0562,  0.0340, -0.0691,  0.0121,  0.0537, -0.0698,  0.0027,\n",
      "        -0.0806,  0.0738, -0.0019,  0.0314,  0.0372,  0.0253, -0.0597, -0.0015,\n",
      "         0.0575,  0.0743, -0.0207, -0.0740, -0.0753,  0.0707, -0.0253,  0.0300])\n",
      "Shape: torch.Size([32]), std: 0.0517, mean: 0.0011\n",
      "\n",
      "prediction.critic.value.layer.weight:\n",
      "tensor([[-0.1616, -0.1581, -0.1024,  0.0756,  0.0351, -0.0237, -0.0644, -0.1660,\n",
      "          0.0598,  0.0669,  0.0103, -0.0196, -0.1602,  0.1175,  0.0312, -0.0799,\n",
      "          0.1666,  0.1341,  0.1546,  0.0620,  0.0815, -0.0859, -0.0856,  0.1624,\n",
      "          0.0662, -0.0240,  0.1763,  0.0369,  0.1253, -0.0730,  0.1470, -0.0391]])\n",
      "Shape: torch.Size([1, 32]), std: 0.1066, mean: 0.0146\n",
      "\n",
      "prediction.critic.value.layer.bias:\n",
      "tensor([0.0978])\n",
      "Shape: torch.Size([1]), std: nan, mean: 0.0978\n",
      "\n",
      "prediction.actor.dense_layers.dense_layers.0.layer.weight:\n",
      "tensor([[ 0.0769,  0.0562,  0.0221,  ...,  0.0513,  0.0676,  0.0279],\n",
      "        [ 0.0251, -0.0812,  0.0870,  ..., -0.0608,  0.0612, -0.0040],\n",
      "        [-0.0820,  0.0634, -0.0474,  ...,  0.0375,  0.0758,  0.0533],\n",
      "        ...,\n",
      "        [ 0.0833,  0.0307, -0.0615,  ...,  0.0414,  0.0883,  0.0803],\n",
      "        [ 0.0407, -0.0719,  0.0338,  ..., -0.0771,  0.0707,  0.0224],\n",
      "        [ 0.0718, -0.0821,  0.0585,  ..., -0.0672,  0.0297, -0.0457]])\n",
      "Shape: torch.Size([32, 128]), std: 0.0513, mean: -0.0002\n",
      "\n",
      "prediction.actor.dense_layers.dense_layers.0.layer.bias:\n",
      "tensor([-0.0234,  0.0195,  0.0468,  0.0245, -0.0558,  0.0259,  0.0345, -0.0829,\n",
      "        -0.0592,  0.0283, -0.0614, -0.0077, -0.0369, -0.0549, -0.0091,  0.0301,\n",
      "         0.0470,  0.0222, -0.0873, -0.0085,  0.0216, -0.0712,  0.0459, -0.0433,\n",
      "         0.0182, -0.0497,  0.0710, -0.0088,  0.0038, -0.0684,  0.0401, -0.0386])\n",
      "Shape: torch.Size([32]), std: 0.0448, mean: -0.0090\n",
      "\n",
      "prediction.actor.actions.layer.weight:\n",
      "tensor([[ 0.1699,  0.0016, -0.1535,  ..., -0.0898, -0.1206,  0.1215],\n",
      "        [-0.0918, -0.1683,  0.0619,  ...,  0.1249,  0.1424, -0.1149],\n",
      "        [ 0.0862, -0.1186, -0.0354,  ...,  0.0577, -0.0019,  0.0116],\n",
      "        ...,\n",
      "        [ 0.1717, -0.1050,  0.1727,  ..., -0.1404,  0.0475,  0.0841],\n",
      "        [-0.1220,  0.0455, -0.0464,  ...,  0.0195,  0.1604,  0.1155],\n",
      "        [ 0.0331, -0.0192, -0.0966,  ..., -0.0908,  0.1613,  0.1483]])\n",
      "Shape: torch.Size([290, 32]), std: 0.1018, mean: 0.0005\n",
      "\n",
      "prediction.actor.actions.layer.bias:\n",
      "tensor([ 1.5384e-01, -5.9214e-04, -1.5026e-01,  9.4657e-02, -2.0215e-02,\n",
      "        -4.9674e-02, -2.6949e-02, -1.6604e-01,  1.4110e-01, -1.5813e-01,\n",
      "         3.8811e-02, -9.4555e-03,  3.3411e-02,  3.3596e-02, -4.3428e-02,\n",
      "         2.5822e-02,  3.9922e-02,  6.8673e-02,  9.6315e-02, -9.5022e-02,\n",
      "         4.6189e-02,  1.7528e-01,  1.0282e-01,  6.5460e-02, -1.5834e-01,\n",
      "         7.1348e-03,  1.2515e-01,  9.4863e-02, -3.7315e-02,  3.5822e-02,\n",
      "         1.1770e-01,  5.6429e-02, -8.1758e-02,  6.9119e-02, -1.4885e-02,\n",
      "         3.4110e-02,  4.9789e-02,  1.4254e-02,  1.1347e-01, -1.2526e-01,\n",
      "         5.5685e-02,  1.1317e-01, -1.3378e-01,  7.1926e-02, -5.6251e-02,\n",
      "        -1.0594e-01, -6.5777e-02, -6.5388e-02, -1.3648e-01, -9.1846e-02,\n",
      "         6.7499e-02, -6.6778e-02, -7.8601e-02,  6.4966e-02, -1.0354e-01,\n",
      "         8.6421e-02, -3.8644e-02,  8.6771e-02,  2.2653e-02, -9.5260e-02,\n",
      "         1.4242e-01, -5.6936e-03,  4.7757e-02,  1.0031e-01, -1.2811e-01,\n",
      "         5.2190e-02, -3.3304e-02, -1.1721e-01, -1.1518e-01, -1.4616e-01,\n",
      "        -1.4055e-01,  1.4420e-01,  7.1870e-02,  6.0292e-02, -8.1244e-02,\n",
      "        -1.8893e-02, -1.3598e-01,  8.8027e-03, -1.7500e-01, -8.7106e-02,\n",
      "         1.1399e-01,  3.4358e-02,  2.0466e-03, -1.5377e-01, -7.7345e-02,\n",
      "        -6.8202e-02,  7.4136e-02,  3.2220e-02,  9.3519e-02, -1.5820e-01,\n",
      "         1.3346e-01, -5.6840e-02,  6.5682e-02,  1.4073e-01, -3.9394e-02,\n",
      "        -3.7277e-03, -1.4911e-01, -1.0796e-01,  1.5446e-01,  4.9223e-04,\n",
      "        -5.1707e-02,  2.9385e-02, -1.6088e-01, -5.3040e-02,  6.7279e-02,\n",
      "        -2.6119e-02, -1.5143e-01,  1.2347e-01,  1.0448e-01,  1.0719e-01,\n",
      "        -2.8624e-02, -1.0305e-01, -1.0379e-01,  1.1888e-01, -9.4558e-02,\n",
      "        -1.2312e-01,  1.0428e-01, -7.9792e-02, -1.2968e-01, -1.6506e-01,\n",
      "        -1.5854e-01, -1.3692e-01, -7.1303e-02,  6.8150e-02, -5.0495e-03,\n",
      "        -9.6185e-02,  1.7144e-01,  1.7414e-01,  1.0366e-01,  7.5492e-02,\n",
      "         8.4189e-02, -3.0972e-02, -1.7492e-01, -7.4830e-02, -3.7463e-02,\n",
      "        -1.3081e-01,  2.4434e-02,  1.7393e-01, -1.9783e-02,  1.6012e-01,\n",
      "        -7.4334e-02, -1.5621e-01,  3.9017e-02, -1.4064e-01,  6.4187e-02,\n",
      "        -1.1418e-01,  8.5162e-02, -6.0294e-02, -8.0431e-02,  5.7510e-02,\n",
      "         1.6119e-01, -1.3770e-01,  1.0238e-01, -1.0086e-01,  1.2076e-01,\n",
      "        -1.2249e-01, -9.4966e-03,  7.4101e-02, -1.4392e-01,  4.3621e-02,\n",
      "         1.9033e-02,  5.5632e-02,  3.6395e-02,  6.1471e-02,  8.2343e-02,\n",
      "        -1.5199e-01,  1.4183e-01,  1.1352e-01, -7.4088e-02, -1.1826e-01,\n",
      "         1.6214e-01,  1.6042e-01, -1.0286e-01, -9.0870e-02,  1.1741e-01,\n",
      "         1.4039e-02,  8.1726e-02, -1.2249e-01,  7.2667e-02, -5.4931e-02,\n",
      "         7.0547e-02,  1.0714e-01, -7.7015e-02, -1.7674e-01,  1.8957e-02,\n",
      "        -1.6496e-01, -4.7643e-02, -6.1008e-02,  3.8486e-02,  9.5263e-02,\n",
      "         5.4916e-02, -6.2465e-02,  2.4125e-03, -6.8071e-02, -9.5871e-02,\n",
      "         1.3314e-04,  1.5970e-01,  9.9316e-02, -1.5448e-01, -7.6182e-02,\n",
      "        -5.2494e-03,  2.3585e-02,  1.2714e-01,  1.7309e-01,  1.6767e-01,\n",
      "         1.6841e-01, -1.3690e-02, -1.5396e-01, -1.1187e-01,  1.3622e-01,\n",
      "        -1.5744e-01, -1.2986e-01,  1.5858e-01, -1.4580e-01,  8.2157e-02,\n",
      "        -9.9247e-02,  2.1972e-02, -1.2652e-01,  4.1312e-02,  5.7995e-02,\n",
      "         3.2621e-02, -2.4216e-02, -5.8664e-02,  6.3233e-02, -1.5574e-01,\n",
      "        -1.1298e-01, -6.1862e-02,  1.1731e-01, -1.1416e-01, -1.5899e-01,\n",
      "        -4.8933e-02, -4.3569e-02, -1.5743e-01,  9.6858e-02,  5.9058e-02,\n",
      "         6.9562e-02,  3.0597e-02, -9.6958e-02,  9.3106e-02,  4.2302e-02,\n",
      "         1.6568e-01,  5.7729e-03,  2.5171e-02, -1.0366e-01, -1.2841e-01,\n",
      "         1.7382e-02, -1.3891e-01,  1.1838e-01,  9.5877e-02,  7.6160e-02,\n",
      "         1.2022e-01,  1.1735e-01,  8.1207e-02, -1.6786e-01, -1.6249e-01,\n",
      "        -2.3575e-03, -2.8104e-02,  1.2710e-01,  1.2885e-01,  5.8503e-02,\n",
      "        -1.2986e-02, -1.6066e-01, -1.3623e-01, -7.0012e-02,  2.6317e-02,\n",
      "         4.0950e-02, -9.8049e-02,  1.4195e-01,  1.4056e-01, -8.8944e-02,\n",
      "        -1.1917e-02,  1.3053e-01, -1.4794e-01,  1.5246e-01,  5.6134e-02,\n",
      "        -4.2907e-02,  4.0759e-02,  8.2159e-02, -3.7597e-02,  1.6987e-01,\n",
      "         1.4220e-01, -3.3110e-02, -1.2429e-01, -7.4568e-02, -5.1959e-02,\n",
      "         1.3747e-01,  9.8306e-02, -2.8204e-03,  5.5510e-02,  2.8089e-02])\n",
      "Shape: torch.Size([290]), std: 0.1007, mean: -0.0021\n",
      "\n",
      "Warning: for board games it is recommnded to have n_step >= game length\n",
      "Max size: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py:102: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
      "  f\"Shape: {param.shape}, std: {param.std():.4f}, mean: {param.mean():.4f}\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing stat 'score' with subkeys None\n",
      "Initializing stat 'policy_loss' with subkeys None\n",
      "Initializing stat 'value_loss' with subkeys None\n",
      "Initializing stat 'reward_loss' with subkeys None\n",
      "Initializing stat 'to_play_loss' with subkeys None\n",
      "Initializing stat 'loss' with subkeys None\n",
      "Initializing stat 'test_score' with subkeys ['score', 'max_score', 'min_score']\n",
      "Initializing stat 'episode_length' with subkeys None\n",
      "Initializing stat 'test_score_vs_RandomPlayer' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
      "Initializing stat 'test_score_vs_AlphaBetaPlayer' with subkeys ['score', 'player_0_score', 'player_1_score', 'player_0_win%', 'player_1_win%']\n",
      "[Worker 0] Starting self-play...\n",
      "[Worker 1] Starting self-play...\n",
      "[Worker 2] Starting self-play...\n",
      "[Worker 3] Starting self-play...\n",
      "Turn 0 Action 1: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 2)\n",
      "Turn 0 Action 1: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 0)\n",
      "Turn 0 Action 1: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 22)\n",
      "Turn 0 Action 1: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 10)\n",
      "Turn 0 Action 2: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (2, 9))\n",
      "Turn 0 Action 2: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (0, 5))\n",
      "Turn 0 Action 2: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (22, 23))\n",
      "Turn 0 Action 2: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (10, 29))\n",
      "Turn 1 Action 3: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 5)\n",
      "Turn 1 Action 3: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 44)\n",
      "Turn 1 Action 3: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 42)\n",
      "Turn 1 Action 3: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 5)\n",
      "Turn 1 Action 4: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (5, 16))\n",
      "Turn 1 Action 4: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (0, 5))\n",
      "Turn 1 Action 4: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (43, 44))\n",
      "Turn 1 Action 4: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (41, 42))\n",
      "Turn 1 Action 5: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 46)\n",
      "Turn 1 Action 5: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 44)\n",
      "Turn 1 Action 5: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 34)\n",
      "Turn 1 Action 5: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 34)\n",
      "Turn 1 Action 6: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (19, 46))\n",
      "Turn 1 Action 6: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (34, 35))\n",
      "Turn 1 Action 6: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (33, 34))\n",
      "Turn 1 Action 6: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (40, 44))\n",
      "Turn 2 Action 7: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 33)\n",
      "Turn 2 Action 7: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 3)\n",
      "Turn 2 Action 7: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 50)\n",
      "Turn 2 Action 7: (<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, 47)\n",
      "Turn 2 Action 8: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (32, 33))\n",
      "Turn 2 Action 8: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (2, 3))\n",
      "Turn 2 Action 8: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (43, 47))\n",
      "Turn 2 Action 8: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (50, 51))\n",
      "Turn 3 Action 9: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 5 Action 9: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 2 Action 9: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, 1, 0))\n",
      "Turn 3 Action 9: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 5 Action 10: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 0, 2))\n",
      "Turn 7 Action 10: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'WHEAT'))\n",
      "Turn 9 Action 10: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, -1, -1))\n",
      "Turn 5 Action 10: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 11 Action 11: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 5 Action 11: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 10 Action 11: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, -1, -1))\n",
      "Turn 12 Action 11: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', 'SHEEP', 'ORE'))\n",
      "Turn 11 Action 12: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 5 Action 12: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 9 Action 13: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'WHEAT'))\n",
      "Turn 12 Action 12: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', None, 'WHEAT'))\n",
      "Turn 12 Action 12: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'BRICK'))\n",
      "Turn 13 Action 13: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 13 Action 13: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 9 Action 14: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', None, 'ORE'))\n",
      "Turn 13 Action 14: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'ORE'))\n",
      "Turn 12 Action 13: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (2, 3))\n",
      "Turn 15 Action 14: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 17 Action 15: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'WOOD'))\n",
      "Turn 17 Action 14: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'BRICK'))\n",
      "Turn 10 Action 15: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, 0, 1))\n",
      "Turn 15 Action 15: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 17 Action 16: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (5, 16))\n",
      "Turn 17 Action 15: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (46, 48))\n",
      "Turn 13 Action 16: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 0, 2))\n",
      "Turn 15 Action 16: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 2, -2))\n",
      "Turn 15 Action 17: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 16 Action 17: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'BRICK'))\n",
      "Turn 22 Action 16: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 22 Action 17: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 19 Action 18: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'BRICK'))\n",
      "Turn 16 Action 18: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (1, -1, 0))\n",
      "Turn 21 Action 19: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 24 Action 18: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 24 Action 17: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 17 Action 19: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 25 Action 20: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (34, 35))\n",
      "Turn 26 Action 19: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 20 Action 20: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'WOOD'))\n",
      "Turn 24 Action 18: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 30 Action 21: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'BRICK'))\n",
      "Turn 23 Action 21: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 1, 1))\n",
      "Turn 28 Action 20: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 34 Action 22: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', 'BRICK', 'WOOD'))\n",
      "Turn 25 Action 22: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 26 Action 19: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 30 Action 21: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 27 Action 23: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 36 Action 23: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (51, 52))\n",
      "Turn 29 Action 24: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'WHEAT'))\n",
      "Turn 39 Action 24: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 31 Action 22: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 26 Action 20: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 41 Action 25: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'ORE'))\n",
      "Turn 32 Action 23: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', None, 'WOOD'))\n",
      "Turn 30 Action 25: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', 'SHEEP', 'ORE'))\n",
      "Turn 41 Action 26: (<ActionType.BUILD_CITY: 'BUILD_CITY'>, 34)\n",
      "Turn 26 Action 21: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 0, 0))\n",
      "Turn 32 Action 24: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (20, 22))\n",
      "Turn 27 Action 22: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 32 Action 26: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (1, -1, 0))\n",
      "Turn 33 Action 25: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 2, 0))\n",
      "Turn 33 Action 23: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (48, 49))\n",
      "Turn 42 Action 27: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 0, 2))\n",
      "Turn 43 Action 28: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, -1, 2))\n",
      "Turn 33 Action 27: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 40 Action 24: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 33 Action 26: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 35 Action 27: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 42 Action 25: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'ORE'))\n",
      "Turn 34 Action 28: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 52 Action 29: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 49 Action 26: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'ORE'))\n",
      "Turn 37 Action 28: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 37 Action 29: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (1, 1, -2))\n",
      "Turn 35 Action 29: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 52 Action 30: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 37 Action 30: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'WHEAT'))\n",
      "Turn 50 Action 27: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 54 Action 31: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 36 Action 30: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 37 Action 31: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 52 Action 28: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 39 Action 32: (<ActionType.PLAY_MONOPOLY: 'PLAY_MONOPOLY'>, 'WHEAT')\n",
      "Turn 56 Action 32: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 36 Action 31: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 40 Action 33: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 52 Action 29: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 56 Action 33: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 42 Action 34: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 36 Action 32: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 58 Action 34: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 43 Action 35: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 0, 2))\n",
      "Turn 52 Action 30: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 37 Action 33: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 44 Action 36: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 37 Action 34: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, -1, 2))\n",
      "Turn 60 Action 35: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, 0, 1))\n",
      "Turn 52 Action 31: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (3, 4))\n",
      "Turn 46 Action 37: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 37 Action 35: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 60 Action 36: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 61 Action 37: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 60 Action 32: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 1, 1))\n",
      "Turn 48 Action 38: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 39 Action 36: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 63 Action 33: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'ORE'))\n",
      "Turn 50 Action 39: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 62 Action 38: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 41 Action 37: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 64 Action 39: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'BRICK'))\n",
      "Turn 66 Action 34: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 0, 0))\n",
      "Turn 65 Action 40: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 52 Action 40: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 42 Action 38: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 66 Action 35: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (11, 32))\n",
      "Turn 52 Action 41: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 43 Action 39: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 66 Action 41: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 1, -1))\n",
      "Turn 75 Action 36: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, 1, 0))\n",
      "Turn 43 Action 40: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, 0, -2))\n",
      "Turn 54 Action 42: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 67 Action 42: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -2, 2))\n",
      "Turn 77 Action 37: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'BRICK'))\n",
      "Turn 67 Action 43: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (40, 42))\n",
      "Turn 47 Action 41: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 56 Action 43: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', None, 'WHEAT'))\n",
      "Turn 78 Action 38: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 49 Action 42: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', None, 'BRICK'))\n",
      "Turn 53 Action 43: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 56 Action 44: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', None, 'SHEEP'))\n",
      "Turn 70 Action 44: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-1, -1, 2))\n",
      "Turn 53 Action 44: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 80 Action 39: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 0, 0))\n",
      "Turn 73 Action 45: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'WHEAT'))\n",
      "Turn 55 Action 45: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (21, 43))\n",
      "Turn 56 Action 45: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 81 Action 46: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 80 Action 40: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 57 Action 46: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 0, 2))\n",
      "Turn 85 Action 47: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'ORE'))\n",
      "Turn 56 Action 46: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', 'SHEEP', 'ORE'))\n",
      "Turn 61 Action 47: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, -2, 0))\n",
      "Turn 80 Action 41: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 58 Action 47: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 85 Action 48: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 63 Action 48: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (1, 1, -2))\n",
      "Turn 82 Action 42: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 87 Action 49: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 64 Action 49: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 58 Action 48: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 87 Action 50: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, -1, -1))\n",
      "Turn 82 Action 43: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 66 Action 50: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'WHEAT'))\n",
      "Turn 88 Action 51: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'BRICK'))\n",
      "Turn 58 Action 49: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (2, -2, 0))\n",
      "Turn 67 Action 51: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 82 Action 44: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 2, -2))\n",
      "Turn 61 Action 50: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 92 Action 52: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', 'SHEEP', 'ORE'))\n",
      "Turn 93 Action 53: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, 0, 0))\n",
      "Turn 82 Action 45: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 62 Action 51: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 68 Action 52: (<ActionType.BUY_DEVELOPMENT_CARD: 'BUY_DEVELOPMENT_CARD'>, None)\n",
      "Turn 95 Action 54: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WOOD', 'WOOD', 'WOOD', 'WOOD', 'ORE'))\n",
      "Turn 84 Action 46: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 63 Action 52: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('SHEEP', 'SHEEP', 'SHEEP', None, 'ORE'))\n",
      "Turn 69 Action 53: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 86 Action 47: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 96 Action 55: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (-2, 2, 0))\n",
      "Turn 64 Action 53: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', None, 'ORE'))\n",
      "Turn 87 Action 48: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n",
      "Turn 70 Action 54: (<ActionType.ROLL: 'ROLL'>, None)\n",
      "Turn 96 Action 56: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('BRICK', 'BRICK', 'BRICK', 'BRICK', 'SHEEP'))\n",
      "Turn 87 Action 49: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'ORE'))\n",
      "Turn 64 Action 54: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('ORE', 'ORE', 'ORE', None, 'WOOD'))\n",
      "Turn 88 Action 50: (<ActionType.MARITIME_TRADE: 'MARITIME_TRADE'>, ('WHEAT', 'WHEAT', 'WHEAT', 'WHEAT', 'WOOD'))\n",
      "Turn 70 Action 55: (<ActionType.PLAY_KNIGHT_CARD: 'PLAY_KNIGHT_CARD'>, None)\n",
      "Turn 96 Action 57: (<ActionType.END_TURN: 'END_TURN'>, None)\n",
      "Turn 64 Action 55: (<ActionType.BUILD_ROAD: 'BUILD_ROAD'>, (43, 44))\n",
      "Turn 97 Action 58: (<ActionType.MOVE_ROBBER: 'MOVE_ROBBER'>, (0, -1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 226, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 812, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 749, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 384, in monte_carlo_tree_search\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_mcts.py\", line 56, in select_child\n",
      "    action_index = np.random.choice(\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 226, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 812, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 749, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 384, in monte_carlo_tree_search\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_mcts.py\", line 49, in select_child\n",
      "    child_ucbs = [\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_mcts.py\", line 49, in <listcomp>\n",
      "    child_ucbs = [\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 226, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 812, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 749, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 384, in monte_carlo_tree_search\n",
      "    action, node = node.select_child(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_mcts.py\", line 57, in select_child\n",
      "    np.where(np.isclose(child_ucbs, max(child_ucbs)))[0]\n",
      "KeyboardInterrupt\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 226, in worker_fn\n",
      "    score, num_steps = self.play_game(env=worker_env)\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 812, in play_game\n",
      "    prediction = self.predict(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 749, in predict\n",
      "    value, visit_counts = self.monte_carlo_tree_search(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py\", line 413, in monte_carlo_tree_search\n",
      "    node.expand(\n",
      "  File \"/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_mcts.py\", line 28, in expand\n",
      "    self.children[action] = Node((p / (policy_sum + 1e-10)).item(), self)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     79\u001b[0m agent\u001b[38;5;241m.\u001b[39mtest_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 81\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/catan/../../muzero/muzero_agent_torch.py:267\u001b[0m, in \u001b[0;36mMuZeroAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tb))  \u001b[38;5;66;03m# optional: print worker traceback\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrain_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m training_game \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgames_per_generation)):\n",
      "File \u001b[0;32m~/Documents/GitHub/rl-stuff/experiments/catan/../../stats/stats.py:113\u001b[0m, in \u001b[0;36mStatTracker.drain_queue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_client:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrain_queue() can only be called on the host StatTracker.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mget_nowait()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py:129\u001b[0m, in \u001b[0;36mQueue.empty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mempty\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:923\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(object_list, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    918\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m    Wait till an object in object_list is ready/readable.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m    Returns list of those objects in object_list which are ready/readable.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_WaitSelector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m selector:\n\u001b[1;32m    924\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m object_list:\n\u001b[1;32m    925\u001b[0m             selector\u001b[38;5;241m.\u001b[39mregister(obj, selectors\u001b[38;5;241m.\u001b[39mEVENT_READ)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:348\u001b[0m, in \u001b[0;36m_PollLikeSelector.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m _EVENT_READ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m _EVENT_WRITE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector_cls()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from agents.catan_player_wrapper import CatanPlayerWrapper\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "from muzero.action_functions import action_as_onehot, action_as_plane\n",
    "\n",
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.mcts import MCTSPlayer\n",
    "from catanatron.players.minimax import AlphaBetaPlayer\n",
    "from catanatron.players.playouts import GreedyPlayoutsPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.value import ValueFunctionPlayer\n",
    "\n",
    "from game_configs.catan_config import CatanConfig\n",
    "from custom_gym_envs.envs.catan import (\n",
    "    env as catan_env,\n",
    "    CatanAECEnv,\n",
    ")\n",
    "\n",
    "env = CatanConfig().make_env(\n",
    "    num_players=2,\n",
    "    map_type=\"BASE\",\n",
    "    vps_to_win=10,\n",
    "    representation=\"vector\",\n",
    "    invalid_action_reward=-10,\n",
    "    render_mode=None,\n",
    "    auto_play_single_action=True,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"num_simulations\": 100,\n",
    "    \"per_alpha\": 0.0,\n",
    "    \"per_beta\": 0.0,\n",
    "    \"per_beta_final\": 0.0,\n",
    "    \"action_function\": action_as_onehot,\n",
    "    \"n_step\": 1500,\n",
    "    \"residual_layers\": [],\n",
    "    \"dense_layer_widths\": [128] * 5,\n",
    "    \"reward_dense_layer_widths\": [32],\n",
    "    \"reward_conv_layers\": [],\n",
    "    \"actor_dense_layer_widths\": [32],\n",
    "    \"actor_conv_layers\": [],\n",
    "    \"critic_dense_layer_widths\": [32],\n",
    "    \"critic_conv_layers\": [],\n",
    "    \"to_play_dense_layer_widths\": [32],\n",
    "    \"to_play_conv_layers\": [],\n",
    "    \"known_bounds\": [-1, 1],\n",
    "    \"support_range\": None,\n",
    "    \"minibatch_size\": 1024,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"lr_ratio\": float(\"inf\"),\n",
    "    \"num_workers\": 4,\n",
    "    \"min_replay_buffer_size\": 4096,\n",
    "    \"root_dirichlet_alpha\": 0.03,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"temperature_updates\": [500],\n",
    "}\n",
    "game_config = CatanConfig()\n",
    "config = MuZeroConfig(config_dict=params, game_config=game_config)\n",
    "\n",
    "\n",
    "agent = MuZeroAgent(\n",
    "    env=env,\n",
    "    config=config,\n",
    "    name=\"catan_testing\",\n",
    "    device=\"cpu\",\n",
    "    test_agents=[\n",
    "        CatanPlayerWrapper(RandomPlayer, Color.BLUE),\n",
    "        CatanPlayerWrapper(AlphaBetaPlayer, Color.BLUE),\n",
    "    ],\n",
    ")\n",
    "agent.checkpoint_interval = 1\n",
    "agent.test_interval = 100\n",
    "agent.test_trials = 10\n",
    "\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New SMALLEST SEARCH SPACE, IMPROVED\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from hyperparameter_optimization.hyperopt import save_search_space\n",
    "\n",
    "\n",
    "import dill as pickle\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from utils import CategoricalCrossentropyLoss, MSELoss, generate_layer_widths\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from muzero.action_functions import action_as_onehot as action_function\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# size = 5 * 1 * 1 * 4.0 * 3 * 2.0 * 5 * 1 * 1 = 600\n",
    "\n",
    "search_space = {\n",
    "    \"kernel_initializer\": hp.choice(\n",
    "        \"kernel_initializer\",\n",
    "        [\n",
    "            \"he_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"orthogonal\",\n",
    "        ],\n",
    "    ),\n",
    "    \"optimizer\": hp.choice(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            {\n",
    "                \"optimizer\": \"adam\",\n",
    "                # \"adam_epsilon\": 10 ** (-hp.quniform(\"adam_epsilon\", 8, 8 + 1e-8, 2)),\n",
    "                \"adam_epsilon\": hp.choice(\"adam_epsilon\", [1e-8]),\n",
    "                \"adam_learning_rate\": 10\n",
    "                ** (-hp.quniform(\"adam_learning_rate\", 3, 3 + 1e-8, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"optimizer\": \"sgd\",\n",
    "            #     \"momentum\": hp.choice(\"momentum\", [0.0, 0.9]),\n",
    "            #     \"sgd_learning_rate\": 10 ** (-hp.quniform(\"sgd_learning_rate\", 1, 3, 1)),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"conv_layers\": hp.choice(\"conv_layers\", [[]]),\n",
    "    \"known_bounds\": hp.choice(\"known_bounds\", [[-1, 1]]),\n",
    "    # \"residual_filters\": scope.int(\n",
    "    #     hp.qloguniform(\"residual_filters\", np.log(24), np.log(24) + 1e-8, 8)\n",
    "    # ),\n",
    "    # \"residual_stacks\": scope.int(\n",
    "    #     hp.qloguniform(\"residual_stacks\", np.log(1), np.log(4), 1)\n",
    "    # ),\n",
    "    \"residual_layers\": hp.choice(\"residual_layers\", [[]]),\n",
    "    \"actor_conv_layers\": hp.choice(\"actor_conv_layers\", [[]]),\n",
    "    \"critic_conv_layers\": hp.choice(\"critic_conv_layers\", [[]]),\n",
    "    \"reward_conv_layers\": hp.choice(\"reward_conv_layers\", [[]]),\n",
    "    \"to_play_conv_layers\": hp.choice(\"to_play_conv_layers\", [[]]),\n",
    "    \"output_layer_widths\": scope.int(\n",
    "        hp.quniform(\"output_layer_widths\", 16, 16 + 1e-8, 16)\n",
    "    ),\n",
    "    \"dense_layer_width\": scope.int(2 ** hp.quniform(\"dense_layer_width\", 7, 9, 1)),\n",
    "    \"dense_layers\": scope.int(hp.quniform(\"dense_layers\", 1, 1 + 1e-8, 1)),\n",
    "    \"noisy_sigma\": hp.choice(\"noisy_sigma\", [0.0]),\n",
    "    \"value_loss_factor\": hp.choice(\"value_loss_factor\", [1.0]),\n",
    "    \"root_dirichlet_alpha\": 2\n",
    "    ** (hp.quniform(\"root_dirichlet_alpha\", -5, -5 + 1e-8, 1.0)),\n",
    "    \"root_exploration_fraction\": hp.choice(\"root_exploration_fraction\", [0.25]),\n",
    "    \"num_simulations\": scope.int(\n",
    "        800 * 2 ** hp.quniform(\"num_simulations\", -5, -5 + 1e-8, 1)\n",
    "    ),\n",
    "    \"temperature_updates\": [\n",
    "        scope.int(hp.quniform(\"temperature_updates\", 256, 512, 32))\n",
    "    ],\n",
    "    \"temperatures\": hp.choice(\"temperatures\", [[1.0, 0.1]]),\n",
    "    \"temperature_with_training_steps\": hp.choice(\n",
    "        \"temperature_with_training_steps\", [False]\n",
    "    ),\n",
    "    \"clip_low_prob\": hp.choice(\"clip_low_prob\", [0.0]),\n",
    "    \"pb_c_base\": hp.choice(\"pb_c_base\", [19652]),\n",
    "    \"pb_c_init\": hp.choice(\"pb_c_init\", [1.25]),\n",
    "    \"value_loss_function\": hp.choice(\"value_loss_function\", [MSELoss()]),\n",
    "    \"reward_loss_function\": hp.choice(\"reward_loss_function\", [MSELoss()]),\n",
    "    \"policy_loss_function\": hp.choice(\n",
    "        \"policy_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"to_play_loss_function\": hp.choice(\n",
    "        \"to_play_loss_function\", [CategoricalCrossentropyLoss()]\n",
    "    ),\n",
    "    \"training_steps\": scope.int(\n",
    "        hp.qloguniform(\"training_steps\", np.log(100), np.log(1000), 100)\n",
    "    ),\n",
    "    \"minibatch_size\": scope.int(2 ** (hp.quniform(\"minibatch_size\", 3, 11, 1))),\n",
    "    \"min_replay_buffer_size\": scope.int(\n",
    "        10 ** hp.quniform(\"min_replay_buffer_size\", 3, 3 + 1e-8, 1)\n",
    "    ),\n",
    "    \"replay_buffer_size\": scope.int(\n",
    "        10 ** (hp.quniform(\"replay_buffer_size\", 5, 5 + 1e-8, 1))\n",
    "    ),\n",
    "    \"unroll_steps\": hp.choice(\"unroll_steps\", [5]),\n",
    "    \"n_step\": hp.choice(\"n_step\", [10000]),\n",
    "    \"clipnorm\": hp.choice(\n",
    "        # \"clipnorm\", [0.0, scope.int(10 ** (hp.quniform(\"clip_val\", 0, 2, 1)))]\n",
    "        \"clipnorm\",\n",
    "        [0.0],\n",
    "    ),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-4]),\n",
    "    \"per_alpha\": hp.quniform(\"per_alpha\", 0.0, 0.0 + 1e-8, 0.5),\n",
    "    \"per_beta\": hp.quniform(\"per_beta\", 0.0, 0.0 + 1e-8, 0.5),\n",
    "    \"per_beta_final\": hp.quniform(\"per_beta_final\", 0.0, 0.0 + 1e-8, 0.5),\n",
    "    \"per_epsilon\": hp.choice(\"per_epsilon\", [1e-4]),\n",
    "    \"action_function\": hp.choice(\"action_function\", [action_function]),\n",
    "    \"multi_process\": hp.choice(\n",
    "        \"multi_process\",\n",
    "        [\n",
    "            {\n",
    "                \"multi_process\": True,\n",
    "                \"num_workers\": scope.int(hp.quniform(\"num_workers\", 2, 3, 1)),\n",
    "            },\n",
    "            # {\n",
    "            #     \"multi_process\": False,\n",
    "            #     \"games_per_generation\": scope.int(\n",
    "            #         hp.qloguniform(\"games_per_generation\", np.log(8), np.log(32), 8)\n",
    "            #     ),\n",
    "            # },\n",
    "        ],\n",
    "    ),\n",
    "    \"lr_ratio\": hp.choice(\"lr_ratio\", [float(\"inf\"), 0.1]),\n",
    "    \"num_vps_to_win\": hp.quniform(\"num_vps_to_win\", 10, 10 + 1e-8, 1),\n",
    "}\n",
    "\n",
    "initial_best_config = []\n",
    "\n",
    "search_space, initial_best_config = save_search_space(search_space, initial_best_config)\n",
    "\n",
    "\n",
    "def prep_params(params):\n",
    "    params[\"dense_layer_widths\"] = [params[\"dense_layer_width\"]] * params[\n",
    "        \"dense_layers\"\n",
    "    ]\n",
    "    del params[\"dense_layer_width\"]\n",
    "    del params[\"dense_layers\"]\n",
    "    if params[\"output_layer_widths\"] != 0:\n",
    "        params[\"actor_dense_layer_widths\"] = [params[\"output_layer_widths\"]]\n",
    "        params[\"critic_dense_layer_widths\"] = [params[\"output_layer_widths\"]]\n",
    "        params[\"reward_dense_layer_widths\"] = [params[\"output_layer_widths\"]]\n",
    "        params[\"to_play_dense_layer_widths\"] = [params[\"output_layer_widths\"]]\n",
    "    else:\n",
    "        params[\"actor_dense_layer_widths\"] = []\n",
    "        params[\"critic_dense_layer_widths\"] = []\n",
    "        params[\"reward_dense_layer_widths\"] = []\n",
    "        params[\"to_play_dense_layer_widths\"] = []\n",
    "    del params[\"output_layer_widths\"]\n",
    "\n",
    "    if params[\"multi_process\"][\"multi_process\"] == True:\n",
    "        params[\"num_workers\"] = params[\"multi_process\"][\"num_workers\"]\n",
    "        params[\"multi_process\"] = True\n",
    "    else:\n",
    "        params[\"games_per_generation\"] = params[\"multi_process\"][\"games_per_generation\"]\n",
    "        params[\"multi_process\"] = False\n",
    "\n",
    "    if params[\"optimizer\"][\"optimizer\"] == \"adam\":\n",
    "        params[\"adam_epsilon\"] = params[\"optimizer\"][\"adam_epsilon\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"adam_learning_rate\"]\n",
    "        params[\"optimizer\"] = Adam\n",
    "    elif params[\"optimizer\"][\"optimizer\"] == \"sgd\":\n",
    "        params[\"momentum\"] = params[\"optimizer\"][\"momentum\"]\n",
    "        params[\"learning_rate\"] = params[\"optimizer\"][\"sgd_learning_rate\"]\n",
    "        params[\"optimizer\"] = SGD\n",
    "\n",
    "    if isinstance(params[\"clipnorm\"], dict):\n",
    "        params[\"clipnorm\"] = params[\"clipnorm\"][\"clipval\"]\n",
    "    params[\"support_range\"] = None\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_configs.catan_config import CatanConfig\n",
    "import torch\n",
    "from custom_gym_envs.envs.catan import (\n",
    "    env as catan_env,\n",
    "    CatanAECEnv,\n",
    ")\n",
    "\n",
    "\n",
    "def play_game(player1, player2):\n",
    "\n",
    "    env = CatanConfig().make_env()\n",
    "    with torch.no_grad():  # No gradient computation during testing\n",
    "        # Reset environment\n",
    "        env.reset()\n",
    "        state, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "        agent_id = env.agent_selection\n",
    "        current_player = env.agents.index(agent_id)\n",
    "        # state, info = process_petting_zoo_obs(state, info, current_player)\n",
    "        agent_names = env.agents.copy()\n",
    "\n",
    "        episode_length = 0\n",
    "        while not done and episode_length < 1000:  # Safety limit\n",
    "            # Get current agent and player\n",
    "            if current_player == 0:\n",
    "                prediction = player1.predict(state, info, env=env, temperature=0.05)\n",
    "                action = player1.select_actions(prediction, info).item()\n",
    "            else:\n",
    "                prediction = player2.predict(state, info, env=env, temperature=0.05)\n",
    "                action = player2.select_actions(prediction, info).item()\n",
    "\n",
    "            # Step environment\n",
    "            env.step(action)\n",
    "            state, reward, termination, truncation, info = env.last()\n",
    "            agent_id = env.agent_selection\n",
    "            current_player = env.agents.index(agent_id)\n",
    "            # state, info = process_petting_zoo_obs(state, info, current_player)\n",
    "            done = termination or truncation\n",
    "            episode_length += 1\n",
    "        print(env.rewards)\n",
    "        return env.rewards[\"player_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.catan_player_wrapper import CatanPlayerWrapper\n",
    "from hyperparameter_optimization.hyperopt import (\n",
    "    marl_objective,\n",
    "    set_marl_config,\n",
    "    MarlHyperoptConfig,\n",
    ")\n",
    "from hyperopt import atpe, tpe, fmin, space_eval\n",
    "from hyperopt.exceptions import AllTrialsFailed\n",
    "\n",
    "from muzero.muzero_agent_torch import MuZeroAgent\n",
    "from agent_configs import MuZeroConfig\n",
    "\n",
    "search_space_path, initial_best_config_path = (\n",
    "    \"search_space.pkl\",\n",
    "    \"best_config.pkl\",\n",
    ")\n",
    "# search_space = pickle.load(open(search_space_path, \"rb\"))\n",
    "# initial_best_config = pickle.load(open(initial_best_config_path, \"rb\"))\n",
    "file_name = \"catan_muzero\"\n",
    "max_trials = 64\n",
    "trials_step = 24  # how many additional trials to do after loading the last ones\n",
    "\n",
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.mcts import MCTSPlayer\n",
    "from catanatron.players.minimax import AlphaBetaPlayer\n",
    "from catanatron.players.playouts import GreedyPlayoutsPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.value import ValueFunctionPlayer\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import dill as pickle\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from elo.elo import StandingsTable\n",
    "\n",
    "games_per_pair = 10\n",
    "try:\n",
    "    players = pickle.load(open(\"./tictactoe_players.pkl\", \"rb\"))\n",
    "    table = pickle.load(open(\"./tictactoe_table.pkl\", \"rb\"))\n",
    "    print(table.bayes_elo())\n",
    "    print(table.get_win_table())\n",
    "    print(table.get_draw_table())\n",
    "except:\n",
    "    players = []\n",
    "    table = StandingsTable([], start_elo=1000)\n",
    "\n",
    "\n",
    "set_marl_config(\n",
    "    MarlHyperoptConfig(\n",
    "        file_name=file_name,\n",
    "        eval_method=\"test_agents_elo\",\n",
    "        best_agent=CatanPlayerWrapper(AlphaBetaPlayer, Color.BLUE),\n",
    "        make_env=CatanConfig().make_env,\n",
    "        prep_params=prep_params,\n",
    "        agent_class=MuZeroAgent,\n",
    "        agent_config=MuZeroConfig,\n",
    "        game_config=CatanConfig,\n",
    "        games_per_pair=10,\n",
    "        num_opps=1,  # not used\n",
    "        table=table,  # not used\n",
    "        play_game=play_game,\n",
    "        checkpoint_interval=10,\n",
    "        test_interval=100,\n",
    "        test_trials=10,\n",
    "        test_agents=[\n",
    "            CatanPlayerWrapper(RandomPlayer, Color.BLUE),\n",
    "            CatanPlayerWrapper(AlphaBetaPlayer, Color.BLUE),\n",
    "        ],\n",
    "        test_agent_weights=[1.0, 2.0],\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "try:  # try to load an already saved trials object, and increase the max\n",
    "    trials = pickle.load(open(f\"./{file_name}_trials.p\", \"rb\"))\n",
    "    print(\"Found saved Trials! Loading...\")\n",
    "    max_trials = len(trials.trials) + trials_step\n",
    "    print(\n",
    "        \"Rerunning from {} trials to {} (+{}) trials\".format(\n",
    "            len(trials.trials), max_trials, trials_step\n",
    "        )\n",
    "    )\n",
    "except:  # create a new trials object and start searching\n",
    "    print(\"No saved Trials! Starting from scratch.\")\n",
    "    trials = None\n",
    "\n",
    "best = fmin(\n",
    "    fn=marl_objective,  # Objective Function to optimize\n",
    "    space=search_space,  # Hyperparameter's Search Space\n",
    "    algo=atpe.suggest,  # Optimization algorithm (representative TPE)\n",
    "    max_evals=max_trials,  # Number of optimization attempts\n",
    "    trials=trials,  # Record the results\n",
    "    # early_stop_fn=no_progress_loss(5, 1),\n",
    "    trials_save_file=f\"./{file_name}_trials.p\",\n",
    "    points_to_evaluate=initial_best_config,\n",
    "    show_progressbar=False,\n",
    ")\n",
    "print(best)\n",
    "best_trial = space_eval(search_space, best)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65445e1d",
   "metadata": {},
   "source": [
    "RAINBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.append(\"/content/rl-research\")\n",
    "sys.path.append(\"../..\")\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "from wrappers import CatanatronWrapper\n",
    "from utils import CategoricalCrossentropyLoss, KLDivergenceLoss\n",
    "\n",
    "\n",
    "from dqn.rainbow.rainbow_agent import RainbowAgent\n",
    "from agent_configs import RainbowConfig\n",
    "from game_configs.catan_config import SinglePlayerCatanConfig\n",
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.mcts import MCTSPlayer\n",
    "from catanatron.players.minimax import AlphaBetaPlayer\n",
    "from catanatron.players.playouts import GreedyPlayoutsPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.value import ValueFunctionPlayer\n",
    "\n",
    "config_dict = {\n",
    "    \"dense_layer_widths\": [1024, 1024],\n",
    "    \"value_hidden_layers_widths\": [512],  #\n",
    "    \"advatage_hidden_layers_widths\": [512],  #\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"training_steps\": 30000,\n",
    "    \"per_epsilon\": 1e-6,\n",
    "    \"per_alpha\": 0.5,\n",
    "    \"per_beta\": 0.5,\n",
    "    \"minibatch_size\": 128,\n",
    "    \"replay_buffer_size\": 500000,\n",
    "    \"min_replay_buffer_size\": 5000,\n",
    "    \"transfer_interval\": 100,\n",
    "    \"n_step\": 10000,\n",
    "    \"kernel_initializer\": \"orthogonal\",\n",
    "    \"loss_function\": KLDivergenceLoss(),\n",
    "    \"clipnorm\": 0.0,\n",
    "    \"discount_factor\": 0.9999,  # or 0.999 or even 0.9999 not 0.99 < this makes the start of the game possibly 0.05 after bootstrapping\n",
    "    \"atom_size\": 51,\n",
    "    \"replay_interval\": 4096,\n",
    "}\n",
    "game_config = SinglePlayerCatanConfig()\n",
    "config = RainbowConfig(config_dict, game_config)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "import catanatron.gym\n",
    "import gymnasium as gym\n",
    "\n",
    "env = CatanatronWrapper(\n",
    "    gym.make(\n",
    "        \"catanatron/Catanatron-v0\",\n",
    "        config={\n",
    "            \"enemies\": [RandomPlayer(Color.RED)],\n",
    "            \"invalid_action_reward\": -10,\n",
    "            \"map_type\": \"BASE\",\n",
    "            \"vps_to_win\": 6,\n",
    "            \"representation\": \"vector\",\n",
    "        },\n",
    "    )\n",
    ")\n",
    "agent = RainbowAgent(env, config, \"rainbow-catan-10vps\", device)\n",
    "agent.checkpoint_interval = 1\n",
    "agent.test_interval = 100\n",
    "agent.test_trials = 25\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared network but not shared buffer?\n",
    "# 1 vs 2 minibatches\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from dqn.NFSP.nfsp_agent_clean import NFSPDQN\n",
    "from agent_configs import NFSPDQNConfig\n",
    "from game_configs import CatanConfig\n",
    "from utils import KLDivergenceLoss, CategoricalCrossentropyLoss, HuberLoss, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from wrappers import ActionMaskInInfoWrapper, FrameStackWrapper\n",
    "\n",
    "config_dict = {\n",
    "    \"shared_networks_and_buffers\": False,\n",
    "    \"training_steps\": 500000,\n",
    "    \"anticipatory_param\": 0.1,\n",
    "    \"replay_interval\": 2048,  #\n",
    "    \"num_minibatches\": 1,  # or 2, could be 2 minibatches per network, or 2 minibatches (1 for each network/player)\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"momentum\": 0.0,\n",
    "    \"optimizer\": SGD,\n",
    "    \"loss_function\": MSELoss(),\n",
    "    \"min_replay_buffer_size\": 5000,\n",
    "    \"minibatch_size\": 1024,\n",
    "    \"replay_buffer_size\": 1e5,\n",
    "    \"transfer_interval\": 100,\n",
    "    \"residual_layers\": [],\n",
    "    \"conv_layers\": [],\n",
    "    \"dense_layer_widths\": [1024],\n",
    "    \"value_hidden_layer_widths\": [],\n",
    "    \"advantage_hidden_layer_widths\": [],\n",
    "    \"noisy_sigma\": 0.0,\n",
    "    \"eg_epsilon\": 0.12,\n",
    "    # \"eg_epsilon_final\": 0.06,\n",
    "    \"eg_epsilon_decay_type\": \"inverse_sqrt\",\n",
    "    \"eg_epsilon_decay_final_step\": 0,\n",
    "    \"sl_learning_rate\": 0.005,\n",
    "    \"sl_momentum\": 0.0,\n",
    "    # \"sl_weight_decay\": 1e-9,\n",
    "    # \"sl_clipnorm\": 1.0,\n",
    "    \"sl_optimizer\": SGD,\n",
    "    \"sl_loss_function\": CategoricalCrossentropyLoss(),\n",
    "    \"sl_min_replay_buffer_size\": 5000,\n",
    "    \"sl_minibatch_size\": 1024,\n",
    "    \"sl_replay_buffer_size\": 100000,\n",
    "    \"sl_residual_layers\": [],\n",
    "    \"sl_conv_layers\": [],\n",
    "    \"sl_dense_layer_widths\": [1024, 1024, 1024],\n",
    "    \"sl_clip_low_prob\": 0.0,\n",
    "    \"per_alpha\": 0.5,\n",
    "    \"per_beta\": 1.0,\n",
    "    \"per_beta_final\": 1.0,\n",
    "    \"per_epsilon\": 0.00001,\n",
    "    \"n_step\": 9,\n",
    "    \"atom_size\": 1,\n",
    "    \"dueling\": True,\n",
    "    \"clipnorm\": 10.0,\n",
    "    \"sl_clipnorm\": 10.0,\n",
    "}\n",
    "config = NFSPDQNConfig(\n",
    "    config_dict=config_dict,\n",
    "    game_config=CatanConfig(),\n",
    ")\n",
    "config.save_intermediate_weights = False\n",
    "from custom_gym_envs.envs.catan import (\n",
    "    env as catan_env,\n",
    "    CatanAECEnv,\n",
    ")\n",
    "\n",
    "env = catan_env(\n",
    "    num_players=2,\n",
    "    map_type=\"BASE\",\n",
    "    vps_to_win=10,\n",
    "    representation=\"vector\",\n",
    "    invalid_action_reward=-10,\n",
    ")\n",
    "\n",
    "env = ActionMaskInInfoWrapper(env)\n",
    "env = FrameStackWrapper(env, 4, channel_first=False)\n",
    "\n",
    "agent = NFSPDQN(env, config, name=\"nfsp-catan\", device=\"cpu\")\n",
    "agent.checkpoint_interval = 100\n",
    "agent.test_interval = 1000\n",
    "agent.test_trials = 100\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import catanatron.gym\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import gymnasium as gym\n",
    "import random\n",
    "\n",
    "env = gym.make(\"catanatron/Catanatron-v0\")\n",
    "observation, info = env.reset()\n",
    "for _ in range(1000):\n",
    "    # your agent here (this takes random actions)\n",
    "    action = random.choice(info[\"valid_actions\"])\n",
    "\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.mcts import MCTSPlayer\n",
    "from catanatron.players.minimax import AlphaBetaPlayer\n",
    "from catanatron.players.playouts import GreedyPlayoutsPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.value import ValueFunctionPlayer\n",
    "\n",
    "# Instantiate two random players\n",
    "player1 = RandomPlayer(Color.RED)\n",
    "player2 = RandomPlayer(Color.BLUE)\n",
    "\n",
    "# Create a 2-player game (you can fill remaining slots with random agents if needed)\n",
    "players = [player1, player2]\n",
    "game = Game(players)\n",
    "\n",
    "winner = game.play()\n",
    "print(f\"Winner: {winner}\")\n",
    "\n",
    "\n",
    "def play_game(player1, player2):\n",
    "    player1 = player1(Color.RED)\n",
    "    player2 = player2(Color.BLUE)\n",
    "    game = Game([player1, player2])\n",
    "    winner = game.play()\n",
    "\n",
    "    if winner == Color.RED:\n",
    "        return 1\n",
    "    elif winner == Color.BLUE:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from elo.elo import StandingsTable\n",
    "\n",
    "players = [\n",
    "    RandomPlayer,\n",
    "    MCTSPlayer,\n",
    "    AlphaBetaPlayer,\n",
    "    # GreedyPlayoutsPlayer,\n",
    "    VictoryPointPlayer,\n",
    "    WeightedRandomPlayer,\n",
    "    # ValueFunctionPlayer,\n",
    "]\n",
    "games_per_pair = 10\n",
    "\n",
    "player_names = [p.__name__ for p in players]\n",
    "table = StandingsTable(player_names, start_elo=1000)\n",
    "\n",
    "\n",
    "def play_1v1_tournament(players, games_per_pair, play_game):\n",
    "    tournament_results = []\n",
    "    for player1 in players:\n",
    "        results = play_matches(player1, players, games_per_pair, play_game)\n",
    "        tournament_results.extend(results)\n",
    "    tournament_results = pd.DataFrame(\n",
    "        tournament_results, columns=[\"player1\", \"player2\", \"result\"]\n",
    "    )\n",
    "    return tournament_results\n",
    "\n",
    "\n",
    "def play_matches(player1, players, games_per_pair, play_game):\n",
    "    results = []\n",
    "    for opponent in players:\n",
    "        if opponent != player1:\n",
    "            for _ in range(games_per_pair // 2):\n",
    "                print(f\"Playing {player1.__name__} vs {opponent.__name__} game {_+1}\")\n",
    "                result = play_game(player1, opponent)\n",
    "                results.append((player1.__name__, opponent.__name__, result))\n",
    "\n",
    "    for opponent in players:\n",
    "        if opponent != player1:\n",
    "            for _ in range(games_per_pair // 2):\n",
    "                print(f\"Playing {opponent.__name__} vs {player1.__name__} game {_+1}\")\n",
    "                result = play_game(opponent, player1)\n",
    "                results.append(\n",
    "                    (\n",
    "                        player_names[players.index(opponent)],\n",
    "                        player_names[players.index(player1)],\n",
    "                        result,\n",
    "                    )\n",
    "                )\n",
    "    table.add_results_from_array(results)\n",
    "    print(table.bayes_elo())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(table.bayes_elo())\n",
    "print(table.get_win_table())\n",
    "print(table.get_draw_table())\n",
    "file = \"catan_1v1_tournament_results.pkl\"\n",
    "pickle.dump(table, open(file, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.mcts import MCTSPlayer\n",
    "from catanatron.players.minimax import AlphaBetaPlayer\n",
    "from catanatron.players.playouts import GreedyPlayoutsPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.value import ValueFunctionPlayer\n",
    "\n",
    "table.add_player(GreedyPlayoutsPlayer.__name__)\n",
    "players.append(GreedyPlayoutsPlayer) if GreedyPlayoutsPlayer not in players else None\n",
    "\n",
    "play_matches(GreedyPlayoutsPlayer, players, games_per_pair * 2, play_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = play_1v1_tournament(players, games_per_pair, play_game)\n",
    "\n",
    "\n",
    "# table.add_results_from_dataframe(results)  # Adding multiple results\n",
    "print(table.bayes_elo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abaa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a petting zoo environment to see if it has all the functions and attributes needed\n",
    "from custom_gym_envs.envs.catan import (\n",
    "    env as catan_env,\n",
    "    CatanAECEnv,\n",
    ")\n",
    "\n",
    "env = catan_env(\n",
    "    render_mode=\"human\",\n",
    "    num_players=2,\n",
    "    map_type=\"BASE\",\n",
    "    vps_to_win=10,\n",
    "    representation=\"vector\",\n",
    "    invalid_action_reward=-1,\n",
    ")\n",
    "\n",
    "\n",
    "# test reset\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "\n",
    "# # Get initial state for first agent\n",
    "# state, reward, termination, truncation, info = env.last()\n",
    "# print(state, info)\n",
    "\n",
    "\n",
    "# ab_player = CatanPlayerWrapper(AlphaBetaPlayer, Color.RED)\n",
    "# prediction = ab_player.predict(state, info, env)\n",
    "# action = ab_player.select_actions(prediction, info)\n",
    "# print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95931df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from custom_gym_envs.envs.catan import (\n",
    "    env as catan_env,\n",
    "    CatanAECEnv,\n",
    ")\n",
    "\n",
    "env = catan_env(\n",
    "    render_mode=\"rgb_array\",\n",
    "    num_players=2,\n",
    "    map_type=\"BASE\",\n",
    "    vps_to_win=10,\n",
    "    representation=\"vector\",\n",
    "    invalid_action_reward=-1,\n",
    ")\n",
    "\n",
    "# Set metadata fps for 'human' if desired (not required for rgb_array)\n",
    "env.metadata[\"render_fps\"] = 10\n",
    "\n",
    "# Reset the environment (seed optional)\n",
    "env.reset(seed=0)\n",
    "print(\"Starting agent selection:\", env.agent_selection)\n",
    "\n",
    "# # Render one frame as an RGB array, then plot it\n",
    "# frame = env.render()  # will return a HxWx3 numpy array if renderer implemented\n",
    "# if frame is None:\n",
    "#     print(\n",
    "#         \"Renderer returned None. Make sure env.render(mode='rgb_array') is implemented.\"\n",
    "#     )\n",
    "# else:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(frame)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# Setup matplotlib figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "print(\"Starting Catan Game Visualization...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run game for a few steps\n",
    "step_count = 0\n",
    "max_steps = 20\n",
    "\n",
    "while step_count < max_steps:\n",
    "    # Render current state\n",
    "    rgb_array = env.render()\n",
    "\n",
    "    if rgb_array is not None:\n",
    "        # Display in notebook\n",
    "        # clear_output(wait=True)\n",
    "        ax.clear()\n",
    "        ax.imshow(rgb_array)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Catan Game - Step {step_count}\", fontsize=16, fontweight=\"bold\")\n",
    "        plt.tight_layout()\n",
    "        display(fig)\n",
    "\n",
    "        # Print game info\n",
    "        current_agent = env.agent_selection\n",
    "        print(f\"\\nStep {step_count}\")\n",
    "        print(f\"Current Player: {current_agent}\")\n",
    "\n",
    "        if hasattr(env, \"game\") and hasattr(env.game, \"state\"):\n",
    "            print(f\"Turn Number: {env.game.state.num_turns}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Check if game is done\n",
    "    if env.terminations[env.agent_selection] or env.truncations[env.agent_selection]:\n",
    "        print(\"\\nGame Over!\")\n",
    "        break\n",
    "\n",
    "    # Get valid actions\n",
    "    obs = env.observe(env.agent_selection)\n",
    "    action_mask = obs[\"action_mask\"]\n",
    "    valid_actions = np.where(action_mask == 1)[0]\n",
    "\n",
    "    if len(valid_actions) > 0:\n",
    "        # Take a random valid action\n",
    "        action = np.random.choice(valid_actions)\n",
    "        env.step(action)\n",
    "    else:\n",
    "        print(\"No valid actions available!\")\n",
    "        break\n",
    "\n",
    "    step_count += 1\n",
    "    time.sleep(0.5)  # Pause to see each frame\n",
    "\n",
    "print(\"\\nTest completed!\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a11a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from custom_gym_envs.envs.catan import ActionType\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from agents.catan_player_wrapper import ACTIONS_ARRAY\n",
    "\n",
    "n_steps = 25\n",
    "delay = 0.25  # seconds between frames\n",
    "\n",
    "for step in range(n_steps):\n",
    "    # If the current agent is terminated/truncated, we still call env_instance.step per PettingZoo convention:\n",
    "    current_agent = env.agent_selection\n",
    "\n",
    "    # get observation for current agent\n",
    "    obs = env.observe(current_agent)\n",
    "    action_mask = obs[\"action_mask\"]\n",
    "\n",
    "    legal_indices = np.nonzero(action_mask)[0]\n",
    "    if len(legal_indices) == 0:\n",
    "        # no legal moves available (should rarely happen). Choose end-turn fallback if available:\n",
    "        try:\n",
    "            end_turn_index = ACTIONS_ARRAY.index((ActionType.END_TURN, None))\n",
    "            action_choice = end_turn_index\n",
    "        except Exception:\n",
    "            # fallback to 0\n",
    "            action_choice = 0\n",
    "    else:\n",
    "        action_choice = int(random.choice(legal_indices))\n",
    "\n",
    "    # Step the env with the chosen action\n",
    "    env.step(action_choice)\n",
    "\n",
    "    # Render and display frame\n",
    "    frame = env.render()\n",
    "    if frame is not None:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(frame)\n",
    "        plt.title(f\"Step {step+1} - Agent: {current_agent} - Action: {action_choice}\")\n",
    "        plt.axis(\"off\")\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"No frame returned (render returned None)\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "# After rollout, print summary\n",
    "print(\"Done. Final agent selection:\", env.agent_selection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
