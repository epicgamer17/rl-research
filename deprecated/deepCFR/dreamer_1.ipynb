{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gym\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "\n",
    "class TimeLimit(gym.Wrapper):\n",
    "    def __init__(self, env, duration):\n",
    "        super().__init__(env)\n",
    "        self._duration = duration\n",
    "        self._step = None\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self._step is not None, \"Must reset environment.\"\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self._step += 1\n",
    "        if self._step >= self._duration:\n",
    "            done = True\n",
    "            if \"discount\" not in info:\n",
    "                info[\"discount\"] = np.array(1.0).astype(np.float32)\n",
    "            self._step = None\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._step = 0\n",
    "        return self.env.reset()\n",
    "\n",
    "\n",
    "class NormalizeActions(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self._mask = np.logical_and(\n",
    "            np.isfinite(env.action_space.low), np.isfinite(env.action_space.high)\n",
    "        )\n",
    "        self._low = np.where(self._mask, env.action_space.low, -1)\n",
    "        self._high = np.where(self._mask, env.action_space.high, 1)\n",
    "        low = np.where(self._mask, -np.ones_like(self._low), self._low)\n",
    "        high = np.where(self._mask, np.ones_like(self._low), self._high)\n",
    "        self.action_space = gym.spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        original = (action + 1) / 2 * (self._high - self._low) + self._low\n",
    "        original = np.where(self._mask, original, action)\n",
    "        return self.env.step(original)\n",
    "\n",
    "\n",
    "class OneHotAction(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete)\n",
    "        super().__init__(env)\n",
    "        self._random = np.random.RandomState()\n",
    "        shape = (self.env.action_space.n,)\n",
    "        space = gym.spaces.Box(low=0, high=1, shape=shape, dtype=np.float32)\n",
    "        space.discrete = True\n",
    "        self.action_space = space\n",
    "\n",
    "    def step(self, action):\n",
    "        index = np.argmax(action).astype(int)\n",
    "        reference = np.zeros_like(action)\n",
    "        reference[index] = 1\n",
    "        if not np.allclose(reference, action):\n",
    "            raise ValueError(f\"Invalid one-hot action:\\n{action}\")\n",
    "        return self.env.step(index)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def _sample_action(self):\n",
    "        actions = self.env.action_space.n\n",
    "        index = self._random.randint(0, actions)\n",
    "        reference = np.zeros(actions, dtype=np.float32)\n",
    "        reference[index] = 1.0\n",
    "        return reference\n",
    "\n",
    "\n",
    "class RewardObs(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        spaces = self.env.observation_space.spaces\n",
    "        if \"obs_reward\" not in spaces:\n",
    "            spaces[\"obs_reward\"] = gym.spaces.Box(\n",
    "                -np.inf, np.inf, shape=(1,), dtype=np.float32\n",
    "            )\n",
    "        self.observation_space = gym.spaces.Dict(spaces)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([reward], dtype=np.float32)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([0.0], dtype=np.float32)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class SelectAction(gym.Wrapper):\n",
    "    def __init__(self, env, key):\n",
    "        super().__init__(env)\n",
    "        self._key = key\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action[self._key])\n",
    "\n",
    "\n",
    "class UUID(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "\n",
    "    def reset(self):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BettingAbstration: FCPA\n",
      "P0 Cards: 3d\n",
      "P1 Cards: 2c\n",
      "BoardCards \n",
      "Node type?: Player node for player 0\n",
      "PossibleActions (4): [ ACTION_FOLD  ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]\n",
      "Round: 0\n",
      "ACPC State: STATE:0::3d|2c\n",
      "Spent: [P0: 50  P1: 100  ]\n",
      "\n",
      "Action Sequence: dd\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pyspiel\n",
    "\n",
    "env = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "state = env.new_initial_state()\n",
    "if state.is_chance_node():\n",
    "    while state.is_chance_node():\n",
    "        state.apply_action(np.random.choice(state.legal_actions()))\n",
    "print(state)\n",
    "print(state.current_player())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import A\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Poker:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = pyspiel.load_game(\n",
    "                name,\n",
    "                {\n",
    "                    \"numPlayers\": 2,\n",
    "                    \"numSuits\": 2,\n",
    "                    \"numRanks\": 3,\n",
    "                    \"numHoleCards\": 1,\n",
    "                    \"numBoardCards\": \"0 1\",\n",
    "                    \"bettingAbstraction\": \"fcpa\",\n",
    "                    \"numRounds\": 2,\n",
    "                    \"blind\": \"50 100\",\n",
    "                },\n",
    "            )\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        print(\"agent selection\", self.agent_selection)\n",
    "        self.traverser = None\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        spaces = {}\n",
    "        obs_spec = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        for key, value in obs_spec.items():\n",
    "            if not hasattr(value, \"shape\") or len(value.shape) == 0:\n",
    "                shape = (1,)\n",
    "            else:\n",
    "                shape = value.shape\n",
    "            spaces[key] = gym.spaces.Box(-np.inf, np.inf, shape, dtype=np.float32)\n",
    "        # spaces[\"image\"] = gym.spaces.Box(0, 255, self._size + (3,), dtype=np.uint8)\n",
    "        return gym.spaces.Dict(spaces)\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = gym.spaces.Discrete(4)\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"legal actions:\", self.state.legal_actions())\n",
    "        # print(\"action:\", action)\n",
    "        if len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        assert np.isfinite(action).all(), action\n",
    "        if not (action in self.state.legal_actions()):\n",
    "            action = np.random.choice(self.state.legal_actions())\n",
    "        reward = 0\n",
    "        if self.state.is_chance_node():\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "\n",
    "        else:\n",
    "            # print(\"action:\", action)\n",
    "            # print(\"obs:\", self.state)\n",
    "            self.state.apply_action(action)\n",
    "            if self.state.is_chance_node():\n",
    "                while self.state.is_chance_node():\n",
    "                    self.state.apply_action(\n",
    "                        np.random.choice(self.state.legal_actions())\n",
    "                    )\n",
    "\n",
    "        if not self.state.is_terminal():\n",
    "            # store = copy.deepcopy(self.state)\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "            # print(\"3\")\n",
    "            # print(self.state.is_terminal())\n",
    "            # if self.state.is_terminal():\n",
    "            #     print(\"store:\", store)\n",
    "            # print(self.state)\n",
    "            # print(self.state.legal_actions_mask(int(self.agent_selection)))\n",
    "            # print(\"3\")\n",
    "            self.agent_selection = str(self.state.current_player())\n",
    "\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        obs[\"is_terminal\"] = False\n",
    "        obs[\"is_first\"] = True\n",
    "        reward = (\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def last(self):\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {key: [val] if len(val.shape) == 0 else val for key, val in obs.items()}\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CartPole:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = gym.make(name, render_mode=\"rgb_array\")\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        return gym.spaces.Dict(\n",
    "            {\n",
    "                \"obs\": self._env.observation_space,\n",
    "                \"image\": gym.spaces.Box(\n",
    "                    0,\n",
    "                    255,\n",
    "                    (self._env.screen_width, self._env.screen_height) + (3,),\n",
    "                    dtype=np.uint8,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = self._env.action_space\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        if len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        observation, reward, terminated, truncated, info = self._env.step(action)\n",
    "        # print(observation.shape)\n",
    "        return (\n",
    "            {\n",
    "                \"obs\": observation,\n",
    "                \"image\": self._env.render(),\n",
    "                \"is_terminal\": terminated or truncated,\n",
    "                \"is_first\": False,\n",
    "            },\n",
    "            reward,\n",
    "            terminated or truncated,\n",
    "            {},\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs, info = self._env.reset()\n",
    "        # print(obs.shape)\n",
    "        return {\n",
    "            \"obs\": obs,\n",
    "            \"image\": self._env.render(),\n",
    "            \"is_terminal\": False,\n",
    "            \"is_first\": True,\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import collections\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as torchd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def symlog(x):\n",
    "    return torch.sign(x) * torch.log(torch.abs(x) + 1.0)\n",
    "\n",
    "\n",
    "def symexp(x):\n",
    "    return torch.sign(x) * (torch.exp(torch.abs(x)) - 1.0)\n",
    "\n",
    "\n",
    "class RequiresGrad:\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._model.requires_grad_(requires_grad=True)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._model.requires_grad_(requires_grad=False)\n",
    "\n",
    "\n",
    "class TimeRecording:\n",
    "    def __init__(self, comment):\n",
    "        self._comment = comment\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._st = torch.cuda.Event(enable_timing=True)\n",
    "        self._nd = torch.cuda.Event(enable_timing=True)\n",
    "        self._st.record()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._nd.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(self._comment, self._st.elapsed_time(self._nd) / 1000)\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logdir, step):\n",
    "        self._logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=str(logdir), max_queue=1000)\n",
    "        self._last_step = None\n",
    "        self._last_time = None\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "        self.step = step\n",
    "\n",
    "    def scalar(self, name, value):\n",
    "        self._scalars[name] = float(value)\n",
    "\n",
    "    def image(self, name, value):\n",
    "        self._images[name] = np.array(value)\n",
    "\n",
    "    def video(self, name, value):\n",
    "        self._videos[name] = np.array(value)\n",
    "\n",
    "    def write(self, fps=False, step=False):\n",
    "        if not step:\n",
    "            step = self.step\n",
    "        scalars = list(self._scalars.items())\n",
    "        if fps:\n",
    "            scalars.append((\"fps\", self._compute_fps(step)))\n",
    "        print(f\"[{step}]\", \" / \".join(f\"{k} {v:.1f}\" for k, v in scalars))\n",
    "        with (self._logdir / \"metrics.jsonl\").open(\"a\") as f:\n",
    "            f.write(json.dumps({\"step\": step, **dict(scalars)}) + \"\\n\")\n",
    "        for name, value in scalars:\n",
    "            if \"/\" not in name:\n",
    "                self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "            else:\n",
    "                self._writer.add_scalar(name, value, step)\n",
    "        for name, value in self._images.items():\n",
    "            self._writer.add_image(name, value, step)\n",
    "        for name, value in self._videos.items():\n",
    "            name = name if isinstance(name, str) else name.decode(\"utf-8\")\n",
    "            if np.issubdtype(value.dtype, np.floating):\n",
    "                value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "            B, T, H, W, C = value.shape\n",
    "            value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "            self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "        self._writer.flush()\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "\n",
    "    def _compute_fps(self, step):\n",
    "        if self._last_step is None:\n",
    "            self._last_time = time.time()\n",
    "            self._last_step = step\n",
    "            return 0\n",
    "        steps = step - self._last_step\n",
    "        duration = time.time() - self._last_time\n",
    "        self._last_time += duration\n",
    "        self._last_step = step\n",
    "        return steps / duration\n",
    "\n",
    "    def offline_scalar(self, name, value, step):\n",
    "        self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "\n",
    "    def offline_video(self, name, value, step):\n",
    "        if np.issubdtype(value.dtype, np.floating):\n",
    "            value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "        B, T, H, W, C = value.shape\n",
    "        value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "        self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "\n",
    "def simulate(\n",
    "    agent,\n",
    "    envs,\n",
    "    cache,\n",
    "    directory,\n",
    "    logger,\n",
    "    is_eval=False,\n",
    "    limit=None,\n",
    "    steps=0,\n",
    "    episodes=0,\n",
    "    state=None,\n",
    "):\n",
    "    # initialize or unpack simulation state\n",
    "    if state is None:\n",
    "        step, episode = 0, 0\n",
    "        done = np.ones(len(envs), bool)\n",
    "        length = np.zeros(len(envs), np.int32)\n",
    "        obs = [None] * len(envs)\n",
    "        agent_state = None\n",
    "        reward = [0] * len(envs)\n",
    "    else:\n",
    "        step, episode, done, length, obs, agent_state, reward = state\n",
    "    while (steps and step < steps) or (episodes and episode < episodes):\n",
    "        # reset envs if necessary\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            results = [envs[i].reset() for i in indices]\n",
    "            results = [r() for r in results]\n",
    "            for index, result in zip(indices, results):\n",
    "                t = result.copy()\n",
    "                t = {k: convert(v) for k, v in t.items()}\n",
    "                # action will be added to transition in add_to_cache\n",
    "                t[\"reward\"] = 0.0\n",
    "                t[\"discount\"] = 1.0\n",
    "                # initial state should be added to cache\n",
    "                add_to_cache(cache, envs[index].id, t)\n",
    "                # replace obs with done by initial state\n",
    "                obs[index] = result\n",
    "        # step agents\n",
    "        obs = {k: np.stack([o[k] for o in obs]) for k in obs[0] if \"log_\" not in k}\n",
    "        action, agent_state = agent(obs, done, agent_state)\n",
    "        if isinstance(action, dict):\n",
    "            action = [\n",
    "                {k: np.array(action[k][i].detach().cpu()) for k in action}\n",
    "                for i in range(len(envs))\n",
    "            ]\n",
    "        else:\n",
    "            action = np.array(action)\n",
    "        assert len(action) == len(envs)\n",
    "        # step envs\n",
    "        results = [e.step(a) for e, a in zip(envs, action)]\n",
    "        results = [r() for r in results]\n",
    "        obs, reward, done = zip(*[p[:3] for p in results])\n",
    "        obs = list(obs)\n",
    "        reward = list(reward)\n",
    "        done = np.stack(done)\n",
    "        episode += int(done.sum())\n",
    "        length += 1\n",
    "        step += len(envs)\n",
    "        length *= 1 - done\n",
    "        # add to cache\n",
    "        for a, result, env in zip(action, results, envs):\n",
    "            o, r, d, info = result\n",
    "            o = {k: convert(v) for k, v in o.items()}\n",
    "            transition = o.copy()\n",
    "            if isinstance(a, dict):\n",
    "                transition.update(a)\n",
    "            else:\n",
    "                transition[\"action\"] = a\n",
    "            transition[\"reward\"] = r\n",
    "            transition[\"discount\"] = info.get(\"discount\", np.array(1 - float(d)))\n",
    "            add_to_cache(cache, env.id, transition)\n",
    "\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            # logging for done episode\n",
    "            for i in indices:\n",
    "                save_episodes(directory, {envs[i].id: cache[envs[i].id]})\n",
    "                length = len(cache[envs[i].id][\"reward\"]) - 1\n",
    "                score = float(np.array(cache[envs[i].id][\"reward\"]).sum())\n",
    "                # video = cache[envs[i].id][\"image\"]\n",
    "                # record logs given from environments\n",
    "                for key in list(cache[envs[i].id].keys()):\n",
    "                    if \"log_\" in key:\n",
    "                        logger.scalar(\n",
    "                            key, float(np.array(cache[envs[i].id][key]).sum())\n",
    "                        )\n",
    "                        # log items won't be used later\n",
    "                        cache[envs[i].id].pop(key)\n",
    "\n",
    "                if not is_eval:\n",
    "                    step_in_dataset = erase_over_episodes(cache, limit)\n",
    "                    logger.scalar(f\"dataset_size\", step_in_dataset)\n",
    "                    logger.scalar(f\"train_return\", score)\n",
    "                    logger.scalar(f\"train_length\", length)\n",
    "                    logger.scalar(f\"train_episodes\", len(cache))\n",
    "                    logger.write(step=logger.step)\n",
    "                else:\n",
    "                    if not \"eval_lengths\" in locals():\n",
    "                        eval_lengths = []\n",
    "                        eval_scores = []\n",
    "                        eval_done = False\n",
    "                    # start counting scores for evaluation\n",
    "                    eval_scores.append(score)\n",
    "                    eval_lengths.append(length)\n",
    "\n",
    "                    score = sum(eval_scores) / len(eval_scores)\n",
    "                    length = sum(eval_lengths) / len(eval_lengths)\n",
    "                    # logger.video(f\"eval_policy\", np.array(video)[None])\n",
    "\n",
    "                    if len(eval_scores) >= episodes and not eval_done:\n",
    "                        logger.scalar(f\"eval_return\", score)\n",
    "                        logger.scalar(f\"eval_length\", length)\n",
    "                        logger.scalar(f\"eval_episodes\", len(eval_scores))\n",
    "                        logger.write(step=logger.step)\n",
    "                        eval_done = True\n",
    "    if is_eval:\n",
    "        # keep only last item for saving memory. this cache is used for video_pred later\n",
    "        while len(cache) > 1:\n",
    "            # FIFO\n",
    "            cache.popitem(last=False)\n",
    "    return (step - steps, episode - episodes, done, length, obs, agent_state, reward)\n",
    "\n",
    "\n",
    "def add_to_cache(cache, id, transition):\n",
    "    if id not in cache:\n",
    "        cache[id] = dict()\n",
    "        for key, val in transition.items():\n",
    "            cache[id][key] = [convert(val)]\n",
    "    else:\n",
    "        for key, val in transition.items():\n",
    "            if key not in cache[id]:\n",
    "                # fill missing data(action, etc.) at second time\n",
    "                cache[id][key] = [convert(0 * val)]\n",
    "                cache[id][key].append(convert(val))\n",
    "            else:\n",
    "                cache[id][key].append(convert(val))\n",
    "\n",
    "\n",
    "def erase_over_episodes(cache, dataset_size):\n",
    "    step_in_dataset = 0\n",
    "    for key, ep in reversed(sorted(cache.items(), key=lambda x: x[0])):\n",
    "        if (\n",
    "            not dataset_size\n",
    "            or step_in_dataset + (len(ep[\"reward\"]) - 1) <= dataset_size\n",
    "        ):\n",
    "            step_in_dataset += len(ep[\"reward\"]) - 1\n",
    "        else:\n",
    "            del cache[key]\n",
    "    return step_in_dataset\n",
    "\n",
    "\n",
    "def convert(value, precision=32):\n",
    "    value = np.array(value)\n",
    "    if np.issubdtype(value.dtype, np.floating):\n",
    "        dtype = {16: np.float16, 32: np.float32, 64: np.float64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.signedinteger):\n",
    "        dtype = {16: np.int16, 32: np.int32, 64: np.int64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.uint8):\n",
    "        dtype = np.uint8\n",
    "    elif np.issubdtype(value.dtype, bool):\n",
    "        dtype = bool\n",
    "    else:\n",
    "        raise NotImplementedError(value.dtype)\n",
    "    return value.astype(dtype)\n",
    "\n",
    "\n",
    "def save_episodes(directory, episodes):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    for filename, episode in episodes.items():\n",
    "        length = len(episode[\"reward\"])\n",
    "        filename = directory / f\"{filename}-{length}.npz\"\n",
    "        with io.BytesIO() as f1:\n",
    "            np.savez_compressed(f1, **episode)\n",
    "            f1.seek(0)\n",
    "            with filename.open(\"wb\") as f2:\n",
    "                f2.write(f1.read())\n",
    "    return True\n",
    "\n",
    "\n",
    "def from_generator(generator, batch_size):\n",
    "    while True:\n",
    "        batch = []\n",
    "        for _ in range(batch_size):\n",
    "            batch.append(next(generator))\n",
    "        data = {}\n",
    "        for key in batch[0].keys():\n",
    "            data[key] = []\n",
    "            for i in range(batch_size):\n",
    "                data[key].append(batch[i][key])\n",
    "            data[key] = np.stack(data[key], 0)\n",
    "        yield data\n",
    "\n",
    "\n",
    "def sample_episodes(episodes, length, seed=0):\n",
    "    np_random = np.random.RandomState(seed)\n",
    "    while True:\n",
    "        size = 0\n",
    "        ret = None\n",
    "        p = np.array(\n",
    "            [len(next(iter(episode.values()))) for episode in episodes.values()]\n",
    "        )\n",
    "        p = p / np.sum(p)\n",
    "        while size < length:\n",
    "            episode = np_random.choice(list(episodes.values()), p=p)\n",
    "            total = len(next(iter(episode.values())))\n",
    "            # make sure at least one transition included\n",
    "            if total < 2:\n",
    "                continue\n",
    "            if not ret:\n",
    "                index = int(np_random.randint(0, total - 1))\n",
    "                ret = {\n",
    "                    k: v[index : min(index + length, total)].copy()\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][0] = True\n",
    "            else:\n",
    "                # 'is_first' comes after 'is_last'\n",
    "                index = 0\n",
    "                possible = length - size\n",
    "                ret = {\n",
    "                    k: np.append(\n",
    "                        ret[k], v[index : min(index + possible, total)].copy(), axis=0\n",
    "                    )\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][size] = True\n",
    "            size = len(next(iter(ret.values())))\n",
    "        yield ret\n",
    "\n",
    "\n",
    "def load_episodes(directory, limit=None, reverse=True):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    episodes = collections.OrderedDict()\n",
    "    total = 0\n",
    "    if reverse:\n",
    "        for filename in reversed(sorted(directory.glob(\"*.npz\"))):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            # extract only filename without extension\n",
    "            episodes[str(os.path.splitext(os.path.basename(filename))[0])] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    else:\n",
    "        for filename in sorted(directory.glob(\"*.npz\")):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            episodes[str(filename)] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    return episodes\n",
    "\n",
    "\n",
    "class SampleDist:\n",
    "    def __init__(self, dist, samples=100):\n",
    "        self._dist = dist\n",
    "        self._samples = samples\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"SampleDist\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def mean(self):\n",
    "        samples = self._dist.sample(self._samples)\n",
    "        return torch.mean(samples, 0)\n",
    "\n",
    "    def mode(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self._dist.log_prob(sample)\n",
    "        return sample[torch.argmax(logprob)][0]\n",
    "\n",
    "    def entropy(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self.log_prob(sample)\n",
    "        return -torch.mean(logprob, 0)\n",
    "\n",
    "\n",
    "class OneHotDist(torchd.one_hot_categorical.OneHotCategorical):\n",
    "    def __init__(self, logits=None, probs=None, unimix_ratio=0.0):\n",
    "        if logits is not None and unimix_ratio > 0.0:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs = probs * (1.0 - unimix_ratio) + unimix_ratio / probs.shape[-1]\n",
    "            logits = torch.log(probs)\n",
    "            super().__init__(logits=logits, probs=None)\n",
    "        else:\n",
    "            super().__init__(logits=logits, probs=probs)\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = F.one_hot(\n",
    "            torch.argmax(super().logits, axis=-1), super().logits.shape[-1]\n",
    "        )\n",
    "        return _mode.detach() + super().logits - super().logits.detach()\n",
    "\n",
    "    def sample(self, sample_shape=(), seed=None):\n",
    "        if seed is not None:\n",
    "            raise ValueError(\"need to check\")\n",
    "        sample = super().sample(sample_shape).detach()\n",
    "        probs = super().probs\n",
    "        while len(probs.shape) < len(sample.shape):\n",
    "            probs = probs[None]\n",
    "        sample += probs - probs.detach()\n",
    "        return sample\n",
    "\n",
    "\n",
    "class DiscDist:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logits,\n",
    "        low=-20.0,\n",
    "        high=20.0,\n",
    "        transfwd=symlog,\n",
    "        transbwd=symexp,\n",
    "        device=\"cuda\",\n",
    "    ):\n",
    "        self.logits = logits\n",
    "        self.probs = torch.softmax(logits, -1)\n",
    "        self.buckets = torch.linspace(low, high, steps=255, device=device)\n",
    "        self.width = (self.buckets[-1] - self.buckets[0]) / 255\n",
    "        self.transfwd = transfwd\n",
    "        self.transbwd = transbwd\n",
    "\n",
    "    def mean(self):\n",
    "        _mean = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mean, dim=-1, keepdim=True))\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mode, dim=-1, keepdim=True))\n",
    "\n",
    "    # Inside OneHotCategorical, log_prob is calculated using only max element in targets\n",
    "    def log_prob(self, x):\n",
    "        x = self.transfwd(x)\n",
    "        # x(time, batch, 1)\n",
    "        below = torch.sum((self.buckets <= x[..., None]).to(torch.int32), dim=-1) - 1\n",
    "        above = len(self.buckets) - torch.sum(\n",
    "            (self.buckets > x[..., None]).to(torch.int32), dim=-1\n",
    "        )\n",
    "        # this is implemented using clip at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        below = torch.clip(below, 0, len(self.buckets) - 1)\n",
    "        above = torch.clip(above, 0, len(self.buckets) - 1)\n",
    "        equal = below == above\n",
    "\n",
    "        dist_to_below = torch.where(equal, 1, torch.abs(self.buckets[below] - x))\n",
    "        dist_to_above = torch.where(equal, 1, torch.abs(self.buckets[above] - x))\n",
    "        total = dist_to_below + dist_to_above\n",
    "        weight_below = dist_to_above / total\n",
    "        weight_above = dist_to_below / total\n",
    "        target = (\n",
    "            F.one_hot(below, num_classes=len(self.buckets)) * weight_below[..., None]\n",
    "            + F.one_hot(above, num_classes=len(self.buckets)) * weight_above[..., None]\n",
    "        )\n",
    "        log_pred = self.logits - torch.logsumexp(self.logits, -1, keepdim=True)\n",
    "        target = target.squeeze(-2)\n",
    "\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "    def log_prob_target(self, target):\n",
    "        log_pred = super().logits - torch.logsumexp(super().logits, -1, keepdim=True)\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "\n",
    "class MSEDist:\n",
    "    def __init__(self, mode, agg=\"sum\"):\n",
    "        self._mode = mode\n",
    "        self._agg = agg\n",
    "\n",
    "    def mode(self):\n",
    "        return self._mode\n",
    "\n",
    "    def mean(self):\n",
    "        return self._mode\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape, (self._mode.shape, value.shape)\n",
    "        distance = (self._mode - value) ** 2\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class SymlogDist:\n",
    "    def __init__(self, mode, dist=\"mse\", agg=\"sum\", tol=1e-8):\n",
    "        self._mode = mode\n",
    "        self._dist = dist\n",
    "        self._agg = agg\n",
    "        self._tol = tol\n",
    "\n",
    "    def mode(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def mean(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape\n",
    "        if self._dist == \"mse\":\n",
    "            distance = (self._mode - symlog(value)) ** 2.0\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        elif self._dist == \"abs\":\n",
    "            distance = torch.abs(self._mode - symlog(value))\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        else:\n",
    "            raise NotImplementedError(self._dist)\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class ContDist:\n",
    "    def __init__(self, dist=None, absmax=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "        self.absmax = absmax\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        out = self._dist.mean\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        out = self._dist.rsample(sample_shape)\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return self._dist.log_prob(x)\n",
    "\n",
    "\n",
    "class Bernoulli:\n",
    "    def __init__(self, dist=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = torch.round(self._dist.mean)\n",
    "        return _mode.detach() + self._dist.mean - self._dist.mean.detach()\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        return self._dist.sample(sample_shape)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        _logits = self._dist.base_dist.logits\n",
    "        log_probs0 = -F.softplus(_logits)\n",
    "        log_probs1 = -F.softplus(-_logits)\n",
    "\n",
    "        return torch.sum(log_probs0 * (1 - x) + log_probs1 * x, -1)\n",
    "\n",
    "\n",
    "class UnnormalizedHuber(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, threshold=1, **kwargs):\n",
    "        super().__init__(loc, scale, **kwargs)\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def log_prob(self, event):\n",
    "        return -(\n",
    "            torch.sqrt((event - self.mean) ** 2 + self._threshold**2) - self._threshold\n",
    "        )\n",
    "\n",
    "    def mode(self):\n",
    "        return self.mean\n",
    "\n",
    "\n",
    "class SafeTruncatedNormal(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, low, high, clip=1e-6, mult=1):\n",
    "        super().__init__(loc, scale)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._clip = clip\n",
    "        self._mult = mult\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        event = super().sample(sample_shape)\n",
    "        if self._clip:\n",
    "            clipped = torch.clip(event, self._low + self._clip, self._high - self._clip)\n",
    "            event = event - event.detach() + clipped.detach()\n",
    "        if self._mult:\n",
    "            event *= self._mult\n",
    "        return event\n",
    "\n",
    "\n",
    "class TanhBijector(torchd.Transform):\n",
    "    def __init__(self, validate_args=False, name=\"tanh\"):\n",
    "        super().__init__()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y = torch.where(\n",
    "            (torch.abs(y) <= 1.0), torch.clamp(y, -0.99999997, 0.99999997), y\n",
    "        )\n",
    "        y = torch.atanh(y)\n",
    "        return y\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        log2 = torch.math.log(2.0)\n",
    "        return 2.0 * (log2 - x - torch.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "def static_scan_for_lambda_return(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    indices = reversed(indices)\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        # (inputs, pcont) -> (inputs[index], pcont[index])\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            outputs = last\n",
    "            flag = False\n",
    "        else:\n",
    "            outputs = torch.cat([outputs, last], dim=-1)\n",
    "    outputs = torch.reshape(outputs, [outputs.shape[0], outputs.shape[1], 1])\n",
    "    outputs = torch.flip(outputs, [1])\n",
    "    outputs = torch.unbind(outputs, dim=0)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def lambda_return(reward, value, pcont, bootstrap, lambda_, axis):\n",
    "    # Setting lambda=1 gives a discounted Monte Carlo return.\n",
    "    # Setting lambda=0 gives a fixed 1-step return.\n",
    "    # assert reward.shape.ndims == value.shape.ndims, (reward.shape, value.shape)\n",
    "    assert len(reward.shape) == len(value.shape), (reward.shape, value.shape)\n",
    "    if isinstance(pcont, (int, float)):\n",
    "        pcont = pcont * torch.ones_like(reward)\n",
    "    dims = list(range(len(reward.shape)))\n",
    "    dims = [axis] + dims[1:axis] + [0] + dims[axis + 1 :]\n",
    "    if axis != 0:\n",
    "        reward = reward.permute(dims)\n",
    "        value = value.permute(dims)\n",
    "        pcont = pcont.permute(dims)\n",
    "    if bootstrap is None:\n",
    "        bootstrap = torch.zeros_like(value[-1])\n",
    "    next_values = torch.cat([value[1:], bootstrap[None]], 0)\n",
    "    inputs = reward + pcont * next_values * (1 - lambda_)\n",
    "    # returns = static_scan(\n",
    "    #    lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg,\n",
    "    #    (inputs, pcont), bootstrap, reverse=True)\n",
    "    # reimplement to optimize performance\n",
    "    returns = static_scan_for_lambda_return(\n",
    "        lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg, (inputs, pcont), bootstrap\n",
    "    )\n",
    "    if axis != 0:\n",
    "        returns = returns.permute(dims)\n",
    "    return returns\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        parameters,\n",
    "        lr,\n",
    "        eps=1e-4,\n",
    "        clip=None,\n",
    "        wd=None,\n",
    "        wd_pattern=r\".*\",\n",
    "        opt=\"adam\",\n",
    "        use_amp=False,\n",
    "    ):\n",
    "        assert 0 <= wd < 1\n",
    "        assert not clip or 1 <= clip\n",
    "        self._name = name\n",
    "        self._parameters = parameters\n",
    "        self._clip = clip\n",
    "        self._wd = wd\n",
    "        self._wd_pattern = wd_pattern\n",
    "        self._opt = {\n",
    "            \"adam\": lambda: torch.optim.Adam(parameters, lr=lr, eps=eps),\n",
    "            \"nadam\": lambda: NotImplemented(f\"{opt} is not implemented\"),\n",
    "            \"adamax\": lambda: torch.optim.Adamax(parameters, lr=lr, eps=eps),\n",
    "            \"sgd\": lambda: torch.optim.SGD(parameters, lr=lr),\n",
    "            \"momentum\": lambda: torch.optim.SGD(parameters, lr=lr, momentum=0.9),\n",
    "        }[opt]()\n",
    "        self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    def __call__(self, loss, params, retain_graph=True):\n",
    "        assert len(loss.shape) == 0, loss.shape\n",
    "        metrics = {}\n",
    "        metrics[f\"{self._name}_loss\"] = loss.detach().cpu().numpy()\n",
    "        self._opt.zero_grad()\n",
    "        self._scaler.scale(loss).backward(retain_graph=retain_graph)\n",
    "        self._scaler.unscale_(self._opt)\n",
    "        # loss.backward(retain_graph=retain_graph)\n",
    "        norm = torch.nn.utils.clip_grad_norm_(params, self._clip)\n",
    "        if self._wd:\n",
    "            self._apply_weight_decay(params)\n",
    "        self._scaler.step(self._opt)\n",
    "        self._scaler.update()\n",
    "        # self._opt.step()\n",
    "        self._opt.zero_grad()\n",
    "        metrics[f\"{self._name}_grad_norm\"] = to_np(norm)\n",
    "        return metrics\n",
    "\n",
    "    def _apply_weight_decay(self, varibs):\n",
    "        nontrivial = self._wd_pattern != r\".*\"\n",
    "        if nontrivial:\n",
    "            raise NotImplementedError\n",
    "        for var in varibs:\n",
    "            var.data = (1 - self._wd) * var.data\n",
    "\n",
    "\n",
    "def args_type(default):\n",
    "    def parse_string(x):\n",
    "        if default is None:\n",
    "            return x\n",
    "        if isinstance(default, bool):\n",
    "            return bool([\"False\", \"True\"].index(x))\n",
    "        if isinstance(default, int):\n",
    "            return float(x) if (\"e\" in x or \".\" in x) else int(x)\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(args_type(default[0])(y) for y in x.split(\",\"))\n",
    "        return type(default)(x)\n",
    "\n",
    "    def parse_object(x):\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(x)\n",
    "        return x\n",
    "\n",
    "    return lambda x: parse_string(x) if isinstance(x, str) else parse_object(x)\n",
    "\n",
    "\n",
    "def static_scan(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            if type(last) == type({}):\n",
    "                outputs = {\n",
    "                    key: value.clone().unsqueeze(0) for key, value in last.items()\n",
    "                }\n",
    "            else:\n",
    "                outputs = []\n",
    "                for _last in last:\n",
    "                    if type(_last) == type({}):\n",
    "                        outputs.append(\n",
    "                            {\n",
    "                                key: value.clone().unsqueeze(0)\n",
    "                                for key, value in _last.items()\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        outputs.append(_last.clone().unsqueeze(0))\n",
    "            flag = False\n",
    "        else:\n",
    "            if type(last) == type({}):\n",
    "                for key in last.keys():\n",
    "                    outputs[key] = torch.cat(\n",
    "                        [outputs[key], last[key].unsqueeze(0)], dim=0\n",
    "                    )\n",
    "            else:\n",
    "                for j in range(len(outputs)):\n",
    "                    if type(last[j]) == type({}):\n",
    "                        for key in last[j].keys():\n",
    "                            outputs[j][key] = torch.cat(\n",
    "                                [outputs[j][key], last[j][key].unsqueeze(0)], dim=0\n",
    "                            )\n",
    "                    else:\n",
    "                        outputs[j] = torch.cat(\n",
    "                            [outputs[j], last[j].unsqueeze(0)], dim=0\n",
    "                        )\n",
    "    if type(last) == type({}):\n",
    "        outputs = [outputs]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class Every:\n",
    "    def __init__(self, every):\n",
    "        self._every = every\n",
    "        self._last = None\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._every:\n",
    "            return 0\n",
    "        if self._last is None:\n",
    "            self._last = step\n",
    "            return 1\n",
    "        count = int((step - self._last) / self._every)\n",
    "        self._last += self._every * count\n",
    "        return count\n",
    "\n",
    "\n",
    "class Once:\n",
    "    def __init__(self):\n",
    "        self._once = True\n",
    "\n",
    "    def __call__(self):\n",
    "        if self._once:\n",
    "            self._once = False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Until:\n",
    "    def __init__(self, until):\n",
    "        self._until = until\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._until:\n",
    "            return True\n",
    "        return step < self._until\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        in_num = m.in_features\n",
    "        out_num = m.out_features\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        space = m.kernel_size[0] * m.kernel_size[1]\n",
    "        in_num = space * m.in_channels\n",
    "        out_num = space * m.out_channels\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def uniform_weight_init(given_scale):\n",
    "    def f(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            in_num = m.in_features\n",
    "            out_num = m.out_features\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            space = m.kernel_size[0] * m.kernel_size[1]\n",
    "            in_num = space * m.in_channels\n",
    "            out_num = space * m.out_channels\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            m.weight.data.fill_(1.0)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def tensorstats(tensor, prefix=None):\n",
    "    metrics = {\n",
    "        \"mean\": to_np(torch.mean(tensor)),\n",
    "        \"std\": to_np(torch.std(tensor)),\n",
    "        \"min\": to_np(torch.min(tensor)),\n",
    "        \"max\": to_np(torch.max(tensor)),\n",
    "    }\n",
    "    if prefix:\n",
    "        metrics = {f\"{prefix}_{k}\": v for k, v in metrics.items()}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def set_seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def enable_deterministic_run():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def recursively_collect_optim_state_dict(\n",
    "    obj, path=\"\", optimizers_state_dicts=None, visited=None\n",
    "):\n",
    "    if optimizers_state_dicts is None:\n",
    "        optimizers_state_dicts = {}\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    # avoid cyclic reference\n",
    "    if id(obj) in visited:\n",
    "        return optimizers_state_dicts\n",
    "    else:\n",
    "        visited.add(id(obj))\n",
    "    attrs = obj.__dict__\n",
    "    if isinstance(obj, torch.nn.Module):\n",
    "        attrs.update(\n",
    "            {k: attr for k, attr in obj.named_modules() if \".\" not in k and obj != attr}\n",
    "        )\n",
    "    for name, attr in attrs.items():\n",
    "        new_path = path + \".\" + name if path else name\n",
    "        if isinstance(attr, torch.optim.Optimizer):\n",
    "            optimizers_state_dicts[new_path] = attr.state_dict()\n",
    "        elif hasattr(attr, \"__dict__\"):\n",
    "            optimizers_state_dicts.update(\n",
    "                recursively_collect_optim_state_dict(\n",
    "                    attr, new_path, optimizers_state_dicts, visited\n",
    "                )\n",
    "            )\n",
    "    return optimizers_state_dicts\n",
    "\n",
    "\n",
    "def recursively_load_optim_state_dict(obj, optimizers_state_dicts):\n",
    "    for path, state_dict in optimizers_state_dicts.items():\n",
    "        keys = path.split(\".\")\n",
    "        obj_now = obj\n",
    "        for key in keys:\n",
    "            obj_now = getattr(obj_now, key)\n",
    "        obj_now.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class Random(nn.Module):\n",
    "    def __init__(self, config, act_space):\n",
    "        super(Random, self).__init__()\n",
    "        self._config = config\n",
    "        self._act_space = act_space\n",
    "\n",
    "    def actor(self, feat):\n",
    "        # if self._config.actor[\"dist\"] == \"onehot\":\n",
    "\n",
    "        return OneHotDist(\n",
    "            torch.zeros(self._config.num_actions, device=self._config.device).repeat(\n",
    "                self._config.envs, 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # else:\n",
    "    #     return torchd.independent.Independent(\n",
    "    #         torchd.uniform.Uniform(\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.low, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.high, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #         ),\n",
    "    #         1,\n",
    "    #     )\n",
    "\n",
    "    def train(self, start, context, data):\n",
    "        return None, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "import enum\n",
    "from functools import partial as bind\n",
    "\n",
    "\n",
    "class Parallel:\n",
    "    def __init__(self, ctor, strategy):\n",
    "        self.worker = Worker(bind(self._respond, ctor), strategy, state=True)\n",
    "        self.callables = {}\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name.startswith(\"_\"):\n",
    "            raise AttributeError(name)\n",
    "        try:\n",
    "            if name not in self.callables:\n",
    "                self.callables[name] = self.worker(PMessage.CALLABLE, name)()\n",
    "            if self.callables[name]:\n",
    "                return bind(self.worker, PMessage.CALL, name)\n",
    "            else:\n",
    "                return self.worker(PMessage.READ, name)()\n",
    "        except AttributeError:\n",
    "            raise ValueError(name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.worker(PMessage.CALL, \"__len__\")()\n",
    "\n",
    "    def close(self):\n",
    "        self.worker.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _respond(ctor, state, message, name, *args, **kwargs):\n",
    "        state = state or ctor\n",
    "        if message == PMessage.CALLABLE:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = callable(getattr(state, name))\n",
    "        elif message == PMessage.CALL:\n",
    "            result = getattr(state, name)(*args, **kwargs)\n",
    "        elif message == PMessage.READ:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = getattr(state, name)\n",
    "        return state, result\n",
    "\n",
    "\n",
    "class PMessage(enum.Enum):\n",
    "    CALLABLE = 2\n",
    "    CALL = 3\n",
    "    READ = 4\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    initializers = []\n",
    "\n",
    "    def __init__(self, fn, strategy=\"thread\", state=False):\n",
    "        if not state:\n",
    "            fn = lambda s, *args, fn=fn, **kwargs: (s, fn(*args, **kwargs))\n",
    "        inits = self.initializers\n",
    "        self.impl = {\n",
    "            \"process\": bind(ProcessPipeWorker, initializers=inits),\n",
    "            \"daemon\": bind(ProcessPipeWorker, initializers=inits, daemon=True),\n",
    "        }[strategy](fn)\n",
    "        self.promise = None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.promise and self.promise()  # Raise previous exception if any.\n",
    "        self.promise = self.impl(*args, **kwargs)\n",
    "        return self.promise\n",
    "\n",
    "    def wait(self):\n",
    "        return self.impl.wait()\n",
    "\n",
    "    def close(self):\n",
    "        self.impl.close()\n",
    "\n",
    "\n",
    "class ProcessPipeWorker:\n",
    "    def __init__(self, fn, initializers=(), daemon=False):\n",
    "        import multiprocessing\n",
    "        import cloudpickle\n",
    "\n",
    "        self._context = multiprocessing.get_context(\"spawn\")\n",
    "        self._pipe, pipe = self._context.Pipe()\n",
    "        fn = cloudpickle.dumps(fn)\n",
    "        initializers = cloudpickle.dumps(initializers)\n",
    "        self._process = self._context.Process(\n",
    "            target=self._loop, args=(pipe, fn, initializers), daemon=daemon\n",
    "        )\n",
    "        self._process.start()\n",
    "        self._nextid = 0\n",
    "        self._results = {}\n",
    "        assert self._submit(Message.OK)()\n",
    "        atexit.register(self.close)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self._submit(Message.RUN, (args, kwargs))\n",
    "\n",
    "    def wait(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self._pipe.send((Message.STOP, self._nextid, None))\n",
    "            self._pipe.close()\n",
    "        except (AttributeError, IOError):\n",
    "            pass  # The connection was already closed.\n",
    "        try:\n",
    "            self._process.join(0.1)\n",
    "            if self._process.exitcode is None:\n",
    "                try:\n",
    "                    os.kill(self._process.pid, 9)\n",
    "                    time.sleep(0.1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except (AttributeError, AssertionError):\n",
    "            pass\n",
    "\n",
    "    def _submit(self, message, payload=None):\n",
    "        callid = self._nextid\n",
    "        self._nextid += 1\n",
    "        self._pipe.send((message, callid, payload))\n",
    "        return Future(self._receive, callid)\n",
    "\n",
    "    def _receive(self, callid):\n",
    "        while callid not in self._results:\n",
    "            try:\n",
    "                message, callid, payload = self._pipe.recv()\n",
    "            except (OSError, EOFError):\n",
    "                raise RuntimeError(\"Lost connection to worker.\")\n",
    "            if message == Message.ERROR:\n",
    "                raise Exception(payload)\n",
    "            assert message == Message.RESULT, message\n",
    "            self._results[callid] = payload\n",
    "        return self._results.pop(callid)\n",
    "\n",
    "    @staticmethod\n",
    "    def _loop(pipe, function, initializers):\n",
    "        try:\n",
    "            callid = None\n",
    "            state = None\n",
    "            import cloudpickle\n",
    "\n",
    "            initializers = cloudpickle.loads(initializers)\n",
    "            function = cloudpickle.loads(function)\n",
    "            [fn() for fn in initializers]\n",
    "            while True:\n",
    "                if not pipe.poll(0.1):\n",
    "                    continue  # Wake up for keyboard interrupts.\n",
    "                message, callid, payload = pipe.recv()\n",
    "                if message == Message.OK:\n",
    "                    pipe.send((Message.RESULT, callid, True))\n",
    "                elif message == Message.STOP:\n",
    "                    return\n",
    "                elif message == Message.RUN:\n",
    "                    args, kwargs = payload\n",
    "                    state, result = function(state, *args, **kwargs)\n",
    "                    pipe.send((Message.RESULT, callid, result))\n",
    "                else:\n",
    "                    raise KeyError(f\"Invalid message: {message}\")\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            return\n",
    "        except Exception:\n",
    "            stacktrace = \"\".join(traceback.format_exception(*sys.exc_info()))\n",
    "            print(f\"Error inside process worker: {stacktrace}.\", flush=True)\n",
    "            pipe.send((Message.ERROR, callid, stacktrace))\n",
    "            return\n",
    "        finally:\n",
    "            try:\n",
    "                pipe.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "class Message(enum.Enum):\n",
    "    OK = 1\n",
    "    RUN = 2\n",
    "    RESULT = 3\n",
    "    STOP = 4\n",
    "    ERROR = 5\n",
    "\n",
    "\n",
    "class Future:\n",
    "    def __init__(self, receive, callid):\n",
    "        self._receive = receive\n",
    "        self._callid = callid\n",
    "        self._result = None\n",
    "        self._complete = False\n",
    "\n",
    "    def __call__(self):\n",
    "        if not self._complete:\n",
    "            self._result = self._receive(self._callid)\n",
    "            self._complete = True\n",
    "        return self._result\n",
    "\n",
    "\n",
    "class Damy:\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    def step(self, action):\n",
    "        return lambda: self._env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        return lambda: self._env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "# torch.set_default_device(\"mps\")\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def count_steps(folder):\n",
    "    return sum(int(str(n).split(\"-\")[-1][:-4]) - 1 for n in folder.glob(\"*.npz\"))\n",
    "\n",
    "\n",
    "def make_dataset(episodes, config):\n",
    "    generator = sample_episodes(episodes, config.batch_length)\n",
    "    dataset = from_generator(generator, config.batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_env(config, mode, id):\n",
    "    suite, task = config.task.split(\"_\", 1)\n",
    "    if suite == \"dmc\":\n",
    "        import envs.dmc as dmc\n",
    "\n",
    "        env = dmc.DeepMindControl(\n",
    "            task, config.action_repeat, config.size, seed=config.seed + id\n",
    "        )\n",
    "        env = NormalizeActions(env)\n",
    "    elif suite == \"cartpole\":\n",
    "        env = CartPole(\n",
    "            task,\n",
    "        )\n",
    "    elif suite == \"poker\":\n",
    "        env = Poker(\n",
    "            \"universal_poker\",\n",
    "        )\n",
    "    elif suite == \"atari\":\n",
    "        import envs.atari as atari\n",
    "\n",
    "        env = atari.Atari(\n",
    "            task,\n",
    "            config.action_repeat,\n",
    "            config.size,\n",
    "            gray=config.grayscale,\n",
    "            noops=config.noops,\n",
    "            lives=config.lives,\n",
    "            sticky=config.stickey,\n",
    "            actions=config.actions,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"dmlab\":\n",
    "        import envs.dmlab as dmlab\n",
    "\n",
    "        env = dmlab.DeepMindLabyrinth(\n",
    "            task,\n",
    "            mode if \"train\" in mode else \"test\",\n",
    "            config.action_repeat,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"memorymaze\":\n",
    "        from envs.memorymaze import MemoryMaze\n",
    "\n",
    "        env = MemoryMaze(task, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"crafter\":\n",
    "        import envs.crafter as crafter\n",
    "\n",
    "        env = crafter.Crafter(task, config.size, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"minecraft\":\n",
    "        import envs.minecraft as minecraft\n",
    "\n",
    "        env = minecraft.make_env(task, size=config.size, break_speed=config.break_speed)\n",
    "        env = OneHotAction(env)\n",
    "    else:\n",
    "        raise NotImplementedError(suite)\n",
    "    env = TimeLimit(env, config.time_limit)\n",
    "    env = SelectAction(env, key=\"action\")\n",
    "    env = UUID(env)\n",
    "    if suite == \"minecraft\":\n",
    "        env = RewardObs(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    set_seed_everywhere(config.seed)\n",
    "    if config.deterministic_run:\n",
    "        enable_deterministic_run()\n",
    "    logdir = pathlib.Path(config.logdir).expanduser()\n",
    "    config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "    config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "    config.steps //= config.action_repeat\n",
    "    config.eval_every //= config.action_repeat\n",
    "    config.log_every //= config.action_repeat\n",
    "    config.time_limit //= config.action_repeat\n",
    "\n",
    "    print(\"Logdir\", logdir)\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "    config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "    step = count_steps(config.traindir)\n",
    "    # step in logger is environmental step\n",
    "    logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "    print(\"Create envs.\")\n",
    "    if config.offline_traindir:\n",
    "        directory = config.offline_traindir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.traindir\n",
    "    train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "    if config.offline_evaldir:\n",
    "        directory = config.offline_evaldir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.evaldir\n",
    "    eval_eps = load_episodes(directory, limit=1)\n",
    "    make = lambda mode, id: make_env(config, mode, id)\n",
    "    train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "    eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "    if config.parallel:\n",
    "        train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "        eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "    else:\n",
    "        train_envs = [Damy(env) for env in train_envs]\n",
    "        eval_envs = [Damy(env) for env in eval_envs]\n",
    "    acts = train_envs[0].action_space\n",
    "    print(\"Action Space\", acts)\n",
    "    config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "    state = None\n",
    "    if not config.offline_traindir:\n",
    "        prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "        print(f\"Prefill dataset ({prefill} steps).\")\n",
    "        if hasattr(acts, \"discrete\"):\n",
    "            random_actor = OneHotDist(\n",
    "                torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "            )\n",
    "        else:\n",
    "            random_actor = torchd.independent.Independent(\n",
    "                torchd.uniform.Uniform(\n",
    "                    torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                    torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "                ),\n",
    "                1,\n",
    "            )\n",
    "\n",
    "        def random_agent(o, d, s):\n",
    "            action = random_actor.sample()\n",
    "            logprob = random_actor.log_prob(action)\n",
    "            return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "        state = simulate(\n",
    "            random_agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=prefill,\n",
    "        )\n",
    "        logger.step += prefill * config.action_repeat\n",
    "        print(f\"Logger: ({logger.step} steps).\")\n",
    "\n",
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "        logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "            eval_policy = funcpartial(agent, training=False)\n",
    "            simulate(\n",
    "                eval_policy,\n",
    "                eval_envs,\n",
    "                eval_eps,\n",
    "                config.evaldir,\n",
    "                logger,\n",
    "                is_eval=True,\n",
    "                episodes=config.eval_episode_num,\n",
    "            )\n",
    "            if config.video_pred_log:\n",
    "                video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import Loss\n",
    "import yaml\n",
    "\n",
    "from game_configs import GameConfig\n",
    "from utils import (\n",
    "    prepare_kernel_initializers,\n",
    "    prepare_activations,\n",
    ")\n",
    "\n",
    "\n",
    "class ConfigBase:\n",
    "    def parse_field(\n",
    "        self, field_name, default=None, wrapper=None, required=True, dtype=None\n",
    "    ):\n",
    "        if field_name in self.config_dict:\n",
    "            val = self.config_dict[field_name]\n",
    "            # print(\"value: \", val)\n",
    "            print(f\"Using         {field_name:30}: {val}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(val)\n",
    "            return self.config_dict[field_name]\n",
    "\n",
    "        if default is not None:\n",
    "            print(f\"Using default {field_name:30}: {default}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(default)\n",
    "            return default\n",
    "\n",
    "        if required:\n",
    "            raise ValueError(\n",
    "                f\"Missing required field without default value: {field_name}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Using         {field_name:30}: {default}\")\n",
    "\n",
    "        if field_name in self._parsed_fields:\n",
    "            print(\"warning: duplicate field: \", field_name)\n",
    "        self._parsed_fields.add(field_name)\n",
    "\n",
    "    def __init__(self, config_dict: dict):\n",
    "        self.config_dict = config_dict\n",
    "        self._parsed_fields = set()\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "\n",
    "class Config(ConfigBase):\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"], game_config=o[\"game\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict, game=self.game)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "    def __init__(self, config_dict: dict, game_config: GameConfig) -> None:\n",
    "        super().__init__(config_dict)\n",
    "        # could take in a game config and set an action space and observation shape here\n",
    "        # OR DO THAT IN BASE AGENT?\n",
    "        self.game = game_config\n",
    "\n",
    "        self._verify_game()\n",
    "\n",
    "        # not hyperparameters but utility things\n",
    "        self.save_intermediate_weights: bool = self.parse_field(\n",
    "            \"save_intermediate_weights\", False\n",
    "        )\n",
    "\n",
    "        # ADD LEARNING RATE SCHEDULES\n",
    "        self.training_steps: int = self.parse_field(\"training_steps\", 10000)\n",
    "\n",
    "        self.adam_epsilon: float = self.parse_field(\"adam_epsilon\", 1e-6)\n",
    "        self.momentum = self.parse_field(\"momentum\", 0.9)\n",
    "        self.learning_rate: float = self.parse_field(\"learning_rate\", 0.001)\n",
    "        self.clipnorm: int = self.parse_field(\"clipnorm\", 0)\n",
    "        self.optimizer: torch.optim.Optimizer = self.parse_field(\n",
    "            \"optimizer\", torch.optim.Adam\n",
    "        )\n",
    "        self.weight_decay: float = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.loss_function: Loss = self.parse_field(\"loss_function\", required=True)\n",
    "        self.activation = self.parse_field(\n",
    "            \"activation\", \"relu\", wrapper=prepare_activations\n",
    "        )\n",
    "        self.kernel_initializer = self.parse_field(\n",
    "            \"kernel_initializer\",\n",
    "            None,\n",
    "            required=False,\n",
    "            wrapper=kernel_initializer_wrapper,\n",
    "        )\n",
    "\n",
    "        self.minibatch_size: int = self.parse_field(\"minibatch_size\", 64)\n",
    "        self.replay_buffer_size: int = self.parse_field(\"replay_buffer_size\", 5000)\n",
    "        self.min_replay_buffer_size: int = self.parse_field(\n",
    "            \"min_replay_buffer_size\", self.minibatch_size\n",
    "        )\n",
    "        self.num_minibatches: int = self.parse_field(\"num_minibatches\", 1)\n",
    "        self.training_iterations: int = self.parse_field(\"training_iterations\", 1)\n",
    "        self.print_interval: int = self.parse_field(\"print_interval\", 100)\n",
    "\n",
    "    def _verify_game(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def kernel_initializer_wrapper(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    elif isinstance(x, str):\n",
    "        return prepare_kernel_initializers(x)\n",
    "    else:\n",
    "        assert callable(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.symlog_inputs = self.parse_field(\"symlog_inputs\", True)\n",
    "\n",
    "\n",
    "class DecoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.cnn_sigmoid = self.parse_field(\"cnn_sigmoid\", False)\n",
    "        self.image_dist = self.parse_field(\"image_dist\", \"mse\")\n",
    "        self.vector_dist = self.parse_field(\"vector_dist\", \"symlog_mse\")\n",
    "        self.outscale = self.parse_field(\"outscale\", 1.0)\n",
    "\n",
    "\n",
    "class HeadConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.layers = self.parse_field(\"layers\", 2)\n",
    "        self.dist = self.parse_field(\"dist\", \"symlog_disc\")\n",
    "        self.loss_scale = self.parse_field(\"loss_scale\", 1.0)\n",
    "        self.outscale = self.parse_field(\"outscale\", 0.0)\n",
    "\n",
    "\n",
    "class DreamerConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "\n",
    "        self.logdir = self.parse_field(\"logdir\", \"./logdir\")\n",
    "        self.traindir = self.parse_field(\"traindir\", \"./traindir\")\n",
    "        self.evaldir = self.parse_field(\"evaldir\", \"./evaldir\")\n",
    "        self.offline_traindir = self.parse_field(\n",
    "            \"offline_traindir\", \"./offline_traindir\"\n",
    "        )\n",
    "        self.offline_evaldir = self.parse_field(\"offline_evaldir\", \"./offline_evaldir\")\n",
    "        self.seed = self.parse_field(\"seed\", 0)\n",
    "        self.deterministic_run = self.parse_field(\"deterministic_run\", False)\n",
    "        self.steps: int = self.parse_field(\"steps\", 1000000, wrapper=float)\n",
    "        self.parallel = self.parse_field(\"parallel\", False)\n",
    "        self.eval_every = self.parse_field(\"eval_every\", 10000, wrapper=float)\n",
    "        self.eval_episode_num = self.parse_field(\"eval_episode_num\", 10)\n",
    "        self.log_every = self.parse_field(\"log_every\", 100, wrapper=float)\n",
    "        self.reset_every = self.parse_field(\"reset_every\", 1000, wrapper=float)\n",
    "        self.device = self.parse_field(\n",
    "            \"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.compile = self.parse_field(\"compile\", False)\n",
    "        self.precision = self.parse_field(\"precision\", \"fp32\")\n",
    "        self.debug = self.parse_field(\"debug\", False)\n",
    "        self.video_pred_log = self.parse_field(\"video_pred_log\", True)\n",
    "\n",
    "        self.task = self.parse_field(\"task\", \"atari_MsPacmanNoFrameskip-v4\")\n",
    "        self.size = self.parse_field(\"size\", (64, 64), wrapper=tuple)\n",
    "        self.envs = self.parse_field(\"envs\", 1)\n",
    "        self.action_repeat = self.parse_field(\"action_repeat\", 4)\n",
    "        self.noops = self.parse_field(\"noops\", 0)\n",
    "        self.lives = self.parse_field(\"lives\", \"unused\")\n",
    "        self.stickey = self.parse_field(\"stickey\", True)\n",
    "        self.actions = self.parse_field(\"actions\", \"needed\")\n",
    "        self.resize = self.parse_field(\"resize\", \"opencv\")\n",
    "        self.time_limit = self.parse_field(\"time_limit\", 1000)\n",
    "        self.grayscale = self.parse_field(\"grayscale\", True)\n",
    "        self.prefill = self.parse_field(\"prefill\", 10)\n",
    "        self.reward_EMA = self.parse_field(\"reward_EMA\", True)\n",
    "\n",
    "        self.dyn_hidden = self.parse_field(\"dyn_hidden\", 256)\n",
    "        self.dyn_deter = self.parse_field(\"dyn_deter\", 256)\n",
    "        self.dyn_stoch = self.parse_field(\"dyn_stoch\", 16)\n",
    "        self.dyn_discrete = self.parse_field(\"dyn_discrete\", 16)\n",
    "        self.dyn_rec_depth = self.parse_field(\"dyn_rec_depth\", 1)\n",
    "        self.dyn_mean_act = self.parse_field(\"dyn_mean_act\", \"none\")\n",
    "        self.dyn_std_act = self.parse_field(\"dyn_std_act\", \"sigmoid2\")\n",
    "        self.dyn_min_std = self.parse_field(\"dyn_min_std\", 0.1)\n",
    "        self.grad_heads = self.parse_field(\"grad_heads\", [\"decoder\", \"reward\", \"cont\"])\n",
    "        self.units = self.parse_field(\"units\", 256)\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.encoder = EncoderConfig(self.config_dict[\"encoder\"])\n",
    "        self.decoder = DecoderConfig(self.config_dict[\"decoder\"])\n",
    "        self.reward_head = HeadConfig(self.config_dict[\"reward_head\"])\n",
    "        self.cont_head = HeadConfig(self.config_dict[\"cont_head\"])\n",
    "        self.dyn_scale = self.parse_field(\"dyn_scale\", 0.5)\n",
    "        self.rep_scale = self.parse_field(\"rep_scale\", 0.1)\n",
    "        self.kl_free = self.parse_field(\"kl_free\", 1.0)\n",
    "        self.weight_decay = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.unimix_ratio = self.parse_field(\"unimix_ratio\", 0.01)\n",
    "        self.initial = self.parse_field(\"initial\", \"learned\")\n",
    "\n",
    "        self.batch_size = self.parse_field(\"batch_size\", 8)\n",
    "        self.batch_length = self.parse_field(\"batch_length\", 32)\n",
    "        self.train_ratio = self.parse_field(\"train_ratio\", 512)\n",
    "        self.pretrain: int = self.parse_field(\"pretrain\", 100)\n",
    "        self.model_lr = self.parse_field(\"model_lr\", 1e-4, wrapper=float)\n",
    "        self.opt_eps = self.parse_field(\"opt_eps\", 1e-8, wrapper=float)\n",
    "        self.grad_clip: int = self.parse_field(\"grad_clip\", 1000, wrapper=float)\n",
    "        self.dataset_size: int = self.parse_field(\n",
    "            \"dataset_size\", 1000000, wrapper=float\n",
    "        )\n",
    "        self.opt = self.parse_field(\"opt\", \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using         logdir                        : ./logdir\n",
      "Using         traindir                      : None\n",
      "Using         evaldir                       : None\n",
      "Using         offline_traindir              : None\n",
      "Using         offline_evaldir               : None\n",
      "Using         seed                          : 0\n",
      "Using         deterministic_run             : False\n",
      "Using         steps                         : 1e1\n",
      "Using         parallel                      : False\n",
      "Using         eval_every                    : 1e4\n",
      "Using         eval_episode_num              : 10\n",
      "Using         log_every                     : 10\n",
      "Using         reset_every                   : 0\n",
      "Using         device                        : cpu\n",
      "Using         compile                       : True\n",
      "Using         precision                     : 16\n",
      "Using         debug                         : False\n",
      "Using         video_pred_log                : False\n",
      "Using         task                          : poker_universal_poker\n",
      "Using         size                          : [64, 64]\n",
      "Using         envs                          : 1\n",
      "Using         action_repeat                 : 2\n",
      "Using default noops                         : 0\n",
      "Using default lives                         : unused\n",
      "Using default stickey                       : True\n",
      "Using default actions                       : needed\n",
      "Using default resize                        : opencv\n",
      "Using         time_limit                    : 1000\n",
      "Using         grayscale                     : False\n",
      "Using         prefill                       : 2500\n",
      "Using         reward_EMA                    : True\n",
      "Using         dyn_hidden                    : 256\n",
      "Using         dyn_deter                     : 256\n",
      "Using         dyn_stoch                     : 16\n",
      "Using         dyn_discrete                  : 16\n",
      "Using         dyn_rec_depth                 : 1\n",
      "Using         dyn_mean_act                  : none\n",
      "Using         dyn_std_act                   : sigmoid2\n",
      "Using         dyn_min_std                   : 0.1\n",
      "Using         grad_heads                    : ['decoder', 'reward', 'cont']\n",
      "Using         units                         : 256\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         symlog_inputs                 : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         cnn_sigmoid                   : False\n",
      "Using         image_dist                    : mse\n",
      "Using         vector_dist                   : symlog_mse\n",
      "Using         outscale                      : 1.0\n",
      "Using         layers                        : 2\n",
      "Using         dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 0.0\n",
      "Using         layers                        : 2\n",
      "Using default dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 1.0\n",
      "Using         dyn_scale                     : 0.5\n",
      "Using         rep_scale                     : 0.1\n",
      "Using         kl_free                       : 1.0\n",
      "Using         weight_decay                  : 0.0\n",
      "Using         unimix_ratio                  : 0.01\n",
      "Using         initial                       : learned\n",
      "Using         batch_size                    : 8\n",
      "Using         batch_length                  : 32\n",
      "Using         train_ratio                   : 512\n",
      "Using         pretrain                      : 100\n",
      "Using         model_lr                      : 1e-4\n",
      "Using         opt_eps                       : 1e-8\n",
      "Using         grad_clip                     : 1000\n",
      "Using         dataset_size                  : 1000000\n",
      "Using         opt                           : adam\n"
     ]
    }
   ],
   "source": [
    "configs = yaml.safe_load(pathlib.Path(\"./configs.yaml\").read_text())\n",
    "config_dict = configs[\"defaults\"]\n",
    "config_dict[\"logdir\"] = \"./logdir\"\n",
    "config_dict[\"offline_traindir\"] = None  # \"./offline_traindir\"\n",
    "config_dict[\"offline_evaldir\"] = None  # \"./offline_evaldir\"\n",
    "config = DreamerConfig(config_dict=config_dict)\n",
    "# config = DreamerConfig(config_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class RSSM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        stoch=30,\n",
    "        deter=200,\n",
    "        hidden=200,\n",
    "        rec_depth=1,\n",
    "        discrete=False,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        mean_act=\"none\",\n",
    "        std_act=\"softplus\",\n",
    "        min_std=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        initial=\"learned\",\n",
    "        num_actions=None,\n",
    "        embed=None,\n",
    "        device=None,\n",
    "    ):\n",
    "        super(RSSM, self).__init__()\n",
    "        self._stoch = stoch\n",
    "        self._deter = deter\n",
    "        self._hidden = hidden\n",
    "        self._min_std = min_std\n",
    "        self._rec_depth = rec_depth\n",
    "        self._discrete = discrete\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._mean_act = mean_act\n",
    "        self._std_act = std_act\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._initial = initial\n",
    "        self._num_actions = num_actions\n",
    "        self._embed = embed\n",
    "        self._device = device\n",
    "\n",
    "        inp_layers = []\n",
    "        if self._discrete:\n",
    "            inp_dim = self._stoch * self._discrete + num_actions\n",
    "        else:\n",
    "            inp_dim = self._stoch + num_actions\n",
    "        inp_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            inp_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        inp_layers.append(act())\n",
    "        self._img_in_layers = nn.Sequential(*inp_layers)\n",
    "        self._img_in_layers.apply(weight_init)\n",
    "        self._cell = GRUCell(self._hidden, self._deter, norm=norm)\n",
    "        self._cell.apply(weight_init)\n",
    "\n",
    "        img_out_layers = []\n",
    "        inp_dim = self._deter\n",
    "        img_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            img_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        img_out_layers.append(act())\n",
    "        self._img_out_layers = nn.Sequential(*img_out_layers)\n",
    "        self._img_out_layers.apply(weight_init)\n",
    "\n",
    "        obs_out_layers = []\n",
    "        inp_dim = self._deter + self._embed\n",
    "        obs_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            obs_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        obs_out_layers.append(act())\n",
    "        self._obs_out_layers = nn.Sequential(*obs_out_layers)\n",
    "        self._obs_out_layers.apply(weight_init)\n",
    "\n",
    "        if self._discrete:\n",
    "            self._imgs_stat_layer = nn.Linear(\n",
    "                self._hidden, self._stoch * self._discrete\n",
    "            )\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, self._stoch * self._discrete)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "        else:\n",
    "            self._imgs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "\n",
    "        if self._initial == \"learned\":\n",
    "            self.W = torch.nn.Parameter(\n",
    "                torch.zeros((1, self._deter), device=torch.device(self._device)),\n",
    "                requires_grad=True,\n",
    "            )\n",
    "\n",
    "    def initial(self, batch_size):\n",
    "        deter = torch.zeros(batch_size, self._deter, device=self._device)\n",
    "        if self._discrete:\n",
    "            state = dict(\n",
    "                logit=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                stoch=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                deter=deter,\n",
    "            )\n",
    "        else:\n",
    "            state = dict(\n",
    "                mean=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                std=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                stoch=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                deter=deter,\n",
    "            )\n",
    "        if self._initial == \"zeros\":\n",
    "            return state\n",
    "        elif self._initial == \"learned\":\n",
    "            state[\"deter\"] = torch.tanh(self.W).repeat(batch_size, 1)\n",
    "            state[\"stoch\"] = self.get_stoch(state[\"deter\"])\n",
    "            return state\n",
    "        else:\n",
    "            raise NotImplementedError(self._initial)\n",
    "\n",
    "    def observe(self, embed, action, is_first, state=None):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        # (batch, time, ch) -> (time, batch, ch)\n",
    "        embed, action, is_first = swap(embed), swap(action), swap(is_first)\n",
    "        # prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\n",
    "        post, prior = static_scan(\n",
    "            lambda prev_state, prev_act, embed, is_first: self.obs_step(\n",
    "                prev_state[0], prev_act, embed, is_first\n",
    "            ),\n",
    "            (action, embed, is_first),\n",
    "            (state, state),\n",
    "        )\n",
    "\n",
    "        # (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\n",
    "        post = {k: swap(v) for k, v in post.items()}\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return post, prior\n",
    "\n",
    "    def imagine_with_action(self, action, state):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        assert isinstance(state, dict), state\n",
    "        action = swap(action)\n",
    "        prior = static_scan(self.img_step, [action], state)\n",
    "        prior = prior[0]\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return prior\n",
    "\n",
    "    def get_feat(self, state):\n",
    "        stoch = state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            stoch = stoch.reshape(shape)\n",
    "        return torch.cat([stoch, state[\"deter\"]], -1)\n",
    "\n",
    "    def get_dist(self, state, dtype=None):\n",
    "        if self._discrete:\n",
    "            logit = state[\"logit\"]\n",
    "            dist = torchd.independent.Independent(\n",
    "                OneHotDist(logit, unimix_ratio=self._unimix_ratio), 1\n",
    "            )\n",
    "        else:\n",
    "            mean, std = state[\"mean\"], state[\"std\"]\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, std), 1)\n",
    "            )\n",
    "        return dist\n",
    "\n",
    "    def obs_step(self, prev_state, prev_action, embed, is_first, sample=True):\n",
    "        # initialize all prev_state\n",
    "        if prev_state == None or torch.sum(is_first) == len(is_first):\n",
    "            prev_state = self.initial(len(is_first))\n",
    "            prev_action = torch.zeros(\n",
    "                (len(is_first), self._num_actions), device=self._device\n",
    "            )\n",
    "        # overwrite the prev_state only where is_first=True\n",
    "        elif torch.sum(is_first) > 0:\n",
    "            is_first = is_first[:, None]\n",
    "            prev_action *= 1.0 - is_first\n",
    "            init_state = self.initial(len(is_first))\n",
    "            for key, val in prev_state.items():\n",
    "                is_first_r = torch.reshape(\n",
    "                    is_first,\n",
    "                    is_first.shape + (1,) * (len(val.shape) - len(is_first.shape)),\n",
    "                )\n",
    "                prev_state[key] = (\n",
    "                    val * (1.0 - is_first_r) + init_state[key] * is_first_r\n",
    "                )\n",
    "        # print(\"prev_state shape: \", prev_state[\"deter\"].shape)\n",
    "        prior = self.img_step(prev_state, prev_action)\n",
    "        # print(\"embed shape: \", embed.shape)\n",
    "        # print(\"prior shape: \", prior[\"deter\"].shape)\n",
    "        x = torch.cat([prior[\"deter\"], embed], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # print(self._deter + self._embed)\n",
    "        # print(self._hidden)\n",
    "        # (batch_size, prior_deter + embed) -> (batch_size, hidden)\n",
    "        x = self._obs_out_layers(x)\n",
    "        # (batch_size, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"obs\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        post = {\"stoch\": stoch, \"deter\": prior[\"deter\"], **stats}\n",
    "        return post, prior\n",
    "\n",
    "    def img_step(self, prev_state, prev_action, sample=True):\n",
    "        # (batch, stoch, discrete_num)\n",
    "        prev_stoch = prev_state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(prev_stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            # (batch, stoch, discrete_num) -> (batch, stoch * discrete_num)\n",
    "            prev_stoch = prev_stoch.reshape(shape)\n",
    "        # (batch, stoch * discrete_num) -> (batch, stoch * discrete_num + action)\n",
    "        x = torch.cat([prev_stoch, prev_action], -1)\n",
    "        # (batch, stoch * discrete_num + action, embed) -> (batch, hidden)\n",
    "        x = self._img_in_layers(x)\n",
    "        for _ in range(self._rec_depth):  # rec depth is not correctly implemented\n",
    "            deter = prev_state[\"deter\"]\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            # (batch, hidden), (batch, deter) -> (batch, deter), (batch, deter)\n",
    "            x, deter = self._cell(x, [deter])\n",
    "            # print(\"x shape: \", x.shape)\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            deter = deter[0]  # Keras wraps the state in a list.\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "        # (batch, deter) -> (batch, hidden)\n",
    "        x = self._img_out_layers(x)\n",
    "        # (batch, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        prior = {\"stoch\": stoch, \"deter\": deter, **stats}\n",
    "        return prior\n",
    "\n",
    "    def get_stoch(self, deter):\n",
    "        x = self._img_out_layers(deter)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        dist = self.get_dist(stats)\n",
    "        return dist.mode()\n",
    "\n",
    "    def _suff_stats_layer(self, name, x):\n",
    "        if self._discrete:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            logit = x.reshape(list(x.shape[:-1]) + [self._stoch, self._discrete])\n",
    "            return {\"logit\": logit}\n",
    "        else:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            mean, std = torch.split(x, [self._stoch] * 2, -1)\n",
    "            mean = {\n",
    "                \"none\": lambda: mean,\n",
    "                \"tanh5\": lambda: 5.0 * torch.tanh(mean / 5.0),\n",
    "            }[self._mean_act]()\n",
    "            std = {\n",
    "                \"softplus\": lambda: torch.softplus(std),\n",
    "                \"abs\": lambda: torch.abs(std + 1),\n",
    "                \"sigmoid\": lambda: torch.sigmoid(std),\n",
    "                \"sigmoid2\": lambda: 2 * torch.sigmoid(std / 2),\n",
    "            }[self._std_act]()\n",
    "            std = std + self._min_std\n",
    "            return {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    def kl_loss(self, post, prior, free, dyn_scale, rep_scale):\n",
    "        kld = torchd.kl.kl_divergence\n",
    "        dist = lambda x: self.get_dist(x)\n",
    "        sg = lambda x: {k: v.detach() for k, v in x.items()}\n",
    "\n",
    "        rep_loss = value = kld(\n",
    "            dist(post) if self._discrete else dist(post)._dist,\n",
    "            dist(sg(prior)) if self._discrete else dist(sg(prior))._dist,\n",
    "        )\n",
    "        dyn_loss = kld(\n",
    "            dist(sg(post)) if self._discrete else dist(sg(post))._dist,\n",
    "            dist(prior) if self._discrete else dist(prior)._dist,\n",
    "        )\n",
    "        # this is implemented using maximum at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        rep_loss = torch.clip(rep_loss, min=free)\n",
    "        dyn_loss = torch.clip(dyn_loss, min=free)\n",
    "        loss = dyn_scale * dyn_loss + rep_scale * rep_loss\n",
    "\n",
    "        return loss, value, dyn_loss, rep_loss\n",
    "\n",
    "\n",
    "class MultiEncoder(nn.Module):\n",
    "    def __init__(self, shapes, config):\n",
    "        super(MultiEncoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\", \"reward\")\n",
    "        shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if k not in excluded and not k.startswith(\"log_\")\n",
    "        }\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "\n",
    "        print(shapes.items())\n",
    "        print(config.mlp_keys)\n",
    "        print(config.cnn_keys)\n",
    "        for k, v in shapes.items():\n",
    "            print(\"cnn\")\n",
    "            print(len(v) == 3)\n",
    "            print(re.match(self.config.cnn_keys, k))\n",
    "            print(self.config.cnn_keys)\n",
    "            print(k)\n",
    "            print(\"mlp\")\n",
    "            print(len(v) in (1, 2))\n",
    "            print(re.match(self.config.mlp_keys, k))\n",
    "            print(self.config.mlp_keys)\n",
    "            print(k)\n",
    "\n",
    "        print(\"Encoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Encoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        self.outdim = 0\n",
    "        if self.cnn_shapes:\n",
    "            input_ch = sum([v[-1] for v in self.cnn_shapes.values()])\n",
    "            input_shape = tuple(self.cnn_shapes.values())[0][:2] + (input_ch,)\n",
    "            self._cnn = ConvEncoder(\n",
    "                input_shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "            )\n",
    "            self.outdim += self._cnn.outdim\n",
    "        if self.mlp_shapes:\n",
    "            input_size = sum([sum(v) for v in self.mlp_shapes.values()])\n",
    "            for v in self.mlp_shapes.values():\n",
    "                print(\"v: \", v)\n",
    "            print(\"input_size: \", input_size)\n",
    "            self._mlp = MLP(\n",
    "                input_size,\n",
    "                None,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                symlog_inputs=self.config.symlog_inputs,\n",
    "                name=\"Encoder\",\n",
    "            )\n",
    "            self.outdim += self.config.mlp_units\n",
    "\n",
    "    def forward(self, obs):\n",
    "        outputs = []\n",
    "        if self.cnn_shapes:\n",
    "            inputs = torch.cat([obs[k] for k in self.cnn_shapes], -1)\n",
    "            outputs.append(self._cnn(inputs))\n",
    "            # print(\"CNN output shape: \", outputs[-1].shape)\n",
    "        if self.mlp_shapes:\n",
    "            # print(\"obs\", obs)\n",
    "            inputs = torch.cat([obs[k] for k in self.mlp_shapes], -1)\n",
    "            # print(inputs.shape)\n",
    "            outputs.append(self._mlp(inputs))\n",
    "            # print(\"MLP output shape: \", outputs[-1].shape)\n",
    "        outputs = torch.cat(outputs, -1)\n",
    "        # print(\"Encoder output shape: \", outputs.shape)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MultiDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shapes,\n",
    "        config,\n",
    "    ):\n",
    "        super(MultiDecoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\")\n",
    "        shapes = {k: v for k, v in shapes.items() if k not in excluded}\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "        print(\"Decoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Decoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        if self.cnn_shapes:\n",
    "            some_shape = list(self.cnn_shapes.values())[0]\n",
    "            shape = (sum(x[-1] for x in self.cnn_shapes.values()),) + some_shape[:-1]\n",
    "            self._cnn = ConvDecoder(\n",
    "                feat_size,\n",
    "                shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "                outscale=self.config.outscale,\n",
    "                cnn_sigmoid=self.config.cnn_sigmoid,\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            self._mlp = MLP(\n",
    "                feat_size,\n",
    "                self.mlp_shapes,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.vector_dist,\n",
    "                outscale=self.config.outscale,\n",
    "                name=\"Decoder\",\n",
    "            )\n",
    "        self._image_dist = self.config.image_dist\n",
    "\n",
    "    def forward(self, features):\n",
    "        dists = {}\n",
    "        if self.cnn_shapes:\n",
    "            feat = features\n",
    "            outputs = self._cnn(feat)\n",
    "            split_sizes = [v[-1] for v in self.cnn_shapes.values()]\n",
    "            outputs = torch.split(outputs, split_sizes, -1)\n",
    "            dists.update(\n",
    "                {\n",
    "                    key: self._make_image_dist(output)\n",
    "                    for key, output in zip(self.cnn_shapes.keys(), outputs)\n",
    "                }\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            dists.update(self._mlp(features))\n",
    "        return dists\n",
    "\n",
    "    def _make_image_dist(self, mean):\n",
    "        if self._image_dist == \"normal\":\n",
    "            return ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, 1), 3)\n",
    "            )\n",
    "        if self._image_dist == \"mse\":\n",
    "            return MSEDist(mean)\n",
    "        raise NotImplementedError(self._image_dist)\n",
    "\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        depth=32,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "    ):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        h, w, input_ch = input_shape\n",
    "        stages = int(np.log2(h) - np.log2(minres))\n",
    "        in_dim = input_ch\n",
    "        out_dim = depth\n",
    "        layers = []\n",
    "        for i in range(stages):\n",
    "            layers.append(\n",
    "                Conv2dSamePad(\n",
    "                    in_channels=in_dim,\n",
    "                    out_channels=out_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=2,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim *= 2\n",
    "            h, w = h // 2, w // 2\n",
    "\n",
    "        # self.outdim = out_dim // 2 * h * w\n",
    "        # print(\"h, w: \", h, w)\n",
    "        # print(\"Encoder output shape (outdim): \", self.outdim)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # print(\"Encoder layers: \", self.layers)\n",
    "        # print(\"Encoder layers shape: \", self.layers[0].weight.shape)\n",
    "        self.layers.apply(weight_init)\n",
    "        self.outdim = self.calculate_outdim(input_shape)\n",
    "\n",
    "    def calculate_outdim(self, input_shape):\n",
    "        obs = torch.randn(1, *input_shape)\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]]).shape[-1]\n",
    "\n",
    "    def forward(self, obs):\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]])\n",
    "\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shape=(3, 64, 64),\n",
    "        depth=32,\n",
    "        act=nn.ELU,\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "        outscale=1.0,\n",
    "        cnn_sigmoid=False,\n",
    "    ):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._shape = shape\n",
    "        self._cnn_sigmoid = cnn_sigmoid\n",
    "        layer_num = int(np.log2(shape[1]) - np.log2(minres))\n",
    "        self._minres = minres\n",
    "        out_ch = minres**2 * depth * 2 ** (layer_num - 1)\n",
    "        self._embed_size = out_ch\n",
    "\n",
    "        self._linear_layer = nn.Linear(feat_size, out_ch)\n",
    "        self._linear_layer.apply(uniform_weight_init(outscale))\n",
    "        in_dim = out_ch // (minres**2)\n",
    "        out_dim = in_dim // 2\n",
    "\n",
    "        layers = []\n",
    "        h, w = minres, minres\n",
    "        for i in range(layer_num):\n",
    "            bias = False\n",
    "            if i == layer_num - 1:\n",
    "                out_dim = self._shape[0]\n",
    "                act = False\n",
    "                bias = True\n",
    "                norm = False\n",
    "\n",
    "            if i != 0:\n",
    "                in_dim = 2 ** (layer_num - (i - 1) - 2) * depth\n",
    "            pad_h, outpad_h = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            pad_w, outpad_w = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            layers.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    kernel_size,\n",
    "                    2,\n",
    "                    padding=(pad_h, pad_w),\n",
    "                    output_padding=(outpad_h, outpad_w),\n",
    "                    bias=bias,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            if act:\n",
    "                layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim //= 2\n",
    "            h, w = h * 2, w * 2\n",
    "        [m.apply(weight_init) for m in layers[:-1]]\n",
    "        layers[-1].apply(uniform_weight_init(outscale))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def calc_same_pad(self, k, s, d):\n",
    "        val = d * (k - 1) - s + 1\n",
    "        pad = math.ceil(val / 2)\n",
    "        outpad = pad * 2 - val\n",
    "        return pad, outpad\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = self._linear_layer(features)\n",
    "        # (batch, time, -1) -> (batch * time, h, w, ch)\n",
    "        x = x.reshape(\n",
    "            [-1, self._minres, self._minres, self._embed_size // self._minres**2]\n",
    "        )\n",
    "        # (batch, time, -1) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.layers(x)\n",
    "        # (batch, time, -1) -> (batch, time, ch, h, w)\n",
    "        mean = x.reshape(features.shape[:-1] + self._shape)\n",
    "        # (batch, time, ch, h, w) -> (batch, time, h, w, ch)\n",
    "        mean = mean.permute(0, 1, 3, 4, 2)\n",
    "        if self._cnn_sigmoid:\n",
    "            mean = F.sigmoid(mean)\n",
    "        else:\n",
    "            mean += 0.5\n",
    "        return mean\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim,\n",
    "        shape,\n",
    "        layers,\n",
    "        units,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        dist=\"normal\",\n",
    "        std=1.0,\n",
    "        min_std=0.1,\n",
    "        max_std=1.0,\n",
    "        absmax=None,\n",
    "        temp=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        outscale=1.0,\n",
    "        symlog_inputs=False,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        name=\"NoName\",\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self._shape = (shape,) if isinstance(shape, int) else shape\n",
    "        if self._shape is not None and len(self._shape) == 0:\n",
    "            self._shape = (1,)\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._dist = dist\n",
    "        self._std = std if isinstance(std, str) else torch.tensor((std,), device=device)\n",
    "        self._min_std = min_std\n",
    "        self._max_std = max_std\n",
    "        self._absmax = absmax\n",
    "        self._temp = temp\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._symlog_inputs = symlog_inputs\n",
    "        self._device = device\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for i in range(layers):\n",
    "            self.layers.add_module(\n",
    "                f\"{name}_linear{i}\", nn.Linear(inp_dim, units, bias=False)\n",
    "            )\n",
    "            if norm:\n",
    "                self.layers.add_module(\n",
    "                    f\"{name}_norm{i}\", nn.LayerNorm(units, eps=1e-03)\n",
    "                )\n",
    "            self.layers.add_module(f\"{name}_act{i}\", act())\n",
    "            if i == 0:\n",
    "                inp_dim = units\n",
    "        self.layers.apply(weight_init)\n",
    "\n",
    "        if isinstance(self._shape, dict):\n",
    "            self.mean_layer = nn.ModuleDict()\n",
    "            for name, shape in self._shape.items():\n",
    "                self.mean_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.ModuleDict()\n",
    "                for name, shape in self._shape.items():\n",
    "                    self.std_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "        elif self._shape is not None:\n",
    "            self.mean_layer = nn.Linear(inp_dim, np.prod(self._shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.Linear(units, np.prod(self._shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = features\n",
    "        # print(\"MLP input shape: \", x.shape)\n",
    "        if self._symlog_inputs:\n",
    "            x = symlog(x)\n",
    "            # print(\"MLP input shape after symlog: \", x.shape)\n",
    "        out = self.layers(x)\n",
    "        # print(\"MLP output shape: \", out.shape)\n",
    "        # Used for encoder output\n",
    "        if self._shape is None:\n",
    "            return out\n",
    "        if isinstance(self._shape, dict):\n",
    "            dists = {}\n",
    "            for name, shape in self._shape.items():\n",
    "                mean = self.mean_layer[name](out)\n",
    "                if self._std == \"learned\":\n",
    "                    std = self.std_layer[name](out)\n",
    "                else:\n",
    "                    std = self._std\n",
    "                dists.update({name: self.dist(self._dist, mean, std, shape)})\n",
    "            return dists\n",
    "        else:\n",
    "            mean = self.mean_layer(out)\n",
    "            if self._std == \"learned\":\n",
    "                std = self.std_layer(out)\n",
    "            else:\n",
    "                std = self._std\n",
    "            return self.dist(self._dist, mean, std, self._shape)\n",
    "\n",
    "    def dist(self, dist, mean, std, shape):\n",
    "        if dist == \"tanh_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = F.softplus(std) + self._min_std\n",
    "            dist = torchd.normal.Normal(mean, std)\n",
    "            dist = torchd.transformed_distribution.TransformedDistribution(\n",
    "                dist, TanhBijector()\n",
    "            )\n",
    "            dist = torchd.independent.Independent(dist, 1)\n",
    "            dist = SampleDist(dist)\n",
    "        elif dist == \"normal\":\n",
    "            std = (self._max_std - self._min_std) * torch.sigmoid(\n",
    "                std + 2.0\n",
    "            ) + self._min_std\n",
    "            dist = torchd.normal.Normal(torch.tanh(mean), std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"normal_std_fixed\":\n",
    "            dist = torchd.normal.Normal(mean, self._std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"trunc_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = 2 * torch.sigmoid(std / 2) + self._min_std\n",
    "            dist = SafeTruncatedNormal(mean, std, -1, 1)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"onehot\":\n",
    "            dist = OneHotDist(mean, unimix_ratio=self._unimix_ratio)\n",
    "        elif dist == \"onehot_gumble\":\n",
    "            dist = ContDist(\n",
    "                torchd.gumbel.Gumbel(mean, 1 / self._temp), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"huber\":\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(\n",
    "                    UnnormalizedHuber(mean, std, 1.0),\n",
    "                    len(shape),\n",
    "                    absmax=self._absmax,\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"binary\":\n",
    "            dist = Bernoulli(\n",
    "                torchd.independent.Independent(\n",
    "                    torchd.bernoulli.Bernoulli(logits=mean), len(shape)\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"symlog_disc\":\n",
    "            dist = DiscDist(logits=mean, device=self._device)\n",
    "        elif dist == \"symlog_mse\":\n",
    "            dist = SymlogDist(mean)\n",
    "        else:\n",
    "            raise NotImplementedError(dist)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, inp_size, size, norm=True, act=torch.tanh, update_bias=-1):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self._inp_size = inp_size\n",
    "        self._size = size\n",
    "        self._act = act\n",
    "        self._update_bias = update_bias\n",
    "        self.layers = nn.Sequential()\n",
    "        self.layers.add_module(\n",
    "            \"GRU_linear\", nn.Linear(inp_size + size, 3 * size, bias=False)\n",
    "        )\n",
    "        if norm:\n",
    "            self.layers.add_module(\"GRU_norm\", nn.LayerNorm(3 * size, eps=1e-03))\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._size\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        state = state[0]  # Keras wraps the state in a list.\n",
    "        parts = self.layers(torch.cat([inputs, state], -1))\n",
    "        reset, cand, update = torch.split(parts, [self._size] * 3, -1)\n",
    "        reset = torch.sigmoid(reset)\n",
    "        cand = self._act(reset * cand)\n",
    "        update = torch.sigmoid(update + self._update_bias)\n",
    "        output = update * cand + (1 - update) * state\n",
    "        return output, [output]\n",
    "\n",
    "\n",
    "class Conv2dSamePad(torch.nn.Conv2d):\n",
    "    def calc_same_pad(self, i, k, s, d):\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        pad_h = self.calc_same_pad(\n",
    "            i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0]\n",
    "        )\n",
    "        pad_w = self.calc_same_pad(\n",
    "            i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1]\n",
    "        )\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "\n",
    "        ret = F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "        return ret\n",
    "\n",
    "\n",
    "class ImgChLayerNorm(nn.Module):\n",
    "    def __init__(self, ch, eps=1e-03):\n",
    "        super(ImgChLayerNorm, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(ch, eps=eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class RewardEMA:\n",
    "    \"\"\"running mean and std\"\"\"\n",
    "\n",
    "    def __init__(self, device, alpha=1e-2):\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.range = torch.tensor([0.05, 0.95], device=device)\n",
    "\n",
    "    def __call__(self, x, ema_vals):\n",
    "        flat_x = torch.flatten(x.detach())\n",
    "        x_quantile = torch.quantile(input=flat_x, q=self.range)\n",
    "        # this should be in-place operation\n",
    "        ema_vals[:] = self.alpha * x_quantile + (1 - self.alpha) * ema_vals\n",
    "        scale = torch.clip(ema_vals[1] - ema_vals[0], min=1.0)\n",
    "        offset = ema_vals[0]\n",
    "        return offset.detach(), scale.detach()\n",
    "\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, step, config):\n",
    "        super(WorldModel, self).__init__()\n",
    "        self._step = step\n",
    "        self._use_amp = True if config.precision == 16 else False\n",
    "        self._config = config\n",
    "        shapes = {k: tuple(v.shape) for k, v in obs_space.spaces.items()}\n",
    "        self.encoder = MultiEncoder(shapes, config.encoder)\n",
    "        self.embed_size = self.encoder.outdim\n",
    "        self.dynamics = RSSM(\n",
    "            config.dyn_stoch,\n",
    "            config.dyn_deter,\n",
    "            config.dyn_hidden,\n",
    "            config.dyn_rec_depth,\n",
    "            config.dyn_discrete,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            config.dyn_mean_act,\n",
    "            config.dyn_std_act,\n",
    "            config.dyn_min_std,\n",
    "            config.unimix_ratio,\n",
    "            config.initial,\n",
    "            config.num_actions,\n",
    "            self.embed_size,\n",
    "            config.device,\n",
    "        )\n",
    "        self.heads = nn.ModuleDict()\n",
    "        if config.dyn_discrete:\n",
    "            feat_size = config.dyn_stoch * config.dyn_discrete + config.dyn_deter\n",
    "        else:\n",
    "            feat_size = config.dyn_stoch + config.dyn_deter\n",
    "        self.heads[\"decoder\"] = MultiDecoder(feat_size, shapes, config.decoder)\n",
    "        self.heads[\"reward\"] = MLP(\n",
    "            feat_size,\n",
    "            (255,) if config.reward_head.dist == \"symlog_disc\" else (),\n",
    "            config.reward_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=config.reward_head.dist,\n",
    "            outscale=config.reward_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Reward\",\n",
    "        )\n",
    "        self.heads[\"cont\"] = MLP(\n",
    "            feat_size,\n",
    "            (),\n",
    "            config.cont_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=\"binary\",\n",
    "            outscale=config.cont_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Cont\",\n",
    "        )\n",
    "        for name in config.grad_heads:\n",
    "            assert name in self.heads, name\n",
    "        self._model_opt = Optimizer(\n",
    "            \"model\",\n",
    "            self.parameters(),\n",
    "            config.model_lr,\n",
    "            config.opt_eps,\n",
    "            config.grad_clip,\n",
    "            config.weight_decay,\n",
    "            opt=config.opt,\n",
    "            use_amp=self._use_amp,\n",
    "        )\n",
    "        print(\n",
    "            f\"Optimizer model_opt has {sum(param.numel() for param in self.parameters())} variables.\"\n",
    "        )\n",
    "        # other losses are scaled by 1.0.\n",
    "        self._scales = dict(\n",
    "            reward=config.reward_head.loss_scale,\n",
    "            cont=config.cont_head.loss_scale,\n",
    "        )\n",
    "\n",
    "    def _train(self, data):\n",
    "        # action (batch_size, batch_length, act_dim)\n",
    "        # image (batch_size, batch_length, h, w, ch)\n",
    "        # reward (batch_size, batch_length)\n",
    "        # discount (batch_size, batch_length)\n",
    "        data = self.preprocess(data)\n",
    "\n",
    "        with RequiresGrad(self):\n",
    "            with torch.cuda.amp.autocast(self._use_amp):\n",
    "                embed = self.encoder(data)\n",
    "                post, prior = self.dynamics.observe(\n",
    "                    embed, data[\"action\"], data[\"is_first\"]\n",
    "                )\n",
    "                kl_free = self._config.kl_free\n",
    "                dyn_scale = self._config.dyn_scale\n",
    "                rep_scale = self._config.rep_scale\n",
    "                kl_loss, kl_value, dyn_loss, rep_loss = self.dynamics.kl_loss(\n",
    "                    post, prior, kl_free, dyn_scale, rep_scale\n",
    "                )\n",
    "                assert kl_loss.shape == embed.shape[:2], kl_loss.shape\n",
    "                preds = {}\n",
    "                for name, head in self.heads.items():\n",
    "                    grad_head = name in self._config.grad_heads\n",
    "                    feat = self.dynamics.get_feat(post)\n",
    "                    feat = feat if grad_head else feat.detach()\n",
    "                    pred = head(feat)\n",
    "                    if type(pred) is dict:\n",
    "                        preds.update(pred)\n",
    "                    else:\n",
    "                        preds[name] = pred\n",
    "                losses = {}\n",
    "                for name, pred in preds.items():\n",
    "                    loss = -pred.log_prob(data[name])\n",
    "                    assert loss.shape == embed.shape[:2], (name, loss.shape)\n",
    "                    losses[name] = loss\n",
    "                scaled = {\n",
    "                    key: value * self._scales.get(key, 1.0)\n",
    "                    for key, value in losses.items()\n",
    "                }\n",
    "                model_loss = sum(scaled.values()) + kl_loss\n",
    "            metrics = self._model_opt(torch.mean(model_loss), self.parameters())\n",
    "\n",
    "        metrics.update({f\"{name}_loss\": to_np(loss) for name, loss in losses.items()})\n",
    "        metrics[\"kl_free\"] = kl_free\n",
    "        metrics[\"dyn_scale\"] = dyn_scale\n",
    "        metrics[\"rep_scale\"] = rep_scale\n",
    "        metrics[\"dyn_loss\"] = to_np(dyn_loss)\n",
    "        metrics[\"rep_loss\"] = to_np(rep_loss)\n",
    "        metrics[\"kl\"] = to_np(torch.mean(kl_value))\n",
    "        with torch.cuda.amp.autocast(self._use_amp):\n",
    "            metrics[\"prior_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(prior).entropy())\n",
    "            )\n",
    "            metrics[\"post_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(post).entropy())\n",
    "            )\n",
    "            context = dict(\n",
    "                embed=embed,\n",
    "                feat=self.dynamics.get_feat(post),\n",
    "                kl=kl_value,\n",
    "                postent=self.dynamics.get_dist(post).entropy(),\n",
    "            )\n",
    "        post = {k: v.detach() for k, v in post.items()}\n",
    "        return post, context, metrics\n",
    "\n",
    "    # this function is called during both rollout and training\n",
    "    def preprocess(self, obs):\n",
    "        # print(\"WorldModel preprocess\")\n",
    "        obs = {\n",
    "            k: torch.tensor(v, device=self._config.device, dtype=torch.float32)\n",
    "            for k, v in obs.items()\n",
    "        }\n",
    "        if \"image\" in obs:\n",
    "            obs[\"image\"] = obs[\"image\"] / 255.0\n",
    "        # print(\"obs image shape: \", obs[\"image\"].shape)\n",
    "        # if \"discount\" in obs:\n",
    "        #     obs[\"discount\"] *= self._config.discount\n",
    "        #     # (batch_size, batch_length) -> (batch_size, batch_length, 1)\n",
    "        #     obs[\"discount\"] = obs[\"discount\"].unsqueeze(-1)\n",
    "        # 'is_first' is necesarry to initialize hidden state at training\n",
    "        assert \"is_first\" in obs\n",
    "        # 'is_terminal' is necesarry to train cont_head\n",
    "        assert \"is_terminal\" in obs\n",
    "        obs[\"cont\"] = (1.0 - obs[\"is_terminal\"]).unsqueeze(-1)\n",
    "        return obs\n",
    "\n",
    "    def video_pred(self, data):\n",
    "        print(\"WorldModel video_pred\")\n",
    "        data = self.preprocess(data)\n",
    "        embed = self.encoder(data)\n",
    "\n",
    "        if \"image\" not in data:\n",
    "            return None\n",
    "\n",
    "        states, _ = self.dynamics.observe(\n",
    "            embed[:6, :5], data[\"action\"][:6, :5], data[\"is_first\"][:6, :5]\n",
    "        )\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()[\n",
    "            :6\n",
    "        ]\n",
    "        reward_post = self.heads[\"reward\"](self.dynamics.get_feat(states)).mode()[:6]\n",
    "        init = {k: v[:, -1] for k, v in states.items()}\n",
    "        prior = self.dynamics.imagine_with_action(data[\"action\"][:6, 5:], init)\n",
    "        openl = self.heads[\"decoder\"](self.dynamics.get_feat(prior))[\"image\"].mode()\n",
    "        reward_prior = self.heads[\"reward\"](self.dynamics.get_feat(prior)).mode()\n",
    "        # observed image is given until 5 steps\n",
    "        model = torch.cat([recon[:, :5], openl], 1)\n",
    "        truth = data[\"image\"][:6]\n",
    "        model = model\n",
    "        error = (model - truth + 1.0) / 2.0\n",
    "\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        obs = data[\"image\"]\n",
    "        states, _ = self.dynamics.observe(embed, data[\"action\"], data[\"is_first\"])\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()\n",
    "        decoded_obs = recon\n",
    "        # rewards = reward_post\n",
    "        # predicted_rewards = reward_prior\n",
    "        batch_idx = np.random.randint(0, obs.shape[0])\n",
    "        seq_idx = np.random.randint(0, obs.shape[1] - 3)\n",
    "        grayscale = obs.shape[-1] == 1\n",
    "\n",
    "        # print(rewards.shape, predicted_rewards.shape)\n",
    "        obs = obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        decoded_obs = decoded_obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # rewards = rewards[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # predicted_rewards = predicted_rewards[batch_idx][seq_idx : seq_idx + 3]\n",
    "\n",
    "        obs = obs.cpu().detach().numpy()\n",
    "        fig, axs = plt.subplots(3, 2)\n",
    "        axs[0][0].imshow(obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][0].set_title(f\"Iteration: {self._step} -- Reward: {rewards[0]:.4f}\")\n",
    "        axs[0][0].axis(\"off\")\n",
    "        axs[0][1].imshow(decoded_obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][1].set_title(f\"Pred. Reward: {predicted_rewards[0, 0]:.4f}\")\n",
    "        axs[0][1].axis(\"off\")\n",
    "\n",
    "        axs[1][0].imshow(obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        axs[1][0].axis(\"off\")\n",
    "        # axs[1][0].set_title(f\"Reward: {rewards[1, 0]:.4f} \")\n",
    "        axs[1][1].imshow(decoded_obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[1][1].set_title(f\"Pred. Reward: {predicted_rewards[1]:.4f}\")\n",
    "        axs[1][1].axis(\"off\")\n",
    "\n",
    "        axs[2][0].imshow(obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        axs[2][0].axis(\"off\")\n",
    "        # axs[2][0].set_title(f\"Reward: {rewards[2, 0]:.4f}\")\n",
    "        axs[2][1].imshow(decoded_obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[2][1].set_title(f\"Pred. Reward: {predicted_rewards[2]:.4f}\")\n",
    "        axs[2][1].axis(\"off\")\n",
    "\n",
    "        if not os.path.exists(\"reconstructions\"):\n",
    "            os.makedirs(\"reconstructions\")\n",
    "        fig.savefig(f\"reconstructions/iteration_{step}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        return torch.cat([truth, model, error], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class Dreamer(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, config, logger, dataset):\n",
    "        super(Dreamer, self).__init__()\n",
    "        self._config = config\n",
    "        self._logger = logger\n",
    "        self._should_log = Every(config.log_every)\n",
    "        batch_steps = config.batch_size * config.batch_length\n",
    "        self._should_train = Every(batch_steps / config.train_ratio)\n",
    "        self._should_pretrain = Once()\n",
    "        self._should_reset = Every(config.reset_every)\n",
    "        # self._should_expl = Until(int(config.expl_until / config.action_repeat))\n",
    "        self._metrics = {}\n",
    "        # this is update step\n",
    "        self._step = logger.step // config.action_repeat\n",
    "        self._update_count = 0\n",
    "        self._dataset = dataset\n",
    "        self._wm = WorldModel(obs_space, act_space, self._step, config)\n",
    "        if (\n",
    "            config.compile and os.name != \"nt\"\n",
    "        ):  # compilation is not supported on windows\n",
    "            self._wm = torch.compile(self._wm)\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](f).mean()\n",
    "        self._expl_behavior = Random(config, act_space)\n",
    "\n",
    "    def __call__(self, obs, reset, state=None, training=True):\n",
    "        step = self._step\n",
    "        if training:\n",
    "            steps = (\n",
    "                self._config.pretrain\n",
    "                if self._should_pretrain()\n",
    "                else self._should_train(step)\n",
    "            )\n",
    "            for _ in range(steps):\n",
    "                print(\"iter: \", _)\n",
    "                self._train(next(self._dataset))\n",
    "                self._update_count += 1\n",
    "                self._metrics[\"update_count\"] = self._update_count\n",
    "            if self._should_log(step):\n",
    "                for name, values in self._metrics.items():\n",
    "                    self._logger.scalar(name, float(np.mean(values)))\n",
    "                    self._metrics[name] = []\n",
    "                if self._config.video_pred_log:\n",
    "                    openl = self._wm.video_pred(next(self._dataset))\n",
    "                    self._logger.video(\"train_openl\", to_np(openl))\n",
    "                self._logger.write(fps=True)\n",
    "        # policy_output, state = self._policy(obs, state, training)\n",
    "        if state is None:\n",
    "            latent = action = None\n",
    "        else:\n",
    "            latent, action = state\n",
    "        obs = self._wm.preprocess(obs)\n",
    "        embed = self._wm.encoder(obs)\n",
    "        latent, _ = self._wm.dynamics.obs_step(latent, action, embed, obs[\"is_first\"])\n",
    "        # if self._config.eval_state_mean:\n",
    "        #     latent[\"stoch\"] = latent[\"mean\"]\n",
    "        feat = self._wm.dynamics.get_feat(latent)\n",
    "        actor = self._expl_behavior.actor(feat)\n",
    "        action = actor.sample()\n",
    "        # print(\"obs action mask\", obs[\"action_mask\"])\n",
    "        print(action)\n",
    "\n",
    "        logprob = actor.log_prob(action)\n",
    "        latent = {k: v.detach() for k, v in latent.items()}\n",
    "        action = action.detach()\n",
    "        # if self._config.actor[\"dist\"] == \"onehot_gumble\":\n",
    "        # action = torch.one_hot(\n",
    "        action = torch.nn.functional.one_hot(\n",
    "            torch.argmax(action, dim=-1), self._config.num_actions\n",
    "        )\n",
    "        policy_output = {\"action\": action, \"logprob\": logprob}\n",
    "        print(policy_output[\"action\"].shape)\n",
    "        state = (latent, action)\n",
    "\n",
    "        if training:\n",
    "            self._step += len(reset)\n",
    "            self._logger.step = self._config.action_repeat * self._step\n",
    "        return policy_output, state\n",
    "\n",
    "    def _train(self, data):\n",
    "        print(\"dreamer train step:\")\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        metrics = {}\n",
    "        post, context, mets = self._wm._train(data)\n",
    "        metrics.update(mets)\n",
    "        start = post\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](\n",
    "            self._wm.dynamics.get_feat(s)\n",
    "        ).mode()\n",
    "        # metrics.update(self._task_behavior._train(start, reward)[-1])\n",
    "        for name, value in metrics.items():\n",
    "            if not name in self._metrics.keys():\n",
    "                self._metrics[name] = [value]\n",
    "            else:\n",
    "                self._metrics[name].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logdir logdir\n",
      "Create envs.\n",
      "agent selection 0\n",
      "agent selection 0\n",
      "Action Space Discrete(4)\n",
      "Prefill dataset (2500 steps).\n",
      "[0] dataset_size 4.0 / train_return -900.0 / train_length 4.0 / train_episodes 1.0\n",
      "[0] dataset_size 7.0 / train_return -100.0 / train_length 3.0 / train_episodes 2.0\n",
      "[0] dataset_size 11.0 / train_return 1200.0 / train_length 4.0 / train_episodes 3.0\n",
      "[0] dataset_size 13.0 / train_return 1200.0 / train_length 2.0 / train_episodes 4.0\n",
      "[0] dataset_size 14.0 / train_return -50.0 / train_length 1.0 / train_episodes 5.0\n",
      "[0] dataset_size 18.0 / train_return -300.0 / train_length 4.0 / train_episodes 6.0\n",
      "[0] dataset_size 21.0 / train_return 1200.0 / train_length 3.0 / train_episodes 7.0\n",
      "[0] dataset_size 23.0 / train_return -1200.0 / train_length 2.0 / train_episodes 8.0\n",
      "[0] dataset_size 26.0 / train_return -100.0 / train_length 3.0 / train_episodes 9.0\n",
      "[0] dataset_size 27.0 / train_return -50.0 / train_length 1.0 / train_episodes 10.0\n",
      "[0] dataset_size 30.0 / train_return 1200.0 / train_length 3.0 / train_episodes 11.0\n",
      "[0] dataset_size 32.0 / train_return -100.0 / train_length 2.0 / train_episodes 12.0\n",
      "[0] dataset_size 33.0 / train_return -50.0 / train_length 1.0 / train_episodes 13.0\n",
      "[0] dataset_size 35.0 / train_return -100.0 / train_length 2.0 / train_episodes 14.0\n",
      "[0] dataset_size 36.0 / train_return -50.0 / train_length 1.0 / train_episodes 15.0\n",
      "[0] dataset_size 37.0 / train_return -50.0 / train_length 1.0 / train_episodes 16.0\n",
      "[0] dataset_size 40.0 / train_return -300.0 / train_length 3.0 / train_episodes 17.0\n",
      "[0] dataset_size 41.0 / train_return -50.0 / train_length 1.0 / train_episodes 18.0\n",
      "[0] dataset_size 43.0 / train_return -100.0 / train_length 2.0 / train_episodes 19.0\n",
      "[0] dataset_size 46.0 / train_return -300.0 / train_length 3.0 / train_episodes 20.0\n",
      "[0] dataset_size 48.0 / train_return -100.0 / train_length 2.0 / train_episodes 21.0\n",
      "[0] dataset_size 51.0 / train_return -1200.0 / train_length 3.0 / train_episodes 22.0\n",
      "[0] dataset_size 53.0 / train_return 1200.0 / train_length 2.0 / train_episodes 23.0\n",
      "[0] dataset_size 55.0 / train_return 0.0 / train_length 2.0 / train_episodes 24.0\n",
      "[0] dataset_size 56.0 / train_return -50.0 / train_length 1.0 / train_episodes 25.0\n",
      "[0] dataset_size 57.0 / train_return -50.0 / train_length 1.0 / train_episodes 26.0\n",
      "[0] dataset_size 59.0 / train_return -100.0 / train_length 2.0 / train_episodes 27.0\n",
      "[0] dataset_size 60.0 / train_return -50.0 / train_length 1.0 / train_episodes 28.0\n",
      "[0] dataset_size 61.0 / train_return -50.0 / train_length 1.0 / train_episodes 29.0\n",
      "[0] dataset_size 62.0 / train_return -50.0 / train_length 1.0 / train_episodes 30.0\n",
      "[0] dataset_size 64.0 / train_return 0.0 / train_length 2.0 / train_episodes 31.0\n",
      "[0] dataset_size 67.0 / train_return -1200.0 / train_length 3.0 / train_episodes 32.0\n",
      "[0] dataset_size 69.0 / train_return -1200.0 / train_length 2.0 / train_episodes 33.0\n",
      "[0] dataset_size 71.0 / train_return -100.0 / train_length 2.0 / train_episodes 34.0\n",
      "[0] dataset_size 72.0 / train_return -50.0 / train_length 1.0 / train_episodes 35.0\n",
      "[0] dataset_size 74.0 / train_return -100.0 / train_length 2.0 / train_episodes 36.0\n",
      "[0] dataset_size 75.0 / train_return -50.0 / train_length 1.0 / train_episodes 37.0\n",
      "[0] dataset_size 77.0 / train_return -100.0 / train_length 2.0 / train_episodes 38.0\n",
      "[0] dataset_size 78.0 / train_return -50.0 / train_length 1.0 / train_episodes 39.0\n",
      "[0] dataset_size 80.0 / train_return -100.0 / train_length 2.0 / train_episodes 40.0\n",
      "[0] dataset_size 85.0 / train_return -100.0 / train_length 5.0 / train_episodes 41.0\n",
      "[0] dataset_size 87.0 / train_return -100.0 / train_length 2.0 / train_episodes 42.0\n",
      "[0] dataset_size 91.0 / train_return -900.0 / train_length 4.0 / train_episodes 43.0\n",
      "[0] dataset_size 95.0 / train_return -300.0 / train_length 4.0 / train_episodes 44.0\n",
      "[0] dataset_size 97.0 / train_return -1200.0 / train_length 2.0 / train_episodes 45.0\n",
      "[0] dataset_size 99.0 / train_return -1200.0 / train_length 2.0 / train_episodes 46.0\n",
      "[0] dataset_size 101.0 / train_return -100.0 / train_length 2.0 / train_episodes 47.0\n",
      "[0] dataset_size 104.0 / train_return -300.0 / train_length 3.0 / train_episodes 48.0\n",
      "[0] dataset_size 105.0 / train_return -50.0 / train_length 1.0 / train_episodes 49.0\n",
      "[0] dataset_size 110.0 / train_return -100.0 / train_length 5.0 / train_episodes 50.0\n",
      "[0] dataset_size 115.0 / train_return 0.0 / train_length 5.0 / train_episodes 51.0\n",
      "[0] dataset_size 119.0 / train_return 1200.0 / train_length 4.0 / train_episodes 52.0\n",
      "[0] dataset_size 121.0 / train_return 0.0 / train_length 2.0 / train_episodes 53.0\n",
      "[0] dataset_size 125.0 / train_return 0.0 / train_length 4.0 / train_episodes 54.0\n",
      "[0] dataset_size 127.0 / train_return -100.0 / train_length 2.0 / train_episodes 55.0\n",
      "[0] dataset_size 130.0 / train_return 1200.0 / train_length 3.0 / train_episodes 56.0\n",
      "[0] dataset_size 131.0 / train_return -50.0 / train_length 1.0 / train_episodes 57.0\n",
      "[0] dataset_size 132.0 / train_return -50.0 / train_length 1.0 / train_episodes 58.0\n",
      "[0] dataset_size 133.0 / train_return -50.0 / train_length 1.0 / train_episodes 59.0\n",
      "[0] dataset_size 134.0 / train_return -50.0 / train_length 1.0 / train_episodes 60.0\n",
      "[0] dataset_size 138.0 / train_return -300.0 / train_length 4.0 / train_episodes 61.0\n",
      "[0] dataset_size 140.0 / train_return -1200.0 / train_length 2.0 / train_episodes 62.0\n",
      "[0] dataset_size 142.0 / train_return -100.0 / train_length 2.0 / train_episodes 63.0\n",
      "[0] dataset_size 145.0 / train_return 1200.0 / train_length 3.0 / train_episodes 64.0\n",
      "[0] dataset_size 146.0 / train_return -50.0 / train_length 1.0 / train_episodes 65.0\n",
      "[0] dataset_size 151.0 / train_return -300.0 / train_length 5.0 / train_episodes 66.0\n",
      "[0] dataset_size 154.0 / train_return 1200.0 / train_length 3.0 / train_episodes 67.0\n",
      "[0] dataset_size 155.0 / train_return -50.0 / train_length 1.0 / train_episodes 68.0\n",
      "[0] dataset_size 157.0 / train_return -1200.0 / train_length 2.0 / train_episodes 69.0\n",
      "[0] dataset_size 158.0 / train_return -50.0 / train_length 1.0 / train_episodes 70.0\n",
      "[0] dataset_size 163.0 / train_return -100.0 / train_length 5.0 / train_episodes 71.0\n",
      "[0] dataset_size 170.0 / train_return 1200.0 / train_length 7.0 / train_episodes 72.0\n",
      "[0] dataset_size 171.0 / train_return -50.0 / train_length 1.0 / train_episodes 73.0\n",
      "[0] dataset_size 173.0 / train_return -100.0 / train_length 2.0 / train_episodes 74.0\n",
      "[0] dataset_size 174.0 / train_return -50.0 / train_length 1.0 / train_episodes 75.0\n",
      "[0] dataset_size 176.0 / train_return -100.0 / train_length 2.0 / train_episodes 76.0\n",
      "[0] dataset_size 177.0 / train_return -50.0 / train_length 1.0 / train_episodes 77.0\n",
      "[0] dataset_size 179.0 / train_return -100.0 / train_length 2.0 / train_episodes 78.0\n",
      "[0] dataset_size 181.0 / train_return -100.0 / train_length 2.0 / train_episodes 79.0\n",
      "[0] dataset_size 183.0 / train_return -100.0 / train_length 2.0 / train_episodes 80.0\n",
      "[0] dataset_size 185.0 / train_return 1200.0 / train_length 2.0 / train_episodes 81.0\n",
      "[0] dataset_size 188.0 / train_return -100.0 / train_length 3.0 / train_episodes 82.0\n",
      "[0] dataset_size 193.0 / train_return 1200.0 / train_length 5.0 / train_episodes 83.0\n",
      "[0] dataset_size 197.0 / train_return 300.0 / train_length 4.0 / train_episodes 84.0\n",
      "[0] dataset_size 200.0 / train_return -100.0 / train_length 3.0 / train_episodes 85.0\n",
      "[0] dataset_size 205.0 / train_return -1200.0 / train_length 5.0 / train_episodes 86.0\n",
      "[0] dataset_size 208.0 / train_return -100.0 / train_length 3.0 / train_episodes 87.0\n",
      "[0] dataset_size 213.0 / train_return 1200.0 / train_length 5.0 / train_episodes 88.0\n",
      "[0] dataset_size 215.0 / train_return 1200.0 / train_length 2.0 / train_episodes 89.0\n",
      "[0] dataset_size 216.0 / train_return -50.0 / train_length 1.0 / train_episodes 90.0\n",
      "[0] dataset_size 218.0 / train_return -100.0 / train_length 2.0 / train_episodes 91.0\n",
      "[0] dataset_size 221.0 / train_return -100.0 / train_length 3.0 / train_episodes 92.0\n",
      "[0] dataset_size 223.0 / train_return 0.0 / train_length 2.0 / train_episodes 93.0\n",
      "[0] dataset_size 227.0 / train_return 1200.0 / train_length 4.0 / train_episodes 94.0\n",
      "[0] dataset_size 228.0 / train_return -50.0 / train_length 1.0 / train_episodes 95.0\n",
      "[0] dataset_size 229.0 / train_return -50.0 / train_length 1.0 / train_episodes 96.0\n",
      "[0] dataset_size 231.0 / train_return -100.0 / train_length 2.0 / train_episodes 97.0\n",
      "[0] dataset_size 235.0 / train_return -300.0 / train_length 4.0 / train_episodes 98.0\n",
      "[0] dataset_size 238.0 / train_return -300.0 / train_length 3.0 / train_episodes 99.0\n",
      "[0] dataset_size 240.0 / train_return -100.0 / train_length 2.0 / train_episodes 100.0\n",
      "[0] dataset_size 242.0 / train_return -100.0 / train_length 2.0 / train_episodes 101.0\n",
      "[0] dataset_size 244.0 / train_return -100.0 / train_length 2.0 / train_episodes 102.0\n",
      "[0] dataset_size 249.0 / train_return -100.0 / train_length 5.0 / train_episodes 103.0\n",
      "[0] dataset_size 251.0 / train_return -100.0 / train_length 2.0 / train_episodes 104.0\n",
      "[0] dataset_size 252.0 / train_return -50.0 / train_length 1.0 / train_episodes 105.0\n",
      "[0] dataset_size 254.0 / train_return 0.0 / train_length 2.0 / train_episodes 106.0\n",
      "[0] dataset_size 257.0 / train_return 1200.0 / train_length 3.0 / train_episodes 107.0\n",
      "[0] dataset_size 258.0 / train_return -50.0 / train_length 1.0 / train_episodes 108.0\n",
      "[0] dataset_size 259.0 / train_return -50.0 / train_length 1.0 / train_episodes 109.0\n",
      "[0] dataset_size 262.0 / train_return 1200.0 / train_length 3.0 / train_episodes 110.0\n",
      "[0] dataset_size 266.0 / train_return -300.0 / train_length 4.0 / train_episodes 111.0\n",
      "[0] dataset_size 268.0 / train_return -100.0 / train_length 2.0 / train_episodes 112.0\n",
      "[0] dataset_size 269.0 / train_return -50.0 / train_length 1.0 / train_episodes 113.0\n",
      "[0] dataset_size 270.0 / train_return -50.0 / train_length 1.0 / train_episodes 114.0\n",
      "[0] dataset_size 272.0 / train_return -100.0 / train_length 2.0 / train_episodes 115.0\n",
      "[0] dataset_size 274.0 / train_return -100.0 / train_length 2.0 / train_episodes 116.0\n",
      "[0] dataset_size 276.0 / train_return -100.0 / train_length 2.0 / train_episodes 117.0\n",
      "[0] dataset_size 278.0 / train_return -100.0 / train_length 2.0 / train_episodes 118.0\n",
      "[0] dataset_size 280.0 / train_return 1200.0 / train_length 2.0 / train_episodes 119.0\n",
      "[0] dataset_size 282.0 / train_return 1200.0 / train_length 2.0 / train_episodes 120.0\n",
      "[0] dataset_size 283.0 / train_return -50.0 / train_length 1.0 / train_episodes 121.0\n",
      "[0] dataset_size 284.0 / train_return -50.0 / train_length 1.0 / train_episodes 122.0\n",
      "[0] dataset_size 290.0 / train_return -900.0 / train_length 6.0 / train_episodes 123.0\n",
      "[0] dataset_size 291.0 / train_return -50.0 / train_length 1.0 / train_episodes 124.0\n",
      "[0] dataset_size 295.0 / train_return 0.0 / train_length 4.0 / train_episodes 125.0\n",
      "[0] dataset_size 296.0 / train_return -50.0 / train_length 1.0 / train_episodes 126.0\n",
      "[0] dataset_size 298.0 / train_return -1200.0 / train_length 2.0 / train_episodes 127.0\n",
      "[0] dataset_size 302.0 / train_return -300.0 / train_length 4.0 / train_episodes 128.0\n",
      "[0] dataset_size 304.0 / train_return -100.0 / train_length 2.0 / train_episodes 129.0\n",
      "[0] dataset_size 306.0 / train_return -100.0 / train_length 2.0 / train_episodes 130.0\n",
      "[0] dataset_size 308.0 / train_return -100.0 / train_length 2.0 / train_episodes 131.0\n",
      "[0] dataset_size 310.0 / train_return -100.0 / train_length 2.0 / train_episodes 132.0\n",
      "[0] dataset_size 315.0 / train_return -300.0 / train_length 5.0 / train_episodes 133.0\n",
      "[0] dataset_size 316.0 / train_return -50.0 / train_length 1.0 / train_episodes 134.0\n",
      "[0] dataset_size 318.0 / train_return -100.0 / train_length 2.0 / train_episodes 135.0\n",
      "[0] dataset_size 321.0 / train_return -300.0 / train_length 3.0 / train_episodes 136.0\n",
      "[0] dataset_size 323.0 / train_return 0.0 / train_length 2.0 / train_episodes 137.0\n",
      "[0] dataset_size 327.0 / train_return 0.0 / train_length 4.0 / train_episodes 138.0\n",
      "[0] dataset_size 329.0 / train_return -1200.0 / train_length 2.0 / train_episodes 139.0\n",
      "[0] dataset_size 331.0 / train_return -1200.0 / train_length 2.0 / train_episodes 140.0\n",
      "[0] dataset_size 333.0 / train_return -100.0 / train_length 2.0 / train_episodes 141.0\n",
      "[0] dataset_size 335.0 / train_return -100.0 / train_length 2.0 / train_episodes 142.0\n",
      "[0] dataset_size 337.0 / train_return -100.0 / train_length 2.0 / train_episodes 143.0\n",
      "[0] dataset_size 339.0 / train_return -100.0 / train_length 2.0 / train_episodes 144.0\n",
      "[0] dataset_size 340.0 / train_return -50.0 / train_length 1.0 / train_episodes 145.0\n",
      "[0] dataset_size 343.0 / train_return -300.0 / train_length 3.0 / train_episodes 146.0\n",
      "[0] dataset_size 347.0 / train_return -1200.0 / train_length 4.0 / train_episodes 147.0\n",
      "[0] dataset_size 350.0 / train_return 1200.0 / train_length 3.0 / train_episodes 148.0\n",
      "[0] dataset_size 354.0 / train_return -300.0 / train_length 4.0 / train_episodes 149.0\n",
      "[0] dataset_size 357.0 / train_return -300.0 / train_length 3.0 / train_episodes 150.0\n",
      "[0] dataset_size 359.0 / train_return -100.0 / train_length 2.0 / train_episodes 151.0\n",
      "[0] dataset_size 363.0 / train_return 0.0 / train_length 4.0 / train_episodes 152.0\n",
      "[0] dataset_size 366.0 / train_return -300.0 / train_length 3.0 / train_episodes 153.0\n",
      "[0] dataset_size 367.0 / train_return -50.0 / train_length 1.0 / train_episodes 154.0\n",
      "[0] dataset_size 369.0 / train_return -100.0 / train_length 2.0 / train_episodes 155.0\n",
      "[0] dataset_size 372.0 / train_return -300.0 / train_length 3.0 / train_episodes 156.0\n",
      "[0] dataset_size 374.0 / train_return -100.0 / train_length 2.0 / train_episodes 157.0\n",
      "[0] dataset_size 376.0 / train_return -100.0 / train_length 2.0 / train_episodes 158.0\n",
      "[0] dataset_size 378.0 / train_return 0.0 / train_length 2.0 / train_episodes 159.0\n",
      "[0] dataset_size 380.0 / train_return -100.0 / train_length 2.0 / train_episodes 160.0\n",
      "[0] dataset_size 383.0 / train_return -100.0 / train_length 3.0 / train_episodes 161.0\n",
      "[0] dataset_size 388.0 / train_return -300.0 / train_length 5.0 / train_episodes 162.0\n",
      "[0] dataset_size 393.0 / train_return -300.0 / train_length 5.0 / train_episodes 163.0\n",
      "[0] dataset_size 395.0 / train_return -100.0 / train_length 2.0 / train_episodes 164.0\n",
      "[0] dataset_size 397.0 / train_return -100.0 / train_length 2.0 / train_episodes 165.0\n",
      "[0] dataset_size 399.0 / train_return -100.0 / train_length 2.0 / train_episodes 166.0\n",
      "[0] dataset_size 400.0 / train_return -50.0 / train_length 1.0 / train_episodes 167.0\n",
      "[0] dataset_size 403.0 / train_return -100.0 / train_length 3.0 / train_episodes 168.0\n",
      "[0] dataset_size 407.0 / train_return -100.0 / train_length 4.0 / train_episodes 169.0\n",
      "[0] dataset_size 408.0 / train_return -50.0 / train_length 1.0 / train_episodes 170.0\n",
      "[0] dataset_size 410.0 / train_return -100.0 / train_length 2.0 / train_episodes 171.0\n",
      "[0] dataset_size 415.0 / train_return 1200.0 / train_length 5.0 / train_episodes 172.0\n",
      "[0] dataset_size 416.0 / train_return -50.0 / train_length 1.0 / train_episodes 173.0\n",
      "[0] dataset_size 417.0 / train_return -50.0 / train_length 1.0 / train_episodes 174.0\n",
      "[0] dataset_size 420.0 / train_return -100.0 / train_length 3.0 / train_episodes 175.0\n",
      "[0] dataset_size 422.0 / train_return -100.0 / train_length 2.0 / train_episodes 176.0\n",
      "[0] dataset_size 424.0 / train_return -100.0 / train_length 2.0 / train_episodes 177.0\n",
      "[0] dataset_size 425.0 / train_return -50.0 / train_length 1.0 / train_episodes 178.0\n",
      "[0] dataset_size 427.0 / train_return -100.0 / train_length 2.0 / train_episodes 179.0\n",
      "[0] dataset_size 430.0 / train_return 1200.0 / train_length 3.0 / train_episodes 180.0\n",
      "[0] dataset_size 435.0 / train_return -300.0 / train_length 5.0 / train_episodes 181.0\n",
      "[0] dataset_size 438.0 / train_return -100.0 / train_length 3.0 / train_episodes 182.0\n",
      "[0] dataset_size 443.0 / train_return 1200.0 / train_length 5.0 / train_episodes 183.0\n",
      "[0] dataset_size 444.0 / train_return -50.0 / train_length 1.0 / train_episodes 184.0\n",
      "[0] dataset_size 445.0 / train_return -50.0 / train_length 1.0 / train_episodes 185.0\n",
      "[0] dataset_size 446.0 / train_return -50.0 / train_length 1.0 / train_episodes 186.0\n",
      "[0] dataset_size 448.0 / train_return 1200.0 / train_length 2.0 / train_episodes 187.0\n",
      "[0] dataset_size 450.0 / train_return 1200.0 / train_length 2.0 / train_episodes 188.0\n",
      "[0] dataset_size 451.0 / train_return -50.0 / train_length 1.0 / train_episodes 189.0\n",
      "[0] dataset_size 453.0 / train_return -100.0 / train_length 2.0 / train_episodes 190.0\n",
      "[0] dataset_size 457.0 / train_return 0.0 / train_length 4.0 / train_episodes 191.0\n",
      "[0] dataset_size 461.0 / train_return 100.0 / train_length 4.0 / train_episodes 192.0\n",
      "[0] dataset_size 463.0 / train_return 1200.0 / train_length 2.0 / train_episodes 193.0\n",
      "[0] dataset_size 464.0 / train_return -50.0 / train_length 1.0 / train_episodes 194.0\n",
      "[0] dataset_size 465.0 / train_return -50.0 / train_length 1.0 / train_episodes 195.0\n",
      "[0] dataset_size 467.0 / train_return -100.0 / train_length 2.0 / train_episodes 196.0\n",
      "[0] dataset_size 469.0 / train_return -100.0 / train_length 2.0 / train_episodes 197.0\n",
      "[0] dataset_size 470.0 / train_return -50.0 / train_length 1.0 / train_episodes 198.0\n",
      "[0] dataset_size 472.0 / train_return -100.0 / train_length 2.0 / train_episodes 199.0\n",
      "[0] dataset_size 474.0 / train_return -1200.0 / train_length 2.0 / train_episodes 200.0\n",
      "[0] dataset_size 476.0 / train_return 1200.0 / train_length 2.0 / train_episodes 201.0\n",
      "[0] dataset_size 480.0 / train_return -100.0 / train_length 4.0 / train_episodes 202.0\n",
      "[0] dataset_size 483.0 / train_return 1200.0 / train_length 3.0 / train_episodes 203.0\n",
      "[0] dataset_size 486.0 / train_return -300.0 / train_length 3.0 / train_episodes 204.0\n",
      "[0] dataset_size 488.0 / train_return -100.0 / train_length 2.0 / train_episodes 205.0\n",
      "[0] dataset_size 489.0 / train_return -50.0 / train_length 1.0 / train_episodes 206.0\n",
      "[0] dataset_size 490.0 / train_return -50.0 / train_length 1.0 / train_episodes 207.0\n",
      "[0] dataset_size 495.0 / train_return 1200.0 / train_length 5.0 / train_episodes 208.0\n",
      "[0] dataset_size 500.0 / train_return 900.0 / train_length 5.0 / train_episodes 209.0\n",
      "[0] dataset_size 503.0 / train_return 1200.0 / train_length 3.0 / train_episodes 210.0\n",
      "[0] dataset_size 505.0 / train_return 0.0 / train_length 2.0 / train_episodes 211.0\n",
      "[0] dataset_size 506.0 / train_return -50.0 / train_length 1.0 / train_episodes 212.0\n",
      "[0] dataset_size 509.0 / train_return -100.0 / train_length 3.0 / train_episodes 213.0\n",
      "[0] dataset_size 511.0 / train_return -100.0 / train_length 2.0 / train_episodes 214.0\n",
      "[0] dataset_size 515.0 / train_return -900.0 / train_length 4.0 / train_episodes 215.0\n",
      "[0] dataset_size 517.0 / train_return -100.0 / train_length 2.0 / train_episodes 216.0\n",
      "[0] dataset_size 518.0 / train_return -50.0 / train_length 1.0 / train_episodes 217.0\n",
      "[0] dataset_size 520.0 / train_return -100.0 / train_length 2.0 / train_episodes 218.0\n",
      "[0] dataset_size 524.0 / train_return -1200.0 / train_length 4.0 / train_episodes 219.0\n",
      "[0] dataset_size 525.0 / train_return -50.0 / train_length 1.0 / train_episodes 220.0\n",
      "[0] dataset_size 527.0 / train_return -100.0 / train_length 2.0 / train_episodes 221.0\n",
      "[0] dataset_size 529.0 / train_return -100.0 / train_length 2.0 / train_episodes 222.0\n",
      "[0] dataset_size 534.0 / train_return 0.0 / train_length 5.0 / train_episodes 223.0\n",
      "[0] dataset_size 537.0 / train_return -100.0 / train_length 3.0 / train_episodes 224.0\n",
      "[0] dataset_size 538.0 / train_return -50.0 / train_length 1.0 / train_episodes 225.0\n",
      "[0] dataset_size 540.0 / train_return -100.0 / train_length 2.0 / train_episodes 226.0\n",
      "[0] dataset_size 541.0 / train_return -50.0 / train_length 1.0 / train_episodes 227.0\n",
      "[0] dataset_size 547.0 / train_return 0.0 / train_length 6.0 / train_episodes 228.0\n",
      "[0] dataset_size 550.0 / train_return 1200.0 / train_length 3.0 / train_episodes 229.0\n",
      "[0] dataset_size 551.0 / train_return -50.0 / train_length 1.0 / train_episodes 230.0\n",
      "[0] dataset_size 555.0 / train_return -300.0 / train_length 4.0 / train_episodes 231.0\n",
      "[0] dataset_size 557.0 / train_return -100.0 / train_length 2.0 / train_episodes 232.0\n",
      "[0] dataset_size 561.0 / train_return -900.0 / train_length 4.0 / train_episodes 233.0\n",
      "[0] dataset_size 563.0 / train_return 0.0 / train_length 2.0 / train_episodes 234.0\n",
      "[0] dataset_size 565.0 / train_return -1200.0 / train_length 2.0 / train_episodes 235.0\n",
      "[0] dataset_size 569.0 / train_return 900.0 / train_length 4.0 / train_episodes 236.0\n",
      "[0] dataset_size 571.0 / train_return -1200.0 / train_length 2.0 / train_episodes 237.0\n",
      "[0] dataset_size 574.0 / train_return -300.0 / train_length 3.0 / train_episodes 238.0\n",
      "[0] dataset_size 576.0 / train_return 0.0 / train_length 2.0 / train_episodes 239.0\n",
      "[0] dataset_size 580.0 / train_return -300.0 / train_length 4.0 / train_episodes 240.0\n",
      "[0] dataset_size 582.0 / train_return 0.0 / train_length 2.0 / train_episodes 241.0\n",
      "[0] dataset_size 583.0 / train_return -50.0 / train_length 1.0 / train_episodes 242.0\n",
      "[0] dataset_size 585.0 / train_return -1200.0 / train_length 2.0 / train_episodes 243.0\n",
      "[0] dataset_size 587.0 / train_return -100.0 / train_length 2.0 / train_episodes 244.0\n",
      "[0] dataset_size 588.0 / train_return -50.0 / train_length 1.0 / train_episodes 245.0\n",
      "[0] dataset_size 590.0 / train_return 1200.0 / train_length 2.0 / train_episodes 246.0\n",
      "[0] dataset_size 591.0 / train_return -50.0 / train_length 1.0 / train_episodes 247.0\n",
      "[0] dataset_size 596.0 / train_return -900.0 / train_length 5.0 / train_episodes 248.0\n",
      "[0] dataset_size 598.0 / train_return -100.0 / train_length 2.0 / train_episodes 249.0\n",
      "[0] dataset_size 600.0 / train_return 1200.0 / train_length 2.0 / train_episodes 250.0\n",
      "[0] dataset_size 602.0 / train_return -1200.0 / train_length 2.0 / train_episodes 251.0\n",
      "[0] dataset_size 607.0 / train_return -900.0 / train_length 5.0 / train_episodes 252.0\n",
      "[0] dataset_size 608.0 / train_return -50.0 / train_length 1.0 / train_episodes 253.0\n",
      "[0] dataset_size 610.0 / train_return -100.0 / train_length 2.0 / train_episodes 254.0\n",
      "[0] dataset_size 613.0 / train_return -100.0 / train_length 3.0 / train_episodes 255.0\n",
      "[0] dataset_size 618.0 / train_return -300.0 / train_length 5.0 / train_episodes 256.0\n",
      "[0] dataset_size 621.0 / train_return -100.0 / train_length 3.0 / train_episodes 257.0\n",
      "[0] dataset_size 623.0 / train_return -1200.0 / train_length 2.0 / train_episodes 258.0\n",
      "[0] dataset_size 626.0 / train_return -300.0 / train_length 3.0 / train_episodes 259.0\n",
      "[0] dataset_size 627.0 / train_return -50.0 / train_length 1.0 / train_episodes 260.0\n",
      "[0] dataset_size 628.0 / train_return -50.0 / train_length 1.0 / train_episodes 261.0\n",
      "[0] dataset_size 631.0 / train_return -1200.0 / train_length 3.0 / train_episodes 262.0\n",
      "[0] dataset_size 634.0 / train_return -100.0 / train_length 3.0 / train_episodes 263.0\n",
      "[0] dataset_size 635.0 / train_return -50.0 / train_length 1.0 / train_episodes 264.0\n",
      "[0] dataset_size 636.0 / train_return -50.0 / train_length 1.0 / train_episodes 265.0\n",
      "[0] dataset_size 637.0 / train_return -50.0 / train_length 1.0 / train_episodes 266.0\n",
      "[0] dataset_size 639.0 / train_return -100.0 / train_length 2.0 / train_episodes 267.0\n",
      "[0] dataset_size 640.0 / train_return -50.0 / train_length 1.0 / train_episodes 268.0\n",
      "[0] dataset_size 641.0 / train_return -50.0 / train_length 1.0 / train_episodes 269.0\n",
      "[0] dataset_size 642.0 / train_return -50.0 / train_length 1.0 / train_episodes 270.0\n",
      "[0] dataset_size 644.0 / train_return 1200.0 / train_length 2.0 / train_episodes 271.0\n",
      "[0] dataset_size 648.0 / train_return -900.0 / train_length 4.0 / train_episodes 272.0\n",
      "[0] dataset_size 651.0 / train_return 0.0 / train_length 3.0 / train_episodes 273.0\n",
      "[0] dataset_size 654.0 / train_return -300.0 / train_length 3.0 / train_episodes 274.0\n",
      "[0] dataset_size 656.0 / train_return -1200.0 / train_length 2.0 / train_episodes 275.0\n",
      "[0] dataset_size 657.0 / train_return -50.0 / train_length 1.0 / train_episodes 276.0\n",
      "[0] dataset_size 659.0 / train_return -100.0 / train_length 2.0 / train_episodes 277.0\n",
      "[0] dataset_size 661.0 / train_return 1200.0 / train_length 2.0 / train_episodes 278.0\n",
      "[0] dataset_size 667.0 / train_return 900.0 / train_length 6.0 / train_episodes 279.0\n",
      "[0] dataset_size 671.0 / train_return -300.0 / train_length 4.0 / train_episodes 280.0\n",
      "[0] dataset_size 672.0 / train_return -50.0 / train_length 1.0 / train_episodes 281.0\n",
      "[0] dataset_size 675.0 / train_return -100.0 / train_length 3.0 / train_episodes 282.0\n",
      "[0] dataset_size 678.0 / train_return -100.0 / train_length 3.0 / train_episodes 283.0\n",
      "[0] dataset_size 679.0 / train_return -50.0 / train_length 1.0 / train_episodes 284.0\n",
      "[0] dataset_size 682.0 / train_return -100.0 / train_length 3.0 / train_episodes 285.0\n",
      "[0] dataset_size 687.0 / train_return 900.0 / train_length 5.0 / train_episodes 286.0\n",
      "[0] dataset_size 691.0 / train_return -900.0 / train_length 4.0 / train_episodes 287.0\n",
      "[0] dataset_size 692.0 / train_return -50.0 / train_length 1.0 / train_episodes 288.0\n",
      "[0] dataset_size 694.0 / train_return -100.0 / train_length 2.0 / train_episodes 289.0\n",
      "[0] dataset_size 695.0 / train_return -50.0 / train_length 1.0 / train_episodes 290.0\n",
      "[0] dataset_size 696.0 / train_return -50.0 / train_length 1.0 / train_episodes 291.0\n",
      "[0] dataset_size 698.0 / train_return -100.0 / train_length 2.0 / train_episodes 292.0\n",
      "[0] dataset_size 700.0 / train_return -100.0 / train_length 2.0 / train_episodes 293.0\n",
      "[0] dataset_size 705.0 / train_return -100.0 / train_length 5.0 / train_episodes 294.0\n",
      "[0] dataset_size 708.0 / train_return 1200.0 / train_length 3.0 / train_episodes 295.0\n",
      "[0] dataset_size 713.0 / train_return -300.0 / train_length 5.0 / train_episodes 296.0\n",
      "[0] dataset_size 714.0 / train_return -50.0 / train_length 1.0 / train_episodes 297.0\n",
      "[0] dataset_size 718.0 / train_return 0.0 / train_length 4.0 / train_episodes 298.0\n",
      "[0] dataset_size 723.0 / train_return -100.0 / train_length 5.0 / train_episodes 299.0\n",
      "[0] dataset_size 727.0 / train_return -1200.0 / train_length 4.0 / train_episodes 300.0\n",
      "[0] dataset_size 729.0 / train_return 0.0 / train_length 2.0 / train_episodes 301.0\n",
      "[0] dataset_size 731.0 / train_return -100.0 / train_length 2.0 / train_episodes 302.0\n",
      "[0] dataset_size 732.0 / train_return -50.0 / train_length 1.0 / train_episodes 303.0\n",
      "[0] dataset_size 734.0 / train_return 1200.0 / train_length 2.0 / train_episodes 304.0\n",
      "[0] dataset_size 735.0 / train_return -50.0 / train_length 1.0 / train_episodes 305.0\n",
      "[0] dataset_size 736.0 / train_return -50.0 / train_length 1.0 / train_episodes 306.0\n",
      "[0] dataset_size 738.0 / train_return -100.0 / train_length 2.0 / train_episodes 307.0\n",
      "[0] dataset_size 741.0 / train_return -100.0 / train_length 3.0 / train_episodes 308.0\n",
      "[0] dataset_size 743.0 / train_return -100.0 / train_length 2.0 / train_episodes 309.0\n",
      "[0] dataset_size 749.0 / train_return -300.0 / train_length 6.0 / train_episodes 310.0\n",
      "[0] dataset_size 754.0 / train_return 1200.0 / train_length 5.0 / train_episodes 311.0\n",
      "[0] dataset_size 758.0 / train_return 0.0 / train_length 4.0 / train_episodes 312.0\n",
      "[0] dataset_size 761.0 / train_return -1200.0 / train_length 3.0 / train_episodes 313.0\n",
      "[0] dataset_size 763.0 / train_return -100.0 / train_length 2.0 / train_episodes 314.0\n",
      "[0] dataset_size 764.0 / train_return -50.0 / train_length 1.0 / train_episodes 315.0\n",
      "[0] dataset_size 768.0 / train_return -900.0 / train_length 4.0 / train_episodes 316.0\n",
      "[0] dataset_size 770.0 / train_return -100.0 / train_length 2.0 / train_episodes 317.0\n",
      "[0] dataset_size 772.0 / train_return -100.0 / train_length 2.0 / train_episodes 318.0\n",
      "[0] dataset_size 773.0 / train_return -50.0 / train_length 1.0 / train_episodes 319.0\n",
      "[0] dataset_size 774.0 / train_return -50.0 / train_length 1.0 / train_episodes 320.0\n",
      "[0] dataset_size 776.0 / train_return -100.0 / train_length 2.0 / train_episodes 321.0\n",
      "[0] dataset_size 778.0 / train_return -100.0 / train_length 2.0 / train_episodes 322.0\n",
      "[0] dataset_size 779.0 / train_return -50.0 / train_length 1.0 / train_episodes 323.0\n",
      "[0] dataset_size 781.0 / train_return -100.0 / train_length 2.0 / train_episodes 324.0\n",
      "[0] dataset_size 782.0 / train_return -50.0 / train_length 1.0 / train_episodes 325.0\n",
      "[0] dataset_size 783.0 / train_return -50.0 / train_length 1.0 / train_episodes 326.0\n",
      "[0] dataset_size 789.0 / train_return -900.0 / train_length 6.0 / train_episodes 327.0\n",
      "[0] dataset_size 791.0 / train_return -100.0 / train_length 2.0 / train_episodes 328.0\n",
      "[0] dataset_size 792.0 / train_return -50.0 / train_length 1.0 / train_episodes 329.0\n",
      "[0] dataset_size 794.0 / train_return -100.0 / train_length 2.0 / train_episodes 330.0\n",
      "[0] dataset_size 795.0 / train_return -50.0 / train_length 1.0 / train_episodes 331.0\n",
      "[0] dataset_size 801.0 / train_return -900.0 / train_length 6.0 / train_episodes 332.0\n",
      "[0] dataset_size 804.0 / train_return 1200.0 / train_length 3.0 / train_episodes 333.0\n",
      "[0] dataset_size 810.0 / train_return -1200.0 / train_length 6.0 / train_episodes 334.0\n",
      "[0] dataset_size 813.0 / train_return -100.0 / train_length 3.0 / train_episodes 335.0\n",
      "[0] dataset_size 815.0 / train_return -100.0 / train_length 2.0 / train_episodes 336.0\n",
      "[0] dataset_size 818.0 / train_return -300.0 / train_length 3.0 / train_episodes 337.0\n",
      "[0] dataset_size 820.0 / train_return -100.0 / train_length 2.0 / train_episodes 338.0\n",
      "[0] dataset_size 822.0 / train_return -100.0 / train_length 2.0 / train_episodes 339.0\n",
      "[0] dataset_size 824.0 / train_return -100.0 / train_length 2.0 / train_episodes 340.0\n",
      "[0] dataset_size 825.0 / train_return -50.0 / train_length 1.0 / train_episodes 341.0\n",
      "[0] dataset_size 826.0 / train_return -50.0 / train_length 1.0 / train_episodes 342.0\n",
      "[0] dataset_size 828.0 / train_return 1200.0 / train_length 2.0 / train_episodes 343.0\n",
      "[0] dataset_size 831.0 / train_return -1200.0 / train_length 3.0 / train_episodes 344.0\n",
      "[0] dataset_size 834.0 / train_return 1200.0 / train_length 3.0 / train_episodes 345.0\n",
      "[0] dataset_size 837.0 / train_return -100.0 / train_length 3.0 / train_episodes 346.0\n",
      "[0] dataset_size 839.0 / train_return -100.0 / train_length 2.0 / train_episodes 347.0\n",
      "[0] dataset_size 840.0 / train_return -50.0 / train_length 1.0 / train_episodes 348.0\n",
      "[0] dataset_size 843.0 / train_return -100.0 / train_length 3.0 / train_episodes 349.0\n",
      "[0] dataset_size 846.0 / train_return -300.0 / train_length 3.0 / train_episodes 350.0\n",
      "[0] dataset_size 848.0 / train_return -100.0 / train_length 2.0 / train_episodes 351.0\n",
      "[0] dataset_size 852.0 / train_return -900.0 / train_length 4.0 / train_episodes 352.0\n",
      "[0] dataset_size 858.0 / train_return -900.0 / train_length 6.0 / train_episodes 353.0\n",
      "[0] dataset_size 861.0 / train_return -100.0 / train_length 3.0 / train_episodes 354.0\n",
      "[0] dataset_size 864.0 / train_return -1200.0 / train_length 3.0 / train_episodes 355.0\n",
      "[0] dataset_size 868.0 / train_return -300.0 / train_length 4.0 / train_episodes 356.0\n",
      "[0] dataset_size 870.0 / train_return -100.0 / train_length 2.0 / train_episodes 357.0\n",
      "[0] dataset_size 871.0 / train_return -50.0 / train_length 1.0 / train_episodes 358.0\n",
      "[0] dataset_size 872.0 / train_return -50.0 / train_length 1.0 / train_episodes 359.0\n",
      "[0] dataset_size 873.0 / train_return -50.0 / train_length 1.0 / train_episodes 360.0\n",
      "[0] dataset_size 876.0 / train_return 1200.0 / train_length 3.0 / train_episodes 361.0\n",
      "[0] dataset_size 877.0 / train_return -50.0 / train_length 1.0 / train_episodes 362.0\n",
      "[0] dataset_size 878.0 / train_return -50.0 / train_length 1.0 / train_episodes 363.0\n",
      "[0] dataset_size 883.0 / train_return -900.0 / train_length 5.0 / train_episodes 364.0\n",
      "[0] dataset_size 884.0 / train_return -50.0 / train_length 1.0 / train_episodes 365.0\n",
      "[0] dataset_size 885.0 / train_return -50.0 / train_length 1.0 / train_episodes 366.0\n",
      "[0] dataset_size 889.0 / train_return 1200.0 / train_length 4.0 / train_episodes 367.0\n",
      "[0] dataset_size 894.0 / train_return -300.0 / train_length 5.0 / train_episodes 368.0\n",
      "[0] dataset_size 897.0 / train_return -300.0 / train_length 3.0 / train_episodes 369.0\n",
      "[0] dataset_size 903.0 / train_return -1200.0 / train_length 6.0 / train_episodes 370.0\n",
      "[0] dataset_size 907.0 / train_return 0.0 / train_length 4.0 / train_episodes 371.0\n",
      "[0] dataset_size 908.0 / train_return -50.0 / train_length 1.0 / train_episodes 372.0\n",
      "[0] dataset_size 910.0 / train_return -100.0 / train_length 2.0 / train_episodes 373.0\n",
      "[0] dataset_size 913.0 / train_return -300.0 / train_length 3.0 / train_episodes 374.0\n",
      "[0] dataset_size 919.0 / train_return 1200.0 / train_length 6.0 / train_episodes 375.0\n",
      "[0] dataset_size 920.0 / train_return -50.0 / train_length 1.0 / train_episodes 376.0\n",
      "[0] dataset_size 923.0 / train_return 1200.0 / train_length 3.0 / train_episodes 377.0\n",
      "[0] dataset_size 925.0 / train_return 1200.0 / train_length 2.0 / train_episodes 378.0\n",
      "[0] dataset_size 927.0 / train_return -1200.0 / train_length 2.0 / train_episodes 379.0\n",
      "[0] dataset_size 928.0 / train_return -50.0 / train_length 1.0 / train_episodes 380.0\n",
      "[0] dataset_size 930.0 / train_return -100.0 / train_length 2.0 / train_episodes 381.0\n",
      "[0] dataset_size 933.0 / train_return -300.0 / train_length 3.0 / train_episodes 382.0\n",
      "[0] dataset_size 936.0 / train_return -100.0 / train_length 3.0 / train_episodes 383.0\n",
      "[0] dataset_size 938.0 / train_return -1200.0 / train_length 2.0 / train_episodes 384.0\n",
      "[0] dataset_size 940.0 / train_return -100.0 / train_length 2.0 / train_episodes 385.0\n",
      "[0] dataset_size 941.0 / train_return -50.0 / train_length 1.0 / train_episodes 386.0\n",
      "[0] dataset_size 945.0 / train_return 300.0 / train_length 4.0 / train_episodes 387.0\n",
      "[0] dataset_size 946.0 / train_return -50.0 / train_length 1.0 / train_episodes 388.0\n",
      "[0] dataset_size 949.0 / train_return -100.0 / train_length 3.0 / train_episodes 389.0\n",
      "[0] dataset_size 952.0 / train_return -1200.0 / train_length 3.0 / train_episodes 390.0\n",
      "[0] dataset_size 953.0 / train_return -50.0 / train_length 1.0 / train_episodes 391.0\n",
      "[0] dataset_size 959.0 / train_return -900.0 / train_length 6.0 / train_episodes 392.0\n",
      "[0] dataset_size 960.0 / train_return -50.0 / train_length 1.0 / train_episodes 393.0\n",
      "[0] dataset_size 962.0 / train_return -100.0 / train_length 2.0 / train_episodes 394.0\n",
      "[0] dataset_size 963.0 / train_return -50.0 / train_length 1.0 / train_episodes 395.0\n",
      "[0] dataset_size 968.0 / train_return -900.0 / train_length 5.0 / train_episodes 396.0\n",
      "[0] dataset_size 970.0 / train_return -1200.0 / train_length 2.0 / train_episodes 397.0\n",
      "[0] dataset_size 972.0 / train_return -100.0 / train_length 2.0 / train_episodes 398.0\n",
      "[0] dataset_size 975.0 / train_return -300.0 / train_length 3.0 / train_episodes 399.0\n",
      "[0] dataset_size 978.0 / train_return -100.0 / train_length 3.0 / train_episodes 400.0\n",
      "[0] dataset_size 980.0 / train_return -100.0 / train_length 2.0 / train_episodes 401.0\n",
      "[0] dataset_size 983.0 / train_return -100.0 / train_length 3.0 / train_episodes 402.0\n",
      "[0] dataset_size 987.0 / train_return -900.0 / train_length 4.0 / train_episodes 403.0\n",
      "[0] dataset_size 989.0 / train_return -100.0 / train_length 2.0 / train_episodes 404.0\n",
      "[0] dataset_size 991.0 / train_return -100.0 / train_length 2.0 / train_episodes 405.0\n",
      "[0] dataset_size 992.0 / train_return -50.0 / train_length 1.0 / train_episodes 406.0\n",
      "[0] dataset_size 994.0 / train_return 0.0 / train_length 2.0 / train_episodes 407.0\n",
      "[0] dataset_size 999.0 / train_return 1200.0 / train_length 5.0 / train_episodes 408.0\n",
      "[0] dataset_size 1002.0 / train_return 1200.0 / train_length 3.0 / train_episodes 409.0\n",
      "[0] dataset_size 1004.0 / train_return -1200.0 / train_length 2.0 / train_episodes 410.0\n",
      "[0] dataset_size 1007.0 / train_return -100.0 / train_length 3.0 / train_episodes 411.0\n",
      "[0] dataset_size 1010.0 / train_return -100.0 / train_length 3.0 / train_episodes 412.0\n",
      "[0] dataset_size 1012.0 / train_return -100.0 / train_length 2.0 / train_episodes 413.0\n",
      "[0] dataset_size 1014.0 / train_return -100.0 / train_length 2.0 / train_episodes 414.0\n",
      "[0] dataset_size 1016.0 / train_return -100.0 / train_length 2.0 / train_episodes 415.0\n",
      "[0] dataset_size 1017.0 / train_return -50.0 / train_length 1.0 / train_episodes 416.0\n",
      "[0] dataset_size 1020.0 / train_return -100.0 / train_length 3.0 / train_episodes 417.0\n",
      "[0] dataset_size 1023.0 / train_return -100.0 / train_length 3.0 / train_episodes 418.0\n",
      "[0] dataset_size 1027.0 / train_return -300.0 / train_length 4.0 / train_episodes 419.0\n",
      "[0] dataset_size 1029.0 / train_return -100.0 / train_length 2.0 / train_episodes 420.0\n",
      "[0] dataset_size 1031.0 / train_return -100.0 / train_length 2.0 / train_episodes 421.0\n",
      "[0] dataset_size 1035.0 / train_return -300.0 / train_length 4.0 / train_episodes 422.0\n",
      "[0] dataset_size 1036.0 / train_return -50.0 / train_length 1.0 / train_episodes 423.0\n",
      "[0] dataset_size 1040.0 / train_return -300.0 / train_length 4.0 / train_episodes 424.0\n",
      "[0] dataset_size 1041.0 / train_return -50.0 / train_length 1.0 / train_episodes 425.0\n",
      "[0] dataset_size 1046.0 / train_return -900.0 / train_length 5.0 / train_episodes 426.0\n",
      "[0] dataset_size 1051.0 / train_return -300.0 / train_length 5.0 / train_episodes 427.0\n",
      "[0] dataset_size 1054.0 / train_return 1200.0 / train_length 3.0 / train_episodes 428.0\n",
      "[0] dataset_size 1056.0 / train_return -1200.0 / train_length 2.0 / train_episodes 429.0\n",
      "[0] dataset_size 1057.0 / train_return -50.0 / train_length 1.0 / train_episodes 430.0\n",
      "[0] dataset_size 1060.0 / train_return -100.0 / train_length 3.0 / train_episodes 431.0\n",
      "[0] dataset_size 1062.0 / train_return -100.0 / train_length 2.0 / train_episodes 432.0\n",
      "[0] dataset_size 1066.0 / train_return 100.0 / train_length 4.0 / train_episodes 433.0\n",
      "[0] dataset_size 1069.0 / train_return -100.0 / train_length 3.0 / train_episodes 434.0\n",
      "[0] dataset_size 1074.0 / train_return 0.0 / train_length 5.0 / train_episodes 435.0\n",
      "[0] dataset_size 1080.0 / train_return 0.0 / train_length 6.0 / train_episodes 436.0\n",
      "[0] dataset_size 1082.0 / train_return -100.0 / train_length 2.0 / train_episodes 437.0\n",
      "[0] dataset_size 1086.0 / train_return 0.0 / train_length 4.0 / train_episodes 438.0\n",
      "[0] dataset_size 1091.0 / train_return -1200.0 / train_length 5.0 / train_episodes 439.0\n",
      "[0] dataset_size 1094.0 / train_return -100.0 / train_length 3.0 / train_episodes 440.0\n",
      "[0] dataset_size 1096.0 / train_return -100.0 / train_length 2.0 / train_episodes 441.0\n",
      "[0] dataset_size 1097.0 / train_return -50.0 / train_length 1.0 / train_episodes 442.0\n",
      "[0] dataset_size 1103.0 / train_return -900.0 / train_length 6.0 / train_episodes 443.0\n",
      "[0] dataset_size 1105.0 / train_return -1200.0 / train_length 2.0 / train_episodes 444.0\n",
      "[0] dataset_size 1106.0 / train_return -50.0 / train_length 1.0 / train_episodes 445.0\n",
      "[0] dataset_size 1107.0 / train_return -50.0 / train_length 1.0 / train_episodes 446.0\n",
      "[0] dataset_size 1109.0 / train_return -100.0 / train_length 2.0 / train_episodes 447.0\n",
      "[0] dataset_size 1111.0 / train_return -100.0 / train_length 2.0 / train_episodes 448.0\n",
      "[0] dataset_size 1114.0 / train_return -1200.0 / train_length 3.0 / train_episodes 449.0\n",
      "[0] dataset_size 1116.0 / train_return -100.0 / train_length 2.0 / train_episodes 450.0\n",
      "[0] dataset_size 1119.0 / train_return -300.0 / train_length 3.0 / train_episodes 451.0\n",
      "[0] dataset_size 1121.0 / train_return -100.0 / train_length 2.0 / train_episodes 452.0\n",
      "[0] dataset_size 1126.0 / train_return -900.0 / train_length 5.0 / train_episodes 453.0\n",
      "[0] dataset_size 1127.0 / train_return -50.0 / train_length 1.0 / train_episodes 454.0\n",
      "[0] dataset_size 1128.0 / train_return -50.0 / train_length 1.0 / train_episodes 455.0\n",
      "[0] dataset_size 1129.0 / train_return -50.0 / train_length 1.0 / train_episodes 456.0\n",
      "[0] dataset_size 1131.0 / train_return -1200.0 / train_length 2.0 / train_episodes 457.0\n",
      "[0] dataset_size 1134.0 / train_return -1200.0 / train_length 3.0 / train_episodes 458.0\n",
      "[0] dataset_size 1136.0 / train_return -100.0 / train_length 2.0 / train_episodes 459.0\n",
      "[0] dataset_size 1138.0 / train_return -100.0 / train_length 2.0 / train_episodes 460.0\n",
      "[0] dataset_size 1141.0 / train_return -300.0 / train_length 3.0 / train_episodes 461.0\n",
      "[0] dataset_size 1142.0 / train_return -50.0 / train_length 1.0 / train_episodes 462.0\n",
      "[0] dataset_size 1143.0 / train_return -50.0 / train_length 1.0 / train_episodes 463.0\n",
      "[0] dataset_size 1144.0 / train_return -50.0 / train_length 1.0 / train_episodes 464.0\n",
      "[0] dataset_size 1146.0 / train_return -100.0 / train_length 2.0 / train_episodes 465.0\n",
      "[0] dataset_size 1147.0 / train_return -50.0 / train_length 1.0 / train_episodes 466.0\n",
      "[0] dataset_size 1150.0 / train_return -300.0 / train_length 3.0 / train_episodes 467.0\n",
      "[0] dataset_size 1151.0 / train_return -50.0 / train_length 1.0 / train_episodes 468.0\n",
      "[0] dataset_size 1156.0 / train_return -900.0 / train_length 5.0 / train_episodes 469.0\n",
      "[0] dataset_size 1162.0 / train_return -900.0 / train_length 6.0 / train_episodes 470.0\n",
      "[0] dataset_size 1164.0 / train_return -100.0 / train_length 2.0 / train_episodes 471.0\n",
      "[0] dataset_size 1166.0 / train_return 1200.0 / train_length 2.0 / train_episodes 472.0\n",
      "[0] dataset_size 1167.0 / train_return -50.0 / train_length 1.0 / train_episodes 473.0\n",
      "[0] dataset_size 1169.0 / train_return -100.0 / train_length 2.0 / train_episodes 474.0\n",
      "[0] dataset_size 1171.0 / train_return -100.0 / train_length 2.0 / train_episodes 475.0\n",
      "[0] dataset_size 1173.0 / train_return 1200.0 / train_length 2.0 / train_episodes 476.0\n",
      "[0] dataset_size 1174.0 / train_return -50.0 / train_length 1.0 / train_episodes 477.0\n",
      "[0] dataset_size 1176.0 / train_return 1200.0 / train_length 2.0 / train_episodes 478.0\n",
      "[0] dataset_size 1180.0 / train_return -1200.0 / train_length 4.0 / train_episodes 479.0\n",
      "[0] dataset_size 1182.0 / train_return -100.0 / train_length 2.0 / train_episodes 480.0\n",
      "[0] dataset_size 1183.0 / train_return -50.0 / train_length 1.0 / train_episodes 481.0\n",
      "[0] dataset_size 1187.0 / train_return -300.0 / train_length 4.0 / train_episodes 482.0\n",
      "[0] dataset_size 1189.0 / train_return -100.0 / train_length 2.0 / train_episodes 483.0\n",
      "[0] dataset_size 1190.0 / train_return -50.0 / train_length 1.0 / train_episodes 484.0\n",
      "[0] dataset_size 1192.0 / train_return -1200.0 / train_length 2.0 / train_episodes 485.0\n",
      "[0] dataset_size 1197.0 / train_return 900.0 / train_length 5.0 / train_episodes 486.0\n",
      "[0] dataset_size 1199.0 / train_return 0.0 / train_length 2.0 / train_episodes 487.0\n",
      "[0] dataset_size 1202.0 / train_return 1200.0 / train_length 3.0 / train_episodes 488.0\n",
      "[0] dataset_size 1204.0 / train_return -100.0 / train_length 2.0 / train_episodes 489.0\n",
      "[0] dataset_size 1206.0 / train_return -100.0 / train_length 2.0 / train_episodes 490.0\n",
      "[0] dataset_size 1208.0 / train_return 0.0 / train_length 2.0 / train_episodes 491.0\n",
      "[0] dataset_size 1211.0 / train_return -1200.0 / train_length 3.0 / train_episodes 492.0\n",
      "[0] dataset_size 1212.0 / train_return -50.0 / train_length 1.0 / train_episodes 493.0\n",
      "[0] dataset_size 1217.0 / train_return -100.0 / train_length 5.0 / train_episodes 494.0\n",
      "[0] dataset_size 1222.0 / train_return -300.0 / train_length 5.0 / train_episodes 495.0\n",
      "[0] dataset_size 1224.0 / train_return -100.0 / train_length 2.0 / train_episodes 496.0\n",
      "[0] dataset_size 1225.0 / train_return -50.0 / train_length 1.0 / train_episodes 497.0\n",
      "[0] dataset_size 1229.0 / train_return -300.0 / train_length 4.0 / train_episodes 498.0\n",
      "[0] dataset_size 1231.0 / train_return -100.0 / train_length 2.0 / train_episodes 499.0\n",
      "[0] dataset_size 1232.0 / train_return -50.0 / train_length 1.0 / train_episodes 500.0\n",
      "[0] dataset_size 1233.0 / train_return -50.0 / train_length 1.0 / train_episodes 501.0\n",
      "[0] dataset_size 1236.0 / train_return 1200.0 / train_length 3.0 / train_episodes 502.0\n",
      "[0] dataset_size 1239.0 / train_return -100.0 / train_length 3.0 / train_episodes 503.0\n",
      "[0] dataset_size 1243.0 / train_return -900.0 / train_length 4.0 / train_episodes 504.0\n",
      "[0] dataset_size 1248.0 / train_return -900.0 / train_length 5.0 / train_episodes 505.0\n",
      "[0] dataset_size 1251.0 / train_return -100.0 / train_length 3.0 / train_episodes 506.0\n",
      "[0] dataset_size 1253.0 / train_return -100.0 / train_length 2.0 / train_episodes 507.0\n",
      "[0] dataset_size 1257.0 / train_return -1200.0 / train_length 4.0 / train_episodes 508.0\n",
      "[0] dataset_size 1260.0 / train_return -100.0 / train_length 3.0 / train_episodes 509.0\n",
      "[0] dataset_size 1261.0 / train_return -50.0 / train_length 1.0 / train_episodes 510.0\n",
      "[0] dataset_size 1263.0 / train_return 1200.0 / train_length 2.0 / train_episodes 511.0\n",
      "[0] dataset_size 1264.0 / train_return -50.0 / train_length 1.0 / train_episodes 512.0\n",
      "[0] dataset_size 1267.0 / train_return -300.0 / train_length 3.0 / train_episodes 513.0\n",
      "[0] dataset_size 1270.0 / train_return -1200.0 / train_length 3.0 / train_episodes 514.0\n",
      "[0] dataset_size 1272.0 / train_return -100.0 / train_length 2.0 / train_episodes 515.0\n",
      "[0] dataset_size 1274.0 / train_return -100.0 / train_length 2.0 / train_episodes 516.0\n",
      "[0] dataset_size 1276.0 / train_return -100.0 / train_length 2.0 / train_episodes 517.0\n",
      "[0] dataset_size 1278.0 / train_return -100.0 / train_length 2.0 / train_episodes 518.0\n",
      "[0] dataset_size 1280.0 / train_return -1200.0 / train_length 2.0 / train_episodes 519.0\n",
      "[0] dataset_size 1282.0 / train_return -1200.0 / train_length 2.0 / train_episodes 520.0\n",
      "[0] dataset_size 1284.0 / train_return -100.0 / train_length 2.0 / train_episodes 521.0\n",
      "[0] dataset_size 1285.0 / train_return -50.0 / train_length 1.0 / train_episodes 522.0\n",
      "[0] dataset_size 1287.0 / train_return -100.0 / train_length 2.0 / train_episodes 523.0\n",
      "[0] dataset_size 1290.0 / train_return -300.0 / train_length 3.0 / train_episodes 524.0\n",
      "[0] dataset_size 1293.0 / train_return -100.0 / train_length 3.0 / train_episodes 525.0\n",
      "[0] dataset_size 1295.0 / train_return 1200.0 / train_length 2.0 / train_episodes 526.0\n",
      "[0] dataset_size 1299.0 / train_return -100.0 / train_length 4.0 / train_episodes 527.0\n",
      "[0] dataset_size 1301.0 / train_return -100.0 / train_length 2.0 / train_episodes 528.0\n",
      "[0] dataset_size 1303.0 / train_return -100.0 / train_length 2.0 / train_episodes 529.0\n",
      "[0] dataset_size 1304.0 / train_return -50.0 / train_length 1.0 / train_episodes 530.0\n",
      "[0] dataset_size 1306.0 / train_return -100.0 / train_length 2.0 / train_episodes 531.0\n",
      "[0] dataset_size 1308.0 / train_return 0.0 / train_length 2.0 / train_episodes 532.0\n",
      "[0] dataset_size 1311.0 / train_return -100.0 / train_length 3.0 / train_episodes 533.0\n",
      "[0] dataset_size 1315.0 / train_return -1200.0 / train_length 4.0 / train_episodes 534.0\n",
      "[0] dataset_size 1317.0 / train_return -1200.0 / train_length 2.0 / train_episodes 535.0\n",
      "[0] dataset_size 1319.0 / train_return -1200.0 / train_length 2.0 / train_episodes 536.0\n",
      "[0] dataset_size 1323.0 / train_return -900.0 / train_length 4.0 / train_episodes 537.0\n",
      "[0] dataset_size 1325.0 / train_return -1200.0 / train_length 2.0 / train_episodes 538.0\n",
      "[0] dataset_size 1327.0 / train_return -1200.0 / train_length 2.0 / train_episodes 539.0\n",
      "[0] dataset_size 1328.0 / train_return -50.0 / train_length 1.0 / train_episodes 540.0\n",
      "[0] dataset_size 1329.0 / train_return -50.0 / train_length 1.0 / train_episodes 541.0\n",
      "[0] dataset_size 1332.0 / train_return -300.0 / train_length 3.0 / train_episodes 542.0\n",
      "[0] dataset_size 1335.0 / train_return -100.0 / train_length 3.0 / train_episodes 543.0\n",
      "[0] dataset_size 1336.0 / train_return -50.0 / train_length 1.0 / train_episodes 544.0\n",
      "[0] dataset_size 1337.0 / train_return -50.0 / train_length 1.0 / train_episodes 545.0\n",
      "[0] dataset_size 1339.0 / train_return -100.0 / train_length 2.0 / train_episodes 546.0\n",
      "[0] dataset_size 1344.0 / train_return -100.0 / train_length 5.0 / train_episodes 547.0\n",
      "[0] dataset_size 1350.0 / train_return 1200.0 / train_length 6.0 / train_episodes 548.0\n",
      "[0] dataset_size 1351.0 / train_return -50.0 / train_length 1.0 / train_episodes 549.0\n",
      "[0] dataset_size 1356.0 / train_return -100.0 / train_length 5.0 / train_episodes 550.0\n",
      "[0] dataset_size 1360.0 / train_return -1200.0 / train_length 4.0 / train_episodes 551.0\n",
      "[0] dataset_size 1364.0 / train_return -100.0 / train_length 4.0 / train_episodes 552.0\n",
      "[0] dataset_size 1366.0 / train_return -100.0 / train_length 2.0 / train_episodes 553.0\n",
      "[0] dataset_size 1371.0 / train_return -300.0 / train_length 5.0 / train_episodes 554.0\n",
      "[0] dataset_size 1376.0 / train_return -900.0 / train_length 5.0 / train_episodes 555.0\n",
      "[0] dataset_size 1377.0 / train_return -50.0 / train_length 1.0 / train_episodes 556.0\n",
      "[0] dataset_size 1380.0 / train_return -300.0 / train_length 3.0 / train_episodes 557.0\n",
      "[0] dataset_size 1381.0 / train_return -50.0 / train_length 1.0 / train_episodes 558.0\n",
      "[0] dataset_size 1382.0 / train_return -50.0 / train_length 1.0 / train_episodes 559.0\n",
      "[0] dataset_size 1383.0 / train_return -50.0 / train_length 1.0 / train_episodes 560.0\n",
      "[0] dataset_size 1386.0 / train_return -100.0 / train_length 3.0 / train_episodes 561.0\n",
      "[0] dataset_size 1387.0 / train_return -50.0 / train_length 1.0 / train_episodes 562.0\n",
      "[0] dataset_size 1388.0 / train_return -50.0 / train_length 1.0 / train_episodes 563.0\n",
      "[0] dataset_size 1389.0 / train_return -50.0 / train_length 1.0 / train_episodes 564.0\n",
      "[0] dataset_size 1395.0 / train_return -900.0 / train_length 6.0 / train_episodes 565.0\n",
      "[0] dataset_size 1400.0 / train_return -300.0 / train_length 5.0 / train_episodes 566.0\n",
      "[0] dataset_size 1401.0 / train_return -50.0 / train_length 1.0 / train_episodes 567.0\n",
      "[0] dataset_size 1402.0 / train_return -50.0 / train_length 1.0 / train_episodes 568.0\n",
      "[0] dataset_size 1404.0 / train_return 0.0 / train_length 2.0 / train_episodes 569.0\n",
      "[0] dataset_size 1406.0 / train_return 1200.0 / train_length 2.0 / train_episodes 570.0\n",
      "[0] dataset_size 1407.0 / train_return -50.0 / train_length 1.0 / train_episodes 571.0\n",
      "[0] dataset_size 1409.0 / train_return -100.0 / train_length 2.0 / train_episodes 572.0\n",
      "[0] dataset_size 1414.0 / train_return -900.0 / train_length 5.0 / train_episodes 573.0\n",
      "[0] dataset_size 1420.0 / train_return 0.0 / train_length 6.0 / train_episodes 574.0\n",
      "[0] dataset_size 1423.0 / train_return -300.0 / train_length 3.0 / train_episodes 575.0\n",
      "[0] dataset_size 1425.0 / train_return -100.0 / train_length 2.0 / train_episodes 576.0\n",
      "[0] dataset_size 1427.0 / train_return -100.0 / train_length 2.0 / train_episodes 577.0\n",
      "[0] dataset_size 1429.0 / train_return -100.0 / train_length 2.0 / train_episodes 578.0\n",
      "[0] dataset_size 1432.0 / train_return -100.0 / train_length 3.0 / train_episodes 579.0\n",
      "[0] dataset_size 1435.0 / train_return -100.0 / train_length 3.0 / train_episodes 580.0\n",
      "[0] dataset_size 1440.0 / train_return -900.0 / train_length 5.0 / train_episodes 581.0\n",
      "[0] dataset_size 1442.0 / train_return -100.0 / train_length 2.0 / train_episodes 582.0\n",
      "[0] dataset_size 1444.0 / train_return -1200.0 / train_length 2.0 / train_episodes 583.0\n",
      "[0] dataset_size 1447.0 / train_return -100.0 / train_length 3.0 / train_episodes 584.0\n",
      "[0] dataset_size 1451.0 / train_return -100.0 / train_length 4.0 / train_episodes 585.0\n",
      "[0] dataset_size 1456.0 / train_return 1200.0 / train_length 5.0 / train_episodes 586.0\n",
      "[0] dataset_size 1457.0 / train_return -50.0 / train_length 1.0 / train_episodes 587.0\n",
      "[0] dataset_size 1460.0 / train_return -300.0 / train_length 3.0 / train_episodes 588.0\n",
      "[0] dataset_size 1462.0 / train_return -100.0 / train_length 2.0 / train_episodes 589.0\n",
      "[0] dataset_size 1464.0 / train_return -100.0 / train_length 2.0 / train_episodes 590.0\n",
      "[0] dataset_size 1466.0 / train_return -100.0 / train_length 2.0 / train_episodes 591.0\n",
      "[0] dataset_size 1470.0 / train_return 0.0 / train_length 4.0 / train_episodes 592.0\n",
      "[0] dataset_size 1472.0 / train_return -100.0 / train_length 2.0 / train_episodes 593.0\n",
      "[0] dataset_size 1473.0 / train_return -50.0 / train_length 1.0 / train_episodes 594.0\n",
      "[0] dataset_size 1475.0 / train_return 1200.0 / train_length 2.0 / train_episodes 595.0\n",
      "[0] dataset_size 1477.0 / train_return -100.0 / train_length 2.0 / train_episodes 596.0\n",
      "[0] dataset_size 1482.0 / train_return -300.0 / train_length 5.0 / train_episodes 597.0\n",
      "[0] dataset_size 1484.0 / train_return -100.0 / train_length 2.0 / train_episodes 598.0\n",
      "[0] dataset_size 1485.0 / train_return -50.0 / train_length 1.0 / train_episodes 599.0\n",
      "[0] dataset_size 1487.0 / train_return 1200.0 / train_length 2.0 / train_episodes 600.0\n",
      "[0] dataset_size 1492.0 / train_return -900.0 / train_length 5.0 / train_episodes 601.0\n",
      "[0] dataset_size 1497.0 / train_return -1200.0 / train_length 5.0 / train_episodes 602.0\n",
      "[0] dataset_size 1498.0 / train_return -50.0 / train_length 1.0 / train_episodes 603.0\n",
      "[0] dataset_size 1499.0 / train_return -50.0 / train_length 1.0 / train_episodes 604.0\n",
      "[0] dataset_size 1501.0 / train_return -100.0 / train_length 2.0 / train_episodes 605.0\n",
      "[0] dataset_size 1502.0 / train_return -50.0 / train_length 1.0 / train_episodes 606.0\n",
      "[0] dataset_size 1504.0 / train_return 0.0 / train_length 2.0 / train_episodes 607.0\n",
      "[0] dataset_size 1507.0 / train_return -300.0 / train_length 3.0 / train_episodes 608.0\n",
      "[0] dataset_size 1509.0 / train_return -100.0 / train_length 2.0 / train_episodes 609.0\n",
      "[0] dataset_size 1512.0 / train_return 1200.0 / train_length 3.0 / train_episodes 610.0\n",
      "[0] dataset_size 1515.0 / train_return 0.0 / train_length 3.0 / train_episodes 611.0\n",
      "[0] dataset_size 1516.0 / train_return -50.0 / train_length 1.0 / train_episodes 612.0\n",
      "[0] dataset_size 1518.0 / train_return 1200.0 / train_length 2.0 / train_episodes 613.0\n",
      "[0] dataset_size 1520.0 / train_return -100.0 / train_length 2.0 / train_episodes 614.0\n",
      "[0] dataset_size 1521.0 / train_return -50.0 / train_length 1.0 / train_episodes 615.0\n",
      "[0] dataset_size 1524.0 / train_return -100.0 / train_length 3.0 / train_episodes 616.0\n",
      "[0] dataset_size 1529.0 / train_return 0.0 / train_length 5.0 / train_episodes 617.0\n",
      "[0] dataset_size 1530.0 / train_return -50.0 / train_length 1.0 / train_episodes 618.0\n",
      "[0] dataset_size 1533.0 / train_return -300.0 / train_length 3.0 / train_episodes 619.0\n",
      "[0] dataset_size 1534.0 / train_return -50.0 / train_length 1.0 / train_episodes 620.0\n",
      "[0] dataset_size 1537.0 / train_return -1200.0 / train_length 3.0 / train_episodes 621.0\n",
      "[0] dataset_size 1538.0 / train_return -50.0 / train_length 1.0 / train_episodes 622.0\n",
      "[0] dataset_size 1539.0 / train_return -50.0 / train_length 1.0 / train_episodes 623.0\n",
      "[0] dataset_size 1542.0 / train_return -100.0 / train_length 3.0 / train_episodes 624.0\n",
      "[0] dataset_size 1544.0 / train_return -100.0 / train_length 2.0 / train_episodes 625.0\n",
      "[0] dataset_size 1545.0 / train_return -50.0 / train_length 1.0 / train_episodes 626.0\n",
      "[0] dataset_size 1548.0 / train_return -1200.0 / train_length 3.0 / train_episodes 627.0\n",
      "[0] dataset_size 1551.0 / train_return -1200.0 / train_length 3.0 / train_episodes 628.0\n",
      "[0] dataset_size 1555.0 / train_return -300.0 / train_length 4.0 / train_episodes 629.0\n",
      "[0] dataset_size 1560.0 / train_return -900.0 / train_length 5.0 / train_episodes 630.0\n",
      "[0] dataset_size 1561.0 / train_return -50.0 / train_length 1.0 / train_episodes 631.0\n",
      "[0] dataset_size 1562.0 / train_return -50.0 / train_length 1.0 / train_episodes 632.0\n",
      "[0] dataset_size 1564.0 / train_return -1200.0 / train_length 2.0 / train_episodes 633.0\n",
      "[0] dataset_size 1567.0 / train_return -300.0 / train_length 3.0 / train_episodes 634.0\n",
      "[0] dataset_size 1570.0 / train_return -1200.0 / train_length 3.0 / train_episodes 635.0\n",
      "[0] dataset_size 1571.0 / train_return -50.0 / train_length 1.0 / train_episodes 636.0\n",
      "[0] dataset_size 1572.0 / train_return -50.0 / train_length 1.0 / train_episodes 637.0\n",
      "[0] dataset_size 1573.0 / train_return -50.0 / train_length 1.0 / train_episodes 638.0\n",
      "[0] dataset_size 1577.0 / train_return -900.0 / train_length 4.0 / train_episodes 639.0\n",
      "[0] dataset_size 1578.0 / train_return -50.0 / train_length 1.0 / train_episodes 640.0\n",
      "[0] dataset_size 1580.0 / train_return -100.0 / train_length 2.0 / train_episodes 641.0\n",
      "[0] dataset_size 1581.0 / train_return -50.0 / train_length 1.0 / train_episodes 642.0\n",
      "[0] dataset_size 1582.0 / train_return -50.0 / train_length 1.0 / train_episodes 643.0\n",
      "[0] dataset_size 1583.0 / train_return -50.0 / train_length 1.0 / train_episodes 644.0\n",
      "[0] dataset_size 1588.0 / train_return -300.0 / train_length 5.0 / train_episodes 645.0\n",
      "[0] dataset_size 1589.0 / train_return -50.0 / train_length 1.0 / train_episodes 646.0\n",
      "[0] dataset_size 1592.0 / train_return -100.0 / train_length 3.0 / train_episodes 647.0\n",
      "[0] dataset_size 1596.0 / train_return 1200.0 / train_length 4.0 / train_episodes 648.0\n",
      "[0] dataset_size 1597.0 / train_return -50.0 / train_length 1.0 / train_episodes 649.0\n",
      "[0] dataset_size 1598.0 / train_return -50.0 / train_length 1.0 / train_episodes 650.0\n",
      "[0] dataset_size 1601.0 / train_return -100.0 / train_length 3.0 / train_episodes 651.0\n",
      "[0] dataset_size 1603.0 / train_return 1200.0 / train_length 2.0 / train_episodes 652.0\n",
      "[0] dataset_size 1606.0 / train_return -100.0 / train_length 3.0 / train_episodes 653.0\n",
      "[0] dataset_size 1607.0 / train_return -50.0 / train_length 1.0 / train_episodes 654.0\n",
      "[0] dataset_size 1608.0 / train_return -50.0 / train_length 1.0 / train_episodes 655.0\n",
      "[0] dataset_size 1612.0 / train_return -100.0 / train_length 4.0 / train_episodes 656.0\n",
      "[0] dataset_size 1613.0 / train_return -50.0 / train_length 1.0 / train_episodes 657.0\n",
      "[0] dataset_size 1614.0 / train_return -50.0 / train_length 1.0 / train_episodes 658.0\n",
      "[0] dataset_size 1615.0 / train_return -50.0 / train_length 1.0 / train_episodes 659.0\n",
      "[0] dataset_size 1616.0 / train_return -50.0 / train_length 1.0 / train_episodes 660.0\n",
      "[0] dataset_size 1619.0 / train_return -100.0 / train_length 3.0 / train_episodes 661.0\n",
      "[0] dataset_size 1621.0 / train_return -100.0 / train_length 2.0 / train_episodes 662.0\n",
      "[0] dataset_size 1625.0 / train_return -900.0 / train_length 4.0 / train_episodes 663.0\n",
      "[0] dataset_size 1626.0 / train_return -50.0 / train_length 1.0 / train_episodes 664.0\n",
      "[0] dataset_size 1627.0 / train_return -50.0 / train_length 1.0 / train_episodes 665.0\n",
      "[0] dataset_size 1628.0 / train_return -50.0 / train_length 1.0 / train_episodes 666.0\n",
      "[0] dataset_size 1631.0 / train_return 0.0 / train_length 3.0 / train_episodes 667.0\n",
      "[0] dataset_size 1633.0 / train_return -100.0 / train_length 2.0 / train_episodes 668.0\n",
      "[0] dataset_size 1635.0 / train_return -100.0 / train_length 2.0 / train_episodes 669.0\n",
      "[0] dataset_size 1637.0 / train_return 1200.0 / train_length 2.0 / train_episodes 670.0\n",
      "[0] dataset_size 1641.0 / train_return -300.0 / train_length 4.0 / train_episodes 671.0\n",
      "[0] dataset_size 1643.0 / train_return -100.0 / train_length 2.0 / train_episodes 672.0\n",
      "[0] dataset_size 1644.0 / train_return -50.0 / train_length 1.0 / train_episodes 673.0\n",
      "[0] dataset_size 1647.0 / train_return -100.0 / train_length 3.0 / train_episodes 674.0\n",
      "[0] dataset_size 1651.0 / train_return -100.0 / train_length 4.0 / train_episodes 675.0\n",
      "[0] dataset_size 1652.0 / train_return -50.0 / train_length 1.0 / train_episodes 676.0\n",
      "[0] dataset_size 1653.0 / train_return -50.0 / train_length 1.0 / train_episodes 677.0\n",
      "[0] dataset_size 1656.0 / train_return -300.0 / train_length 3.0 / train_episodes 678.0\n",
      "[0] dataset_size 1660.0 / train_return -1200.0 / train_length 4.0 / train_episodes 679.0\n",
      "[0] dataset_size 1664.0 / train_return -300.0 / train_length 4.0 / train_episodes 680.0\n",
      "[0] dataset_size 1665.0 / train_return -50.0 / train_length 1.0 / train_episodes 681.0\n",
      "[0] dataset_size 1667.0 / train_return -1200.0 / train_length 2.0 / train_episodes 682.0\n",
      "[0] dataset_size 1669.0 / train_return -1200.0 / train_length 2.0 / train_episodes 683.0\n",
      "[0] dataset_size 1674.0 / train_return -1200.0 / train_length 5.0 / train_episodes 684.0\n",
      "[0] dataset_size 1681.0 / train_return -1200.0 / train_length 7.0 / train_episodes 685.0\n",
      "[0] dataset_size 1684.0 / train_return 1200.0 / train_length 3.0 / train_episodes 686.0\n",
      "[0] dataset_size 1687.0 / train_return -100.0 / train_length 3.0 / train_episodes 687.0\n",
      "[0] dataset_size 1688.0 / train_return -50.0 / train_length 1.0 / train_episodes 688.0\n",
      "[0] dataset_size 1689.0 / train_return -50.0 / train_length 1.0 / train_episodes 689.0\n",
      "[0] dataset_size 1694.0 / train_return -300.0 / train_length 5.0 / train_episodes 690.0\n",
      "[0] dataset_size 1697.0 / train_return -300.0 / train_length 3.0 / train_episodes 691.0\n",
      "[0] dataset_size 1698.0 / train_return -50.0 / train_length 1.0 / train_episodes 692.0\n",
      "[0] dataset_size 1702.0 / train_return -100.0 / train_length 4.0 / train_episodes 693.0\n",
      "[0] dataset_size 1705.0 / train_return -100.0 / train_length 3.0 / train_episodes 694.0\n",
      "[0] dataset_size 1707.0 / train_return -1200.0 / train_length 2.0 / train_episodes 695.0\n",
      "[0] dataset_size 1710.0 / train_return 1200.0 / train_length 3.0 / train_episodes 696.0\n",
      "[0] dataset_size 1714.0 / train_return -100.0 / train_length 4.0 / train_episodes 697.0\n",
      "[0] dataset_size 1717.0 / train_return -300.0 / train_length 3.0 / train_episodes 698.0\n",
      "[0] dataset_size 1722.0 / train_return -1200.0 / train_length 5.0 / train_episodes 699.0\n",
      "[0] dataset_size 1723.0 / train_return -50.0 / train_length 1.0 / train_episodes 700.0\n",
      "[0] dataset_size 1725.0 / train_return -100.0 / train_length 2.0 / train_episodes 701.0\n",
      "[0] dataset_size 1728.0 / train_return -300.0 / train_length 3.0 / train_episodes 702.0\n",
      "[0] dataset_size 1729.0 / train_return -50.0 / train_length 1.0 / train_episodes 703.0\n",
      "[0] dataset_size 1730.0 / train_return -50.0 / train_length 1.0 / train_episodes 704.0\n",
      "[0] dataset_size 1732.0 / train_return 0.0 / train_length 2.0 / train_episodes 705.0\n",
      "[0] dataset_size 1733.0 / train_return -50.0 / train_length 1.0 / train_episodes 706.0\n",
      "[0] dataset_size 1736.0 / train_return -100.0 / train_length 3.0 / train_episodes 707.0\n",
      "[0] dataset_size 1737.0 / train_return -50.0 / train_length 1.0 / train_episodes 708.0\n",
      "[0] dataset_size 1742.0 / train_return -100.0 / train_length 5.0 / train_episodes 709.0\n",
      "[0] dataset_size 1744.0 / train_return -100.0 / train_length 2.0 / train_episodes 710.0\n",
      "[0] dataset_size 1746.0 / train_return -100.0 / train_length 2.0 / train_episodes 711.0\n",
      "[0] dataset_size 1749.0 / train_return -300.0 / train_length 3.0 / train_episodes 712.0\n",
      "[0] dataset_size 1753.0 / train_return -300.0 / train_length 4.0 / train_episodes 713.0\n",
      "[0] dataset_size 1757.0 / train_return -300.0 / train_length 4.0 / train_episodes 714.0\n",
      "[0] dataset_size 1760.0 / train_return -300.0 / train_length 3.0 / train_episodes 715.0\n",
      "[0] dataset_size 1762.0 / train_return 1200.0 / train_length 2.0 / train_episodes 716.0\n",
      "[0] dataset_size 1765.0 / train_return -300.0 / train_length 3.0 / train_episodes 717.0\n",
      "[0] dataset_size 1767.0 / train_return -100.0 / train_length 2.0 / train_episodes 718.0\n",
      "[0] dataset_size 1768.0 / train_return -50.0 / train_length 1.0 / train_episodes 719.0\n",
      "[0] dataset_size 1770.0 / train_return -100.0 / train_length 2.0 / train_episodes 720.0\n",
      "[0] dataset_size 1774.0 / train_return -1200.0 / train_length 4.0 / train_episodes 721.0\n",
      "[0] dataset_size 1775.0 / train_return -50.0 / train_length 1.0 / train_episodes 722.0\n",
      "[0] dataset_size 1777.0 / train_return -1200.0 / train_length 2.0 / train_episodes 723.0\n",
      "[0] dataset_size 1781.0 / train_return -100.0 / train_length 4.0 / train_episodes 724.0\n",
      "[0] dataset_size 1783.0 / train_return 1200.0 / train_length 2.0 / train_episodes 725.0\n",
      "[0] dataset_size 1786.0 / train_return -300.0 / train_length 3.0 / train_episodes 726.0\n",
      "[0] dataset_size 1788.0 / train_return -100.0 / train_length 2.0 / train_episodes 727.0\n",
      "[0] dataset_size 1790.0 / train_return -100.0 / train_length 2.0 / train_episodes 728.0\n",
      "[0] dataset_size 1792.0 / train_return -100.0 / train_length 2.0 / train_episodes 729.0\n",
      "[0] dataset_size 1795.0 / train_return 1200.0 / train_length 3.0 / train_episodes 730.0\n",
      "[0] dataset_size 1798.0 / train_return 1200.0 / train_length 3.0 / train_episodes 731.0\n",
      "[0] dataset_size 1800.0 / train_return -1200.0 / train_length 2.0 / train_episodes 732.0\n",
      "[0] dataset_size 1802.0 / train_return 1200.0 / train_length 2.0 / train_episodes 733.0\n",
      "[0] dataset_size 1804.0 / train_return -100.0 / train_length 2.0 / train_episodes 734.0\n",
      "[0] dataset_size 1806.0 / train_return 0.0 / train_length 2.0 / train_episodes 735.0\n",
      "[0] dataset_size 1809.0 / train_return -100.0 / train_length 3.0 / train_episodes 736.0\n",
      "[0] dataset_size 1810.0 / train_return -50.0 / train_length 1.0 / train_episodes 737.0\n",
      "[0] dataset_size 1812.0 / train_return -100.0 / train_length 2.0 / train_episodes 738.0\n",
      "[0] dataset_size 1814.0 / train_return -100.0 / train_length 2.0 / train_episodes 739.0\n",
      "[0] dataset_size 1817.0 / train_return 1200.0 / train_length 3.0 / train_episodes 740.0\n",
      "[0] dataset_size 1819.0 / train_return -100.0 / train_length 2.0 / train_episodes 741.0\n",
      "[0] dataset_size 1823.0 / train_return -100.0 / train_length 4.0 / train_episodes 742.0\n",
      "[0] dataset_size 1825.0 / train_return -100.0 / train_length 2.0 / train_episodes 743.0\n",
      "[0] dataset_size 1828.0 / train_return -100.0 / train_length 3.0 / train_episodes 744.0\n",
      "[0] dataset_size 1830.0 / train_return 1200.0 / train_length 2.0 / train_episodes 745.0\n",
      "[0] dataset_size 1834.0 / train_return 100.0 / train_length 4.0 / train_episodes 746.0\n",
      "[0] dataset_size 1836.0 / train_return -1200.0 / train_length 2.0 / train_episodes 747.0\n",
      "[0] dataset_size 1838.0 / train_return 1200.0 / train_length 2.0 / train_episodes 748.0\n",
      "[0] dataset_size 1839.0 / train_return -50.0 / train_length 1.0 / train_episodes 749.0\n",
      "[0] dataset_size 1845.0 / train_return 1200.0 / train_length 6.0 / train_episodes 750.0\n",
      "[0] dataset_size 1849.0 / train_return 1200.0 / train_length 4.0 / train_episodes 751.0\n",
      "[0] dataset_size 1851.0 / train_return 0.0 / train_length 2.0 / train_episodes 752.0\n",
      "[0] dataset_size 1855.0 / train_return -100.0 / train_length 4.0 / train_episodes 753.0\n",
      "[0] dataset_size 1857.0 / train_return -1200.0 / train_length 2.0 / train_episodes 754.0\n",
      "[0] dataset_size 1863.0 / train_return -900.0 / train_length 6.0 / train_episodes 755.0\n",
      "[0] dataset_size 1866.0 / train_return -100.0 / train_length 3.0 / train_episodes 756.0\n",
      "[0] dataset_size 1868.0 / train_return -100.0 / train_length 2.0 / train_episodes 757.0\n",
      "[0] dataset_size 1870.0 / train_return 1200.0 / train_length 2.0 / train_episodes 758.0\n",
      "[0] dataset_size 1876.0 / train_return 900.0 / train_length 6.0 / train_episodes 759.0\n",
      "[0] dataset_size 1882.0 / train_return 1200.0 / train_length 6.0 / train_episodes 760.0\n",
      "[0] dataset_size 1884.0 / train_return -1200.0 / train_length 2.0 / train_episodes 761.0\n",
      "[0] dataset_size 1885.0 / train_return -50.0 / train_length 1.0 / train_episodes 762.0\n",
      "[0] dataset_size 1888.0 / train_return -100.0 / train_length 3.0 / train_episodes 763.0\n",
      "[0] dataset_size 1890.0 / train_return 1200.0 / train_length 2.0 / train_episodes 764.0\n",
      "[0] dataset_size 1893.0 / train_return -300.0 / train_length 3.0 / train_episodes 765.0\n",
      "[0] dataset_size 1894.0 / train_return -50.0 / train_length 1.0 / train_episodes 766.0\n",
      "[0] dataset_size 1897.0 / train_return 1200.0 / train_length 3.0 / train_episodes 767.0\n",
      "[0] dataset_size 1899.0 / train_return -100.0 / train_length 2.0 / train_episodes 768.0\n",
      "[0] dataset_size 1900.0 / train_return -50.0 / train_length 1.0 / train_episodes 769.0\n",
      "[0] dataset_size 1905.0 / train_return -900.0 / train_length 5.0 / train_episodes 770.0\n",
      "[0] dataset_size 1906.0 / train_return -50.0 / train_length 1.0 / train_episodes 771.0\n",
      "[0] dataset_size 1910.0 / train_return 0.0 / train_length 4.0 / train_episodes 772.0\n",
      "[0] dataset_size 1911.0 / train_return -50.0 / train_length 1.0 / train_episodes 773.0\n",
      "[0] dataset_size 1912.0 / train_return -50.0 / train_length 1.0 / train_episodes 774.0\n",
      "[0] dataset_size 1913.0 / train_return -50.0 / train_length 1.0 / train_episodes 775.0\n",
      "[0] dataset_size 1919.0 / train_return 1200.0 / train_length 6.0 / train_episodes 776.0\n",
      "[0] dataset_size 1922.0 / train_return -300.0 / train_length 3.0 / train_episodes 777.0\n",
      "[0] dataset_size 1923.0 / train_return -50.0 / train_length 1.0 / train_episodes 778.0\n",
      "[0] dataset_size 1928.0 / train_return 1200.0 / train_length 5.0 / train_episodes 779.0\n",
      "[0] dataset_size 1931.0 / train_return -100.0 / train_length 3.0 / train_episodes 780.0\n",
      "[0] dataset_size 1932.0 / train_return -50.0 / train_length 1.0 / train_episodes 781.0\n",
      "[0] dataset_size 1933.0 / train_return -50.0 / train_length 1.0 / train_episodes 782.0\n",
      "[0] dataset_size 1935.0 / train_return -1200.0 / train_length 2.0 / train_episodes 783.0\n",
      "[0] dataset_size 1937.0 / train_return -100.0 / train_length 2.0 / train_episodes 784.0\n",
      "[0] dataset_size 1940.0 / train_return 1200.0 / train_length 3.0 / train_episodes 785.0\n",
      "[0] dataset_size 1941.0 / train_return -50.0 / train_length 1.0 / train_episodes 786.0\n",
      "[0] dataset_size 1947.0 / train_return -1200.0 / train_length 6.0 / train_episodes 787.0\n",
      "[0] dataset_size 1950.0 / train_return -300.0 / train_length 3.0 / train_episodes 788.0\n",
      "[0] dataset_size 1954.0 / train_return 900.0 / train_length 4.0 / train_episodes 789.0\n",
      "[0] dataset_size 1956.0 / train_return -100.0 / train_length 2.0 / train_episodes 790.0\n",
      "[0] dataset_size 1960.0 / train_return -100.0 / train_length 4.0 / train_episodes 791.0\n",
      "[0] dataset_size 1962.0 / train_return -1200.0 / train_length 2.0 / train_episodes 792.0\n",
      "[0] dataset_size 1964.0 / train_return 1200.0 / train_length 2.0 / train_episodes 793.0\n",
      "[0] dataset_size 1967.0 / train_return -100.0 / train_length 3.0 / train_episodes 794.0\n",
      "[0] dataset_size 1968.0 / train_return -50.0 / train_length 1.0 / train_episodes 795.0\n",
      "[0] dataset_size 1970.0 / train_return 1200.0 / train_length 2.0 / train_episodes 796.0\n",
      "[0] dataset_size 1972.0 / train_return -100.0 / train_length 2.0 / train_episodes 797.0\n",
      "[0] dataset_size 1973.0 / train_return -50.0 / train_length 1.0 / train_episodes 798.0\n",
      "[0] dataset_size 1975.0 / train_return -1200.0 / train_length 2.0 / train_episodes 799.0\n",
      "[0] dataset_size 1979.0 / train_return -300.0 / train_length 4.0 / train_episodes 800.0\n",
      "[0] dataset_size 1981.0 / train_return -100.0 / train_length 2.0 / train_episodes 801.0\n",
      "[0] dataset_size 1983.0 / train_return 1200.0 / train_length 2.0 / train_episodes 802.0\n",
      "[0] dataset_size 1984.0 / train_return -50.0 / train_length 1.0 / train_episodes 803.0\n",
      "[0] dataset_size 1986.0 / train_return 0.0 / train_length 2.0 / train_episodes 804.0\n",
      "[0] dataset_size 1990.0 / train_return 1200.0 / train_length 4.0 / train_episodes 805.0\n",
      "[0] dataset_size 1994.0 / train_return 300.0 / train_length 4.0 / train_episodes 806.0\n",
      "[0] dataset_size 1996.0 / train_return 1200.0 / train_length 2.0 / train_episodes 807.0\n",
      "[0] dataset_size 1999.0 / train_return 0.0 / train_length 3.0 / train_episodes 808.0\n",
      "[0] dataset_size 2002.0 / train_return -100.0 / train_length 3.0 / train_episodes 809.0\n",
      "[0] dataset_size 2003.0 / train_return -50.0 / train_length 1.0 / train_episodes 810.0\n",
      "[0] dataset_size 2007.0 / train_return 900.0 / train_length 4.0 / train_episodes 811.0\n",
      "[0] dataset_size 2009.0 / train_return -100.0 / train_length 2.0 / train_episodes 812.0\n",
      "[0] dataset_size 2011.0 / train_return 1200.0 / train_length 2.0 / train_episodes 813.0\n",
      "[0] dataset_size 2013.0 / train_return -100.0 / train_length 2.0 / train_episodes 814.0\n",
      "[0] dataset_size 2018.0 / train_return -900.0 / train_length 5.0 / train_episodes 815.0\n",
      "[0] dataset_size 2022.0 / train_return -100.0 / train_length 4.0 / train_episodes 816.0\n",
      "[0] dataset_size 2025.0 / train_return -1200.0 / train_length 3.0 / train_episodes 817.0\n",
      "[0] dataset_size 2029.0 / train_return 1200.0 / train_length 4.0 / train_episodes 818.0\n",
      "[0] dataset_size 2032.0 / train_return -1200.0 / train_length 3.0 / train_episodes 819.0\n",
      "[0] dataset_size 2035.0 / train_return 1200.0 / train_length 3.0 / train_episodes 820.0\n",
      "[0] dataset_size 2038.0 / train_return -100.0 / train_length 3.0 / train_episodes 821.0\n",
      "[0] dataset_size 2040.0 / train_return -100.0 / train_length 2.0 / train_episodes 822.0\n",
      "[0] dataset_size 2042.0 / train_return -100.0 / train_length 2.0 / train_episodes 823.0\n",
      "[0] dataset_size 2045.0 / train_return -100.0 / train_length 3.0 / train_episodes 824.0\n",
      "[0] dataset_size 2046.0 / train_return -50.0 / train_length 1.0 / train_episodes 825.0\n",
      "[0] dataset_size 2048.0 / train_return -100.0 / train_length 2.0 / train_episodes 826.0\n",
      "[0] dataset_size 2050.0 / train_return -100.0 / train_length 2.0 / train_episodes 827.0\n",
      "[0] dataset_size 2052.0 / train_return -100.0 / train_length 2.0 / train_episodes 828.0\n",
      "[0] dataset_size 2054.0 / train_return -100.0 / train_length 2.0 / train_episodes 829.0\n",
      "[0] dataset_size 2056.0 / train_return -100.0 / train_length 2.0 / train_episodes 830.0\n",
      "[0] dataset_size 2057.0 / train_return -50.0 / train_length 1.0 / train_episodes 831.0\n",
      "[0] dataset_size 2059.0 / train_return 1200.0 / train_length 2.0 / train_episodes 832.0\n",
      "[0] dataset_size 2063.0 / train_return -1200.0 / train_length 4.0 / train_episodes 833.0\n",
      "[0] dataset_size 2065.0 / train_return -100.0 / train_length 2.0 / train_episodes 834.0\n",
      "[0] dataset_size 2066.0 / train_return -50.0 / train_length 1.0 / train_episodes 835.0\n",
      "[0] dataset_size 2071.0 / train_return 1200.0 / train_length 5.0 / train_episodes 836.0\n",
      "[0] dataset_size 2073.0 / train_return -100.0 / train_length 2.0 / train_episodes 837.0\n",
      "[0] dataset_size 2075.0 / train_return -100.0 / train_length 2.0 / train_episodes 838.0\n",
      "[0] dataset_size 2078.0 / train_return 1200.0 / train_length 3.0 / train_episodes 839.0\n",
      "[0] dataset_size 2081.0 / train_return -1200.0 / train_length 3.0 / train_episodes 840.0\n",
      "[0] dataset_size 2085.0 / train_return -900.0 / train_length 4.0 / train_episodes 841.0\n",
      "[0] dataset_size 2086.0 / train_return -50.0 / train_length 1.0 / train_episodes 842.0\n",
      "[0] dataset_size 2091.0 / train_return 0.0 / train_length 5.0 / train_episodes 843.0\n",
      "[0] dataset_size 2092.0 / train_return -50.0 / train_length 1.0 / train_episodes 844.0\n",
      "[0] dataset_size 2093.0 / train_return -50.0 / train_length 1.0 / train_episodes 845.0\n",
      "[0] dataset_size 2095.0 / train_return -100.0 / train_length 2.0 / train_episodes 846.0\n",
      "[0] dataset_size 2098.0 / train_return -300.0 / train_length 3.0 / train_episodes 847.0\n",
      "[0] dataset_size 2104.0 / train_return -300.0 / train_length 6.0 / train_episodes 848.0\n",
      "[0] dataset_size 2106.0 / train_return -100.0 / train_length 2.0 / train_episodes 849.0\n",
      "[0] dataset_size 2108.0 / train_return -100.0 / train_length 2.0 / train_episodes 850.0\n",
      "[0] dataset_size 2110.0 / train_return -100.0 / train_length 2.0 / train_episodes 851.0\n",
      "[0] dataset_size 2112.0 / train_return 1200.0 / train_length 2.0 / train_episodes 852.0\n",
      "[0] dataset_size 2113.0 / train_return -50.0 / train_length 1.0 / train_episodes 853.0\n",
      "[0] dataset_size 2115.0 / train_return -100.0 / train_length 2.0 / train_episodes 854.0\n",
      "[0] dataset_size 2116.0 / train_return -50.0 / train_length 1.0 / train_episodes 855.0\n",
      "[0] dataset_size 2120.0 / train_return -900.0 / train_length 4.0 / train_episodes 856.0\n",
      "[0] dataset_size 2121.0 / train_return -50.0 / train_length 1.0 / train_episodes 857.0\n",
      "[0] dataset_size 2126.0 / train_return -300.0 / train_length 5.0 / train_episodes 858.0\n",
      "[0] dataset_size 2128.0 / train_return -100.0 / train_length 2.0 / train_episodes 859.0\n",
      "[0] dataset_size 2131.0 / train_return -1200.0 / train_length 3.0 / train_episodes 860.0\n",
      "[0] dataset_size 2135.0 / train_return -100.0 / train_length 4.0 / train_episodes 861.0\n",
      "[0] dataset_size 2137.0 / train_return -100.0 / train_length 2.0 / train_episodes 862.0\n",
      "[0] dataset_size 2139.0 / train_return -100.0 / train_length 2.0 / train_episodes 863.0\n",
      "[0] dataset_size 2141.0 / train_return 1200.0 / train_length 2.0 / train_episodes 864.0\n",
      "[0] dataset_size 2144.0 / train_return -1200.0 / train_length 3.0 / train_episodes 865.0\n",
      "[0] dataset_size 2146.0 / train_return 0.0 / train_length 2.0 / train_episodes 866.0\n",
      "[0] dataset_size 2147.0 / train_return -50.0 / train_length 1.0 / train_episodes 867.0\n",
      "[0] dataset_size 2149.0 / train_return -100.0 / train_length 2.0 / train_episodes 868.0\n",
      "[0] dataset_size 2150.0 / train_return -50.0 / train_length 1.0 / train_episodes 869.0\n",
      "[0] dataset_size 2152.0 / train_return -100.0 / train_length 2.0 / train_episodes 870.0\n",
      "[0] dataset_size 2155.0 / train_return 1200.0 / train_length 3.0 / train_episodes 871.0\n",
      "[0] dataset_size 2156.0 / train_return -50.0 / train_length 1.0 / train_episodes 872.0\n",
      "[0] dataset_size 2158.0 / train_return -100.0 / train_length 2.0 / train_episodes 873.0\n",
      "[0] dataset_size 2161.0 / train_return 1200.0 / train_length 3.0 / train_episodes 874.0\n",
      "[0] dataset_size 2164.0 / train_return -100.0 / train_length 3.0 / train_episodes 875.0\n",
      "[0] dataset_size 2165.0 / train_return -50.0 / train_length 1.0 / train_episodes 876.0\n",
      "[0] dataset_size 2169.0 / train_return -100.0 / train_length 4.0 / train_episodes 877.0\n",
      "[0] dataset_size 2170.0 / train_return -50.0 / train_length 1.0 / train_episodes 878.0\n",
      "[0] dataset_size 2173.0 / train_return -300.0 / train_length 3.0 / train_episodes 879.0\n",
      "[0] dataset_size 2175.0 / train_return -1200.0 / train_length 2.0 / train_episodes 880.0\n",
      "[0] dataset_size 2178.0 / train_return -1200.0 / train_length 3.0 / train_episodes 881.0\n",
      "[0] dataset_size 2181.0 / train_return -100.0 / train_length 3.0 / train_episodes 882.0\n",
      "[0] dataset_size 2186.0 / train_return -900.0 / train_length 5.0 / train_episodes 883.0\n",
      "[0] dataset_size 2187.0 / train_return -50.0 / train_length 1.0 / train_episodes 884.0\n",
      "[0] dataset_size 2189.0 / train_return 0.0 / train_length 2.0 / train_episodes 885.0\n",
      "[0] dataset_size 2191.0 / train_return 1200.0 / train_length 2.0 / train_episodes 886.0\n",
      "[0] dataset_size 2195.0 / train_return 1200.0 / train_length 4.0 / train_episodes 887.0\n",
      "[0] dataset_size 2199.0 / train_return -900.0 / train_length 4.0 / train_episodes 888.0\n",
      "[0] dataset_size 2202.0 / train_return -100.0 / train_length 3.0 / train_episodes 889.0\n",
      "[0] dataset_size 2207.0 / train_return -900.0 / train_length 5.0 / train_episodes 890.0\n",
      "[0] dataset_size 2208.0 / train_return -50.0 / train_length 1.0 / train_episodes 891.0\n",
      "[0] dataset_size 2209.0 / train_return -50.0 / train_length 1.0 / train_episodes 892.0\n",
      "[0] dataset_size 2211.0 / train_return 0.0 / train_length 2.0 / train_episodes 893.0\n",
      "[0] dataset_size 2215.0 / train_return 1200.0 / train_length 4.0 / train_episodes 894.0\n",
      "[0] dataset_size 2219.0 / train_return 900.0 / train_length 4.0 / train_episodes 895.0\n",
      "[0] dataset_size 2221.0 / train_return -100.0 / train_length 2.0 / train_episodes 896.0\n",
      "[0] dataset_size 2225.0 / train_return -300.0 / train_length 4.0 / train_episodes 897.0\n",
      "[0] dataset_size 2227.0 / train_return -100.0 / train_length 2.0 / train_episodes 898.0\n",
      "[0] dataset_size 2233.0 / train_return -300.0 / train_length 6.0 / train_episodes 899.0\n",
      "[0] dataset_size 2235.0 / train_return -1200.0 / train_length 2.0 / train_episodes 900.0\n",
      "[0] dataset_size 2236.0 / train_return -50.0 / train_length 1.0 / train_episodes 901.0\n",
      "[0] dataset_size 2237.0 / train_return -50.0 / train_length 1.0 / train_episodes 902.0\n",
      "[0] dataset_size 2240.0 / train_return -100.0 / train_length 3.0 / train_episodes 903.0\n",
      "[0] dataset_size 2241.0 / train_return -50.0 / train_length 1.0 / train_episodes 904.0\n",
      "[0] dataset_size 2243.0 / train_return -100.0 / train_length 2.0 / train_episodes 905.0\n",
      "[0] dataset_size 2245.0 / train_return 0.0 / train_length 2.0 / train_episodes 906.0\n",
      "[0] dataset_size 2247.0 / train_return -100.0 / train_length 2.0 / train_episodes 907.0\n",
      "[0] dataset_size 2249.0 / train_return -100.0 / train_length 2.0 / train_episodes 908.0\n",
      "[0] dataset_size 2254.0 / train_return 0.0 / train_length 5.0 / train_episodes 909.0\n",
      "[0] dataset_size 2257.0 / train_return -300.0 / train_length 3.0 / train_episodes 910.0\n",
      "[0] dataset_size 2259.0 / train_return -100.0 / train_length 2.0 / train_episodes 911.0\n",
      "[0] dataset_size 2263.0 / train_return 300.0 / train_length 4.0 / train_episodes 912.0\n",
      "[0] dataset_size 2265.0 / train_return -100.0 / train_length 2.0 / train_episodes 913.0\n",
      "[0] dataset_size 2268.0 / train_return -300.0 / train_length 3.0 / train_episodes 914.0\n",
      "[0] dataset_size 2271.0 / train_return 1200.0 / train_length 3.0 / train_episodes 915.0\n",
      "[0] dataset_size 2275.0 / train_return 300.0 / train_length 4.0 / train_episodes 916.0\n",
      "[0] dataset_size 2277.0 / train_return -100.0 / train_length 2.0 / train_episodes 917.0\n",
      "[0] dataset_size 2282.0 / train_return -100.0 / train_length 5.0 / train_episodes 918.0\n",
      "[0] dataset_size 2283.0 / train_return -50.0 / train_length 1.0 / train_episodes 919.0\n",
      "[0] dataset_size 2285.0 / train_return -100.0 / train_length 2.0 / train_episodes 920.0\n",
      "[0] dataset_size 2286.0 / train_return -50.0 / train_length 1.0 / train_episodes 921.0\n",
      "[0] dataset_size 2287.0 / train_return -50.0 / train_length 1.0 / train_episodes 922.0\n",
      "[0] dataset_size 2289.0 / train_return 1200.0 / train_length 2.0 / train_episodes 923.0\n",
      "[0] dataset_size 2291.0 / train_return -1200.0 / train_length 2.0 / train_episodes 924.0\n",
      "[0] dataset_size 2295.0 / train_return -1200.0 / train_length 4.0 / train_episodes 925.0\n",
      "[0] dataset_size 2298.0 / train_return -300.0 / train_length 3.0 / train_episodes 926.0\n",
      "[0] dataset_size 2299.0 / train_return -50.0 / train_length 1.0 / train_episodes 927.0\n",
      "[0] dataset_size 2301.0 / train_return 1200.0 / train_length 2.0 / train_episodes 928.0\n",
      "[0] dataset_size 2302.0 / train_return -50.0 / train_length 1.0 / train_episodes 929.0\n",
      "[0] dataset_size 2305.0 / train_return -100.0 / train_length 3.0 / train_episodes 930.0\n",
      "[0] dataset_size 2308.0 / train_return -1200.0 / train_length 3.0 / train_episodes 931.0\n",
      "[0] dataset_size 2310.0 / train_return -100.0 / train_length 2.0 / train_episodes 932.0\n",
      "[0] dataset_size 2314.0 / train_return 100.0 / train_length 4.0 / train_episodes 933.0\n",
      "[0] dataset_size 2317.0 / train_return -1200.0 / train_length 3.0 / train_episodes 934.0\n",
      "[0] dataset_size 2320.0 / train_return -100.0 / train_length 3.0 / train_episodes 935.0\n",
      "[0] dataset_size 2323.0 / train_return -300.0 / train_length 3.0 / train_episodes 936.0\n",
      "[0] dataset_size 2327.0 / train_return -300.0 / train_length 4.0 / train_episodes 937.0\n",
      "[0] dataset_size 2329.0 / train_return -100.0 / train_length 2.0 / train_episodes 938.0\n",
      "[0] dataset_size 2331.0 / train_return 0.0 / train_length 2.0 / train_episodes 939.0\n",
      "[0] dataset_size 2333.0 / train_return -100.0 / train_length 2.0 / train_episodes 940.0\n",
      "[0] dataset_size 2336.0 / train_return -100.0 / train_length 3.0 / train_episodes 941.0\n",
      "[0] dataset_size 2340.0 / train_return -100.0 / train_length 4.0 / train_episodes 942.0\n",
      "[0] dataset_size 2343.0 / train_return -300.0 / train_length 3.0 / train_episodes 943.0\n",
      "[0] dataset_size 2346.0 / train_return -300.0 / train_length 3.0 / train_episodes 944.0\n",
      "[0] dataset_size 2352.0 / train_return 1200.0 / train_length 6.0 / train_episodes 945.0\n",
      "[0] dataset_size 2353.0 / train_return -50.0 / train_length 1.0 / train_episodes 946.0\n",
      "[0] dataset_size 2356.0 / train_return -100.0 / train_length 3.0 / train_episodes 947.0\n",
      "[0] dataset_size 2357.0 / train_return -50.0 / train_length 1.0 / train_episodes 948.0\n",
      "[0] dataset_size 2361.0 / train_return 300.0 / train_length 4.0 / train_episodes 949.0\n",
      "[0] dataset_size 2362.0 / train_return -50.0 / train_length 1.0 / train_episodes 950.0\n",
      "[0] dataset_size 2366.0 / train_return -1200.0 / train_length 4.0 / train_episodes 951.0\n",
      "[0] dataset_size 2368.0 / train_return 1200.0 / train_length 2.0 / train_episodes 952.0\n",
      "[0] dataset_size 2374.0 / train_return -900.0 / train_length 6.0 / train_episodes 953.0\n",
      "[0] dataset_size 2376.0 / train_return 0.0 / train_length 2.0 / train_episodes 954.0\n",
      "[0] dataset_size 2379.0 / train_return -100.0 / train_length 3.0 / train_episodes 955.0\n",
      "[0] dataset_size 2383.0 / train_return -300.0 / train_length 4.0 / train_episodes 956.0\n",
      "[0] dataset_size 2387.0 / train_return 1200.0 / train_length 4.0 / train_episodes 957.0\n",
      "[0] dataset_size 2388.0 / train_return -50.0 / train_length 1.0 / train_episodes 958.0\n",
      "[0] dataset_size 2389.0 / train_return -50.0 / train_length 1.0 / train_episodes 959.0\n",
      "[0] dataset_size 2390.0 / train_return -50.0 / train_length 1.0 / train_episodes 960.0\n",
      "[0] dataset_size 2391.0 / train_return -50.0 / train_length 1.0 / train_episodes 961.0\n",
      "[0] dataset_size 2393.0 / train_return -100.0 / train_length 2.0 / train_episodes 962.0\n",
      "[0] dataset_size 2396.0 / train_return -300.0 / train_length 3.0 / train_episodes 963.0\n",
      "[0] dataset_size 2399.0 / train_return -100.0 / train_length 3.0 / train_episodes 964.0\n",
      "[0] dataset_size 2400.0 / train_return -50.0 / train_length 1.0 / train_episodes 965.0\n",
      "[0] dataset_size 2405.0 / train_return -300.0 / train_length 5.0 / train_episodes 966.0\n",
      "[0] dataset_size 2408.0 / train_return -1200.0 / train_length 3.0 / train_episodes 967.0\n",
      "[0] dataset_size 2409.0 / train_return -50.0 / train_length 1.0 / train_episodes 968.0\n",
      "[0] dataset_size 2410.0 / train_return -50.0 / train_length 1.0 / train_episodes 969.0\n",
      "[0] dataset_size 2412.0 / train_return -100.0 / train_length 2.0 / train_episodes 970.0\n",
      "[0] dataset_size 2415.0 / train_return -300.0 / train_length 3.0 / train_episodes 971.0\n",
      "[0] dataset_size 2417.0 / train_return -100.0 / train_length 2.0 / train_episodes 972.0\n",
      "[0] dataset_size 2422.0 / train_return 900.0 / train_length 5.0 / train_episodes 973.0\n",
      "[0] dataset_size 2425.0 / train_return -100.0 / train_length 3.0 / train_episodes 974.0\n",
      "[0] dataset_size 2430.0 / train_return 1200.0 / train_length 5.0 / train_episodes 975.0\n",
      "[0] dataset_size 2433.0 / train_return -300.0 / train_length 3.0 / train_episodes 976.0\n",
      "[0] dataset_size 2436.0 / train_return -1200.0 / train_length 3.0 / train_episodes 977.0\n",
      "[0] dataset_size 2437.0 / train_return -50.0 / train_length 1.0 / train_episodes 978.0\n",
      "[0] dataset_size 2438.0 / train_return -50.0 / train_length 1.0 / train_episodes 979.0\n",
      "[0] dataset_size 2440.0 / train_return -100.0 / train_length 2.0 / train_episodes 980.0\n",
      "[0] dataset_size 2443.0 / train_return -100.0 / train_length 3.0 / train_episodes 981.0\n",
      "[0] dataset_size 2447.0 / train_return -1200.0 / train_length 4.0 / train_episodes 982.0\n",
      "[0] dataset_size 2451.0 / train_return -100.0 / train_length 4.0 / train_episodes 983.0\n",
      "[0] dataset_size 2454.0 / train_return -1200.0 / train_length 3.0 / train_episodes 984.0\n",
      "[0] dataset_size 2455.0 / train_return -50.0 / train_length 1.0 / train_episodes 985.0\n",
      "[0] dataset_size 2457.0 / train_return -100.0 / train_length 2.0 / train_episodes 986.0\n",
      "[0] dataset_size 2460.0 / train_return -1200.0 / train_length 3.0 / train_episodes 987.0\n",
      "[0] dataset_size 2462.0 / train_return -100.0 / train_length 2.0 / train_episodes 988.0\n",
      "[0] dataset_size 2466.0 / train_return 0.0 / train_length 4.0 / train_episodes 989.0\n",
      "[0] dataset_size 2470.0 / train_return -300.0 / train_length 4.0 / train_episodes 990.0\n",
      "[0] dataset_size 2471.0 / train_return -50.0 / train_length 1.0 / train_episodes 991.0\n",
      "[0] dataset_size 2474.0 / train_return -300.0 / train_length 3.0 / train_episodes 992.0\n",
      "[0] dataset_size 2477.0 / train_return -100.0 / train_length 3.0 / train_episodes 993.0\n",
      "[0] dataset_size 2480.0 / train_return -300.0 / train_length 3.0 / train_episodes 994.0\n",
      "[0] dataset_size 2481.0 / train_return -50.0 / train_length 1.0 / train_episodes 995.0\n",
      "[0] dataset_size 2485.0 / train_return 0.0 / train_length 4.0 / train_episodes 996.0\n",
      "[0] dataset_size 2487.0 / train_return 1200.0 / train_length 2.0 / train_episodes 997.0\n",
      "[0] dataset_size 2490.0 / train_return 1200.0 / train_length 3.0 / train_episodes 998.0\n",
      "[0] dataset_size 2492.0 / train_return -100.0 / train_length 2.0 / train_episodes 999.0\n",
      "[0] dataset_size 2496.0 / train_return -900.0 / train_length 4.0 / train_episodes 1000.0\n",
      "[0] dataset_size 2498.0 / train_return -100.0 / train_length 2.0 / train_episodes 1001.0\n",
      "Logger: (5000 steps).\n"
     ]
    }
   ],
   "source": [
    "set_seed_everywhere(config.seed)\n",
    "if config.deterministic_run:\n",
    "    enable_deterministic_run()\n",
    "logdir = pathlib.Path(config.logdir).expanduser()\n",
    "config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "config.steps //= config.action_repeat\n",
    "config.eval_every //= config.action_repeat\n",
    "config.log_every //= config.action_repeat\n",
    "config.time_limit //= config.action_repeat\n",
    "\n",
    "print(\"Logdir\", logdir)\n",
    "config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "step = count_steps(config.traindir)\n",
    "# step in logger is environmental step\n",
    "logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "if config.offline_evaldir:\n",
    "    directory = config.offline_evaldir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.evaldir\n",
    "eval_eps = load_episodes(directory, limit=1)\n",
    "make = lambda mode, id: make_env(config, mode, id)\n",
    "train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "if config.parallel:\n",
    "    train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "    eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "else:\n",
    "    train_envs = [Damy(env) for env in train_envs]\n",
    "    eval_envs = [Damy(env) for env in eval_envs]\n",
    "acts = train_envs[0].action_space\n",
    "print(\"Action Space\", acts)\n",
    "config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "state = None\n",
    "if not config.offline_traindir:\n",
    "    prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "    print(f\"Prefill dataset ({prefill} steps).\")\n",
    "    if hasattr(acts, \"discrete\"):\n",
    "        random_actor = OneHotDist(\n",
    "            torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "        )\n",
    "    else:\n",
    "        random_actor = torchd.independent.Independent(\n",
    "            torchd.uniform.Uniform(\n",
    "                torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def random_agent(o, d, s):\n",
    "        action = random_actor.sample()\n",
    "        logprob = random_actor.log_prob(action)\n",
    "        return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "    state = simulate(\n",
    "        random_agent,\n",
    "        train_envs,\n",
    "        train_eps,\n",
    "        config.traindir,\n",
    "        logger,\n",
    "        limit=config.dataset_size,\n",
    "        steps=prefill,\n",
    "    )\n",
    "    logger.step += prefill * config.action_repeat\n",
    "    print(f\"Logger: ({logger.step} steps).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate agent.\n",
      "dict_items([('observation', (16,))])\n",
      ".*\n",
      "$^\n",
      "cnn\n",
      "False\n",
      "None\n",
      "$^\n",
      "observation\n",
      "mlp\n",
      "True\n",
      "<re.Match object; span=(0, 11), match='observation'>\n",
      ".*\n",
      "observation\n",
      "Encoder CNN shapes: {}\n",
      "Encoder MLP shapes: {'observation': (16,)}\n",
      "v:  (16,)\n",
      "input_size:  16\n",
      "Decoder CNN shapes: {}\n",
      "Decoder MLP shapes: {'observation': (16,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_88785/3206908984.py:747: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer model_opt has 3703824 variables.\n",
      "Start evaluation.\n",
      "Start training.\n",
      "Agent step:  2500\n",
      "iter:  0\n",
      "dreamer train step:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_88785/4161829076.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._use_amp):\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_88785/4161829076.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  1\n",
      "dreamer train step:\n",
      "iter:  2\n",
      "dreamer train step:\n",
      "iter:  3\n",
      "dreamer train step:\n",
      "iter:  4\n",
      "dreamer train step:\n",
      "iter:  5\n",
      "dreamer train step:\n",
      "iter:  6\n",
      "dreamer train step:\n",
      "iter:  7\n",
      "dreamer train step:\n",
      "iter:  8\n",
      "dreamer train step:\n",
      "iter:  9\n",
      "dreamer train step:\n",
      "iter:  10\n",
      "dreamer train step:\n",
      "iter:  11\n",
      "dreamer train step:\n",
      "iter:  12\n",
      "dreamer train step:\n",
      "iter:  13\n",
      "dreamer train step:\n",
      "iter:  14\n",
      "dreamer train step:\n",
      "iter:  15\n",
      "dreamer train step:\n",
      "iter:  16\n",
      "dreamer train step:\n",
      "iter:  17\n",
      "dreamer train step:\n",
      "iter:  18\n",
      "dreamer train step:\n",
      "iter:  19\n",
      "dreamer train step:\n",
      "iter:  20\n",
      "dreamer train step:\n",
      "iter:  21\n",
      "dreamer train step:\n",
      "iter:  22\n",
      "dreamer train step:\n",
      "iter:  23\n",
      "dreamer train step:\n",
      "iter:  24\n",
      "dreamer train step:\n",
      "iter:  25\n",
      "dreamer train step:\n",
      "iter:  26\n",
      "dreamer train step:\n",
      "iter:  27\n",
      "dreamer train step:\n",
      "iter:  28\n",
      "dreamer train step:\n",
      "iter:  29\n",
      "dreamer train step:\n",
      "iter:  30\n",
      "dreamer train step:\n",
      "iter:  31\n",
      "dreamer train step:\n",
      "iter:  32\n",
      "dreamer train step:\n",
      "iter:  33\n",
      "dreamer train step:\n",
      "iter:  34\n",
      "dreamer train step:\n",
      "iter:  35\n",
      "dreamer train step:\n",
      "iter:  36\n",
      "dreamer train step:\n",
      "iter:  37\n",
      "dreamer train step:\n",
      "iter:  38\n",
      "dreamer train step:\n",
      "iter:  39\n",
      "dreamer train step:\n",
      "iter:  40\n",
      "dreamer train step:\n",
      "iter:  41\n",
      "dreamer train step:\n",
      "iter:  42\n",
      "dreamer train step:\n",
      "iter:  43\n",
      "dreamer train step:\n",
      "iter:  44\n",
      "dreamer train step:\n",
      "iter:  45\n",
      "dreamer train step:\n",
      "iter:  46\n",
      "dreamer train step:\n",
      "iter:  47\n",
      "dreamer train step:\n",
      "iter:  48\n",
      "dreamer train step:\n",
      "iter:  49\n",
      "dreamer train step:\n",
      "iter:  50\n",
      "dreamer train step:\n",
      "iter:  51\n",
      "dreamer train step:\n",
      "iter:  52\n",
      "dreamer train step:\n",
      "iter:  53\n",
      "dreamer train step:\n",
      "iter:  54\n",
      "dreamer train step:\n",
      "iter:  55\n",
      "dreamer train step:\n",
      "iter:  56\n",
      "dreamer train step:\n",
      "iter:  57\n",
      "dreamer train step:\n",
      "iter:  58\n",
      "dreamer train step:\n",
      "iter:  59\n",
      "dreamer train step:\n",
      "iter:  60\n",
      "dreamer train step:\n",
      "iter:  61\n",
      "dreamer train step:\n",
      "iter:  62\n",
      "dreamer train step:\n",
      "iter:  63\n",
      "dreamer train step:\n",
      "iter:  64\n",
      "dreamer train step:\n",
      "iter:  65\n",
      "dreamer train step:\n",
      "iter:  66\n",
      "dreamer train step:\n",
      "iter:  67\n",
      "dreamer train step:\n",
      "iter:  68\n",
      "dreamer train step:\n",
      "iter:  69\n",
      "dreamer train step:\n",
      "iter:  70\n",
      "dreamer train step:\n",
      "iter:  71\n",
      "dreamer train step:\n",
      "iter:  72\n",
      "dreamer train step:\n",
      "iter:  73\n",
      "dreamer train step:\n",
      "iter:  74\n",
      "dreamer train step:\n",
      "iter:  75\n",
      "dreamer train step:\n",
      "iter:  76\n",
      "dreamer train step:\n",
      "iter:  77\n",
      "dreamer train step:\n",
      "iter:  78\n",
      "dreamer train step:\n",
      "iter:  79\n",
      "dreamer train step:\n",
      "iter:  80\n",
      "dreamer train step:\n",
      "iter:  81\n",
      "dreamer train step:\n",
      "iter:  82\n",
      "dreamer train step:\n",
      "iter:  83\n",
      "dreamer train step:\n",
      "iter:  84\n",
      "dreamer train step:\n",
      "iter:  85\n",
      "dreamer train step:\n",
      "iter:  86\n",
      "dreamer train step:\n",
      "iter:  87\n",
      "dreamer train step:\n",
      "iter:  88\n",
      "dreamer train step:\n",
      "iter:  89\n",
      "dreamer train step:\n",
      "iter:  90\n",
      "dreamer train step:\n",
      "iter:  91\n",
      "dreamer train step:\n",
      "iter:  92\n",
      "dreamer train step:\n",
      "iter:  93\n",
      "dreamer train step:\n",
      "iter:  94\n",
      "dreamer train step:\n",
      "iter:  95\n",
      "dreamer train step:\n",
      "iter:  96\n",
      "dreamer train step:\n",
      "iter:  97\n",
      "dreamer train step:\n",
      "iter:  98\n",
      "dreamer train step:\n",
      "iter:  99\n",
      "dreamer train step:\n",
      "[5000] model_loss 11.5 / model_grad_norm 33.6 / observation_loss 5.1 / reward_loss 4.5 / cont_loss 0.5 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 2.5 / rep_loss 2.5 / kl 2.4 / prior_ent 41.8 / post_ent 40.5 / update_count 100.0 / fps 0.0\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5002] dataset_size 2501.0 / train_return -300.0 / train_length 3.0 / train_episodes 1002.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5008] dataset_size 2504.0 / train_return -100.0 / train_length 3.0 / train_episodes 1003.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5010] model_loss 6.4 / model_grad_norm 11.0 / observation_loss 1.9 / reward_loss 3.2 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.5 / rep_loss 1.5 / kl 1.4 / prior_ent 40.8 / post_ent 39.4 / update_count 109.0 / fps 2.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5012] dataset_size 2506.0 / train_return -100.0 / train_length 2.0 / train_episodes 1004.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5020] dataset_size 2510.0 / train_return -300.0 / train_length 4.0 / train_episodes 1005.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5020] model_loss 6.1 / model_grad_norm 11.5 / observation_loss 1.8 / reward_loss 2.9 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.5 / prior_ent 40.6 / post_ent 38.9 / update_count 119.0 / fps 4.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5030] model_loss 5.7 / model_grad_norm 10.0 / observation_loss 1.6 / reward_loss 2.7 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 40.2 / post_ent 38.4 / update_count 129.0 / fps 3.3\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5032] dataset_size 2516.0 / train_return -1200.0 / train_length 6.0 / train_episodes 1006.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5034] dataset_size 2517.0 / train_return -50.0 / train_length 1.0 / train_episodes 1007.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5036] dataset_size 2518.0 / train_return -50.0 / train_length 1.0 / train_episodes 1008.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5040] model_loss 5.5 / model_grad_norm 11.5 / observation_loss 1.6 / reward_loss 2.5 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 39.8 / post_ent 37.9 / update_count 139.0 / fps 2.9\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5044] dataset_size 2522.0 / train_return -300.0 / train_length 4.0 / train_episodes 1009.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5050] model_loss 5.3 / model_grad_norm 9.6 / observation_loss 1.5 / reward_loss 2.3 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 39.4 / post_ent 37.2 / update_count 149.0 / fps 2.9\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5054] dataset_size 2527.0 / train_return 300.0 / train_length 5.0 / train_episodes 1010.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5056] dataset_size 2528.0 / train_return -50.0 / train_length 1.0 / train_episodes 1011.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5058] dataset_size 2529.0 / train_return -50.0 / train_length 1.0 / train_episodes 1012.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5060] model_loss 5.0 / model_grad_norm 10.2 / observation_loss 1.5 / reward_loss 2.1 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 38.8 / post_ent 36.8 / update_count 159.0 / fps 3.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5066] dataset_size 2533.0 / train_return -300.0 / train_length 4.0 / train_episodes 1013.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5070] model_loss 4.9 / model_grad_norm 11.2 / observation_loss 1.5 / reward_loss 2.0 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 38.3 / post_ent 36.3 / update_count 169.0 / fps 2.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5074] dataset_size 2537.0 / train_return -300.0 / train_length 4.0 / train_episodes 1014.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5076] dataset_size 2538.0 / train_return -50.0 / train_length 1.0 / train_episodes 1015.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5080] model_loss 4.7 / model_grad_norm 9.4 / observation_loss 1.4 / reward_loss 1.8 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 37.9 / post_ent 35.9 / update_count 179.0 / fps 3.2\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5084] dataset_size 2542.0 / train_return -300.0 / train_length 4.0 / train_episodes 1016.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5090] model_loss 4.5 / model_grad_norm 10.1 / observation_loss 1.4 / reward_loss 1.7 / cont_loss 0.4 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 37.6 / post_ent 35.6 / update_count 189.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5092] dataset_size 2546.0 / train_return -1200.0 / train_length 4.0 / train_episodes 1017.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5098] dataset_size 2549.0 / train_return -300.0 / train_length 3.0 / train_episodes 1018.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5100] model_loss 4.4 / model_grad_norm 9.5 / observation_loss 1.3 / reward_loss 1.6 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 37.2 / post_ent 35.2 / update_count 199.0 / fps 3.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5108] dataset_size 2554.0 / train_return -900.0 / train_length 5.0 / train_episodes 1019.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5110] model_loss 4.3 / model_grad_norm 9.1 / observation_loss 1.3 / reward_loss 1.5 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 36.8 / post_ent 35.0 / update_count 209.0 / fps 2.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5114] dataset_size 2557.0 / train_return -300.0 / train_length 3.0 / train_episodes 1020.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5120] model_loss 4.2 / model_grad_norm 9.2 / observation_loss 1.3 / reward_loss 1.4 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 36.6 / post_ent 34.6 / update_count 219.0 / fps 2.3\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5124] dataset_size 2562.0 / train_return 900.0 / train_length 5.0 / train_episodes 1021.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5126] dataset_size 2563.0 / train_return -50.0 / train_length 1.0 / train_episodes 1022.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5130] dataset_size 2565.0 / train_return -100.0 / train_length 2.0 / train_episodes 1023.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5130] model_loss 4.1 / model_grad_norm 8.6 / observation_loss 1.2 / reward_loss 1.4 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 36.5 / post_ent 34.4 / update_count 229.0 / fps 0.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5132] dataset_size 2566.0 / train_return -50.0 / train_length 1.0 / train_episodes 1024.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5136] dataset_size 2568.0 / train_return 0.0 / train_length 2.0 / train_episodes 1025.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5138] dataset_size 2569.0 / train_return -50.0 / train_length 1.0 / train_episodes 1026.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5140] dataset_size 2570.0 / train_return -50.0 / train_length 1.0 / train_episodes 1027.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5140] model_loss 3.9 / model_grad_norm 9.3 / observation_loss 1.2 / reward_loss 1.3 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 36.2 / post_ent 34.3 / update_count 239.0 / fps 1.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5144] dataset_size 2572.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1028.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5150] dataset_size 2575.0 / train_return -300.0 / train_length 3.0 / train_episodes 1029.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5150] model_loss 3.9 / model_grad_norm 8.1 / observation_loss 1.2 / reward_loss 1.3 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 36.0 / post_ent 34.1 / update_count 249.0 / fps 2.9\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5160] model_loss 3.9 / model_grad_norm 7.8 / observation_loss 1.2 / reward_loss 1.3 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 36.0 / post_ent 33.8 / update_count 259.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5162] dataset_size 2581.0 / train_return 0.0 / train_length 6.0 / train_episodes 1030.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5166] dataset_size 2583.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1031.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5170] model_loss 3.9 / model_grad_norm 8.6 / observation_loss 1.2 / reward_loss 1.3 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 35.7 / post_ent 33.5 / update_count 269.0 / fps 3.5\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5172] dataset_size 2586.0 / train_return -100.0 / train_length 3.0 / train_episodes 1032.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5176] dataset_size 2588.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1033.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5180] model_loss 3.8 / model_grad_norm 8.6 / observation_loss 1.2 / reward_loss 1.2 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 35.5 / post_ent 33.3 / update_count 279.0 / fps 3.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5182] dataset_size 2591.0 / train_return -100.0 / train_length 3.0 / train_episodes 1034.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5190] dataset_size 2595.0 / train_return -100.0 / train_length 4.0 / train_episodes 1035.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5190] model_loss 3.7 / model_grad_norm 9.0 / observation_loss 1.1 / reward_loss 1.2 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 35.2 / post_ent 33.1 / update_count 289.0 / fps 3.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5194] dataset_size 2597.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1036.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5198] dataset_size 2599.0 / train_return 0.0 / train_length 2.0 / train_episodes 1037.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5200] model_loss 3.7 / model_grad_norm 9.2 / observation_loss 1.1 / reward_loss 1.2 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 35.1 / post_ent 32.8 / update_count 299.0 / fps 3.4\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5202] dataset_size 2601.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1038.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5206] dataset_size 2603.0 / train_return -100.0 / train_length 2.0 / train_episodes 1039.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5208] dataset_size 2604.0 / train_return -50.0 / train_length 1.0 / train_episodes 1040.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5210] model_loss 3.7 / model_grad_norm 8.7 / observation_loss 1.2 / reward_loss 1.2 / cont_loss 0.3 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 34.9 / post_ent 32.7 / update_count 309.0 / fps 2.8\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5212] dataset_size 2606.0 / train_return -100.0 / train_length 2.0 / train_episodes 1041.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5216] dataset_size 2608.0 / train_return 0.0 / train_length 2.0 / train_episodes 1042.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5220] model_loss 3.6 / model_grad_norm 7.1 / observation_loss 1.1 / reward_loss 1.2 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 34.7 / post_ent 32.5 / update_count 319.0 / fps 3.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5226] dataset_size 2613.0 / train_return -300.0 / train_length 5.0 / train_episodes 1043.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5230] dataset_size 2615.0 / train_return -100.0 / train_length 2.0 / train_episodes 1044.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5230] model_loss 3.6 / model_grad_norm 7.6 / observation_loss 1.1 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 34.6 / post_ent 32.3 / update_count 329.0 / fps 3.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5236] dataset_size 2618.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1045.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5240] dataset_size 2620.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1046.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5240] model_loss 3.6 / model_grad_norm 8.3 / observation_loss 1.1 / reward_loss 1.2 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 34.4 / post_ent 32.1 / update_count 339.0 / fps 1.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5244] dataset_size 2622.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1047.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5250] model_loss 3.5 / model_grad_norm 6.8 / observation_loss 1.1 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 34.2 / post_ent 31.8 / update_count 349.0 / fps 1.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5252] dataset_size 2626.0 / train_return -100.0 / train_length 4.0 / train_episodes 1048.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5256] dataset_size 2628.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1049.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5260] dataset_size 2630.0 / train_return -100.0 / train_length 2.0 / train_episodes 1050.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5260] model_loss 3.5 / model_grad_norm 7.5 / observation_loss 1.1 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 34.0 / post_ent 31.5 / update_count 359.0 / fps 3.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5264] dataset_size 2632.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1051.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5270] dataset_size 2635.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1052.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5270] model_loss 3.4 / model_grad_norm 6.3 / observation_loss 1.1 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 33.8 / post_ent 31.6 / update_count 369.0 / fps 4.0\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5280] model_loss 3.5 / model_grad_norm 8.0 / observation_loss 1.1 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 33.6 / post_ent 31.3 / update_count 379.0 / fps 3.5\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5282] dataset_size 2641.0 / train_return -900.0 / train_length 6.0 / train_episodes 1053.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5286] dataset_size 2643.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1054.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5290] dataset_size 2645.0 / train_return -100.0 / train_length 2.0 / train_episodes 1055.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5290] model_loss 3.4 / model_grad_norm 7.3 / observation_loss 1.0 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 33.5 / post_ent 31.1 / update_count 389.0 / fps 4.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5300] dataset_size 2650.0 / train_return 1200.0 / train_length 5.0 / train_episodes 1056.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5300] model_loss 3.4 / model_grad_norm 8.0 / observation_loss 1.0 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 33.4 / post_ent 31.0 / update_count 399.0 / fps 3.8\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5304] dataset_size 2652.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1057.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5308] dataset_size 2654.0 / train_return -100.0 / train_length 2.0 / train_episodes 1058.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5310] model_loss 3.4 / model_grad_norm 7.2 / observation_loss 1.0 / reward_loss 1.1 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 33.1 / post_ent 30.7 / update_count 409.0 / fps 4.5\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5312] dataset_size 2656.0 / train_return -100.0 / train_length 2.0 / train_episodes 1059.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5316] dataset_size 2658.0 / train_return -100.0 / train_length 2.0 / train_episodes 1060.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5320] model_loss 3.3 / model_grad_norm 7.5 / observation_loss 1.0 / reward_loss 1.0 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 33.1 / post_ent 30.6 / update_count 419.0 / fps 4.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5322] dataset_size 2661.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1061.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5328] dataset_size 2664.0 / train_return -300.0 / train_length 3.0 / train_episodes 1062.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5330] dataset_size 2665.0 / train_return -50.0 / train_length 1.0 / train_episodes 1063.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5330] model_loss 3.4 / model_grad_norm 8.7 / observation_loss 1.1 / reward_loss 1.0 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 32.9 / post_ent 30.5 / update_count 429.0 / fps 4.0\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5334] dataset_size 2667.0 / train_return -100.0 / train_length 2.0 / train_episodes 1064.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5336] dataset_size 2668.0 / train_return -50.0 / train_length 1.0 / train_episodes 1065.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5340] model_loss 3.3 / model_grad_norm 8.0 / observation_loss 1.0 / reward_loss 1.0 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 32.7 / post_ent 30.3 / update_count 439.0 / fps 2.7\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5342] dataset_size 2671.0 / train_return -100.0 / train_length 3.0 / train_episodes 1066.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5348] dataset_size 2674.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1067.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5350] model_loss 3.2 / model_grad_norm 9.0 / observation_loss 1.0 / reward_loss 1.0 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 32.4 / post_ent 30.2 / update_count 449.0 / fps 3.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5352] dataset_size 2676.0 / train_return -100.0 / train_length 2.0 / train_episodes 1068.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5356] dataset_size 2678.0 / train_return -100.0 / train_length 2.0 / train_episodes 1069.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5358] dataset_size 2679.0 / train_return -50.0 / train_length 1.0 / train_episodes 1070.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5360] model_loss 3.3 / model_grad_norm 6.7 / observation_loss 1.0 / reward_loss 0.9 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 32.5 / post_ent 29.9 / update_count 459.0 / fps 4.3\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5368] dataset_size 2684.0 / train_return 900.0 / train_length 5.0 / train_episodes 1071.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5370] dataset_size 2685.0 / train_return -50.0 / train_length 1.0 / train_episodes 1072.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5370] model_loss 3.2 / model_grad_norm 6.5 / observation_loss 1.0 / reward_loss 0.9 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 32.1 / post_ent 29.8 / update_count 469.0 / fps 4.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5372] dataset_size 2686.0 / train_return -50.0 / train_length 1.0 / train_episodes 1073.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5380] dataset_size 2690.0 / train_return -300.0 / train_length 4.0 / train_episodes 1074.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5380] model_loss 3.1 / model_grad_norm 6.1 / observation_loss 1.0 / reward_loss 0.9 / cont_loss 0.2 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 32.1 / post_ent 29.5 / update_count 479.0 / fps 4.0\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5384] dataset_size 2692.0 / train_return -100.0 / train_length 2.0 / train_episodes 1075.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5390] model_loss 3.0 / model_grad_norm 5.6 / observation_loss 0.9 / reward_loss 0.9 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 31.9 / post_ent 29.4 / update_count 489.0 / fps 4.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5392] dataset_size 2696.0 / train_return -100.0 / train_length 4.0 / train_episodes 1076.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5394] dataset_size 2697.0 / train_return -50.0 / train_length 1.0 / train_episodes 1077.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5400] model_loss 3.0 / model_grad_norm 6.6 / observation_loss 1.0 / reward_loss 0.9 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 31.8 / post_ent 29.3 / update_count 499.0 / fps 4.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5402] dataset_size 2701.0 / train_return -300.0 / train_length 4.0 / train_episodes 1078.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5404] dataset_size 2702.0 / train_return -50.0 / train_length 1.0 / train_episodes 1079.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5408] dataset_size 2704.0 / train_return -100.0 / train_length 2.0 / train_episodes 1080.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5410] model_loss 3.0 / model_grad_norm 7.0 / observation_loss 0.9 / reward_loss 0.9 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 31.5 / post_ent 29.3 / update_count 509.0 / fps 3.3\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5412] dataset_size 2706.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1081.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5420] dataset_size 2710.0 / train_return -300.0 / train_length 4.0 / train_episodes 1082.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5420] model_loss 3.0 / model_grad_norm 8.3 / observation_loss 0.9 / reward_loss 0.9 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 31.4 / post_ent 28.9 / update_count 519.0 / fps 3.5\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5428] dataset_size 2714.0 / train_return -100.0 / train_length 4.0 / train_episodes 1083.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5430] model_loss 3.0 / model_grad_norm 7.5 / observation_loss 0.9 / reward_loss 0.9 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 31.1 / post_ent 28.6 / update_count 529.0 / fps 3.6\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5434] dataset_size 2717.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1084.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5440] model_loss 2.9 / model_grad_norm 6.1 / observation_loss 0.9 / reward_loss 0.8 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 31.2 / post_ent 28.7 / update_count 539.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5442] dataset_size 2721.0 / train_return -900.0 / train_length 4.0 / train_episodes 1085.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5444] dataset_size 2722.0 / train_return -50.0 / train_length 1.0 / train_episodes 1086.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5448] dataset_size 2724.0 / train_return -100.0 / train_length 2.0 / train_episodes 1087.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5450] model_loss 3.0 / model_grad_norm 7.5 / observation_loss 0.9 / reward_loss 0.8 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 31.0 / post_ent 28.5 / update_count 549.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5460] model_loss 2.9 / model_grad_norm 6.5 / observation_loss 0.9 / reward_loss 0.8 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 30.9 / post_ent 28.4 / update_count 559.0 / fps 4.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5462] dataset_size 2731.0 / train_return -900.0 / train_length 7.0 / train_episodes 1088.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5468] dataset_size 2734.0 / train_return 0.0 / train_length 3.0 / train_episodes 1089.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5470] model_loss 2.9 / model_grad_norm 7.2 / observation_loss 0.9 / reward_loss 0.8 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 31.0 / post_ent 28.3 / update_count 569.0 / fps 3.3\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5472] dataset_size 2736.0 / train_return 0.0 / train_length 2.0 / train_episodes 1090.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5474] dataset_size 2737.0 / train_return -50.0 / train_length 1.0 / train_episodes 1091.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5476] dataset_size 2738.0 / train_return -50.0 / train_length 1.0 / train_episodes 1092.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5480] dataset_size 2740.0 / train_return -100.0 / train_length 2.0 / train_episodes 1093.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5480] model_loss 2.9 / model_grad_norm 7.1 / observation_loss 0.9 / reward_loss 0.8 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 30.6 / post_ent 28.1 / update_count 579.0 / fps 2.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5482] dataset_size 2741.0 / train_return -50.0 / train_length 1.0 / train_episodes 1094.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5484] dataset_size 2742.0 / train_return -50.0 / train_length 1.0 / train_episodes 1095.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5488] dataset_size 2744.0 / train_return -100.0 / train_length 2.0 / train_episodes 1096.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5490] model_loss 2.9 / model_grad_norm 7.1 / observation_loss 0.9 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 30.6 / post_ent 27.9 / update_count 589.0 / fps 2.3\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5496] dataset_size 2748.0 / train_return -100.0 / train_length 4.0 / train_episodes 1097.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5500] dataset_size 2750.0 / train_return -100.0 / train_length 2.0 / train_episodes 1098.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5500] model_loss 2.9 / model_grad_norm 8.1 / observation_loss 0.9 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.9 / prior_ent 30.5 / post_ent 27.7 / update_count 599.0 / fps 2.9\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5510] dataset_size 2755.0 / train_return 1200.0 / train_length 5.0 / train_episodes 1099.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5510] model_loss 2.8 / model_grad_norm 9.7 / observation_loss 0.9 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 30.2 / post_ent 27.6 / update_count 609.0 / fps 3.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5516] dataset_size 2758.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1100.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5518] dataset_size 2759.0 / train_return -50.0 / train_length 1.0 / train_episodes 1101.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5520] model_loss 2.8 / model_grad_norm 7.7 / observation_loss 0.9 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 30.2 / post_ent 27.3 / update_count 619.0 / fps 3.5\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5522] dataset_size 2761.0 / train_return -100.0 / train_length 2.0 / train_episodes 1102.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5528] dataset_size 2764.0 / train_return 0.0 / train_length 3.0 / train_episodes 1103.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5530] dataset_size 2765.0 / train_return -50.0 / train_length 1.0 / train_episodes 1104.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5530] model_loss 2.7 / model_grad_norm 8.6 / observation_loss 0.8 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 30.1 / post_ent 27.3 / update_count 629.0 / fps 3.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5532] dataset_size 2766.0 / train_return -50.0 / train_length 1.0 / train_episodes 1105.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5534] dataset_size 2767.0 / train_return -50.0 / train_length 1.0 / train_episodes 1106.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5540] model_loss 2.7 / model_grad_norm 8.0 / observation_loss 0.8 / reward_loss 0.7 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 29.8 / post_ent 27.0 / update_count 639.0 / fps 3.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5542] dataset_size 2771.0 / train_return -1200.0 / train_length 4.0 / train_episodes 1107.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5548] dataset_size 2774.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1108.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5550] model_loss 2.6 / model_grad_norm 6.7 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 29.8 / post_ent 27.1 / update_count 649.0 / fps 2.6\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5554] dataset_size 2777.0 / train_return -100.0 / train_length 3.0 / train_episodes 1109.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5560] model_loss 2.6 / model_grad_norm 8.6 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.7 / prior_ent 29.6 / post_ent 26.8 / update_count 659.0 / fps 3.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5562] dataset_size 2781.0 / train_return -100.0 / train_length 4.0 / train_episodes 1110.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5566] dataset_size 2783.0 / train_return -100.0 / train_length 2.0 / train_episodes 1111.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5570] model_loss 2.6 / model_grad_norm 7.0 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 29.4 / post_ent 26.5 / update_count 669.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5572] dataset_size 2786.0 / train_return -100.0 / train_length 3.0 / train_episodes 1112.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5576] dataset_size 2788.0 / train_return -100.0 / train_length 2.0 / train_episodes 1113.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5580] dataset_size 2790.0 / train_return -100.0 / train_length 2.0 / train_episodes 1114.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5580] model_loss 2.5 / model_grad_norm 8.0 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 29.2 / post_ent 26.4 / update_count 679.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5588] dataset_size 2794.0 / train_return 0.0 / train_length 4.0 / train_episodes 1115.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5590] model_loss 2.6 / model_grad_norm 7.6 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.9 / post_ent 26.2 / update_count 689.0 / fps 3.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5594] dataset_size 2797.0 / train_return -100.0 / train_length 3.0 / train_episodes 1116.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5600] dataset_size 2800.0 / train_return -100.0 / train_length 3.0 / train_episodes 1117.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5600] model_loss 2.6 / model_grad_norm 7.8 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.9 / post_ent 26.1 / update_count 699.0 / fps 3.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5610] model_loss 2.5 / model_grad_norm 9.3 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.6 / post_ent 25.7 / update_count 709.0 / fps 3.3\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5612] dataset_size 2806.0 / train_return 0.0 / train_length 6.0 / train_episodes 1118.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5614] dataset_size 2807.0 / train_return -50.0 / train_length 1.0 / train_episodes 1119.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5620] dataset_size 2810.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1120.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5620] model_loss 2.5 / model_grad_norm 7.0 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.5 / post_ent 25.6 / update_count 719.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5628] dataset_size 2814.0 / train_return -900.0 / train_length 4.0 / train_episodes 1121.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5630] model_loss 2.4 / model_grad_norm 8.3 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 28.3 / post_ent 25.7 / update_count 729.0 / fps 3.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5632] dataset_size 2816.0 / train_return -100.0 / train_length 2.0 / train_episodes 1122.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5634] dataset_size 2817.0 / train_return -50.0 / train_length 1.0 / train_episodes 1123.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5638] dataset_size 2819.0 / train_return -100.0 / train_length 2.0 / train_episodes 1124.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5640] model_loss 2.5 / model_grad_norm 9.4 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.1 / post_ent 25.5 / update_count 739.0 / fps 4.3\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5644] dataset_size 2822.0 / train_return -300.0 / train_length 3.0 / train_episodes 1125.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5650] dataset_size 2825.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1126.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5650] model_loss 2.5 / model_grad_norm 8.0 / observation_loss 0.8 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 28.0 / post_ent 25.2 / update_count 749.0 / fps 4.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5654] dataset_size 2827.0 / train_return -100.0 / train_length 2.0 / train_episodes 1127.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5656] dataset_size 2828.0 / train_return -50.0 / train_length 1.0 / train_episodes 1128.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5660] model_loss 2.4 / model_grad_norm 7.1 / observation_loss 0.8 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 27.9 / post_ent 25.0 / update_count 759.0 / fps 3.1\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5662] dataset_size 2831.0 / train_return -100.0 / train_length 3.0 / train_episodes 1129.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5664] dataset_size 2832.0 / train_return -50.0 / train_length 1.0 / train_episodes 1130.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5670] model_loss 2.4 / model_grad_norm 7.2 / observation_loss 0.7 / reward_loss 0.6 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 27.6 / post_ent 24.9 / update_count 769.0 / fps 2.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5672] dataset_size 2836.0 / train_return -100.0 / train_length 4.0 / train_episodes 1131.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5674] dataset_size 2837.0 / train_return -50.0 / train_length 1.0 / train_episodes 1132.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5680] model_loss 2.4 / model_grad_norm 7.4 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 27.6 / post_ent 24.9 / update_count 779.0 / fps 3.2\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5686] dataset_size 2843.0 / train_return 1200.0 / train_length 6.0 / train_episodes 1133.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5690] model_loss 2.4 / model_grad_norm 8.6 / observation_loss 0.8 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 27.5 / post_ent 25.0 / update_count 789.0 / fps 2.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5694] dataset_size 2847.0 / train_return -300.0 / train_length 4.0 / train_episodes 1134.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5700] model_loss 2.3 / model_grad_norm 9.0 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 27.2 / post_ent 24.8 / update_count 799.0 / fps 1.3\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5704] dataset_size 2852.0 / train_return -900.0 / train_length 5.0 / train_episodes 1135.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5706] dataset_size 2853.0 / train_return -50.0 / train_length 1.0 / train_episodes 1136.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5710] model_loss 2.3 / model_grad_norm 8.8 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 27.2 / post_ent 24.6 / update_count 809.0 / fps 3.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5714] dataset_size 2857.0 / train_return 1200.0 / train_length 4.0 / train_episodes 1137.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5718] dataset_size 2859.0 / train_return -100.0 / train_length 2.0 / train_episodes 1138.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5720] model_loss 2.3 / model_grad_norm 9.9 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 27.0 / post_ent 24.5 / update_count 819.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5722] dataset_size 2861.0 / train_return 0.0 / train_length 2.0 / train_episodes 1139.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5726] dataset_size 2863.0 / train_return -100.0 / train_length 2.0 / train_episodes 1140.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5728] dataset_size 2864.0 / train_return -50.0 / train_length 1.0 / train_episodes 1141.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5730] model_loss 2.3 / model_grad_norm 9.8 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.1 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.9 / post_ent 24.2 / update_count 829.0 / fps 3.3\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5734] dataset_size 2867.0 / train_return -100.0 / train_length 3.0 / train_episodes 1142.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5740] dataset_size 2870.0 / train_return -100.0 / train_length 3.0 / train_episodes 1143.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5740] model_loss 2.3 / model_grad_norm 8.3 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.8 / post_ent 24.0 / update_count 839.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5744] dataset_size 2872.0 / train_return -100.0 / train_length 2.0 / train_episodes 1144.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5750] model_loss 2.3 / model_grad_norm 8.3 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.5 / post_ent 24.1 / update_count 849.0 / fps 4.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5752] dataset_size 2876.0 / train_return -900.0 / train_length 4.0 / train_episodes 1145.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5760] dataset_size 2880.0 / train_return -300.0 / train_length 4.0 / train_episodes 1146.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5760] model_loss 2.2 / model_grad_norm 7.8 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.5 / post_ent 23.9 / update_count 859.0 / fps 3.8\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5764] dataset_size 2882.0 / train_return -100.0 / train_length 2.0 / train_episodes 1147.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5768] dataset_size 2884.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1148.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5770] dataset_size 2885.0 / train_return -50.0 / train_length 1.0 / train_episodes 1149.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5770] model_loss 2.2 / model_grad_norm 8.2 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.3 / post_ent 23.8 / update_count 869.0 / fps 3.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5772] dataset_size 2886.0 / train_return -50.0 / train_length 1.0 / train_episodes 1150.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5778] dataset_size 2889.0 / train_return -100.0 / train_length 3.0 / train_episodes 1151.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5780] dataset_size 2890.0 / train_return -50.0 / train_length 1.0 / train_episodes 1152.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5780] model_loss 2.2 / model_grad_norm 8.8 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.3 / post_ent 23.8 / update_count 879.0 / fps 3.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5784] dataset_size 2892.0 / train_return -100.0 / train_length 2.0 / train_episodes 1153.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5788] dataset_size 2894.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1154.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5790] dataset_size 2895.0 / train_return -50.0 / train_length 1.0 / train_episodes 1155.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5790] model_loss 2.2 / model_grad_norm 8.0 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.2 / post_ent 23.6 / update_count 889.0 / fps 3.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5792] dataset_size 2896.0 / train_return -50.0 / train_length 1.0 / train_episodes 1156.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5798] dataset_size 2899.0 / train_return -300.0 / train_length 3.0 / train_episodes 1157.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5800] model_loss 2.3 / model_grad_norm 7.3 / observation_loss 0.7 / reward_loss 0.5 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.1 / post_ent 23.5 / update_count 899.0 / fps 3.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5802] dataset_size 2901.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1158.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5806] dataset_size 2903.0 / train_return -100.0 / train_length 2.0 / train_episodes 1159.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5810] dataset_size 2905.0 / train_return -100.0 / train_length 2.0 / train_episodes 1160.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5810] model_loss 2.1 / model_grad_norm 7.8 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.5 / prior_ent 26.1 / post_ent 23.7 / update_count 909.0 / fps 3.6\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5814] dataset_size 2907.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1161.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5820] dataset_size 2910.0 / train_return -300.0 / train_length 3.0 / train_episodes 1162.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5820] model_loss 2.2 / model_grad_norm 7.5 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 26.0 / post_ent 23.2 / update_count 919.0 / fps 3.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5824] dataset_size 2912.0 / train_return -100.0 / train_length 2.0 / train_episodes 1163.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5830] model_loss 2.2 / model_grad_norm 7.2 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 25.8 / post_ent 23.3 / update_count 929.0 / fps 2.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5834] dataset_size 2917.0 / train_return 1200.0 / train_length 5.0 / train_episodes 1164.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5840] dataset_size 2920.0 / train_return -100.0 / train_length 3.0 / train_episodes 1165.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5840] model_loss 2.2 / model_grad_norm 8.9 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 25.7 / post_ent 23.1 / update_count 939.0 / fps 1.7\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5850] dataset_size 2925.0 / train_return 1200.0 / train_length 5.0 / train_episodes 1166.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5850] model_loss 2.1 / model_grad_norm 8.4 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 25.4 / post_ent 22.9 / update_count 949.0 / fps 1.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5854] dataset_size 2927.0 / train_return -100.0 / train_length 2.0 / train_episodes 1167.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5860] model_loss 2.1 / model_grad_norm 6.5 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.5 / prior_ent 25.2 / post_ent 22.8 / update_count 959.0 / fps 3.3\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5866] dataset_size 2933.0 / train_return 1200.0 / train_length 6.0 / train_episodes 1168.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5868] dataset_size 2934.0 / train_return -50.0 / train_length 1.0 / train_episodes 1169.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5870] model_loss 2.1 / model_grad_norm 7.0 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 25.2 / post_ent 22.8 / update_count 969.0 / fps 2.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5880] model_loss 2.2 / model_grad_norm 8.1 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 25.2 / post_ent 22.8 / update_count 979.0 / fps 3.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5882] dataset_size 2941.0 / train_return -900.0 / train_length 7.0 / train_episodes 1170.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5884] dataset_size 2942.0 / train_return -50.0 / train_length 1.0 / train_episodes 1171.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5888] dataset_size 2944.0 / train_return -100.0 / train_length 2.0 / train_episodes 1172.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5890] model_loss 2.1 / model_grad_norm 7.7 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 25.0 / post_ent 22.6 / update_count 989.0 / fps 2.3\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5898] dataset_size 2949.0 / train_return -900.0 / train_length 5.0 / train_episodes 1173.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5900] model_loss 2.2 / model_grad_norm 8.6 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 24.9 / post_ent 22.6 / update_count 999.0 / fps 2.8\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5902] dataset_size 2951.0 / train_return -100.0 / train_length 2.0 / train_episodes 1174.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5904] dataset_size 2952.0 / train_return -50.0 / train_length 1.0 / train_episodes 1175.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5910] model_loss 2.1 / model_grad_norm 8.9 / observation_loss 0.7 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 24.9 / post_ent 22.4 / update_count 1009.0 / fps 3.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5912] dataset_size 2956.0 / train_return -300.0 / train_length 4.0 / train_episodes 1176.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5920] dataset_size 2960.0 / train_return -300.0 / train_length 4.0 / train_episodes 1177.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5920] model_loss 2.2 / model_grad_norm 10.0 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 24.7 / post_ent 22.2 / update_count 1019.0 / fps 2.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5922] dataset_size 2961.0 / train_return -50.0 / train_length 1.0 / train_episodes 1178.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5930] model_loss 2.1 / model_grad_norm 10.5 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 24.6 / post_ent 22.1 / update_count 1029.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5932] dataset_size 2966.0 / train_return -300.0 / train_length 5.0 / train_episodes 1179.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5940] model_loss 2.1 / model_grad_norm 7.6 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 24.4 / post_ent 22.0 / update_count 1039.0 / fps 2.6\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5942] dataset_size 2971.0 / train_return -1200.0 / train_length 5.0 / train_episodes 1180.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5950] model_loss 2.0 / model_grad_norm 7.7 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 24.3 / post_ent 22.0 / update_count 1049.0 / fps 3.8\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5952] dataset_size 2976.0 / train_return -1200.0 / train_length 5.0 / train_episodes 1181.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5958] dataset_size 2979.0 / train_return -100.0 / train_length 3.0 / train_episodes 1182.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5960] dataset_size 2980.0 / train_return -50.0 / train_length 1.0 / train_episodes 1183.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5960] model_loss 2.1 / model_grad_norm 7.2 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 24.3 / post_ent 21.8 / update_count 1059.0 / fps 2.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5968] dataset_size 2984.0 / train_return -300.0 / train_length 4.0 / train_episodes 1184.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5970] model_loss 2.0 / model_grad_norm 7.3 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.5 / prior_ent 24.2 / post_ent 21.8 / update_count 1069.0 / fps 2.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5972] dataset_size 2986.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1185.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5974] dataset_size 2987.0 / train_return -50.0 / train_length 1.0 / train_episodes 1186.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5978] dataset_size 2989.0 / train_return -100.0 / train_length 2.0 / train_episodes 1187.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5980] model_loss 2.0 / model_grad_norm 6.8 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 24.1 / post_ent 21.7 / update_count 1079.0 / fps 4.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5990] dataset_size 2995.0 / train_return 1200.0 / train_length 6.0 / train_episodes 1188.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[5990] model_loss 2.0 / model_grad_norm 6.8 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 23.9 / post_ent 21.3 / update_count 1089.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[5996] dataset_size 2998.0 / train_return -300.0 / train_length 3.0 / train_episodes 1189.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[5998] dataset_size 2999.0 / train_return -50.0 / train_length 1.0 / train_episodes 1190.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6000] model_loss 2.0 / model_grad_norm 8.5 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 23.8 / post_ent 21.4 / update_count 1099.0 / fps 4.0\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6004] dataset_size 3002.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1191.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6008] dataset_size 3004.0 / train_return 0.0 / train_length 2.0 / train_episodes 1192.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6010] model_loss 2.0 / model_grad_norm 6.9 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 23.7 / post_ent 21.4 / update_count 1109.0 / fps 3.4\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6016] dataset_size 3008.0 / train_return -300.0 / train_length 4.0 / train_episodes 1193.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6020] model_loss 2.0 / model_grad_norm 6.0 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.6 / prior_ent 23.6 / post_ent 21.4 / update_count 1119.0 / fps 3.9\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6022] dataset_size 3011.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1194.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6030] dataset_size 3015.0 / train_return -1200.0 / train_length 4.0 / train_episodes 1195.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6030] model_loss 2.1 / model_grad_norm 8.7 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 23.6 / post_ent 21.3 / update_count 1129.0 / fps 3.4\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6040] dataset_size 3020.0 / train_return -300.0 / train_length 5.0 / train_episodes 1196.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6040] model_loss 2.0 / model_grad_norm 7.1 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 23.3 / post_ent 21.1 / update_count 1139.0 / fps 3.0\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6046] dataset_size 3023.0 / train_return 0.0 / train_length 3.0 / train_episodes 1197.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6050] model_loss 2.0 / model_grad_norm 6.1 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.6 / prior_ent 23.1 / post_ent 21.1 / update_count 1149.0 / fps 1.5\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6052] dataset_size 3026.0 / train_return -100.0 / train_length 3.0 / train_episodes 1198.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6058] dataset_size 3029.0 / train_return -100.0 / train_length 3.0 / train_episodes 1199.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6060] model_loss 2.0 / model_grad_norm 7.6 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 23.4 / post_ent 21.2 / update_count 1159.0 / fps 3.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6066] dataset_size 3033.0 / train_return 900.0 / train_length 4.0 / train_episodes 1200.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6070] model_loss 2.0 / model_grad_norm 6.7 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 23.2 / post_ent 20.9 / update_count 1169.0 / fps 3.4\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6076] dataset_size 3038.0 / train_return -900.0 / train_length 5.0 / train_episodes 1201.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6080] model_loss 2.0 / model_grad_norm 6.0 / observation_loss 0.6 / reward_loss 0.4 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 23.0 / post_ent 20.8 / update_count 1179.0 / fps 4.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6084] dataset_size 3042.0 / train_return -300.0 / train_length 4.0 / train_episodes 1202.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6086] dataset_size 3043.0 / train_return -50.0 / train_length 1.0 / train_episodes 1203.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6090] model_loss 2.0 / model_grad_norm 7.8 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 23.0 / post_ent 20.7 / update_count 1189.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6092] dataset_size 3046.0 / train_return -300.0 / train_length 3.0 / train_episodes 1204.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6096] dataset_size 3048.0 / train_return -100.0 / train_length 2.0 / train_episodes 1205.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6100] dataset_size 3050.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1206.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6100] model_loss 2.0 / model_grad_norm 7.1 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 22.8 / post_ent 20.5 / update_count 1199.0 / fps 4.1\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6104] dataset_size 3052.0 / train_return -100.0 / train_length 2.0 / train_episodes 1207.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6110] dataset_size 3055.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1208.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6110] model_loss 2.0 / model_grad_norm 8.0 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.7 / post_ent 20.6 / update_count 1209.0 / fps 3.4\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6116] dataset_size 3058.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1209.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6120] dataset_size 3060.0 / train_return -100.0 / train_length 2.0 / train_episodes 1210.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6120] model_loss 2.0 / model_grad_norm 8.0 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.7 / post_ent 20.4 / update_count 1219.0 / fps 3.7\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6124] dataset_size 3062.0 / train_return 0.0 / train_length 2.0 / train_episodes 1211.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6130] model_loss 2.0 / model_grad_norm 7.8 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 22.6 / post_ent 20.4 / update_count 1229.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6132] dataset_size 3066.0 / train_return -300.0 / train_length 4.0 / train_episodes 1212.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6138] dataset_size 3069.0 / train_return -100.0 / train_length 3.0 / train_episodes 1213.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6140] model_loss 2.0 / model_grad_norm 7.9 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.7 / post_ent 20.3 / update_count 1239.0 / fps 3.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6142] dataset_size 3071.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1214.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6144] dataset_size 3072.0 / train_return -50.0 / train_length 1.0 / train_episodes 1215.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6148] dataset_size 3074.0 / train_return -100.0 / train_length 2.0 / train_episodes 1216.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6150] dataset_size 3075.0 / train_return -50.0 / train_length 1.0 / train_episodes 1217.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6150] model_loss 2.0 / model_grad_norm 7.3 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 22.5 / post_ent 20.2 / update_count 1249.0 / fps 4.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6154] dataset_size 3077.0 / train_return -100.0 / train_length 2.0 / train_episodes 1218.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6158] dataset_size 3079.0 / train_return -100.0 / train_length 2.0 / train_episodes 1219.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6160] model_loss 2.0 / model_grad_norm 7.2 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.4 / post_ent 20.3 / update_count 1259.0 / fps 4.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6164] dataset_size 3082.0 / train_return -100.0 / train_length 3.0 / train_episodes 1220.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6170] dataset_size 3085.0 / train_return -300.0 / train_length 3.0 / train_episodes 1221.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6170] model_loss 2.0 / model_grad_norm 11.1 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 22.4 / post_ent 20.1 / update_count 1269.0 / fps 4.5\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6176] dataset_size 3088.0 / train_return -100.0 / train_length 3.0 / train_episodes 1222.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6178] dataset_size 3089.0 / train_return -50.0 / train_length 1.0 / train_episodes 1223.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6180] model_loss 2.1 / model_grad_norm 14.9 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 22.2 / post_ent 20.1 / update_count 1279.0 / fps 3.7\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6184] dataset_size 3092.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1224.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6186] dataset_size 3093.0 / train_return -50.0 / train_length 1.0 / train_episodes 1225.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6190] model_loss 2.0 / model_grad_norm 9.0 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.2 / post_ent 19.9 / update_count 1289.0 / fps 4.8\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6194] dataset_size 3097.0 / train_return 0.0 / train_length 4.0 / train_episodes 1226.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6198] dataset_size 3099.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1227.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6200] model_loss 1.9 / model_grad_norm 7.7 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.2 / post_ent 20.1 / update_count 1299.0 / fps 3.8\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6206] dataset_size 3103.0 / train_return -300.0 / train_length 4.0 / train_episodes 1228.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6210] model_loss 1.9 / model_grad_norm 6.8 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 22.1 / post_ent 19.9 / update_count 1309.0 / fps 2.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6212] dataset_size 3106.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1229.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6216] dataset_size 3108.0 / train_return -100.0 / train_length 2.0 / train_episodes 1230.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6218] dataset_size 3109.0 / train_return -50.0 / train_length 1.0 / train_episodes 1231.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6220] model_loss 1.9 / model_grad_norm 7.2 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 21.8 / post_ent 19.8 / update_count 1319.0 / fps 1.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6226] dataset_size 3113.0 / train_return -300.0 / train_length 4.0 / train_episodes 1232.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6228] dataset_size 3114.0 / train_return -50.0 / train_length 1.0 / train_episodes 1233.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6230] dataset_size 3115.0 / train_return -50.0 / train_length 1.0 / train_episodes 1234.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6230] model_loss 1.9 / model_grad_norm 5.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 21.8 / post_ent 19.7 / update_count 1329.0 / fps 3.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6234] dataset_size 3117.0 / train_return -100.0 / train_length 2.0 / train_episodes 1235.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6240] model_loss 1.9 / model_grad_norm 6.9 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 22.0 / post_ent 19.8 / update_count 1339.0 / fps 4.0\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6242] dataset_size 3121.0 / train_return 100.0 / train_length 4.0 / train_episodes 1236.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6244] dataset_size 3122.0 / train_return -50.0 / train_length 1.0 / train_episodes 1237.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6246] dataset_size 3123.0 / train_return -50.0 / train_length 1.0 / train_episodes 1238.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6250] model_loss 1.9 / model_grad_norm 7.5 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.9 / post_ent 19.7 / update_count 1349.0 / fps 4.1\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6252] dataset_size 3126.0 / train_return -300.0 / train_length 3.0 / train_episodes 1239.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6256] dataset_size 3128.0 / train_return -100.0 / train_length 2.0 / train_episodes 1240.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6260] dataset_size 3130.0 / train_return -100.0 / train_length 2.0 / train_episodes 1241.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6260] model_loss 1.8 / model_grad_norm 7.0 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 21.6 / post_ent 19.6 / update_count 1359.0 / fps 3.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6262] dataset_size 3131.0 / train_return -50.0 / train_length 1.0 / train_episodes 1242.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6268] dataset_size 3134.0 / train_return -100.0 / train_length 3.0 / train_episodes 1243.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6270] model_loss 1.9 / model_grad_norm 6.3 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 21.6 / post_ent 19.7 / update_count 1369.0 / fps 3.4\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6272] dataset_size 3136.0 / train_return -100.0 / train_length 2.0 / train_episodes 1244.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6280] dataset_size 3140.0 / train_return -1200.0 / train_length 4.0 / train_episodes 1245.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6280] model_loss 2.0 / model_grad_norm 6.8 / observation_loss 0.6 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 21.8 / post_ent 19.6 / update_count 1379.0 / fps 3.9\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6286] dataset_size 3143.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1246.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6290] model_loss 1.9 / model_grad_norm 7.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.6 / post_ent 19.4 / update_count 1389.0 / fps 4.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6292] dataset_size 3146.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1247.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6296] dataset_size 3148.0 / train_return -100.0 / train_length 2.0 / train_episodes 1248.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6298] dataset_size 3149.0 / train_return -50.0 / train_length 1.0 / train_episodes 1249.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6300] dataset_size 3150.0 / train_return -50.0 / train_length 1.0 / train_episodes 1250.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6300] model_loss 1.9 / model_grad_norm 7.9 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.5 / post_ent 19.5 / update_count 1399.0 / fps 4.1\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6304] dataset_size 3152.0 / train_return -100.0 / train_length 2.0 / train_episodes 1251.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6310] dataset_size 3155.0 / train_return -300.0 / train_length 3.0 / train_episodes 1252.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6310] model_loss 1.9 / model_grad_norm 7.1 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.4 / post_ent 19.2 / update_count 1409.0 / fps 3.7\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6312] dataset_size 3156.0 / train_return -50.0 / train_length 1.0 / train_episodes 1253.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6320] dataset_size 3160.0 / train_return -1200.0 / train_length 4.0 / train_episodes 1254.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6320] model_loss 1.8 / model_grad_norm 6.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 21.3 / post_ent 19.2 / update_count 1419.0 / fps 2.9\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6328] dataset_size 3164.0 / train_return -300.0 / train_length 4.0 / train_episodes 1255.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6330] dataset_size 3165.0 / train_return -50.0 / train_length 1.0 / train_episodes 1256.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6330] model_loss 1.9 / model_grad_norm 5.8 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 21.3 / post_ent 19.3 / update_count 1429.0 / fps 4.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6340] dataset_size 3170.0 / train_return -300.0 / train_length 5.0 / train_episodes 1257.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6340] model_loss 1.9 / model_grad_norm 6.8 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.3 / post_ent 19.1 / update_count 1439.0 / fps 3.9\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6350] model_loss 1.9 / model_grad_norm 8.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.3 / post_ent 19.2 / update_count 1449.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6352] dataset_size 3176.0 / train_return -900.0 / train_length 6.0 / train_episodes 1258.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6360] model_loss 1.9 / model_grad_norm 9.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 21.1 / post_ent 19.0 / update_count 1459.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6362] dataset_size 3181.0 / train_return -300.0 / train_length 5.0 / train_episodes 1259.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6368] dataset_size 3184.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1260.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6370] model_loss 1.9 / model_grad_norm 9.9 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 21.0 / post_ent 18.9 / update_count 1469.0 / fps 4.2\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6374] dataset_size 3187.0 / train_return -100.0 / train_length 3.0 / train_episodes 1261.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6378] dataset_size 3189.0 / train_return -100.0 / train_length 2.0 / train_episodes 1262.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6380] dataset_size 3190.0 / train_return -50.0 / train_length 1.0 / train_episodes 1263.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6380] model_loss 1.9 / model_grad_norm 7.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 21.0 / post_ent 18.9 / update_count 1479.0 / fps 3.9\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6382] dataset_size 3191.0 / train_return -50.0 / train_length 1.0 / train_episodes 1264.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6384] dataset_size 3192.0 / train_return -50.0 / train_length 1.0 / train_episodes 1265.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6386] dataset_size 3193.0 / train_return -50.0 / train_length 1.0 / train_episodes 1266.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6390] model_loss 1.9 / model_grad_norm 6.5 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.9 / rep_loss 1.9 / kl 1.8 / prior_ent 21.1 / post_ent 18.9 / update_count 1489.0 / fps 4.2\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6392] dataset_size 3196.0 / train_return -300.0 / train_length 3.0 / train_episodes 1267.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6400] model_loss 1.9 / model_grad_norm 6.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.9 / post_ent 18.8 / update_count 1499.0 / fps 4.0\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6402] dataset_size 3201.0 / train_return -900.0 / train_length 5.0 / train_episodes 1268.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6408] dataset_size 3204.0 / train_return -100.0 / train_length 3.0 / train_episodes 1269.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6410] dataset_size 3205.0 / train_return -50.0 / train_length 1.0 / train_episodes 1270.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6410] model_loss 1.8 / model_grad_norm 5.8 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.7 / post_ent 18.8 / update_count 1509.0 / fps 4.4\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6420] dataset_size 3210.0 / train_return -1200.0 / train_length 5.0 / train_episodes 1271.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6420] model_loss 1.9 / model_grad_norm 7.3 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.8 / post_ent 18.7 / update_count 1519.0 / fps 4.7\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6424] dataset_size 3212.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1272.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6428] dataset_size 3214.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1273.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6430] model_loss 1.8 / model_grad_norm 7.4 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.8 / post_ent 18.7 / update_count 1529.0 / fps 4.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6432] dataset_size 3216.0 / train_return -100.0 / train_length 2.0 / train_episodes 1274.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6434] dataset_size 3217.0 / train_return -50.0 / train_length 1.0 / train_episodes 1275.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6438] dataset_size 3219.0 / train_return -100.0 / train_length 2.0 / train_episodes 1276.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6440] dataset_size 3220.0 / train_return -50.0 / train_length 1.0 / train_episodes 1277.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6440] model_loss 1.8 / model_grad_norm 7.2 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.7 / post_ent 18.6 / update_count 1539.0 / fps 1.3\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6442] dataset_size 3221.0 / train_return -50.0 / train_length 1.0 / train_episodes 1278.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6448] dataset_size 3224.0 / train_return -300.0 / train_length 3.0 / train_episodes 1279.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6450] model_loss 1.9 / model_grad_norm 6.1 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 20.6 / post_ent 18.5 / update_count 1549.0 / fps 2.5\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6458] dataset_size 3229.0 / train_return -100.0 / train_length 5.0 / train_episodes 1280.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6460] model_loss 1.8 / model_grad_norm 5.4 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.6 / rep_loss 1.6 / kl 1.6 / prior_ent 20.6 / post_ent 18.6 / update_count 1559.0 / fps 3.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6468] dataset_size 3234.0 / train_return -300.0 / train_length 5.0 / train_episodes 1281.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6470] model_loss 1.9 / model_grad_norm 6.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 20.6 / post_ent 18.6 / update_count 1569.0 / fps 3.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6472] dataset_size 3236.0 / train_return -100.0 / train_length 2.0 / train_episodes 1282.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6478] dataset_size 3239.0 / train_return -300.0 / train_length 3.0 / train_episodes 1283.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6480] model_loss 1.8 / model_grad_norm 5.9 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.6 / prior_ent 20.6 / post_ent 18.4 / update_count 1579.0 / fps 3.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6482] dataset_size 3241.0 / train_return -100.0 / train_length 2.0 / train_episodes 1284.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6490] dataset_size 3245.0 / train_return -300.0 / train_length 4.0 / train_episodes 1285.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6490] model_loss 1.8 / model_grad_norm 5.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.3 / post_ent 18.5 / update_count 1589.0 / fps 3.6\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6500] model_loss 1.8 / model_grad_norm 6.1 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.4 / post_ent 18.4 / update_count 1599.0 / fps 3.2\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6502] dataset_size 3251.0 / train_return 1200.0 / train_length 6.0 / train_episodes 1286.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6510] dataset_size 3255.0 / train_return 900.0 / train_length 4.0 / train_episodes 1287.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6510] model_loss 1.8 / model_grad_norm 7.0 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 20.5 / post_ent 18.3 / update_count 1609.0 / fps 3.4\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6520] model_loss 1.8 / model_grad_norm 6.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.3 / post_ent 18.3 / update_count 1619.0 / fps 2.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6522] dataset_size 3261.0 / train_return -300.0 / train_length 6.0 / train_episodes 1288.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6526] dataset_size 3263.0 / train_return -100.0 / train_length 2.0 / train_episodes 1289.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6530] model_loss 1.8 / model_grad_norm 5.8 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.4 / post_ent 18.3 / update_count 1629.0 / fps 3.4\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6536] dataset_size 3268.0 / train_return -300.0 / train_length 5.0 / train_episodes 1290.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6540] dataset_size 3270.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1291.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6540] model_loss 1.8 / model_grad_norm 5.0 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.2 / post_ent 18.2 / update_count 1639.0 / fps 2.6\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6546] dataset_size 3273.0 / train_return -100.0 / train_length 3.0 / train_episodes 1292.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6550] model_loss 1.8 / model_grad_norm 5.8 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.2 / post_ent 18.3 / update_count 1649.0 / fps 3.3\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6552] dataset_size 3276.0 / train_return -100.0 / train_length 3.0 / train_episodes 1293.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6560] dataset_size 3280.0 / train_return -900.0 / train_length 4.0 / train_episodes 1294.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6560] model_loss 1.8 / model_grad_norm 5.7 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 20.1 / post_ent 18.2 / update_count 1659.0 / fps 3.2\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6564] dataset_size 3282.0 / train_return -100.0 / train_length 2.0 / train_episodes 1295.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6566] dataset_size 3283.0 / train_return -50.0 / train_length 1.0 / train_episodes 1296.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6570] model_loss 1.8 / model_grad_norm 5.6 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.1 / post_ent 18.0 / update_count 1669.0 / fps 3.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6572] dataset_size 3286.0 / train_return 1200.0 / train_length 3.0 / train_episodes 1297.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6580] dataset_size 3290.0 / train_return -300.0 / train_length 4.0 / train_episodes 1298.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6580] model_loss 1.8 / model_grad_norm 5.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 20.0 / post_ent 18.1 / update_count 1679.0 / fps 3.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6584] dataset_size 3292.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1299.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6588] dataset_size 3294.0 / train_return -100.0 / train_length 2.0 / train_episodes 1300.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6590] model_loss 1.8 / model_grad_norm 6.8 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 19.9 / post_ent 18.0 / update_count 1689.0 / fps 3.6\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6596] dataset_size 3298.0 / train_return -300.0 / train_length 4.0 / train_episodes 1301.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6600] model_loss 1.8 / model_grad_norm 5.6 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.9 / post_ent 17.8 / update_count 1699.0 / fps 3.5\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6608] dataset_size 3304.0 / train_return -900.0 / train_length 6.0 / train_episodes 1302.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6610] dataset_size 3305.0 / train_return -50.0 / train_length 1.0 / train_episodes 1303.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6610] model_loss 1.8 / model_grad_norm 7.4 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 20.0 / post_ent 17.9 / update_count 1709.0 / fps 2.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6612] dataset_size 3306.0 / train_return -50.0 / train_length 1.0 / train_episodes 1304.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6620] model_loss 1.8 / model_grad_norm 6.6 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 20.0 / post_ent 17.9 / update_count 1719.0 / fps 2.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6622] dataset_size 3311.0 / train_return -1200.0 / train_length 5.0 / train_episodes 1305.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6624] dataset_size 3312.0 / train_return -50.0 / train_length 1.0 / train_episodes 1306.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6626] dataset_size 3313.0 / train_return -50.0 / train_length 1.0 / train_episodes 1307.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6630] dataset_size 3315.0 / train_return -100.0 / train_length 2.0 / train_episodes 1308.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6630] model_loss 1.8 / model_grad_norm 6.8 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 19.7 / post_ent 17.7 / update_count 1729.0 / fps 2.8\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6634] dataset_size 3317.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1309.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6640] model_loss 1.9 / model_grad_norm 10.0 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.6 / post_ent 17.5 / update_count 1739.0 / fps 3.0\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6642] dataset_size 3321.0 / train_return -300.0 / train_length 4.0 / train_episodes 1310.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6650] dataset_size 3325.0 / train_return -900.0 / train_length 4.0 / train_episodes 1311.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6650] model_loss 1.8 / model_grad_norm 10.7 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.6 / post_ent 17.7 / update_count 1749.0 / fps 2.2\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6656] dataset_size 3328.0 / train_return 0.0 / train_length 3.0 / train_episodes 1312.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6658] dataset_size 3329.0 / train_return -50.0 / train_length 1.0 / train_episodes 1313.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6660] dataset_size 3330.0 / train_return -50.0 / train_length 1.0 / train_episodes 1314.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6660] model_loss 1.8 / model_grad_norm 7.9 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.7 / post_ent 17.6 / update_count 1759.0 / fps 3.7\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6666] dataset_size 3333.0 / train_return -100.0 / train_length 3.0 / train_episodes 1315.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6670] model_loss 1.8 / model_grad_norm 7.3 / observation_loss 0.5 / reward_loss 0.3 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.5 / post_ent 17.6 / update_count 1769.0 / fps 3.6\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6674] dataset_size 3337.0 / train_return -300.0 / train_length 4.0 / train_episodes 1316.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6676] dataset_size 3338.0 / train_return -50.0 / train_length 1.0 / train_episodes 1317.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6678] dataset_size 3339.0 / train_return -50.0 / train_length 1.0 / train_episodes 1318.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6680] model_loss 1.8 / model_grad_norm 6.8 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.4 / post_ent 17.5 / update_count 1779.0 / fps 4.1\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6684] dataset_size 3342.0 / train_return -100.0 / train_length 3.0 / train_episodes 1319.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6686] dataset_size 3343.0 / train_return -50.0 / train_length 1.0 / train_episodes 1320.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6690] dataset_size 3345.0 / train_return 0.0 / train_length 2.0 / train_episodes 1321.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6690] model_loss 1.8 / model_grad_norm 5.4 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 19.6 / post_ent 17.5 / update_count 1789.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6694] dataset_size 3347.0 / train_return -100.0 / train_length 2.0 / train_episodes 1322.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6698] dataset_size 3349.0 / train_return -100.0 / train_length 2.0 / train_episodes 1323.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6700] model_loss 1.8 / model_grad_norm 6.1 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.4 / post_ent 17.5 / update_count 1799.0 / fps 4.4\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6704] dataset_size 3352.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1324.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6708] dataset_size 3354.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1325.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6710] model_loss 1.8 / model_grad_norm 6.0 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.5 / post_ent 17.5 / update_count 1809.0 / fps 3.6\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6712] dataset_size 3356.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1326.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6714] dataset_size 3357.0 / train_return -50.0 / train_length 1.0 / train_episodes 1327.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6720] dataset_size 3360.0 / train_return -300.0 / train_length 3.0 / train_episodes 1328.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6720] model_loss 1.8 / model_grad_norm 5.9 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 19.5 / post_ent 17.4 / update_count 1819.0 / fps 4.2\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6726] dataset_size 3363.0 / train_return 0.0 / train_length 3.0 / train_episodes 1329.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6730] dataset_size 3365.0 / train_return -100.0 / train_length 2.0 / train_episodes 1330.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6730] model_loss 1.7 / model_grad_norm 6.3 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 19.3 / post_ent 17.5 / update_count 1829.0 / fps 3.9\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6740] dataset_size 3370.0 / train_return 0.0 / train_length 5.0 / train_episodes 1331.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6740] model_loss 1.8 / model_grad_norm 5.3 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.4 / post_ent 17.4 / update_count 1839.0 / fps 3.7\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6746] dataset_size 3373.0 / train_return -1200.0 / train_length 3.0 / train_episodes 1332.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6750] model_loss 1.7 / model_grad_norm 6.3 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 19.3 / post_ent 17.3 / update_count 1849.0 / fps 3.1\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6752] dataset_size 3376.0 / train_return 0.0 / train_length 3.0 / train_episodes 1333.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6760] dataset_size 3380.0 / train_return -300.0 / train_length 4.0 / train_episodes 1334.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6760] model_loss 1.8 / model_grad_norm 5.8 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 19.2 / post_ent 17.2 / update_count 1859.0 / fps 4.4\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6766] dataset_size 3383.0 / train_return -100.0 / train_length 3.0 / train_episodes 1335.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6770] dataset_size 3385.0 / train_return 1200.0 / train_length 2.0 / train_episodes 1336.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6770] model_loss 1.8 / model_grad_norm 5.6 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 19.0 / post_ent 17.2 / update_count 1869.0 / fps 4.1\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6774] dataset_size 3387.0 / train_return -1200.0 / train_length 2.0 / train_episodes 1337.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6778] dataset_size 3389.0 / train_return -100.0 / train_length 2.0 / train_episodes 1338.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6780] dataset_size 3390.0 / train_return -50.0 / train_length 1.0 / train_episodes 1339.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6780] model_loss 1.8 / model_grad_norm 6.1 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.7 / prior_ent 19.1 / post_ent 17.3 / update_count 1879.0 / fps 3.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6784] dataset_size 3392.0 / train_return -100.0 / train_length 2.0 / train_episodes 1340.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "[6790] dataset_size 3395.0 / train_return -300.0 / train_length 3.0 / train_episodes 1341.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6790] model_loss 1.8 / model_grad_norm 6.4 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 19.3 / post_ent 17.2 / update_count 1889.0 / fps 3.8\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6792] dataset_size 3396.0 / train_return -50.0 / train_length 1.0 / train_episodes 1342.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6794] dataset_size 3397.0 / train_return -50.0 / train_length 1.0 / train_episodes 1343.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6800] model_loss 1.7 / model_grad_norm 5.4 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.7 / rep_loss 1.7 / kl 1.7 / prior_ent 19.1 / post_ent 17.1 / update_count 1899.0 / fps 3.6\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "[6804] dataset_size 3402.0 / train_return -300.0 / train_length 5.0 / train_episodes 1344.0\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 1., 0., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "tensor([[0., 0., 1., 0.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n",
      "[6810] model_loss 1.8 / model_grad_norm 6.2 / observation_loss 0.5 / reward_loss 0.2 / cont_loss 0.0 / kl_free 1.0 / dyn_scale 0.5 / rep_scale 0.1 / dyn_loss 1.8 / rep_loss 1.8 / kl 1.8 / prior_ent 18.9 / post_ent 17.1 / update_count 1909.0 / fps 2.9\n",
      "tensor([[0., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "iter:  0\n",
      "dreamer train step:\n",
      "iter:  1\n",
      "dreamer train step:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(\"Number of training envs: \", len(train_envs))\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(train_envs[0].observation_space)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent step: \u001b[39m\u001b[38;5;124m\"\u001b[39m, agent\u001b[38;5;241m.\u001b[39m_step)\n\u001b[0;32m---> 41\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraindir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m items_to_save \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: agent\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptims_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: recursively_collect_optim_state_dict(agent),\n\u001b[1;32m     54\u001b[0m }\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(items_to_save, logdir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 168\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(agent, envs, cache, directory, logger, is_eval, limit, steps, episodes, state)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# step agents\u001b[39;00m\n\u001b[1;32m    167\u001b[0m obs \u001b[38;5;241m=\u001b[39m {k: np\u001b[38;5;241m.\u001b[39mstack([o[k] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obs]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k}\n\u001b[0;32m--> 168\u001b[0m action, agent_state \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    170\u001b[0m     action \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    171\u001b[0m         {k: np\u001b[38;5;241m.\u001b[39marray(action[k][i]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m action}\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(envs))\n\u001b[1;32m    173\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[13], line 56\u001b[0m, in \u001b[0;36mDreamer.__call__\u001b[0;34m(self, obs, reset, state, training)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter: \u001b[39m\u001b[38;5;124m\"\u001b[39m, _)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count\n",
      "Cell \u001b[0;32mIn[13], line 104\u001b[0m, in \u001b[0;36mDreamer._train\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# print(\"data shape: \", data[\"image\"].shape)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 104\u001b[0m post, context, mets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(mets)\n\u001b[1;32m    106\u001b[0m start \u001b[38;5;241m=\u001b[39m post\n",
      "Cell \u001b[0;32mIn[12], line 113\u001b[0m, in \u001b[0;36mWorldModel._train\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_amp):\n\u001b[1;32m    112\u001b[0m     embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(data)\n\u001b[0;32m--> 113\u001b[0m     post, prior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_first\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     kl_free \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mkl_free\n\u001b[1;32m    117\u001b[0m     dyn_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdyn_scale\n",
      "Cell \u001b[0;32mIn[11], line 130\u001b[0m, in \u001b[0;36mRSSM.observe\u001b[0;34m(self, embed, action, is_first, state)\u001b[0m\n\u001b[1;32m    128\u001b[0m embed, action, is_first \u001b[38;5;241m=\u001b[39m swap(embed), swap(action), swap(is_first)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m post, prior \u001b[38;5;241m=\u001b[39m \u001b[43mstatic_scan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m post \u001b[38;5;241m=\u001b[39m {k: swap(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m post\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[5], line 801\u001b[0m, in \u001b[0;36mstatic_scan\u001b[0;34m(fn, inputs, start)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[1;32m    800\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (_input[x] \u001b[38;5;28;01mfor\u001b[39;00m _input \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m--> 801\u001b[0m     last \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(last) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m({}):\n",
      "Cell \u001b[0;32mIn[11], line 131\u001b[0m, in \u001b[0;36mRSSM.observe.<locals>.<lambda>\u001b[0;34m(prev_state, prev_act, embed, is_first)\u001b[0m\n\u001b[1;32m    128\u001b[0m embed, action, is_first \u001b[38;5;241m=\u001b[39m swap(embed), swap(action), swap(is_first)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\u001b[39;00m\n\u001b[1;32m    130\u001b[0m post, prior \u001b[38;5;241m=\u001b[39m static_scan(\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m prev_state, prev_act, embed, is_first: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_first\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    134\u001b[0m     (action, embed, is_first),\n\u001b[1;32m    135\u001b[0m     (state, state),\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m post \u001b[38;5;241m=\u001b[39m {k: swap(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m post\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[11], line 205\u001b[0m, in \u001b[0;36mRSSM.obs_step\u001b[0;34m(self, prev_state, prev_action, embed, is_first, sample)\u001b[0m\n\u001b[1;32m    203\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_suff_stats_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample:\n\u001b[0;32m--> 205\u001b[0m     stoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     stoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dist(stats)\u001b[38;5;241m.\u001b[39mmode()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/independent.py:104\u001b[0m, in \u001b[0;36mIndependent.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize()):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 444\u001b[0m, in \u001b[0;36mOneHotDist.sample\u001b[0;34m(self, sample_shape, seed)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to check\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 444\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    445\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprobs\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(probs\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(sample\u001b[38;5;241m.\u001b[39mshape):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/one_hot_categorical.py:98\u001b[0m, in \u001b[0;36mOneHotCategorical.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     96\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_categorical\u001b[38;5;241m.\u001b[39mprobs\n\u001b[1;32m     97\u001b[0m num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_categorical\u001b[38;5;241m.\u001b[39m_num_events\n\u001b[0;32m---> 98\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_categorical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(indices, num_events)\u001b[38;5;241m.\u001b[39mto(probs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/categorical.py:134\u001b[0m, in \u001b[0;36mCategorical.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    132\u001b[0m     sample_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\n\u001b[1;32m    133\u001b[0m probs_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events)\n\u001b[0;32m--> 134\u001b[0m samples_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples_2d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "    #     logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "    #         eval_policy = funcpartial(agent, training=False)\n",
    "    #         simulate(\n",
    "    #             eval_policy,\n",
    "    #             eval_envs,\n",
    "    #             eval_eps,\n",
    "    #             config.evaldir,\n",
    "    #             logger,\n",
    "    #             is_eval=True,\n",
    "    #             episodes=config.eval_episode_num,\n",
    "    #         )\n",
    "            # if config.video_pred_log:\n",
    "                # video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                # video_pred = agent._wm.video_pred(next(train_dataset))\n",
    "                # logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        # print(\"Number of training envs: \", len(train_envs))\n",
    "        # print(train_envs[0].observation_space)\n",
    "        print(\"Agent step: \", agent._step)\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_save = {\n",
    "    \"agent_state_dict\": agent.state_dict(),\n",
    "    \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "}\n",
    "torch.save(items_to_save, logdir / \"latest.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gym\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "\n",
    "class TimeLimit(gym.Wrapper):\n",
    "    def __init__(self, env, duration):\n",
    "        super().__init__(env)\n",
    "        self._duration = duration\n",
    "        self._step = None\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self._step is not None, \"Must reset environment.\"\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self._step += 1\n",
    "        if self._step >= self._duration:\n",
    "            done = True\n",
    "            if \"discount\" not in info:\n",
    "                info[\"discount\"] = np.array(1.0).astype(np.float32)\n",
    "            self._step = None\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._step = 0\n",
    "        return self.env.reset()\n",
    "\n",
    "\n",
    "class NormalizeActions(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self._mask = np.logical_and(\n",
    "            np.isfinite(env.action_space.low), np.isfinite(env.action_space.high)\n",
    "        )\n",
    "        self._low = np.where(self._mask, env.action_space.low, -1)\n",
    "        self._high = np.where(self._mask, env.action_space.high, 1)\n",
    "        low = np.where(self._mask, -np.ones_like(self._low), self._low)\n",
    "        high = np.where(self._mask, np.ones_like(self._low), self._high)\n",
    "        self.action_space = gym.spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        original = (action + 1) / 2 * (self._high - self._low) + self._low\n",
    "        original = np.where(self._mask, original, action)\n",
    "        return self.env.step(original)\n",
    "\n",
    "\n",
    "class OneHotAction(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete)\n",
    "        super().__init__(env)\n",
    "        self._random = np.random.RandomState()\n",
    "        shape = (self.env.action_space.n,)\n",
    "        space = gym.spaces.Box(low=0, high=1, shape=shape, dtype=np.float32)\n",
    "        space.discrete = True\n",
    "        self.action_space = space\n",
    "\n",
    "    def step(self, action):\n",
    "        index = np.argmax(action).astype(int)\n",
    "        reference = np.zeros_like(action)\n",
    "        reference[index] = 1\n",
    "        if not np.allclose(reference, action):\n",
    "            raise ValueError(f\"Invalid one-hot action:\\n{action}\")\n",
    "        return self.env.step(index)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def _sample_action(self):\n",
    "        actions = self.env.action_space.n\n",
    "        index = self._random.randint(0, actions)\n",
    "        reference = np.zeros(actions, dtype=np.float32)\n",
    "        reference[index] = 1.0\n",
    "        return reference\n",
    "\n",
    "\n",
    "class RewardObs(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        spaces = self.env.observation_space.spaces\n",
    "        if \"obs_reward\" not in spaces:\n",
    "            spaces[\"obs_reward\"] = gym.spaces.Box(\n",
    "                -np.inf, np.inf, shape=(1,), dtype=np.float32\n",
    "            )\n",
    "        self.observation_space = gym.spaces.Dict(spaces)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([reward], dtype=np.float32)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        if \"obs_reward\" not in obs:\n",
    "            obs[\"obs_reward\"] = np.array([0.0], dtype=np.float32)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class SelectAction(gym.Wrapper):\n",
    "    def __init__(self, env, key):\n",
    "        super().__init__(env)\n",
    "        self._key = key\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action[self._key])\n",
    "\n",
    "\n",
    "class UUID(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "\n",
    "    def reset(self):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        self.id = f\"{timestamp}-{str(uuid.uuid4().hex)}\"\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BettingAbstration: FCPA\n",
      "P0 Cards: 3d\n",
      "P1 Cards: 2d\n",
      "BoardCards \n",
      "Node type?: Player node for player 0\n",
      "PossibleActions (4): [ ACTION_FOLD  ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]\n",
      "Round: 0\n",
      "ACPC State: STATE:0::3d|2d\n",
      "Spent: [P0: 50  P1: 100  ]\n",
      "\n",
      "Action Sequence: dd\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pyspiel\n",
    "\n",
    "env = pyspiel.load_game(\n",
    "    \"universal_poker\",\n",
    "    {\n",
    "        \"numPlayers\": 2,\n",
    "        \"numSuits\": 2,\n",
    "        \"numRanks\": 3,\n",
    "        \"numHoleCards\": 1,\n",
    "        \"numBoardCards\": \"0 1\",\n",
    "        \"bettingAbstraction\": \"fcpa\",\n",
    "        \"numRounds\": 2,\n",
    "        \"blind\": \"50 100\",\n",
    "    },\n",
    ")\n",
    "state = env.new_initial_state()\n",
    "if state.is_chance_node():\n",
    "    while state.is_chance_node():\n",
    "        state.apply_action(np.random.choice(state.legal_actions()))\n",
    "print(state)\n",
    "print(state.current_player())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Poker:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = pyspiel.load_game(\n",
    "                name,\n",
    "                {\n",
    "                    \"numPlayers\": 2,\n",
    "                    \"numSuits\": 2,\n",
    "                    \"numRanks\": 3,\n",
    "                    \"numHoleCards\": 1,\n",
    "                    \"numBoardCards\": \"0 1\",\n",
    "                    \"bettingAbstraction\": \"fcpa\",\n",
    "                    \"numRounds\": 2,\n",
    "                    \"blind\": \"50 100\",\n",
    "                },\n",
    "            )\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        print(\"agent selection\", self.agent_selection)\n",
    "        self.traverser = None\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        spaces = {}\n",
    "        obs_spec = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        for key, value in obs_spec.items():\n",
    "            if not hasattr(value, \"shape\") or len(value.shape) == 0:\n",
    "                shape = (1,)\n",
    "            else:\n",
    "                shape = value.shape\n",
    "            spaces[key] = gym.spaces.Box(-np.inf, np.inf, shape, dtype=np.float32)\n",
    "        # spaces[\"image\"] = gym.spaces.Box(0, 255, self._size + (3,), dtype=np.uint8)\n",
    "        return gym.spaces.Dict(spaces)\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = gym.spaces.Discrete(4)\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"legal actions:\", self.state.legal_actions())\n",
    "        # print(\"action:\", action)\n",
    "        if hasattr(action, \"shape\") and len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        assert np.isfinite(action).all(), action\n",
    "        if not (action in self.state.legal_actions()):\n",
    "            action = np.random.choice(self.state.legal_actions())\n",
    "        reward = 0\n",
    "        if self.state.is_chance_node():\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "\n",
    "        else:\n",
    "            # print(\"action:\", action)\n",
    "            # print(\"obs:\", self.state)\n",
    "            self.state.apply_action(action)\n",
    "            if self.state.is_chance_node():\n",
    "                while self.state.is_chance_node():\n",
    "                    self.state.apply_action(\n",
    "                        np.random.choice(self.state.legal_actions())\n",
    "                    )\n",
    "\n",
    "        if not self.state.is_terminal():\n",
    "            # store = copy.deepcopy(self.state)\n",
    "            while self.state.is_chance_node():\n",
    "                self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "            # print(\"3\")\n",
    "            # print(self.state.is_terminal())\n",
    "            # if self.state.is_terminal():\n",
    "            #     print(\"store:\", store)\n",
    "            # print(self.state)\n",
    "            # print(self.state.legal_actions_mask(int(self.agent_selection)))\n",
    "            # print(\"3\")\n",
    "            self.agent_selection = str(self.state.current_player())\n",
    "\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self._env.new_initial_state()\n",
    "        while self.state.is_chance_node():\n",
    "            self.state.apply_action(np.random.choice(self.state.legal_actions()))\n",
    "        self.agent_selection = str(self.state.current_player())\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {\n",
    "            key: [val] if (hasattr(val, \"shape\") and len(val.shape) == 0) else val\n",
    "            for key, val in obs.items()\n",
    "        }\n",
    "        # obs[\"image\"] = self.render()\n",
    "        obs[\"is_terminal\"] = False\n",
    "        obs[\"is_first\"] = True\n",
    "        reward = (\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def last(self):\n",
    "        obs = dict(\n",
    "            {\n",
    "                \"observation\": np.array(\n",
    "                    self.state.observation_tensor(int(self.agent_selection))\n",
    "                ),\n",
    "                # \"action_mask\": np.stack(\n",
    "                #     self.state.legal_actions_mask(int(self.agent_selection))\n",
    "                # ),\n",
    "            }\n",
    "        )\n",
    "        obs = {key: [val] if len(val.shape) == 0 else val for key, val in obs.items()}\n",
    "        # obs[\"image\"] = self.render()\n",
    "        # There is no terminal state in DMC\n",
    "        obs[\"is_terminal\"] = self.state.is_terminal()\n",
    "        obs[\"is_first\"] = False\n",
    "        info = {}\n",
    "        return (\n",
    "            obs,\n",
    "            (\n",
    "                self.state.player_reward(self.traverser)\n",
    "                if self.traverser is not None\n",
    "                else self.state.player_return(int(self.agent_selection))\n",
    "            ),\n",
    "            self.state.is_terminal(),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CartPole:\n",
    "    LOCK = None\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if self.LOCK is None:\n",
    "            import multiprocessing as mp\n",
    "\n",
    "            mp = mp.get_context(\"spawn\")\n",
    "            self.LOCK = mp.Lock()\n",
    "\n",
    "        self._random = np.random.RandomState(seed)\n",
    "        # print(\"Size: \", size)\n",
    "        with self.LOCK:\n",
    "            self._env = gym.make(name, render_mode=\"rgb_array\")\n",
    "        self.reward_range = [-np.inf, np.inf]\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        return gym.spaces.Dict(\n",
    "            {\n",
    "                \"obs\": self._env.observation_space,\n",
    "                \"image\": gym.spaces.Box(\n",
    "                    0,\n",
    "                    255,\n",
    "                    (self._env.screen_width, self._env.screen_height) + (3,),\n",
    "                    dtype=np.uint8,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        space = self._env.action_space\n",
    "        space.discrete = True\n",
    "        return space\n",
    "\n",
    "    def step(self, action):\n",
    "        if len(action.shape) >= 1:\n",
    "            action = np.argmax(action)\n",
    "        observation, reward, terminated, truncated, info = self._env.step(action)\n",
    "        # print(observation.shape)\n",
    "        return (\n",
    "            {\n",
    "                \"obs\": observation,\n",
    "                \"image\": self._env.render(),\n",
    "                \"is_terminal\": terminated or truncated,\n",
    "                \"is_first\": False,\n",
    "            },\n",
    "            reward,\n",
    "            terminated or truncated,\n",
    "            {},\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs, info = self._env.reset()\n",
    "        # print(obs.shape)\n",
    "        return {\n",
    "            \"obs\": obs,\n",
    "            \"image\": self._env.render(),\n",
    "            \"is_terminal\": False,\n",
    "            \"is_first\": True,\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import collections\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as torchd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def symlog(x):\n",
    "    return torch.sign(x) * torch.log(torch.abs(x) + 1.0)\n",
    "\n",
    "\n",
    "def symexp(x):\n",
    "    return torch.sign(x) * (torch.exp(torch.abs(x)) - 1.0)\n",
    "\n",
    "\n",
    "class RequiresGrad:\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._model.requires_grad_(requires_grad=True)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._model.requires_grad_(requires_grad=False)\n",
    "\n",
    "\n",
    "class TimeRecording:\n",
    "    def __init__(self, comment):\n",
    "        self._comment = comment\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._st = torch.cuda.Event(enable_timing=True)\n",
    "        self._nd = torch.cuda.Event(enable_timing=True)\n",
    "        self._st.record()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._nd.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(self._comment, self._st.elapsed_time(self._nd) / 1000)\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logdir, step):\n",
    "        self._logdir = logdir\n",
    "        self._writer = SummaryWriter(log_dir=str(logdir), max_queue=1000)\n",
    "        self._last_step = None\n",
    "        self._last_time = None\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "        self.step = step\n",
    "\n",
    "    def scalar(self, name, value):\n",
    "        self._scalars[name] = float(value)\n",
    "\n",
    "    def image(self, name, value):\n",
    "        self._images[name] = np.array(value)\n",
    "\n",
    "    def video(self, name, value):\n",
    "        self._videos[name] = np.array(value)\n",
    "\n",
    "    def write(self, fps=False, step=False):\n",
    "        if not step:\n",
    "            step = self.step\n",
    "        scalars = list(self._scalars.items())\n",
    "        if fps:\n",
    "            scalars.append((\"fps\", self._compute_fps(step)))\n",
    "        print(f\"[{step}]\", \" / \".join(f\"{k} {v:.1f}\" for k, v in scalars))\n",
    "        with (self._logdir / \"metrics.jsonl\").open(\"a\") as f:\n",
    "            f.write(json.dumps({\"step\": step, **dict(scalars)}) + \"\\n\")\n",
    "        for name, value in scalars:\n",
    "            if \"/\" not in name:\n",
    "                self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "            else:\n",
    "                self._writer.add_scalar(name, value, step)\n",
    "        for name, value in self._images.items():\n",
    "            self._writer.add_image(name, value, step)\n",
    "        for name, value in self._videos.items():\n",
    "            name = name if isinstance(name, str) else name.decode(\"utf-8\")\n",
    "            if np.issubdtype(value.dtype, np.floating):\n",
    "                value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "            B, T, H, W, C = value.shape\n",
    "            value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "            self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "        self._writer.flush()\n",
    "        self._scalars = {}\n",
    "        self._images = {}\n",
    "        self._videos = {}\n",
    "\n",
    "    def _compute_fps(self, step):\n",
    "        if self._last_step is None:\n",
    "            self._last_time = time.time()\n",
    "            self._last_step = step\n",
    "            return 0\n",
    "        steps = step - self._last_step\n",
    "        duration = time.time() - self._last_time\n",
    "        self._last_time += duration\n",
    "        self._last_step = step\n",
    "        return steps / duration\n",
    "\n",
    "    def offline_scalar(self, name, value, step):\n",
    "        self._writer.add_scalar(\"scalars/\" + name, value, step)\n",
    "\n",
    "    def offline_video(self, name, value, step):\n",
    "        if np.issubdtype(value.dtype, np.floating):\n",
    "            value = np.clip(255 * value, 0, 255).astype(np.uint8)\n",
    "        B, T, H, W, C = value.shape\n",
    "        value = value.transpose(1, 4, 2, 0, 3).reshape((1, T, C, H, B * W))\n",
    "        self._writer.add_video(name, value, step, 16)\n",
    "\n",
    "\n",
    "def simulate(\n",
    "    agent,\n",
    "    envs,\n",
    "    cache,\n",
    "    directory,\n",
    "    logger,\n",
    "    is_eval=False,\n",
    "    limit=None,\n",
    "    steps=0,\n",
    "    episodes=0,\n",
    "    state=None,\n",
    "):\n",
    "    # initialize or unpack simulation state\n",
    "    if state is None:\n",
    "        step, episode = 0, 0\n",
    "        done = np.ones(len(envs), bool)\n",
    "        length = np.zeros(len(envs), np.int32)\n",
    "        obs = [None] * len(envs)\n",
    "        agent_state = None\n",
    "        reward = [0] * len(envs)\n",
    "    else:\n",
    "        step, episode, done, length, obs, agent_state, reward = state\n",
    "    while (steps and step < steps) or (episodes and episode < episodes):\n",
    "        # reset envs if necessary\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            results = [envs[i].reset() for i in indices]\n",
    "            results = [r() for r in results]\n",
    "            for index, result in zip(indices, results):\n",
    "                t = result.copy()\n",
    "                t = {k: convert(v) for k, v in t.items()}\n",
    "                # action will be added to transition in add_to_cache\n",
    "                t[\"reward\"] = 0.0\n",
    "                t[\"discount\"] = 1.0\n",
    "                # initial state should be added to cache\n",
    "                add_to_cache(cache, envs[index].id, t)\n",
    "                # replace obs with done by initial state\n",
    "                obs[index] = result\n",
    "        # step agents\n",
    "        obs = {k: np.stack([o[k] for o in obs]) for k in obs[0] if \"log_\" not in k}\n",
    "        action, agent_state = agent(obs, done, agent_state)\n",
    "        if isinstance(action, dict):\n",
    "            action = [\n",
    "                {k: np.array(action[k][i].detach().cpu()) for k in action}\n",
    "                for i in range(len(envs))\n",
    "            ]\n",
    "        else:\n",
    "            action = np.array(action)\n",
    "        assert len(action) == len(envs)\n",
    "        # step envs\n",
    "        results = [e.step(a) for e, a in zip(envs, action)]\n",
    "        results = [r() for r in results]\n",
    "        obs, reward, done = zip(*[p[:3] for p in results])\n",
    "        obs = list(obs)\n",
    "        reward = list(reward)\n",
    "        done = np.stack(done)\n",
    "        episode += int(done.sum())\n",
    "        length += 1\n",
    "        step += len(envs)\n",
    "        length *= 1 - done\n",
    "        # add to cache\n",
    "        for a, result, env in zip(action, results, envs):\n",
    "            o, r, d, info = result\n",
    "            o = {k: convert(v) for k, v in o.items()}\n",
    "            transition = o.copy()\n",
    "            if isinstance(a, dict):\n",
    "                transition.update(a)\n",
    "            else:\n",
    "                transition[\"action\"] = a\n",
    "            transition[\"reward\"] = r\n",
    "            transition[\"discount\"] = info.get(\"discount\", np.array(1 - float(d)))\n",
    "            add_to_cache(cache, env.id, transition)\n",
    "\n",
    "        if done.any():\n",
    "            indices = [index for index, d in enumerate(done) if d]\n",
    "            # logging for done episode\n",
    "            for i in indices:\n",
    "                save_episodes(directory, {envs[i].id: cache[envs[i].id]})\n",
    "                length = len(cache[envs[i].id][\"reward\"]) - 1\n",
    "                score = float(np.array(cache[envs[i].id][\"reward\"]).sum())\n",
    "                # video = cache[envs[i].id][\"image\"]\n",
    "                # record logs given from environments\n",
    "                for key in list(cache[envs[i].id].keys()):\n",
    "                    if \"log_\" in key:\n",
    "                        logger.scalar(\n",
    "                            key, float(np.array(cache[envs[i].id][key]).sum())\n",
    "                        )\n",
    "                        # log items won't be used later\n",
    "                        cache[envs[i].id].pop(key)\n",
    "\n",
    "                if not is_eval:\n",
    "                    step_in_dataset = erase_over_episodes(cache, limit)\n",
    "                    logger.scalar(f\"dataset_size\", step_in_dataset)\n",
    "                    logger.scalar(f\"train_return\", score)\n",
    "                    logger.scalar(f\"train_length\", length)\n",
    "                    logger.scalar(f\"train_episodes\", len(cache))\n",
    "                    logger.write(step=logger.step)\n",
    "                else:\n",
    "                    if not \"eval_lengths\" in locals():\n",
    "                        eval_lengths = []\n",
    "                        eval_scores = []\n",
    "                        eval_done = False\n",
    "                    # start counting scores for evaluation\n",
    "                    eval_scores.append(score)\n",
    "                    eval_lengths.append(length)\n",
    "\n",
    "                    score = sum(eval_scores) / len(eval_scores)\n",
    "                    length = sum(eval_lengths) / len(eval_lengths)\n",
    "                    # logger.video(f\"eval_policy\", np.array(video)[None])\n",
    "\n",
    "                    if len(eval_scores) >= episodes and not eval_done:\n",
    "                        logger.scalar(f\"eval_return\", score)\n",
    "                        logger.scalar(f\"eval_length\", length)\n",
    "                        logger.scalar(f\"eval_episodes\", len(eval_scores))\n",
    "                        logger.write(step=logger.step)\n",
    "                        eval_done = True\n",
    "    if is_eval:\n",
    "        # keep only last item for saving memory. this cache is used for video_pred later\n",
    "        while len(cache) > 1:\n",
    "            # FIFO\n",
    "            cache.popitem(last=False)\n",
    "    return (step - steps, episode - episodes, done, length, obs, agent_state, reward)\n",
    "\n",
    "\n",
    "def add_to_cache(cache, id, transition):\n",
    "    if id not in cache:\n",
    "        cache[id] = dict()\n",
    "        for key, val in transition.items():\n",
    "            cache[id][key] = [convert(val)]\n",
    "    else:\n",
    "        for key, val in transition.items():\n",
    "            if key not in cache[id]:\n",
    "                # fill missing data(action, etc.) at second time\n",
    "                cache[id][key] = [convert(0 * val)]\n",
    "                cache[id][key].append(convert(val))\n",
    "            else:\n",
    "                cache[id][key].append(convert(val))\n",
    "\n",
    "\n",
    "def erase_over_episodes(cache, dataset_size):\n",
    "    step_in_dataset = 0\n",
    "    for key, ep in reversed(sorted(cache.items(), key=lambda x: x[0])):\n",
    "        if (\n",
    "            not dataset_size\n",
    "            or step_in_dataset + (len(ep[\"reward\"]) - 1) <= dataset_size\n",
    "        ):\n",
    "            step_in_dataset += len(ep[\"reward\"]) - 1\n",
    "        else:\n",
    "            del cache[key]\n",
    "    return step_in_dataset\n",
    "\n",
    "\n",
    "def convert(value, precision=32):\n",
    "    value = np.array(value)\n",
    "    if np.issubdtype(value.dtype, np.floating):\n",
    "        dtype = {16: np.float16, 32: np.float32, 64: np.float64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.signedinteger):\n",
    "        dtype = {16: np.int16, 32: np.int32, 64: np.int64}[precision]\n",
    "    elif np.issubdtype(value.dtype, np.uint8):\n",
    "        dtype = np.uint8\n",
    "    elif np.issubdtype(value.dtype, bool):\n",
    "        dtype = bool\n",
    "    else:\n",
    "        raise NotImplementedError(value.dtype)\n",
    "    return value.astype(dtype)\n",
    "\n",
    "\n",
    "def save_episodes(directory, episodes):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    for filename, episode in episodes.items():\n",
    "        length = len(episode[\"reward\"])\n",
    "        filename = directory / f\"{filename}-{length}.npz\"\n",
    "        with io.BytesIO() as f1:\n",
    "            np.savez_compressed(f1, **episode)\n",
    "            f1.seek(0)\n",
    "            with filename.open(\"wb\") as f2:\n",
    "                f2.write(f1.read())\n",
    "    return True\n",
    "\n",
    "\n",
    "def from_generator(generator, batch_size):\n",
    "    while True:\n",
    "        batch = []\n",
    "        for _ in range(batch_size):\n",
    "            batch.append(next(generator))\n",
    "        data = {}\n",
    "        for key in batch[0].keys():\n",
    "            data[key] = []\n",
    "            for i in range(batch_size):\n",
    "                data[key].append(batch[i][key])\n",
    "            data[key] = np.stack(data[key], 0)\n",
    "        yield data\n",
    "\n",
    "\n",
    "def sample_episodes(episodes, length, seed=0):\n",
    "    np_random = np.random.RandomState(seed)\n",
    "    while True:\n",
    "        size = 0\n",
    "        ret = None\n",
    "        p = np.array(\n",
    "            [len(next(iter(episode.values()))) for episode in episodes.values()]\n",
    "        )\n",
    "        p = p / np.sum(p)\n",
    "        while size < length:\n",
    "            episode = np_random.choice(list(episodes.values()), p=p)\n",
    "            total = len(next(iter(episode.values())))\n",
    "            # make sure at least one transition included\n",
    "            if total < 2:\n",
    "                continue\n",
    "            if not ret:\n",
    "                index = int(np_random.randint(0, total - 1))\n",
    "                ret = {\n",
    "                    k: v[index : min(index + length, total)].copy()\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][0] = True\n",
    "            else:\n",
    "                # 'is_first' comes after 'is_last'\n",
    "                index = 0\n",
    "                possible = length - size\n",
    "                ret = {\n",
    "                    k: np.append(\n",
    "                        ret[k], v[index : min(index + possible, total)].copy(), axis=0\n",
    "                    )\n",
    "                    for k, v in episode.items()\n",
    "                    if \"log_\" not in k\n",
    "                }\n",
    "                if \"is_first\" in ret:\n",
    "                    ret[\"is_first\"][size] = True\n",
    "            size = len(next(iter(ret.values())))\n",
    "        yield ret\n",
    "\n",
    "\n",
    "def load_episodes(directory, limit=None, reverse=True):\n",
    "    directory = pathlib.Path(directory).expanduser()\n",
    "    episodes = collections.OrderedDict()\n",
    "    total = 0\n",
    "    if reverse:\n",
    "        for filename in reversed(sorted(directory.glob(\"*.npz\"))):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            # extract only filename without extension\n",
    "            episodes[str(os.path.splitext(os.path.basename(filename))[0])] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    else:\n",
    "        for filename in sorted(directory.glob(\"*.npz\")):\n",
    "            try:\n",
    "                with filename.open(\"rb\") as f:\n",
    "                    episode = np.load(f)\n",
    "                    episode = {k: episode[k] for k in episode.keys()}\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load episode: {e}\")\n",
    "                continue\n",
    "            episodes[str(filename)] = episode\n",
    "            total += len(episode[\"reward\"]) - 1\n",
    "            if limit and total >= limit:\n",
    "                break\n",
    "    return episodes\n",
    "\n",
    "\n",
    "class SampleDist:\n",
    "    def __init__(self, dist, samples=100):\n",
    "        self._dist = dist\n",
    "        self._samples = samples\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"SampleDist\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def mean(self):\n",
    "        samples = self._dist.sample(self._samples)\n",
    "        return torch.mean(samples, 0)\n",
    "\n",
    "    def mode(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self._dist.log_prob(sample)\n",
    "        return sample[torch.argmax(logprob)][0]\n",
    "\n",
    "    def entropy(self):\n",
    "        sample = self._dist.sample(self._samples)\n",
    "        logprob = self.log_prob(sample)\n",
    "        return -torch.mean(logprob, 0)\n",
    "\n",
    "\n",
    "class OneHotDist(torchd.one_hot_categorical.OneHotCategorical):\n",
    "    def __init__(self, logits=None, probs=None, unimix_ratio=0.0):\n",
    "        if logits is not None and unimix_ratio > 0.0:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs = probs * (1.0 - unimix_ratio) + unimix_ratio / probs.shape[-1]\n",
    "            logits = torch.log(probs)\n",
    "            super().__init__(logits=logits, probs=None)\n",
    "        else:\n",
    "            super().__init__(logits=logits, probs=probs)\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = F.one_hot(\n",
    "            torch.argmax(super().logits, axis=-1), super().logits.shape[-1]\n",
    "        )\n",
    "        return _mode.detach() + super().logits - super().logits.detach()\n",
    "\n",
    "    def sample(self, sample_shape=(), seed=None):\n",
    "        if seed is not None:\n",
    "            raise ValueError(\"need to check\")\n",
    "        sample = super().sample(sample_shape).detach()\n",
    "        probs = super().probs\n",
    "        while len(probs.shape) < len(sample.shape):\n",
    "            probs = probs[None]\n",
    "        sample += probs - probs.detach()\n",
    "        return sample\n",
    "\n",
    "\n",
    "class DiscDist:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logits,\n",
    "        low=-20.0,\n",
    "        high=20.0,\n",
    "        transfwd=symlog,\n",
    "        transbwd=symexp,\n",
    "        device=\"cuda\",\n",
    "    ):\n",
    "        self.logits = logits\n",
    "        self.probs = torch.softmax(logits, -1)\n",
    "        self.buckets = torch.linspace(low, high, steps=255, device=device)\n",
    "        self.width = (self.buckets[-1] - self.buckets[0]) / 255\n",
    "        self.transfwd = transfwd\n",
    "        self.transbwd = transbwd\n",
    "\n",
    "    def mean(self):\n",
    "        _mean = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mean, dim=-1, keepdim=True))\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = self.probs * self.buckets\n",
    "        return self.transbwd(torch.sum(_mode, dim=-1, keepdim=True))\n",
    "\n",
    "    # Inside OneHotCategorical, log_prob is calculated using only max element in targets\n",
    "    def log_prob(self, x):\n",
    "        x = self.transfwd(x)\n",
    "        # x(time, batch, 1)\n",
    "        below = torch.sum((self.buckets <= x[..., None]).to(torch.int32), dim=-1) - 1\n",
    "        above = len(self.buckets) - torch.sum(\n",
    "            (self.buckets > x[..., None]).to(torch.int32), dim=-1\n",
    "        )\n",
    "        # this is implemented using clip at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        below = torch.clip(below, 0, len(self.buckets) - 1)\n",
    "        above = torch.clip(above, 0, len(self.buckets) - 1)\n",
    "        equal = below == above\n",
    "\n",
    "        dist_to_below = torch.where(equal, 1, torch.abs(self.buckets[below] - x))\n",
    "        dist_to_above = torch.where(equal, 1, torch.abs(self.buckets[above] - x))\n",
    "        total = dist_to_below + dist_to_above\n",
    "        weight_below = dist_to_above / total\n",
    "        weight_above = dist_to_below / total\n",
    "        target = (\n",
    "            F.one_hot(below, num_classes=len(self.buckets)) * weight_below[..., None]\n",
    "            + F.one_hot(above, num_classes=len(self.buckets)) * weight_above[..., None]\n",
    "        )\n",
    "        log_pred = self.logits - torch.logsumexp(self.logits, -1, keepdim=True)\n",
    "        target = target.squeeze(-2)\n",
    "\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "    def log_prob_target(self, target):\n",
    "        log_pred = super().logits - torch.logsumexp(super().logits, -1, keepdim=True)\n",
    "        return (target * log_pred).sum(-1)\n",
    "\n",
    "\n",
    "class MSEDist:\n",
    "    def __init__(self, mode, agg=\"sum\"):\n",
    "        self._mode = mode\n",
    "        self._agg = agg\n",
    "\n",
    "    def mode(self):\n",
    "        return self._mode\n",
    "\n",
    "    def mean(self):\n",
    "        return self._mode\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape, (self._mode.shape, value.shape)\n",
    "        distance = (self._mode - value) ** 2\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class SymlogDist:\n",
    "    def __init__(self, mode, dist=\"mse\", agg=\"sum\", tol=1e-8):\n",
    "        self._mode = mode\n",
    "        self._dist = dist\n",
    "        self._agg = agg\n",
    "        self._tol = tol\n",
    "\n",
    "    def mode(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def mean(self):\n",
    "        return symexp(self._mode)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        assert self._mode.shape == value.shape\n",
    "        if self._dist == \"mse\":\n",
    "            distance = (self._mode - symlog(value)) ** 2.0\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        elif self._dist == \"abs\":\n",
    "            distance = torch.abs(self._mode - symlog(value))\n",
    "            distance = torch.where(distance < self._tol, 0, distance)\n",
    "        else:\n",
    "            raise NotImplementedError(self._dist)\n",
    "        if self._agg == \"mean\":\n",
    "            loss = distance.mean(list(range(len(distance.shape)))[2:])\n",
    "        elif self._agg == \"sum\":\n",
    "            loss = distance.sum(list(range(len(distance.shape)))[2:])\n",
    "        else:\n",
    "            raise NotImplementedError(self._agg)\n",
    "        return -loss\n",
    "\n",
    "\n",
    "class ContDist:\n",
    "    def __init__(self, dist=None, absmax=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "        self.absmax = absmax\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        out = self._dist.mean\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        out = self._dist.rsample(sample_shape)\n",
    "        if self.absmax is not None:\n",
    "            out *= (self.absmax / torch.clip(torch.abs(out), min=self.absmax)).detach()\n",
    "        return out\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return self._dist.log_prob(x)\n",
    "\n",
    "\n",
    "class Bernoulli:\n",
    "    def __init__(self, dist=None):\n",
    "        super().__init__()\n",
    "        self._dist = dist\n",
    "        self.mean = dist.mean\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._dist, name)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self._dist.entropy()\n",
    "\n",
    "    def mode(self):\n",
    "        _mode = torch.round(self._dist.mean)\n",
    "        return _mode.detach() + self._dist.mean - self._dist.mean.detach()\n",
    "\n",
    "    def sample(self, sample_shape=()):\n",
    "        # return self._dist.rsample(sample_shape)\n",
    "        return self._dist.sample(sample_shape)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        _logits = self._dist.base_dist.logits\n",
    "        log_probs0 = -F.softplus(_logits)\n",
    "        log_probs1 = -F.softplus(-_logits)\n",
    "\n",
    "        return torch.sum(log_probs0 * (1 - x) + log_probs1 * x, -1)\n",
    "\n",
    "\n",
    "class UnnormalizedHuber(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, threshold=1, **kwargs):\n",
    "        super().__init__(loc, scale, **kwargs)\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def log_prob(self, event):\n",
    "        return -(\n",
    "            torch.sqrt((event - self.mean) ** 2 + self._threshold**2) - self._threshold\n",
    "        )\n",
    "\n",
    "    def mode(self):\n",
    "        return self.mean\n",
    "\n",
    "\n",
    "class SafeTruncatedNormal(torchd.normal.Normal):\n",
    "    def __init__(self, loc, scale, low, high, clip=1e-6, mult=1):\n",
    "        super().__init__(loc, scale)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._clip = clip\n",
    "        self._mult = mult\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        event = super().sample(sample_shape)\n",
    "        if self._clip:\n",
    "            clipped = torch.clip(event, self._low + self._clip, self._high - self._clip)\n",
    "            event = event - event.detach() + clipped.detach()\n",
    "        if self._mult:\n",
    "            event *= self._mult\n",
    "        return event\n",
    "\n",
    "\n",
    "class TanhBijector(torchd.Transform):\n",
    "    def __init__(self, validate_args=False, name=\"tanh\"):\n",
    "        super().__init__()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y = torch.where(\n",
    "            (torch.abs(y) <= 1.0), torch.clamp(y, -0.99999997, 0.99999997), y\n",
    "        )\n",
    "        y = torch.atanh(y)\n",
    "        return y\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        log2 = torch.math.log(2.0)\n",
    "        return 2.0 * (log2 - x - torch.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "def static_scan_for_lambda_return(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    indices = reversed(indices)\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        # (inputs, pcont) -> (inputs[index], pcont[index])\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            outputs = last\n",
    "            flag = False\n",
    "        else:\n",
    "            outputs = torch.cat([outputs, last], dim=-1)\n",
    "    outputs = torch.reshape(outputs, [outputs.shape[0], outputs.shape[1], 1])\n",
    "    outputs = torch.flip(outputs, [1])\n",
    "    outputs = torch.unbind(outputs, dim=0)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def lambda_return(reward, value, pcont, bootstrap, lambda_, axis):\n",
    "    # Setting lambda=1 gives a discounted Monte Carlo return.\n",
    "    # Setting lambda=0 gives a fixed 1-step return.\n",
    "    # assert reward.shape.ndims == value.shape.ndims, (reward.shape, value.shape)\n",
    "    assert len(reward.shape) == len(value.shape), (reward.shape, value.shape)\n",
    "    if isinstance(pcont, (int, float)):\n",
    "        pcont = pcont * torch.ones_like(reward)\n",
    "    dims = list(range(len(reward.shape)))\n",
    "    dims = [axis] + dims[1:axis] + [0] + dims[axis + 1 :]\n",
    "    if axis != 0:\n",
    "        reward = reward.permute(dims)\n",
    "        value = value.permute(dims)\n",
    "        pcont = pcont.permute(dims)\n",
    "    if bootstrap is None:\n",
    "        bootstrap = torch.zeros_like(value[-1])\n",
    "    next_values = torch.cat([value[1:], bootstrap[None]], 0)\n",
    "    inputs = reward + pcont * next_values * (1 - lambda_)\n",
    "    # returns = static_scan(\n",
    "    #    lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg,\n",
    "    #    (inputs, pcont), bootstrap, reverse=True)\n",
    "    # reimplement to optimize performance\n",
    "    returns = static_scan_for_lambda_return(\n",
    "        lambda agg, cur0, cur1: cur0 + cur1 * lambda_ * agg, (inputs, pcont), bootstrap\n",
    "    )\n",
    "    if axis != 0:\n",
    "        returns = returns.permute(dims)\n",
    "    return returns\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        parameters,\n",
    "        lr,\n",
    "        eps=1e-4,\n",
    "        clip=None,\n",
    "        wd=None,\n",
    "        wd_pattern=r\".*\",\n",
    "        opt=\"adam\",\n",
    "        use_amp=False,\n",
    "    ):\n",
    "        assert 0 <= wd < 1\n",
    "        assert not clip or 1 <= clip\n",
    "        self._name = name\n",
    "        self._parameters = parameters\n",
    "        self._clip = clip\n",
    "        self._wd = wd\n",
    "        self._wd_pattern = wd_pattern\n",
    "        self._opt = {\n",
    "            \"adam\": lambda: torch.optim.Adam(parameters, lr=lr, eps=eps),\n",
    "            \"nadam\": lambda: NotImplemented(f\"{opt} is not implemented\"),\n",
    "            \"adamax\": lambda: torch.optim.Adamax(parameters, lr=lr, eps=eps),\n",
    "            \"sgd\": lambda: torch.optim.SGD(parameters, lr=lr),\n",
    "            \"momentum\": lambda: torch.optim.SGD(parameters, lr=lr, momentum=0.9),\n",
    "        }[opt]()\n",
    "        self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    def __call__(self, loss, params, retain_graph=True):\n",
    "        assert len(loss.shape) == 0, loss.shape\n",
    "        metrics = {}\n",
    "        metrics[f\"{self._name}_loss\"] = loss.detach().cpu().numpy()\n",
    "        self._opt.zero_grad()\n",
    "        self._scaler.scale(loss).backward(retain_graph=retain_graph)\n",
    "        self._scaler.unscale_(self._opt)\n",
    "        # loss.backward(retain_graph=retain_graph)\n",
    "        norm = torch.nn.utils.clip_grad_norm_(params, self._clip)\n",
    "        if self._wd:\n",
    "            self._apply_weight_decay(params)\n",
    "        self._scaler.step(self._opt)\n",
    "        self._scaler.update()\n",
    "        # self._opt.step()\n",
    "        self._opt.zero_grad()\n",
    "        metrics[f\"{self._name}_grad_norm\"] = to_np(norm)\n",
    "        return metrics\n",
    "\n",
    "    def _apply_weight_decay(self, varibs):\n",
    "        nontrivial = self._wd_pattern != r\".*\"\n",
    "        if nontrivial:\n",
    "            raise NotImplementedError\n",
    "        for var in varibs:\n",
    "            var.data = (1 - self._wd) * var.data\n",
    "\n",
    "\n",
    "def args_type(default):\n",
    "    def parse_string(x):\n",
    "        if default is None:\n",
    "            return x\n",
    "        if isinstance(default, bool):\n",
    "            return bool([\"False\", \"True\"].index(x))\n",
    "        if isinstance(default, int):\n",
    "            return float(x) if (\"e\" in x or \".\" in x) else int(x)\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(args_type(default[0])(y) for y in x.split(\",\"))\n",
    "        return type(default)(x)\n",
    "\n",
    "    def parse_object(x):\n",
    "        if isinstance(default, (list, tuple)):\n",
    "            return tuple(x)\n",
    "        return x\n",
    "\n",
    "    return lambda x: parse_string(x) if isinstance(x, str) else parse_object(x)\n",
    "\n",
    "\n",
    "def static_scan(fn, inputs, start):\n",
    "    last = start\n",
    "    indices = range(inputs[0].shape[0])\n",
    "    flag = True\n",
    "    for index in indices:\n",
    "        inp = lambda x: (_input[x] for _input in inputs)\n",
    "        last = fn(last, *inp(index))\n",
    "        if flag:\n",
    "            if type(last) == type({}):\n",
    "                outputs = {\n",
    "                    key: value.clone().unsqueeze(0) for key, value in last.items()\n",
    "                }\n",
    "            else:\n",
    "                outputs = []\n",
    "                for _last in last:\n",
    "                    if type(_last) == type({}):\n",
    "                        outputs.append(\n",
    "                            {\n",
    "                                key: value.clone().unsqueeze(0)\n",
    "                                for key, value in _last.items()\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        outputs.append(_last.clone().unsqueeze(0))\n",
    "            flag = False\n",
    "        else:\n",
    "            if type(last) == type({}):\n",
    "                for key in last.keys():\n",
    "                    outputs[key] = torch.cat(\n",
    "                        [outputs[key], last[key].unsqueeze(0)], dim=0\n",
    "                    )\n",
    "            else:\n",
    "                for j in range(len(outputs)):\n",
    "                    if type(last[j]) == type({}):\n",
    "                        for key in last[j].keys():\n",
    "                            outputs[j][key] = torch.cat(\n",
    "                                [outputs[j][key], last[j][key].unsqueeze(0)], dim=0\n",
    "                            )\n",
    "                    else:\n",
    "                        outputs[j] = torch.cat(\n",
    "                            [outputs[j], last[j].unsqueeze(0)], dim=0\n",
    "                        )\n",
    "    if type(last) == type({}):\n",
    "        outputs = [outputs]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class Every:\n",
    "    def __init__(self, every):\n",
    "        self._every = every\n",
    "        self._last = None\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._every:\n",
    "            return 0\n",
    "        if self._last is None:\n",
    "            self._last = step\n",
    "            return 1\n",
    "        count = int((step - self._last) / self._every)\n",
    "        self._last += self._every * count\n",
    "        return count\n",
    "\n",
    "\n",
    "class Once:\n",
    "    def __init__(self):\n",
    "        self._once = True\n",
    "\n",
    "    def __call__(self):\n",
    "        if self._once:\n",
    "            self._once = False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Until:\n",
    "    def __init__(self, until):\n",
    "        self._until = until\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if not self._until:\n",
    "            return True\n",
    "        return step < self._until\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        in_num = m.in_features\n",
    "        out_num = m.out_features\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        space = m.kernel_size[0] * m.kernel_size[1]\n",
    "        in_num = space * m.in_channels\n",
    "        out_num = space * m.out_channels\n",
    "        denoms = (in_num + out_num) / 2.0\n",
    "        scale = 1.0 / denoms\n",
    "        std = np.sqrt(scale) / 0.87962566103423978\n",
    "        nn.init.trunc_normal_(\n",
    "            m.weight.data, mean=0.0, std=std, a=-2.0 * std, b=2.0 * std\n",
    "        )\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def uniform_weight_init(given_scale):\n",
    "    def f(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            in_num = m.in_features\n",
    "            out_num = m.out_features\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            space = m.kernel_size[0] * m.kernel_size[1]\n",
    "            in_num = space * m.in_channels\n",
    "            out_num = space * m.out_channels\n",
    "            denoms = (in_num + out_num) / 2.0\n",
    "            scale = given_scale / denoms\n",
    "            limit = np.sqrt(3 * scale)\n",
    "            nn.init.uniform_(m.weight.data, a=-limit, b=limit)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            m.weight.data.fill_(1.0)\n",
    "            if hasattr(m.bias, \"data\"):\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def tensorstats(tensor, prefix=None):\n",
    "    metrics = {\n",
    "        \"mean\": to_np(torch.mean(tensor)),\n",
    "        \"std\": to_np(torch.std(tensor)),\n",
    "        \"min\": to_np(torch.min(tensor)),\n",
    "        \"max\": to_np(torch.max(tensor)),\n",
    "    }\n",
    "    if prefix:\n",
    "        metrics = {f\"{prefix}_{k}\": v for k, v in metrics.items()}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def set_seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def enable_deterministic_run():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def recursively_collect_optim_state_dict(\n",
    "    obj, path=\"\", optimizers_state_dicts=None, visited=None\n",
    "):\n",
    "    if optimizers_state_dicts is None:\n",
    "        optimizers_state_dicts = {}\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    # avoid cyclic reference\n",
    "    if id(obj) in visited:\n",
    "        return optimizers_state_dicts\n",
    "    else:\n",
    "        visited.add(id(obj))\n",
    "    attrs = obj.__dict__\n",
    "    if isinstance(obj, torch.nn.Module):\n",
    "        attrs.update(\n",
    "            {k: attr for k, attr in obj.named_modules() if \".\" not in k and obj != attr}\n",
    "        )\n",
    "    for name, attr in attrs.items():\n",
    "        new_path = path + \".\" + name if path else name\n",
    "        if isinstance(attr, torch.optim.Optimizer):\n",
    "            optimizers_state_dicts[new_path] = attr.state_dict()\n",
    "        elif hasattr(attr, \"__dict__\"):\n",
    "            optimizers_state_dicts.update(\n",
    "                recursively_collect_optim_state_dict(\n",
    "                    attr, new_path, optimizers_state_dicts, visited\n",
    "                )\n",
    "            )\n",
    "    return optimizers_state_dicts\n",
    "\n",
    "\n",
    "def recursively_load_optim_state_dict(obj, optimizers_state_dicts):\n",
    "    for path, state_dict in optimizers_state_dicts.items():\n",
    "        keys = path.split(\".\")\n",
    "        obj_now = obj\n",
    "        for key in keys:\n",
    "            obj_now = getattr(obj_now, key)\n",
    "        obj_now.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class Random(nn.Module):\n",
    "    def __init__(self, config, act_space):\n",
    "        super(Random, self).__init__()\n",
    "        self._config = config\n",
    "        self._act_space = act_space\n",
    "\n",
    "    def actor(self, feat):\n",
    "        # if self._config.actor[\"dist\"] == \"onehot\":\n",
    "\n",
    "        return OneHotDist(\n",
    "            torch.zeros(self._config.num_actions, device=self._config.device).repeat(\n",
    "                self._config.envs, 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # else:\n",
    "    #     return torchd.independent.Independent(\n",
    "    #         torchd.uniform.Uniform(\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.low, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #             torch.tensor(\n",
    "    #                 self._act_space.high, device=self._config.device\n",
    "    #             ).repeat(self._config.envs, 1),\n",
    "    #         ),\n",
    "    #         1,\n",
    "    #     )\n",
    "\n",
    "    def train(self, start, context, data):\n",
    "        return None, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "import enum\n",
    "from functools import partial as bind\n",
    "\n",
    "\n",
    "class Parallel:\n",
    "    def __init__(self, ctor, strategy):\n",
    "        self.worker = Worker(bind(self._respond, ctor), strategy, state=True)\n",
    "        self.callables = {}\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name.startswith(\"_\"):\n",
    "            raise AttributeError(name)\n",
    "        try:\n",
    "            if name not in self.callables:\n",
    "                self.callables[name] = self.worker(PMessage.CALLABLE, name)()\n",
    "            if self.callables[name]:\n",
    "                return bind(self.worker, PMessage.CALL, name)\n",
    "            else:\n",
    "                return self.worker(PMessage.READ, name)()\n",
    "        except AttributeError:\n",
    "            raise ValueError(name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.worker(PMessage.CALL, \"__len__\")()\n",
    "\n",
    "    def close(self):\n",
    "        self.worker.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _respond(ctor, state, message, name, *args, **kwargs):\n",
    "        state = state or ctor\n",
    "        if message == PMessage.CALLABLE:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = callable(getattr(state, name))\n",
    "        elif message == PMessage.CALL:\n",
    "            result = getattr(state, name)(*args, **kwargs)\n",
    "        elif message == PMessage.READ:\n",
    "            assert not args and not kwargs, (args, kwargs)\n",
    "            result = getattr(state, name)\n",
    "        return state, result\n",
    "\n",
    "\n",
    "class PMessage(enum.Enum):\n",
    "    CALLABLE = 2\n",
    "    CALL = 3\n",
    "    READ = 4\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    initializers = []\n",
    "\n",
    "    def __init__(self, fn, strategy=\"thread\", state=False):\n",
    "        if not state:\n",
    "            fn = lambda s, *args, fn=fn, **kwargs: (s, fn(*args, **kwargs))\n",
    "        inits = self.initializers\n",
    "        self.impl = {\n",
    "            \"process\": bind(ProcessPipeWorker, initializers=inits),\n",
    "            \"daemon\": bind(ProcessPipeWorker, initializers=inits, daemon=True),\n",
    "        }[strategy](fn)\n",
    "        self.promise = None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.promise and self.promise()  # Raise previous exception if any.\n",
    "        self.promise = self.impl(*args, **kwargs)\n",
    "        return self.promise\n",
    "\n",
    "    def wait(self):\n",
    "        return self.impl.wait()\n",
    "\n",
    "    def close(self):\n",
    "        self.impl.close()\n",
    "\n",
    "\n",
    "class ProcessPipeWorker:\n",
    "    def __init__(self, fn, initializers=(), daemon=False):\n",
    "        import multiprocessing\n",
    "        import cloudpickle\n",
    "\n",
    "        self._context = multiprocessing.get_context(\"spawn\")\n",
    "        self._pipe, pipe = self._context.Pipe()\n",
    "        fn = cloudpickle.dumps(fn)\n",
    "        initializers = cloudpickle.dumps(initializers)\n",
    "        self._process = self._context.Process(\n",
    "            target=self._loop, args=(pipe, fn, initializers), daemon=daemon\n",
    "        )\n",
    "        self._process.start()\n",
    "        self._nextid = 0\n",
    "        self._results = {}\n",
    "        assert self._submit(Message.OK)()\n",
    "        atexit.register(self.close)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self._submit(Message.RUN, (args, kwargs))\n",
    "\n",
    "    def wait(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self._pipe.send((Message.STOP, self._nextid, None))\n",
    "            self._pipe.close()\n",
    "        except (AttributeError, IOError):\n",
    "            pass  # The connection was already closed.\n",
    "        try:\n",
    "            self._process.join(0.1)\n",
    "            if self._process.exitcode is None:\n",
    "                try:\n",
    "                    os.kill(self._process.pid, 9)\n",
    "                    time.sleep(0.1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except (AttributeError, AssertionError):\n",
    "            pass\n",
    "\n",
    "    def _submit(self, message, payload=None):\n",
    "        callid = self._nextid\n",
    "        self._nextid += 1\n",
    "        self._pipe.send((message, callid, payload))\n",
    "        return Future(self._receive, callid)\n",
    "\n",
    "    def _receive(self, callid):\n",
    "        while callid not in self._results:\n",
    "            try:\n",
    "                message, callid, payload = self._pipe.recv()\n",
    "            except (OSError, EOFError):\n",
    "                raise RuntimeError(\"Lost connection to worker.\")\n",
    "            if message == Message.ERROR:\n",
    "                raise Exception(payload)\n",
    "            assert message == Message.RESULT, message\n",
    "            self._results[callid] = payload\n",
    "        return self._results.pop(callid)\n",
    "\n",
    "    @staticmethod\n",
    "    def _loop(pipe, function, initializers):\n",
    "        try:\n",
    "            callid = None\n",
    "            state = None\n",
    "            import cloudpickle\n",
    "\n",
    "            initializers = cloudpickle.loads(initializers)\n",
    "            function = cloudpickle.loads(function)\n",
    "            [fn() for fn in initializers]\n",
    "            while True:\n",
    "                if not pipe.poll(0.1):\n",
    "                    continue  # Wake up for keyboard interrupts.\n",
    "                message, callid, payload = pipe.recv()\n",
    "                if message == Message.OK:\n",
    "                    pipe.send((Message.RESULT, callid, True))\n",
    "                elif message == Message.STOP:\n",
    "                    return\n",
    "                elif message == Message.RUN:\n",
    "                    args, kwargs = payload\n",
    "                    state, result = function(state, *args, **kwargs)\n",
    "                    pipe.send((Message.RESULT, callid, result))\n",
    "                else:\n",
    "                    raise KeyError(f\"Invalid message: {message}\")\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            return\n",
    "        except Exception:\n",
    "            stacktrace = \"\".join(traceback.format_exception(*sys.exc_info()))\n",
    "            print(f\"Error inside process worker: {stacktrace}.\", flush=True)\n",
    "            pipe.send((Message.ERROR, callid, stacktrace))\n",
    "            return\n",
    "        finally:\n",
    "            try:\n",
    "                pipe.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "class Message(enum.Enum):\n",
    "    OK = 1\n",
    "    RUN = 2\n",
    "    RESULT = 3\n",
    "    STOP = 4\n",
    "    ERROR = 5\n",
    "\n",
    "\n",
    "class Future:\n",
    "    def __init__(self, receive, callid):\n",
    "        self._receive = receive\n",
    "        self._callid = callid\n",
    "        self._result = None\n",
    "        self._complete = False\n",
    "\n",
    "    def __call__(self):\n",
    "        if not self._complete:\n",
    "            self._result = self._receive(self._callid)\n",
    "            self._complete = True\n",
    "        return self._result\n",
    "\n",
    "\n",
    "class Damy:\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    def step(self, action):\n",
    "        return lambda: self._env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        return lambda: self._env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "# torch.set_default_device(\"mps\")\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def count_steps(folder):\n",
    "    return sum(int(str(n).split(\"-\")[-1][:-4]) - 1 for n in folder.glob(\"*.npz\"))\n",
    "\n",
    "\n",
    "def make_dataset(episodes, config):\n",
    "    generator = sample_episodes(episodes, config.batch_length)\n",
    "    dataset = from_generator(generator, config.batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_env(config, mode, id):\n",
    "    suite, task = config.task.split(\"_\", 1)\n",
    "    if suite == \"dmc\":\n",
    "        import envs.dmc as dmc\n",
    "\n",
    "        env = dmc.DeepMindControl(\n",
    "            task, config.action_repeat, config.size, seed=config.seed + id\n",
    "        )\n",
    "        env = NormalizeActions(env)\n",
    "    elif suite == \"cartpole\":\n",
    "        env = CartPole(\n",
    "            task,\n",
    "        )\n",
    "    elif suite == \"poker\":\n",
    "        env = Poker(\n",
    "            \"universal_poker\",\n",
    "        )\n",
    "    elif suite == \"atari\":\n",
    "        import envs.atari as atari\n",
    "\n",
    "        env = atari.Atari(\n",
    "            task,\n",
    "            config.action_repeat,\n",
    "            config.size,\n",
    "            gray=config.grayscale,\n",
    "            noops=config.noops,\n",
    "            lives=config.lives,\n",
    "            sticky=config.stickey,\n",
    "            actions=config.actions,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"dmlab\":\n",
    "        import envs.dmlab as dmlab\n",
    "\n",
    "        env = dmlab.DeepMindLabyrinth(\n",
    "            task,\n",
    "            mode if \"train\" in mode else \"test\",\n",
    "            config.action_repeat,\n",
    "            seed=config.seed + id,\n",
    "        )\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"memorymaze\":\n",
    "        from envs.memorymaze import MemoryMaze\n",
    "\n",
    "        env = MemoryMaze(task, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"crafter\":\n",
    "        import envs.crafter as crafter\n",
    "\n",
    "        env = crafter.Crafter(task, config.size, seed=config.seed + id)\n",
    "        env = OneHotAction(env)\n",
    "    elif suite == \"minecraft\":\n",
    "        import envs.minecraft as minecraft\n",
    "\n",
    "        env = minecraft.make_env(task, size=config.size, break_speed=config.break_speed)\n",
    "        env = OneHotAction(env)\n",
    "    else:\n",
    "        raise NotImplementedError(suite)\n",
    "    env = TimeLimit(env, config.time_limit)\n",
    "    env = SelectAction(env, key=\"action\")\n",
    "    env = UUID(env)\n",
    "    if suite == \"minecraft\":\n",
    "        env = RewardObs(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    set_seed_everywhere(config.seed)\n",
    "    if config.deterministic_run:\n",
    "        enable_deterministic_run()\n",
    "    logdir = pathlib.Path(config.logdir).expanduser()\n",
    "    config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "    config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "    config.steps //= config.action_repeat\n",
    "    config.eval_every //= config.action_repeat\n",
    "    config.log_every //= config.action_repeat\n",
    "    config.time_limit //= config.action_repeat\n",
    "\n",
    "    print(\"Logdir\", logdir)\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "    config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "    step = count_steps(config.traindir)\n",
    "    # step in logger is environmental step\n",
    "    logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "    print(\"Create envs.\")\n",
    "    if config.offline_traindir:\n",
    "        directory = config.offline_traindir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.traindir\n",
    "    train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "    if config.offline_evaldir:\n",
    "        directory = config.offline_evaldir.format(**vars(config))\n",
    "    else:\n",
    "        directory = config.evaldir\n",
    "    eval_eps = load_episodes(directory, limit=1)\n",
    "    make = lambda mode, id: make_env(config, mode, id)\n",
    "    train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "    eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "    if config.parallel:\n",
    "        train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "        eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "    else:\n",
    "        train_envs = [Damy(env) for env in train_envs]\n",
    "        eval_envs = [Damy(env) for env in eval_envs]\n",
    "    acts = train_envs[0].action_space\n",
    "    print(\"Action Space\", acts)\n",
    "    config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "    state = None\n",
    "    if not config.offline_traindir:\n",
    "        prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "        print(f\"Prefill dataset ({prefill} steps).\")\n",
    "        if hasattr(acts, \"discrete\"):\n",
    "            random_actor = OneHotDist(\n",
    "                torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "            )\n",
    "        else:\n",
    "            random_actor = torchd.independent.Independent(\n",
    "                torchd.uniform.Uniform(\n",
    "                    torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                    torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "                ),\n",
    "                1,\n",
    "            )\n",
    "\n",
    "        def random_agent(o, d, s):\n",
    "            action = random_actor.sample()\n",
    "            logprob = random_actor.log_prob(action)\n",
    "            return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "        state = simulate(\n",
    "            random_agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=prefill,\n",
    "        )\n",
    "        logger.step += prefill * config.action_repeat\n",
    "        print(f\"Logger: ({logger.step} steps).\")\n",
    "\n",
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "        logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "            eval_policy = funcpartial(agent, training=False)\n",
    "            simulate(\n",
    "                eval_policy,\n",
    "                eval_envs,\n",
    "                eval_eps,\n",
    "                config.evaldir,\n",
    "                logger,\n",
    "                is_eval=True,\n",
    "                episodes=config.eval_episode_num,\n",
    "            )\n",
    "            if config.video_pred_log:\n",
    "                video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import Loss\n",
    "import yaml\n",
    "\n",
    "from game_configs import GameConfig\n",
    "from utils import (\n",
    "    prepare_kernel_initializers,\n",
    "    prepare_activations,\n",
    ")\n",
    "\n",
    "\n",
    "class ConfigBase:\n",
    "    def parse_field(\n",
    "        self, field_name, default=None, wrapper=None, required=True, dtype=None\n",
    "    ):\n",
    "        if field_name in self.config_dict:\n",
    "            val = self.config_dict[field_name]\n",
    "            # print(\"value: \", val)\n",
    "            print(f\"Using         {field_name:30}: {val}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(val)\n",
    "            return self.config_dict[field_name]\n",
    "\n",
    "        if default is not None:\n",
    "            print(f\"Using default {field_name:30}: {default}\")\n",
    "            if wrapper is not None:\n",
    "                return wrapper(default)\n",
    "            return default\n",
    "\n",
    "        if required:\n",
    "            raise ValueError(\n",
    "                f\"Missing required field without default value: {field_name}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Using         {field_name:30}: {default}\")\n",
    "\n",
    "        if field_name in self._parsed_fields:\n",
    "            print(\"warning: duplicate field: \", field_name)\n",
    "        self._parsed_fields.add(field_name)\n",
    "\n",
    "    def __init__(self, config_dict: dict):\n",
    "        self.config_dict = config_dict\n",
    "        self._parsed_fields = set()\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "\n",
    "class Config(ConfigBase):\n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            o = yaml.load(f, yaml.Loader)\n",
    "            print(o)\n",
    "            a = cls(config_dict=o[\"config_dict\"], game_config=o[\"game\"])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dump(self, filepath: str):\n",
    "        to_dump = dict(config_dict=self.config_dict, game=self.game)\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(to_dump, f, yaml.Dumper)\n",
    "\n",
    "    def __init__(self, config_dict: dict, game_config: GameConfig) -> None:\n",
    "        super().__init__(config_dict)\n",
    "        # could take in a game config and set an action space and observation shape here\n",
    "        # OR DO THAT IN BASE AGENT?\n",
    "        self.game = game_config\n",
    "\n",
    "        self._verify_game()\n",
    "\n",
    "        # not hyperparameters but utility things\n",
    "        self.save_intermediate_weights: bool = self.parse_field(\n",
    "            \"save_intermediate_weights\", False\n",
    "        )\n",
    "\n",
    "        # ADD LEARNING RATE SCHEDULES\n",
    "        self.training_steps: int = self.parse_field(\"training_steps\", 10000)\n",
    "\n",
    "        self.adam_epsilon: float = self.parse_field(\"adam_epsilon\", 1e-6)\n",
    "        self.momentum = self.parse_field(\"momentum\", 0.9)\n",
    "        self.learning_rate: float = self.parse_field(\"learning_rate\", 0.001)\n",
    "        self.clipnorm: int = self.parse_field(\"clipnorm\", 0)\n",
    "        self.optimizer: torch.optim.Optimizer = self.parse_field(\n",
    "            \"optimizer\", torch.optim.Adam\n",
    "        )\n",
    "        self.weight_decay: float = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.loss_function: Loss = self.parse_field(\"loss_function\", required=True)\n",
    "        self.activation = self.parse_field(\n",
    "            \"activation\", \"relu\", wrapper=prepare_activations\n",
    "        )\n",
    "        self.kernel_initializer = self.parse_field(\n",
    "            \"kernel_initializer\",\n",
    "            None,\n",
    "            required=False,\n",
    "            wrapper=kernel_initializer_wrapper,\n",
    "        )\n",
    "\n",
    "        self.minibatch_size: int = self.parse_field(\"minibatch_size\", 64)\n",
    "        self.replay_buffer_size: int = self.parse_field(\"replay_buffer_size\", 5000)\n",
    "        self.min_replay_buffer_size: int = self.parse_field(\n",
    "            \"min_replay_buffer_size\", self.minibatch_size\n",
    "        )\n",
    "        self.num_minibatches: int = self.parse_field(\"num_minibatches\", 1)\n",
    "        self.training_iterations: int = self.parse_field(\"training_iterations\", 1)\n",
    "        self.print_interval: int = self.parse_field(\"print_interval\", 100)\n",
    "\n",
    "    def _verify_game(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def kernel_initializer_wrapper(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    elif isinstance(x, str):\n",
    "        return prepare_kernel_initializers(x)\n",
    "    else:\n",
    "        assert callable(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.symlog_inputs = self.parse_field(\"symlog_inputs\", True)\n",
    "\n",
    "\n",
    "class DecoderConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.mlp_keys = self.parse_field(\"mlp_keys\", \"$^\")\n",
    "        self.cnn_keys = self.parse_field(\"cnn_keys\", \"image\")\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.cnn_depth = self.parse_field(\"cnn_depth\", 32)\n",
    "        self.kernel_size = self.parse_field(\"kernel_size\", 4)\n",
    "        self.minres = self.parse_field(\"minres\", 4)\n",
    "        self.mlp_layers = self.parse_field(\"mlp_layers\", 5)\n",
    "        self.mlp_units = self.parse_field(\"mlp_units\", 1024)\n",
    "        self.cnn_sigmoid = self.parse_field(\"cnn_sigmoid\", False)\n",
    "        self.image_dist = self.parse_field(\"image_dist\", \"mse\")\n",
    "        self.vector_dist = self.parse_field(\"vector_dist\", \"symlog_mse\")\n",
    "        self.outscale = self.parse_field(\"outscale\", 1.0)\n",
    "\n",
    "\n",
    "class HeadConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "        self.layers = self.parse_field(\"layers\", 2)\n",
    "        self.dist = self.parse_field(\"dist\", \"symlog_disc\")\n",
    "        self.loss_scale = self.parse_field(\"loss_scale\", 1.0)\n",
    "        self.outscale = self.parse_field(\"outscale\", 0.0)\n",
    "\n",
    "\n",
    "class DreamerConfig(ConfigBase):\n",
    "    def __init__(self, config_dict):\n",
    "        super().__init__(config_dict)\n",
    "\n",
    "        self.logdir = self.parse_field(\"logdir\", \"./logdir\")\n",
    "        self.traindir = self.parse_field(\"traindir\", \"./traindir\")\n",
    "        self.evaldir = self.parse_field(\"evaldir\", \"./evaldir\")\n",
    "        self.offline_traindir = self.parse_field(\n",
    "            \"offline_traindir\", \"./offline_traindir\"\n",
    "        )\n",
    "        self.offline_evaldir = self.parse_field(\"offline_evaldir\", \"./offline_evaldir\")\n",
    "        self.seed = self.parse_field(\"seed\", 0)\n",
    "        self.deterministic_run = self.parse_field(\"deterministic_run\", False)\n",
    "        self.steps: int = self.parse_field(\"steps\", 1000000, wrapper=float)\n",
    "        self.parallel = self.parse_field(\"parallel\", False)\n",
    "        self.eval_every = self.parse_field(\"eval_every\", 10000, wrapper=float)\n",
    "        self.eval_episode_num = self.parse_field(\"eval_episode_num\", 10)\n",
    "        self.log_every = self.parse_field(\"log_every\", 100, wrapper=float)\n",
    "        self.reset_every = self.parse_field(\"reset_every\", 1000, wrapper=float)\n",
    "        self.device = self.parse_field(\n",
    "            \"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.compile = self.parse_field(\"compile\", False)\n",
    "        self.precision = self.parse_field(\"precision\", \"fp32\")\n",
    "        self.debug = self.parse_field(\"debug\", False)\n",
    "        self.video_pred_log = self.parse_field(\"video_pred_log\", True)\n",
    "\n",
    "        self.task = self.parse_field(\"task\", \"atari_MsPacmanNoFrameskip-v4\")\n",
    "        self.size = self.parse_field(\"size\", (64, 64), wrapper=tuple)\n",
    "        self.envs = self.parse_field(\"envs\", 1)\n",
    "        self.action_repeat = self.parse_field(\"action_repeat\", 4)\n",
    "        self.noops = self.parse_field(\"noops\", 0)\n",
    "        self.lives = self.parse_field(\"lives\", \"unused\")\n",
    "        self.stickey = self.parse_field(\"stickey\", True)\n",
    "        self.actions = self.parse_field(\"actions\", \"needed\")\n",
    "        self.resize = self.parse_field(\"resize\", \"opencv\")\n",
    "        self.time_limit = self.parse_field(\"time_limit\", 1000)\n",
    "        self.grayscale = self.parse_field(\"grayscale\", True)\n",
    "        self.prefill = self.parse_field(\"prefill\", 10)\n",
    "        self.reward_EMA = self.parse_field(\"reward_EMA\", True)\n",
    "\n",
    "        self.dyn_hidden = self.parse_field(\"dyn_hidden\", 256)\n",
    "        self.dyn_deter = self.parse_field(\"dyn_deter\", 256)\n",
    "        self.dyn_stoch = self.parse_field(\"dyn_stoch\", 16)\n",
    "        self.dyn_discrete = self.parse_field(\"dyn_discrete\", 16)\n",
    "        self.dyn_rec_depth = self.parse_field(\"dyn_rec_depth\", 1)\n",
    "        self.dyn_mean_act = self.parse_field(\"dyn_mean_act\", \"none\")\n",
    "        self.dyn_std_act = self.parse_field(\"dyn_std_act\", \"sigmoid2\")\n",
    "        self.dyn_min_std = self.parse_field(\"dyn_min_std\", 0.1)\n",
    "        self.grad_heads = self.parse_field(\"grad_heads\", [\"decoder\", \"reward\", \"cont\"])\n",
    "        self.units = self.parse_field(\"units\", 256)\n",
    "        self.act = self.parse_field(\"act\", \"SiLU\")\n",
    "        self.norm = self.parse_field(\"norm\", True)\n",
    "        self.encoder = EncoderConfig(self.config_dict[\"encoder\"])\n",
    "        self.decoder = DecoderConfig(self.config_dict[\"decoder\"])\n",
    "        self.reward_head = HeadConfig(self.config_dict[\"reward_head\"])\n",
    "        self.cont_head = HeadConfig(self.config_dict[\"cont_head\"])\n",
    "        self.dyn_scale = self.parse_field(\"dyn_scale\", 0.5)\n",
    "        self.rep_scale = self.parse_field(\"rep_scale\", 0.1)\n",
    "        self.kl_free = self.parse_field(\"kl_free\", 1.0)\n",
    "        self.weight_decay = self.parse_field(\"weight_decay\", 0.0)\n",
    "        self.unimix_ratio = self.parse_field(\"unimix_ratio\", 0.01)\n",
    "        self.initial = self.parse_field(\"initial\", \"learned\")\n",
    "\n",
    "        self.batch_size = self.parse_field(\"batch_size\", 8)\n",
    "        self.batch_length = self.parse_field(\"batch_length\", 32)\n",
    "        self.train_ratio = self.parse_field(\"train_ratio\", 512)\n",
    "        self.pretrain: int = self.parse_field(\"pretrain\", 100)\n",
    "        self.model_lr = self.parse_field(\"model_lr\", 1e-4, wrapper=float)\n",
    "        self.opt_eps = self.parse_field(\"opt_eps\", 1e-8, wrapper=float)\n",
    "        self.grad_clip: int = self.parse_field(\"grad_clip\", 1000, wrapper=float)\n",
    "        self.dataset_size: int = self.parse_field(\n",
    "            \"dataset_size\", 1000000, wrapper=float\n",
    "        )\n",
    "        self.opt = self.parse_field(\"opt\", \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using         logdir                        : ./logdir\n",
      "Using         traindir                      : None\n",
      "Using         evaldir                       : None\n",
      "Using         offline_traindir              : None\n",
      "Using         offline_evaldir               : None\n",
      "Using         seed                          : 0\n",
      "Using         deterministic_run             : False\n",
      "Using         steps                         : 1e1\n",
      "Using         parallel                      : False\n",
      "Using         eval_every                    : 1e4\n",
      "Using         eval_episode_num              : 10\n",
      "Using         log_every                     : 10\n",
      "Using         reset_every                   : 0\n",
      "Using         device                        : cpu\n",
      "Using         compile                       : True\n",
      "Using         precision                     : 16\n",
      "Using         debug                         : False\n",
      "Using         video_pred_log                : False\n",
      "Using         task                          : poker_universal_poker\n",
      "Using         size                          : [64, 64]\n",
      "Using         envs                          : 1\n",
      "Using         action_repeat                 : 2\n",
      "Using default noops                         : 0\n",
      "Using default lives                         : unused\n",
      "Using default stickey                       : True\n",
      "Using default actions                       : needed\n",
      "Using default resize                        : opencv\n",
      "Using         time_limit                    : 1000\n",
      "Using         grayscale                     : False\n",
      "Using         prefill                       : 2500\n",
      "Using         reward_EMA                    : True\n",
      "Using         dyn_hidden                    : 256\n",
      "Using         dyn_deter                     : 256\n",
      "Using         dyn_stoch                     : 16\n",
      "Using         dyn_discrete                  : 16\n",
      "Using         dyn_rec_depth                 : 1\n",
      "Using         dyn_mean_act                  : none\n",
      "Using         dyn_std_act                   : sigmoid2\n",
      "Using         dyn_min_std                   : 0.1\n",
      "Using         grad_heads                    : ['decoder', 'reward', 'cont']\n",
      "Using         units                         : 256\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         symlog_inputs                 : True\n",
      "Using         mlp_keys                      : .*\n",
      "Using         cnn_keys                      : $^\n",
      "Using         act                           : SiLU\n",
      "Using         norm                          : True\n",
      "Using         cnn_depth                     : 32\n",
      "Using         kernel_size                   : 4\n",
      "Using         minres                        : 4\n",
      "Using         mlp_layers                    : 5\n",
      "Using         mlp_units                     : 512\n",
      "Using         cnn_sigmoid                   : False\n",
      "Using         image_dist                    : mse\n",
      "Using         vector_dist                   : symlog_mse\n",
      "Using         outscale                      : 1.0\n",
      "Using         layers                        : 2\n",
      "Using         dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 0.0\n",
      "Using         layers                        : 2\n",
      "Using default dist                          : symlog_disc\n",
      "Using         loss_scale                    : 1.0\n",
      "Using         outscale                      : 1.0\n",
      "Using         dyn_scale                     : 0.5\n",
      "Using         rep_scale                     : 0.1\n",
      "Using         kl_free                       : 1.0\n",
      "Using         weight_decay                  : 0.0\n",
      "Using         unimix_ratio                  : 0.01\n",
      "Using         initial                       : learned\n",
      "Using         batch_size                    : 8\n",
      "Using         batch_length                  : 32\n",
      "Using         train_ratio                   : 512\n",
      "Using         pretrain                      : 100\n",
      "Using         model_lr                      : 1e-4\n",
      "Using         opt_eps                       : 1e-8\n",
      "Using         grad_clip                     : 1000\n",
      "Using         dataset_size                  : 1000000\n",
      "Using         opt                           : adam\n"
     ]
    }
   ],
   "source": [
    "configs = yaml.safe_load(pathlib.Path(\"./configs.yaml\").read_text())\n",
    "config_dict = configs[\"defaults\"]\n",
    "config_dict[\"logdir\"] = \"./logdir\"\n",
    "config_dict[\"offline_traindir\"] = None  # \"./offline_traindir\"\n",
    "config_dict[\"offline_evaldir\"] = None  # \"./offline_evaldir\"\n",
    "config = DreamerConfig(config_dict=config_dict)\n",
    "# config = DreamerConfig(config_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "class RSSM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        stoch=30,\n",
    "        deter=200,\n",
    "        hidden=200,\n",
    "        rec_depth=1,\n",
    "        discrete=False,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        mean_act=\"none\",\n",
    "        std_act=\"softplus\",\n",
    "        min_std=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        initial=\"learned\",\n",
    "        num_actions=None,\n",
    "        embed=None,\n",
    "        device=None,\n",
    "    ):\n",
    "        super(RSSM, self).__init__()\n",
    "        self._stoch = stoch\n",
    "        self._deter = deter\n",
    "        self._hidden = hidden\n",
    "        self._min_std = min_std\n",
    "        self._rec_depth = rec_depth\n",
    "        self._discrete = discrete\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._mean_act = mean_act\n",
    "        self._std_act = std_act\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._initial = initial\n",
    "        self._num_actions = num_actions\n",
    "        self._embed = embed\n",
    "        self._device = device\n",
    "\n",
    "        inp_layers = []\n",
    "        if self._discrete:\n",
    "            inp_dim = self._stoch * self._discrete + num_actions\n",
    "        else:\n",
    "            inp_dim = self._stoch + num_actions\n",
    "        inp_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            inp_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        inp_layers.append(act())\n",
    "        self._img_in_layers = nn.Sequential(*inp_layers)\n",
    "        self._img_in_layers.apply(weight_init)\n",
    "        self._cell = GRUCell(self._hidden, self._deter, norm=norm)\n",
    "        self._cell.apply(weight_init)\n",
    "\n",
    "        img_out_layers = []\n",
    "        inp_dim = self._deter\n",
    "        img_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            img_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        img_out_layers.append(act())\n",
    "        self._img_out_layers = nn.Sequential(*img_out_layers)\n",
    "        self._img_out_layers.apply(weight_init)\n",
    "\n",
    "        obs_out_layers = []\n",
    "        inp_dim = self._deter + self._embed\n",
    "        obs_out_layers.append(nn.Linear(inp_dim, self._hidden, bias=False))\n",
    "        if norm:\n",
    "            obs_out_layers.append(nn.LayerNorm(self._hidden, eps=1e-03))\n",
    "        obs_out_layers.append(act())\n",
    "        self._obs_out_layers = nn.Sequential(*obs_out_layers)\n",
    "        self._obs_out_layers.apply(weight_init)\n",
    "\n",
    "        if self._discrete:\n",
    "            self._imgs_stat_layer = nn.Linear(\n",
    "                self._hidden, self._stoch * self._discrete\n",
    "            )\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, self._stoch * self._discrete)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "        else:\n",
    "            self._imgs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._imgs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "            self._obs_stat_layer = nn.Linear(self._hidden, 2 * self._stoch)\n",
    "            self._obs_stat_layer.apply(uniform_weight_init(1.0))\n",
    "\n",
    "        if self._initial == \"learned\":\n",
    "            self.W = torch.nn.Parameter(\n",
    "                torch.zeros((1, self._deter), device=torch.device(self._device)),\n",
    "                requires_grad=True,\n",
    "            )\n",
    "\n",
    "    def initial(self, batch_size):\n",
    "        deter = torch.zeros(batch_size, self._deter, device=self._device)\n",
    "        if self._discrete:\n",
    "            state = dict(\n",
    "                logit=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                stoch=torch.zeros(\n",
    "                    [batch_size, self._stoch, self._discrete], device=self._device\n",
    "                ),\n",
    "                deter=deter,\n",
    "            )\n",
    "        else:\n",
    "            state = dict(\n",
    "                mean=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                std=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                stoch=torch.zeros([batch_size, self._stoch], device=self._device),\n",
    "                deter=deter,\n",
    "            )\n",
    "        if self._initial == \"zeros\":\n",
    "            return state\n",
    "        elif self._initial == \"learned\":\n",
    "            state[\"deter\"] = torch.tanh(self.W).repeat(batch_size, 1)\n",
    "            state[\"stoch\"] = self.get_stoch(state[\"deter\"])\n",
    "            return state\n",
    "        else:\n",
    "            raise NotImplementedError(self._initial)\n",
    "\n",
    "    def observe(self, embed, action, is_first, state=None):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        # (batch, time, ch) -> (time, batch, ch)\n",
    "        embed, action, is_first = swap(embed), swap(action), swap(is_first)\n",
    "        # prev_state[0] means selecting posterior of return(posterior, prior) from obs_step\n",
    "        post, prior = static_scan(\n",
    "            lambda prev_state, prev_act, embed, is_first: self.obs_step(\n",
    "                prev_state[0], prev_act, embed, is_first\n",
    "            ),\n",
    "            (action, embed, is_first),\n",
    "            (state, state),\n",
    "        )\n",
    "\n",
    "        # (batch, time, stoch, discrete_num) -> (batch, time, stoch, discrete_num)\n",
    "        post = {k: swap(v) for k, v in post.items()}\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return post, prior\n",
    "\n",
    "    def imagine_with_action(self, action, state):\n",
    "        swap = lambda x: x.permute([1, 0] + list(range(2, len(x.shape))))\n",
    "        assert isinstance(state, dict), state\n",
    "        action = swap(action)\n",
    "        prior = static_scan(self.img_step, [action], state)\n",
    "        prior = prior[0]\n",
    "        prior = {k: swap(v) for k, v in prior.items()}\n",
    "        return prior\n",
    "\n",
    "    def get_feat(self, state):\n",
    "        stoch = state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            stoch = stoch.reshape(shape)\n",
    "        return torch.cat([stoch, state[\"deter\"]], -1)\n",
    "\n",
    "    def get_dist(self, state, dtype=None):\n",
    "        if self._discrete:\n",
    "            logit = state[\"logit\"]\n",
    "            dist = torchd.independent.Independent(\n",
    "                OneHotDist(logit, unimix_ratio=self._unimix_ratio), 1\n",
    "            )\n",
    "        else:\n",
    "            mean, std = state[\"mean\"], state[\"std\"]\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, std), 1)\n",
    "            )\n",
    "        return dist\n",
    "\n",
    "    def obs_step(self, prev_state, prev_action, embed, is_first, sample=True):\n",
    "        # initialize all prev_state\n",
    "        if prev_state == None or torch.sum(is_first) == len(is_first):\n",
    "            prev_state = self.initial(len(is_first))\n",
    "            prev_action = torch.zeros(\n",
    "                (len(is_first), self._num_actions), device=self._device\n",
    "            )\n",
    "        # overwrite the prev_state only where is_first=True\n",
    "        elif torch.sum(is_first) > 0:\n",
    "            print(is_first.shape)\n",
    "            is_first = is_first[:, None]\n",
    "            print(is_first.shape)\n",
    "            prev_action *= 1.0 - is_first\n",
    "            init_state = self.initial(len(is_first))\n",
    "            for key, val in prev_state.items():\n",
    "                is_first_r = torch.reshape(\n",
    "                    is_first,\n",
    "                    is_first.shape + (1,) * (len(val.shape) - len(is_first.shape)),\n",
    "                )\n",
    "                prev_state[key] = (\n",
    "                    val * (1.0 - is_first_r) + init_state[key] * is_first_r\n",
    "                )\n",
    "        # print(\"prev_state shape: \", prev_state[\"deter\"].shape)\n",
    "        prior = self.img_step(prev_state, prev_action)\n",
    "        # print(\"embed shape: \", embed.shape)\n",
    "        # print(\"prior shape: \", prior[\"deter\"].shape)\n",
    "        x = torch.cat([prior[\"deter\"], embed], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # print(self._deter + self._embed)\n",
    "        # print(self._hidden)\n",
    "        # (batch_size, prior_deter + embed) -> (batch_size, hidden)\n",
    "        x = self._obs_out_layers(x)\n",
    "        # (batch_size, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"obs\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        post = {\"stoch\": stoch, \"deter\": prior[\"deter\"], **stats}\n",
    "        return post, prior\n",
    "\n",
    "    def img_step(self, prev_state, prev_action, sample=True):\n",
    "        # (batch, stoch, discrete_num)\n",
    "        prev_stoch = prev_state[\"stoch\"]\n",
    "        if self._discrete:\n",
    "            shape = list(prev_stoch.shape[:-2]) + [self._stoch * self._discrete]\n",
    "            # (batch, stoch, discrete_num) -> (batch, stoch * discrete_num)\n",
    "            prev_stoch = prev_stoch.reshape(shape)\n",
    "        # (batch, stoch * discrete_num) -> (batch, stoch * discrete_num + action)\n",
    "        x = torch.cat([prev_stoch, prev_action], -1)\n",
    "        # (batch, stoch * discrete_num + action, embed) -> (batch, hidden)\n",
    "        x = self._img_in_layers(x)\n",
    "        for _ in range(self._rec_depth):  # rec depth is not correctly implemented\n",
    "            deter = prev_state[\"deter\"]\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            # (batch, hidden), (batch, deter) -> (batch, deter), (batch, deter)\n",
    "            x, deter = self._cell(x, [deter])\n",
    "            # print(\"x shape: \", x.shape)\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "            deter = deter[0]  # Keras wraps the state in a list.\n",
    "            # print(\"deter shape: \", deter.shape)\n",
    "        # (batch, deter) -> (batch, hidden)\n",
    "        x = self._img_out_layers(x)\n",
    "        # (batch, hidden) -> (batch_size, stoch, discrete_num)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        if sample:\n",
    "            stoch = self.get_dist(stats).sample()\n",
    "        else:\n",
    "            stoch = self.get_dist(stats).mode()\n",
    "        prior = {\"stoch\": stoch, \"deter\": deter, **stats}\n",
    "        return prior\n",
    "\n",
    "    def get_stoch(self, deter):\n",
    "        x = self._img_out_layers(deter)\n",
    "        stats = self._suff_stats_layer(\"ims\", x)\n",
    "        dist = self.get_dist(stats)\n",
    "        return dist.mode()\n",
    "\n",
    "    def _suff_stats_layer(self, name, x):\n",
    "        if self._discrete:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            logit = x.reshape(list(x.shape[:-1]) + [self._stoch, self._discrete])\n",
    "            return {\"logit\": logit}\n",
    "        else:\n",
    "            if name == \"ims\":\n",
    "                x = self._imgs_stat_layer(x)\n",
    "            elif name == \"obs\":\n",
    "                x = self._obs_stat_layer(x)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            mean, std = torch.split(x, [self._stoch] * 2, -1)\n",
    "            mean = {\n",
    "                \"none\": lambda: mean,\n",
    "                \"tanh5\": lambda: 5.0 * torch.tanh(mean / 5.0),\n",
    "            }[self._mean_act]()\n",
    "            std = {\n",
    "                \"softplus\": lambda: torch.softplus(std),\n",
    "                \"abs\": lambda: torch.abs(std + 1),\n",
    "                \"sigmoid\": lambda: torch.sigmoid(std),\n",
    "                \"sigmoid2\": lambda: 2 * torch.sigmoid(std / 2),\n",
    "            }[self._std_act]()\n",
    "            std = std + self._min_std\n",
    "            return {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    def kl_loss(self, post, prior, free, dyn_scale, rep_scale):\n",
    "        kld = torchd.kl.kl_divergence\n",
    "        dist = lambda x: self.get_dist(x)\n",
    "        sg = lambda x: {k: v.detach() for k, v in x.items()}\n",
    "\n",
    "        rep_loss = value = kld(\n",
    "            dist(post) if self._discrete else dist(post)._dist,\n",
    "            dist(sg(prior)) if self._discrete else dist(sg(prior))._dist,\n",
    "        )\n",
    "        dyn_loss = kld(\n",
    "            dist(sg(post)) if self._discrete else dist(sg(post))._dist,\n",
    "            dist(prior) if self._discrete else dist(prior)._dist,\n",
    "        )\n",
    "        # this is implemented using maximum at the original repo as the gradients are not backpropagated for the out of limits.\n",
    "        rep_loss = torch.clip(rep_loss, min=free)\n",
    "        dyn_loss = torch.clip(dyn_loss, min=free)\n",
    "        loss = dyn_scale * dyn_loss + rep_scale * rep_loss\n",
    "\n",
    "        return loss, value, dyn_loss, rep_loss\n",
    "\n",
    "\n",
    "class MultiEncoder(nn.Module):\n",
    "    def __init__(self, shapes, config):\n",
    "        super(MultiEncoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\", \"reward\")\n",
    "        shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if k not in excluded and not k.startswith(\"log_\")\n",
    "        }\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "\n",
    "        print(shapes.items())\n",
    "        print(config.mlp_keys)\n",
    "        print(config.cnn_keys)\n",
    "        for k, v in shapes.items():\n",
    "            print(\"cnn\")\n",
    "            print(len(v) == 3)\n",
    "            print(re.match(self.config.cnn_keys, k))\n",
    "            print(self.config.cnn_keys)\n",
    "            print(k)\n",
    "            print(\"mlp\")\n",
    "            print(len(v) in (1, 2))\n",
    "            print(re.match(self.config.mlp_keys, k))\n",
    "            print(self.config.mlp_keys)\n",
    "            print(k)\n",
    "\n",
    "        print(\"Encoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Encoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        self.outdim = 0\n",
    "        if self.cnn_shapes:\n",
    "            input_ch = sum([v[-1] for v in self.cnn_shapes.values()])\n",
    "            input_shape = tuple(self.cnn_shapes.values())[0][:2] + (input_ch,)\n",
    "            self._cnn = ConvEncoder(\n",
    "                input_shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "            )\n",
    "            self.outdim += self._cnn.outdim\n",
    "        if self.mlp_shapes:\n",
    "            input_size = sum([sum(v) for v in self.mlp_shapes.values()])\n",
    "            for v in self.mlp_shapes.values():\n",
    "                print(\"v: \", v)\n",
    "            print(\"input_size: \", input_size)\n",
    "            self._mlp = MLP(\n",
    "                input_size,\n",
    "                None,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                symlog_inputs=self.config.symlog_inputs,\n",
    "                name=\"Encoder\",\n",
    "            )\n",
    "            self.outdim += self.config.mlp_units\n",
    "\n",
    "    def forward(self, obs):\n",
    "        outputs = []\n",
    "        if self.cnn_shapes:\n",
    "            inputs = torch.cat([obs[k] for k in self.cnn_shapes], -1)\n",
    "            outputs.append(self._cnn(inputs))\n",
    "            # print(\"CNN output shape: \", outputs[-1].shape)\n",
    "        if self.mlp_shapes:\n",
    "            # print(\"obs\", obs)\n",
    "            inputs = torch.cat([obs[k] for k in self.mlp_shapes], -1)\n",
    "            # print(inputs.shape)\n",
    "            outputs.append(self._mlp(inputs))\n",
    "            # print(\"MLP output shape: \", outputs[-1].shape)\n",
    "        outputs = torch.cat(outputs, -1)\n",
    "        # print(\"Encoder output shape: \", outputs.shape)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MultiDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shapes,\n",
    "        config,\n",
    "    ):\n",
    "        super(MultiDecoder, self).__init__()\n",
    "        self.config = config\n",
    "        excluded = (\"is_first\", \"is_last\", \"is_terminal\")\n",
    "        shapes = {k: v for k, v in shapes.items() if k not in excluded}\n",
    "        self.cnn_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) == 3 and re.match(self.config.cnn_keys, k)\n",
    "        }\n",
    "        self.mlp_shapes = {\n",
    "            k: v\n",
    "            for k, v in shapes.items()\n",
    "            if len(v) in (1, 2) and re.match(self.config.mlp_keys, k)\n",
    "        }\n",
    "        print(\"Decoder CNN shapes:\", self.cnn_shapes)\n",
    "        print(\"Decoder MLP shapes:\", self.mlp_shapes)\n",
    "\n",
    "        if self.cnn_shapes:\n",
    "            some_shape = list(self.cnn_shapes.values())[0]\n",
    "            shape = (sum(x[-1] for x in self.cnn_shapes.values()),) + some_shape[:-1]\n",
    "            self._cnn = ConvDecoder(\n",
    "                feat_size,\n",
    "                shape,\n",
    "                self.config.cnn_depth,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.kernel_size,\n",
    "                self.config.minres,\n",
    "                outscale=self.config.outscale,\n",
    "                cnn_sigmoid=self.config.cnn_sigmoid,\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            self._mlp = MLP(\n",
    "                feat_size,\n",
    "                self.mlp_shapes,\n",
    "                self.config.mlp_layers,\n",
    "                self.config.mlp_units,\n",
    "                self.config.act,\n",
    "                self.config.norm,\n",
    "                self.config.vector_dist,\n",
    "                outscale=self.config.outscale,\n",
    "                name=\"Decoder\",\n",
    "            )\n",
    "        self._image_dist = self.config.image_dist\n",
    "\n",
    "    def forward(self, features):\n",
    "        dists = {}\n",
    "        if self.cnn_shapes:\n",
    "            feat = features\n",
    "            outputs = self._cnn(feat)\n",
    "            split_sizes = [v[-1] for v in self.cnn_shapes.values()]\n",
    "            outputs = torch.split(outputs, split_sizes, -1)\n",
    "            dists.update(\n",
    "                {\n",
    "                    key: self._make_image_dist(output)\n",
    "                    for key, output in zip(self.cnn_shapes.keys(), outputs)\n",
    "                }\n",
    "            )\n",
    "        if self.mlp_shapes:\n",
    "            dists.update(self._mlp(features))\n",
    "        return dists\n",
    "\n",
    "    def _make_image_dist(self, mean):\n",
    "        if self._image_dist == \"normal\":\n",
    "            return ContDist(\n",
    "                torchd.independent.Independent(torchd.normal.Normal(mean, 1), 3)\n",
    "            )\n",
    "        if self._image_dist == \"mse\":\n",
    "            return MSEDist(mean)\n",
    "        raise NotImplementedError(self._image_dist)\n",
    "\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        depth=32,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "    ):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        h, w, input_ch = input_shape\n",
    "        stages = int(np.log2(h) - np.log2(minres))\n",
    "        in_dim = input_ch\n",
    "        out_dim = depth\n",
    "        layers = []\n",
    "        for i in range(stages):\n",
    "            layers.append(\n",
    "                Conv2dSamePad(\n",
    "                    in_channels=in_dim,\n",
    "                    out_channels=out_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=2,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim *= 2\n",
    "            h, w = h // 2, w // 2\n",
    "\n",
    "        # self.outdim = out_dim // 2 * h * w\n",
    "        # print(\"h, w: \", h, w)\n",
    "        # print(\"Encoder output shape (outdim): \", self.outdim)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # print(\"Encoder layers: \", self.layers)\n",
    "        # print(\"Encoder layers shape: \", self.layers[0].weight.shape)\n",
    "        self.layers.apply(weight_init)\n",
    "        self.outdim = self.calculate_outdim(input_shape)\n",
    "\n",
    "    def calculate_outdim(self, input_shape):\n",
    "        obs = torch.randn(1, *input_shape)\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]]).shape[-1]\n",
    "\n",
    "    def forward(self, obs):\n",
    "        obs -= 0.5\n",
    "        # (batch, time, h, w, ch) -> (batch * time, h, w, ch)\n",
    "        x = obs.reshape((-1,) + tuple(obs.shape[-3:]))\n",
    "        # print(\"obs shape: \", obs.shape)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, h, w, ch) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        x = self.layers(x)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, ...) -> (batch * time, -1)\n",
    "        x = x.reshape([x.shape[0], np.prod(x.shape[1:])])\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        # (batch * time, -1) -> (batch, time, -1)\n",
    "        return x.reshape(list(obs.shape[:-3]) + [x.shape[-1]])\n",
    "\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_size,\n",
    "        shape=(3, 64, 64),\n",
    "        depth=32,\n",
    "        act=nn.ELU,\n",
    "        norm=True,\n",
    "        kernel_size=4,\n",
    "        minres=4,\n",
    "        outscale=1.0,\n",
    "        cnn_sigmoid=False,\n",
    "    ):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._shape = shape\n",
    "        self._cnn_sigmoid = cnn_sigmoid\n",
    "        layer_num = int(np.log2(shape[1]) - np.log2(minres))\n",
    "        self._minres = minres\n",
    "        out_ch = minres**2 * depth * 2 ** (layer_num - 1)\n",
    "        self._embed_size = out_ch\n",
    "\n",
    "        self._linear_layer = nn.Linear(feat_size, out_ch)\n",
    "        self._linear_layer.apply(uniform_weight_init(outscale))\n",
    "        in_dim = out_ch // (minres**2)\n",
    "        out_dim = in_dim // 2\n",
    "\n",
    "        layers = []\n",
    "        h, w = minres, minres\n",
    "        for i in range(layer_num):\n",
    "            bias = False\n",
    "            if i == layer_num - 1:\n",
    "                out_dim = self._shape[0]\n",
    "                act = False\n",
    "                bias = True\n",
    "                norm = False\n",
    "\n",
    "            if i != 0:\n",
    "                in_dim = 2 ** (layer_num - (i - 1) - 2) * depth\n",
    "            pad_h, outpad_h = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            pad_w, outpad_w = self.calc_same_pad(k=kernel_size, s=2, d=1)\n",
    "            layers.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    kernel_size,\n",
    "                    2,\n",
    "                    padding=(pad_h, pad_w),\n",
    "                    output_padding=(outpad_h, outpad_w),\n",
    "                    bias=bias,\n",
    "                )\n",
    "            )\n",
    "            if norm:\n",
    "                layers.append(ImgChLayerNorm(out_dim))\n",
    "            if act:\n",
    "                layers.append(act())\n",
    "            in_dim = out_dim\n",
    "            out_dim //= 2\n",
    "            h, w = h * 2, w * 2\n",
    "        [m.apply(weight_init) for m in layers[:-1]]\n",
    "        layers[-1].apply(uniform_weight_init(outscale))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def calc_same_pad(self, k, s, d):\n",
    "        val = d * (k - 1) - s + 1\n",
    "        pad = math.ceil(val / 2)\n",
    "        outpad = pad * 2 - val\n",
    "        return pad, outpad\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = self._linear_layer(features)\n",
    "        # (batch, time, -1) -> (batch * time, h, w, ch)\n",
    "        x = x.reshape(\n",
    "            [-1, self._minres, self._minres, self._embed_size // self._minres**2]\n",
    "        )\n",
    "        # (batch, time, -1) -> (batch * time, ch, h, w)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.layers(x)\n",
    "        # (batch, time, -1) -> (batch, time, ch, h, w)\n",
    "        mean = x.reshape(features.shape[:-1] + self._shape)\n",
    "        # (batch, time, ch, h, w) -> (batch, time, h, w, ch)\n",
    "        mean = mean.permute(0, 1, 3, 4, 2)\n",
    "        if self._cnn_sigmoid:\n",
    "            mean = F.sigmoid(mean)\n",
    "        else:\n",
    "            mean += 0.5\n",
    "        return mean\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim,\n",
    "        shape,\n",
    "        layers,\n",
    "        units,\n",
    "        act=\"SiLU\",\n",
    "        norm=True,\n",
    "        dist=\"normal\",\n",
    "        std=1.0,\n",
    "        min_std=0.1,\n",
    "        max_std=1.0,\n",
    "        absmax=None,\n",
    "        temp=0.1,\n",
    "        unimix_ratio=0.01,\n",
    "        outscale=1.0,\n",
    "        symlog_inputs=False,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        name=\"NoName\",\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self._shape = (shape,) if isinstance(shape, int) else shape\n",
    "        if self._shape is not None and len(self._shape) == 0:\n",
    "            self._shape = (1,)\n",
    "        act = getattr(torch.nn, act)\n",
    "        self._dist = dist\n",
    "        self._std = std if isinstance(std, str) else torch.tensor((std,), device=device)\n",
    "        self._min_std = min_std\n",
    "        self._max_std = max_std\n",
    "        self._absmax = absmax\n",
    "        self._temp = temp\n",
    "        self._unimix_ratio = unimix_ratio\n",
    "        self._symlog_inputs = symlog_inputs\n",
    "        self._device = device\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for i in range(layers):\n",
    "            self.layers.add_module(\n",
    "                f\"{name}_linear{i}\", nn.Linear(inp_dim, units, bias=False)\n",
    "            )\n",
    "            if norm:\n",
    "                self.layers.add_module(\n",
    "                    f\"{name}_norm{i}\", nn.LayerNorm(units, eps=1e-03)\n",
    "                )\n",
    "            self.layers.add_module(f\"{name}_act{i}\", act())\n",
    "            if i == 0:\n",
    "                inp_dim = units\n",
    "        self.layers.apply(weight_init)\n",
    "\n",
    "        if isinstance(self._shape, dict):\n",
    "            self.mean_layer = nn.ModuleDict()\n",
    "            for name, shape in self._shape.items():\n",
    "                self.mean_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.ModuleDict()\n",
    "                for name, shape in self._shape.items():\n",
    "                    self.std_layer[name] = nn.Linear(inp_dim, np.prod(shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "        elif self._shape is not None:\n",
    "            self.mean_layer = nn.Linear(inp_dim, np.prod(self._shape))\n",
    "            self.mean_layer.apply(uniform_weight_init(outscale))\n",
    "            if self._std == \"learned\":\n",
    "                assert dist in (\"tanh_normal\", \"normal\", \"trunc_normal\", \"huber\"), dist\n",
    "                self.std_layer = nn.Linear(units, np.prod(self._shape))\n",
    "                self.std_layer.apply(uniform_weight_init(outscale))\n",
    "\n",
    "    def forward(self, features, dtype=None):\n",
    "        x = features\n",
    "        # print(\"MLP input shape: \", x.shape)\n",
    "        if self._symlog_inputs:\n",
    "            x = symlog(x)\n",
    "            # print(\"MLP input shape after symlog: \", x.shape)\n",
    "        out = self.layers(x)\n",
    "        # print(\"MLP output shape: \", out.shape)\n",
    "        # Used for encoder output\n",
    "        if self._shape is None:\n",
    "            return out\n",
    "        if isinstance(self._shape, dict):\n",
    "            dists = {}\n",
    "            for name, shape in self._shape.items():\n",
    "                mean = self.mean_layer[name](out)\n",
    "                if self._std == \"learned\":\n",
    "                    std = self.std_layer[name](out)\n",
    "                else:\n",
    "                    std = self._std\n",
    "                dists.update({name: self.dist(self._dist, mean, std, shape)})\n",
    "            return dists\n",
    "        else:\n",
    "            mean = self.mean_layer(out)\n",
    "            if self._std == \"learned\":\n",
    "                std = self.std_layer(out)\n",
    "            else:\n",
    "                std = self._std\n",
    "            return self.dist(self._dist, mean, std, self._shape)\n",
    "\n",
    "    def dist(self, dist, mean, std, shape):\n",
    "        if dist == \"tanh_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = F.softplus(std) + self._min_std\n",
    "            dist = torchd.normal.Normal(mean, std)\n",
    "            dist = torchd.transformed_distribution.TransformedDistribution(\n",
    "                dist, TanhBijector()\n",
    "            )\n",
    "            dist = torchd.independent.Independent(dist, 1)\n",
    "            dist = SampleDist(dist)\n",
    "        elif dist == \"normal\":\n",
    "            std = (self._max_std - self._min_std) * torch.sigmoid(\n",
    "                std + 2.0\n",
    "            ) + self._min_std\n",
    "            dist = torchd.normal.Normal(torch.tanh(mean), std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"normal_std_fixed\":\n",
    "            dist = torchd.normal.Normal(mean, self._std)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"trunc_normal\":\n",
    "            mean = torch.tanh(mean)\n",
    "            std = 2 * torch.sigmoid(std / 2) + self._min_std\n",
    "            dist = SafeTruncatedNormal(mean, std, -1, 1)\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(dist, 1), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"onehot\":\n",
    "            dist = OneHotDist(mean, unimix_ratio=self._unimix_ratio)\n",
    "        elif dist == \"onehot_gumble\":\n",
    "            dist = ContDist(\n",
    "                torchd.gumbel.Gumbel(mean, 1 / self._temp), absmax=self._absmax\n",
    "            )\n",
    "        elif dist == \"huber\":\n",
    "            dist = ContDist(\n",
    "                torchd.independent.Independent(\n",
    "                    UnnormalizedHuber(mean, std, 1.0),\n",
    "                    len(shape),\n",
    "                    absmax=self._absmax,\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"binary\":\n",
    "            dist = Bernoulli(\n",
    "                torchd.independent.Independent(\n",
    "                    torchd.bernoulli.Bernoulli(logits=mean), len(shape)\n",
    "                )\n",
    "            )\n",
    "        elif dist == \"symlog_disc\":\n",
    "            dist = DiscDist(logits=mean, device=self._device)\n",
    "        elif dist == \"symlog_mse\":\n",
    "            dist = SymlogDist(mean)\n",
    "        else:\n",
    "            raise NotImplementedError(dist)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, inp_size, size, norm=True, act=torch.tanh, update_bias=-1):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self._inp_size = inp_size\n",
    "        self._size = size\n",
    "        self._act = act\n",
    "        self._update_bias = update_bias\n",
    "        self.layers = nn.Sequential()\n",
    "        self.layers.add_module(\n",
    "            \"GRU_linear\", nn.Linear(inp_size + size, 3 * size, bias=False)\n",
    "        )\n",
    "        if norm:\n",
    "            self.layers.add_module(\"GRU_norm\", nn.LayerNorm(3 * size, eps=1e-03))\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._size\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        state = state[0]  # Keras wraps the state in a list.\n",
    "        parts = self.layers(torch.cat([inputs, state], -1))\n",
    "        reset, cand, update = torch.split(parts, [self._size] * 3, -1)\n",
    "        reset = torch.sigmoid(reset)\n",
    "        cand = self._act(reset * cand)\n",
    "        update = torch.sigmoid(update + self._update_bias)\n",
    "        output = update * cand + (1 - update) * state\n",
    "        return output, [output]\n",
    "\n",
    "\n",
    "class Conv2dSamePad(torch.nn.Conv2d):\n",
    "    def calc_same_pad(self, i, k, s, d):\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        pad_h = self.calc_same_pad(\n",
    "            i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0]\n",
    "        )\n",
    "        pad_w = self.calc_same_pad(\n",
    "            i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1]\n",
    "        )\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "\n",
    "        ret = F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "        return ret\n",
    "\n",
    "\n",
    "class ImgChLayerNorm(nn.Module):\n",
    "    def __init__(self, ch, eps=1e-03):\n",
    "        super(ImgChLayerNorm, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(ch, eps=eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class RewardEMA:\n",
    "    \"\"\"running mean and std\"\"\"\n",
    "\n",
    "    def __init__(self, device, alpha=1e-2):\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.range = torch.tensor([0.05, 0.95], device=device)\n",
    "\n",
    "    def __call__(self, x, ema_vals):\n",
    "        flat_x = torch.flatten(x.detach())\n",
    "        x_quantile = torch.quantile(input=flat_x, q=self.range)\n",
    "        # this should be in-place operation\n",
    "        ema_vals[:] = self.alpha * x_quantile + (1 - self.alpha) * ema_vals\n",
    "        scale = torch.clip(ema_vals[1] - ema_vals[0], min=1.0)\n",
    "        offset = ema_vals[0]\n",
    "        return offset.detach(), scale.detach()\n",
    "\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, step, config):\n",
    "        super(WorldModel, self).__init__()\n",
    "        self._step = step\n",
    "        self._use_amp = True if config.precision == 16 else False\n",
    "        self._config = config\n",
    "        shapes = {k: tuple(v.shape) for k, v in obs_space.spaces.items()}\n",
    "        self.encoder = MultiEncoder(shapes, config.encoder)\n",
    "        self.embed_size = self.encoder.outdim\n",
    "        self.dynamics = RSSM(\n",
    "            config.dyn_stoch,\n",
    "            config.dyn_deter,\n",
    "            config.dyn_hidden,\n",
    "            config.dyn_rec_depth,\n",
    "            config.dyn_discrete,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            config.dyn_mean_act,\n",
    "            config.dyn_std_act,\n",
    "            config.dyn_min_std,\n",
    "            config.unimix_ratio,\n",
    "            config.initial,\n",
    "            config.num_actions,\n",
    "            self.embed_size,\n",
    "            config.device,\n",
    "        )\n",
    "        self.heads = nn.ModuleDict()\n",
    "        if config.dyn_discrete:\n",
    "            feat_size = config.dyn_stoch * config.dyn_discrete + config.dyn_deter\n",
    "        else:\n",
    "            feat_size = config.dyn_stoch + config.dyn_deter\n",
    "        self.heads[\"decoder\"] = MultiDecoder(feat_size, shapes, config.decoder)\n",
    "        self.heads[\"reward\"] = MLP(\n",
    "            feat_size,\n",
    "            (255,) if config.reward_head.dist == \"symlog_disc\" else (),\n",
    "            config.reward_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=config.reward_head.dist,\n",
    "            outscale=config.reward_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Reward\",\n",
    "        )\n",
    "        self.heads[\"cont\"] = MLP(\n",
    "            feat_size,\n",
    "            (),\n",
    "            config.cont_head.layers,\n",
    "            config.units,\n",
    "            config.act,\n",
    "            config.norm,\n",
    "            dist=\"binary\",\n",
    "            outscale=config.cont_head.outscale,\n",
    "            device=config.device,\n",
    "            name=\"Cont\",\n",
    "        )\n",
    "        for name in config.grad_heads:\n",
    "            assert name in self.heads, name\n",
    "        self._model_opt = Optimizer(\n",
    "            \"model\",\n",
    "            self.parameters(),\n",
    "            config.model_lr,\n",
    "            config.opt_eps,\n",
    "            config.grad_clip,\n",
    "            config.weight_decay,\n",
    "            opt=config.opt,\n",
    "            use_amp=self._use_amp,\n",
    "        )\n",
    "        print(\n",
    "            f\"Optimizer model_opt has {sum(param.numel() for param in self.parameters())} variables.\"\n",
    "        )\n",
    "        # other losses are scaled by 1.0.\n",
    "        self._scales = dict(\n",
    "            reward=config.reward_head.loss_scale,\n",
    "            cont=config.cont_head.loss_scale,\n",
    "        )\n",
    "\n",
    "    def _train(self, data):\n",
    "        # action (batch_size, batch_length, act_dim)\n",
    "        # image (batch_size, batch_length, h, w, ch)\n",
    "        # reward (batch_size, batch_length)\n",
    "        # discount (batch_size, batch_length)\n",
    "        data = self.preprocess(data)\n",
    "\n",
    "        with RequiresGrad(self):\n",
    "            with torch.cuda.amp.autocast(self._use_amp):\n",
    "                embed = self.encoder(data)\n",
    "                post, prior = self.dynamics.observe(\n",
    "                    embed, data[\"action\"], data[\"is_first\"]\n",
    "                )\n",
    "                kl_free = self._config.kl_free\n",
    "                dyn_scale = self._config.dyn_scale\n",
    "                rep_scale = self._config.rep_scale\n",
    "                kl_loss, kl_value, dyn_loss, rep_loss = self.dynamics.kl_loss(\n",
    "                    post, prior, kl_free, dyn_scale, rep_scale\n",
    "                )\n",
    "                assert kl_loss.shape == embed.shape[:2], kl_loss.shape\n",
    "                preds = {}\n",
    "                for name, head in self.heads.items():\n",
    "                    grad_head = name in self._config.grad_heads\n",
    "                    feat = self.dynamics.get_feat(post)\n",
    "                    feat = feat if grad_head else feat.detach()\n",
    "                    pred = head(feat)\n",
    "                    if type(pred) is dict:\n",
    "                        preds.update(pred)\n",
    "                    else:\n",
    "                        preds[name] = pred\n",
    "                losses = {}\n",
    "                for name, pred in preds.items():\n",
    "                    loss = -pred.log_prob(data[name])\n",
    "                    assert loss.shape == embed.shape[:2], (name, loss.shape)\n",
    "                    losses[name] = loss\n",
    "                scaled = {\n",
    "                    key: value * self._scales.get(key, 1.0)\n",
    "                    for key, value in losses.items()\n",
    "                }\n",
    "                model_loss = sum(scaled.values()) + kl_loss\n",
    "            metrics = self._model_opt(torch.mean(model_loss), self.parameters())\n",
    "\n",
    "        metrics.update({f\"{name}_loss\": to_np(loss) for name, loss in losses.items()})\n",
    "        metrics[\"kl_free\"] = kl_free\n",
    "        metrics[\"dyn_scale\"] = dyn_scale\n",
    "        metrics[\"rep_scale\"] = rep_scale\n",
    "        metrics[\"dyn_loss\"] = to_np(dyn_loss)\n",
    "        metrics[\"rep_loss\"] = to_np(rep_loss)\n",
    "        metrics[\"kl\"] = to_np(torch.mean(kl_value))\n",
    "        with torch.cuda.amp.autocast(self._use_amp):\n",
    "            metrics[\"prior_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(prior).entropy())\n",
    "            )\n",
    "            metrics[\"post_ent\"] = to_np(\n",
    "                torch.mean(self.dynamics.get_dist(post).entropy())\n",
    "            )\n",
    "            context = dict(\n",
    "                embed=embed,\n",
    "                feat=self.dynamics.get_feat(post),\n",
    "                kl=kl_value,\n",
    "                postent=self.dynamics.get_dist(post).entropy(),\n",
    "            )\n",
    "        post = {k: v.detach() for k, v in post.items()}\n",
    "        return post, context, metrics\n",
    "\n",
    "    # this function is called during both rollout and training\n",
    "    def preprocess(self, obs):\n",
    "        # print(\"WorldModel preprocess\")\n",
    "        obs = {\n",
    "            k: torch.tensor(v, device=self._config.device, dtype=torch.float32)\n",
    "            for k, v in obs.items()\n",
    "        }\n",
    "        if \"image\" in obs:\n",
    "            obs[\"image\"] = obs[\"image\"] / 255.0\n",
    "        # print(\"obs image shape: \", obs[\"image\"].shape)\n",
    "        # if \"discount\" in obs:\n",
    "        #     obs[\"discount\"] *= self._config.discount\n",
    "        #     # (batch_size, batch_length) -> (batch_size, batch_length, 1)\n",
    "        #     obs[\"discount\"] = obs[\"discount\"].unsqueeze(-1)\n",
    "        # 'is_first' is necesarry to initialize hidden state at training\n",
    "        assert \"is_first\" in obs\n",
    "        # 'is_terminal' is necesarry to train cont_head\n",
    "        assert \"is_terminal\" in obs\n",
    "        obs[\"cont\"] = (1.0 - obs[\"is_terminal\"]).unsqueeze(-1)\n",
    "        return obs\n",
    "\n",
    "    def video_pred(self, data):\n",
    "        print(\"WorldModel video_pred\")\n",
    "        data = self.preprocess(data)\n",
    "        embed = self.encoder(data)\n",
    "\n",
    "        if \"image\" not in data:\n",
    "            return None\n",
    "\n",
    "        states, _ = self.dynamics.observe(\n",
    "            embed[:6, :5], data[\"action\"][:6, :5], data[\"is_first\"][:6, :5]\n",
    "        )\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()[\n",
    "            :6\n",
    "        ]\n",
    "        reward_post = self.heads[\"reward\"](self.dynamics.get_feat(states)).mode()[:6]\n",
    "        init = {k: v[:, -1] for k, v in states.items()}\n",
    "        prior = self.dynamics.imagine_with_action(data[\"action\"][:6, 5:], init)\n",
    "        openl = self.heads[\"decoder\"](self.dynamics.get_feat(prior))[\"image\"].mode()\n",
    "        reward_prior = self.heads[\"reward\"](self.dynamics.get_feat(prior)).mode()\n",
    "        # observed image is given until 5 steps\n",
    "        model = torch.cat([recon[:, :5], openl], 1)\n",
    "        truth = data[\"image\"][:6]\n",
    "        model = model\n",
    "        error = (model - truth + 1.0) / 2.0\n",
    "\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        obs = data[\"image\"]\n",
    "        states, _ = self.dynamics.observe(embed, data[\"action\"], data[\"is_first\"])\n",
    "        recon = self.heads[\"decoder\"](self.dynamics.get_feat(states))[\"image\"].mode()\n",
    "        decoded_obs = recon\n",
    "        # rewards = reward_post\n",
    "        # predicted_rewards = reward_prior\n",
    "        batch_idx = np.random.randint(0, obs.shape[0])\n",
    "        seq_idx = np.random.randint(0, obs.shape[1] - 3)\n",
    "        grayscale = obs.shape[-1] == 1\n",
    "\n",
    "        # print(rewards.shape, predicted_rewards.shape)\n",
    "        obs = obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        decoded_obs = decoded_obs[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # rewards = rewards[batch_idx, seq_idx : seq_idx + 3]\n",
    "        # predicted_rewards = predicted_rewards[batch_idx][seq_idx : seq_idx + 3]\n",
    "\n",
    "        obs = obs.cpu().detach().numpy()\n",
    "        fig, axs = plt.subplots(3, 2)\n",
    "        axs[0][0].imshow(obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][0].set_title(f\"Iteration: {self._step} -- Reward: {rewards[0]:.4f}\")\n",
    "        axs[0][0].axis(\"off\")\n",
    "        axs[0][1].imshow(decoded_obs[0], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[0][1].set_title(f\"Pred. Reward: {predicted_rewards[0, 0]:.4f}\")\n",
    "        axs[0][1].axis(\"off\")\n",
    "\n",
    "        axs[1][0].imshow(obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        axs[1][0].axis(\"off\")\n",
    "        # axs[1][0].set_title(f\"Reward: {rewards[1, 0]:.4f} \")\n",
    "        axs[1][1].imshow(decoded_obs[1], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[1][1].set_title(f\"Pred. Reward: {predicted_rewards[1]:.4f}\")\n",
    "        axs[1][1].axis(\"off\")\n",
    "\n",
    "        axs[2][0].imshow(obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        axs[2][0].axis(\"off\")\n",
    "        # axs[2][0].set_title(f\"Reward: {rewards[2, 0]:.4f}\")\n",
    "        axs[2][1].imshow(decoded_obs[2], cmap=\"gray\" if grayscale else None)\n",
    "        # axs[2][1].set_title(f\"Pred. Reward: {predicted_rewards[2]:.4f}\")\n",
    "        axs[2][1].axis(\"off\")\n",
    "\n",
    "        if not os.path.exists(\"reconstructions\"):\n",
    "            os.makedirs(\"reconstructions\")\n",
    "        fig.savefig(f\"reconstructions/iteration_{step}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        return torch.cat([truth, model, error], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"./test_notebook.ipynb\").parent))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class Dreamer(nn.Module):\n",
    "    def __init__(self, obs_space, act_space, config, logger, dataset):\n",
    "        super(Dreamer, self).__init__()\n",
    "        self._config = config\n",
    "        self._logger = logger\n",
    "        self._should_log = Every(config.log_every)\n",
    "        batch_steps = config.batch_size * config.batch_length\n",
    "        self._should_train = Every(batch_steps / config.train_ratio)\n",
    "        self._should_pretrain = Once()\n",
    "        self._should_reset = Every(config.reset_every)\n",
    "        # self._should_expl = Until(int(config.expl_until / config.action_repeat))\n",
    "        self._metrics = {}\n",
    "        # this is update step\n",
    "        self._step = logger.step // config.action_repeat\n",
    "        self._update_count = 0\n",
    "        self._dataset = dataset\n",
    "        self._wm = WorldModel(obs_space, act_space, self._step, config)\n",
    "        if (\n",
    "            config.compile and os.name != \"nt\"\n",
    "        ):  # compilation is not supported on windows\n",
    "            self._wm = torch.compile(self._wm)\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](f).mean()\n",
    "        self._expl_behavior = Random(config, act_space)\n",
    "\n",
    "    def __call__(self, obs, reset, state=None, training=True):\n",
    "        step = self._step\n",
    "        if training:\n",
    "            steps = (\n",
    "                self._config.pretrain\n",
    "                if self._should_pretrain()\n",
    "                else self._should_train(step)\n",
    "            )\n",
    "            for _ in range(steps):\n",
    "                print(\"iter: \", _)\n",
    "                self._train(next(self._dataset))\n",
    "                self._update_count += 1\n",
    "                self._metrics[\"update_count\"] = self._update_count\n",
    "            if self._should_log(step):\n",
    "                for name, values in self._metrics.items():\n",
    "                    self._logger.scalar(name, float(np.mean(values)))\n",
    "                    self._metrics[name] = []\n",
    "                if self._config.video_pred_log:\n",
    "                    openl = self._wm.video_pred(next(self._dataset))\n",
    "                    self._logger.video(\"train_openl\", to_np(openl))\n",
    "                self._logger.write(fps=True)\n",
    "        # policy_output, state = self._policy(obs, state, training)\n",
    "        if state is None:\n",
    "            latent = action = None\n",
    "        else:\n",
    "            latent, action = state\n",
    "        obs = self._wm.preprocess(obs)\n",
    "        embed = self._wm.encoder(obs)\n",
    "        latent, _ = self._wm.dynamics.obs_step(latent, action, embed, obs[\"is_first\"])\n",
    "        # if self._config.eval_state_mean:\n",
    "        #     latent[\"stoch\"] = latent[\"mean\"]\n",
    "        feat = self._wm.dynamics.get_feat(latent)\n",
    "        actor = self._expl_behavior.actor(feat)\n",
    "        action = actor.sample()\n",
    "        # print(\"obs action mask\", obs[\"action_mask\"])\n",
    "        print(action)\n",
    "\n",
    "        logprob = actor.log_prob(action)\n",
    "        latent = {k: v.detach() for k, v in latent.items()}\n",
    "        action = action.detach()\n",
    "        # if self._config.actor[\"dist\"] == \"onehot_gumble\":\n",
    "        # action = torch.one_hot(\n",
    "        action = torch.nn.functional.one_hot(\n",
    "            torch.argmax(action, dim=-1), self._config.num_actions\n",
    "        )\n",
    "        policy_output = {\"action\": action, \"logprob\": logprob}\n",
    "        print(policy_output[\"action\"].shape)\n",
    "        state = (latent, action)\n",
    "\n",
    "        if training:\n",
    "            self._step += len(reset)\n",
    "            self._logger.step = self._config.action_repeat * self._step\n",
    "        return policy_output, state\n",
    "\n",
    "    def _train(self, data):\n",
    "        print(\"dreamer train step:\")\n",
    "        # print(\"data shape: \", data[\"image\"].shape)\n",
    "        metrics = {}\n",
    "        post, context, mets = self._wm._train(data)\n",
    "        metrics.update(mets)\n",
    "        start = post\n",
    "        reward = lambda f, s, a: self._wm.heads[\"reward\"](\n",
    "            self._wm.dynamics.get_feat(s)\n",
    "        ).mode()\n",
    "        # metrics.update(self._task_behavior._train(start, reward)[-1])\n",
    "        for name, value in metrics.items():\n",
    "            if not name in self._metrics.keys():\n",
    "                self._metrics[name] = [value]\n",
    "            else:\n",
    "                self._metrics[name].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logdir logdir\n",
      "Create envs.\n",
      "agent selection 0\n",
      "agent selection 0\n",
      "Action Space Discrete(4)\n",
      "Prefill dataset (0 steps).\n",
      "Logger: (23828 steps).\n"
     ]
    }
   ],
   "source": [
    "set_seed_everywhere(config.seed)\n",
    "if config.deterministic_run:\n",
    "    enable_deterministic_run()\n",
    "logdir = pathlib.Path(config.logdir).expanduser()\n",
    "config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "config.steps //= config.action_repeat\n",
    "config.eval_every //= config.action_repeat\n",
    "config.log_every //= config.action_repeat\n",
    "config.time_limit //= config.action_repeat\n",
    "\n",
    "print(\"Logdir\", logdir)\n",
    "config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "step = count_steps(config.traindir)\n",
    "# step in logger is environmental step\n",
    "logger = Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = load_episodes(directory, limit=config.dataset_size)\n",
    "if config.offline_evaldir:\n",
    "    directory = config.offline_evaldir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.evaldir\n",
    "eval_eps = load_episodes(directory, limit=1)\n",
    "make = lambda mode, id: make_env(config, mode, id)\n",
    "train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "if config.parallel:\n",
    "    train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "    eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "else:\n",
    "    train_envs = [Damy(env) for env in train_envs]\n",
    "    eval_envs = [Damy(env) for env in eval_envs]\n",
    "acts = train_envs[0].action_space\n",
    "print(\"Action Space\", acts)\n",
    "config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]\n",
    "\n",
    "state = None\n",
    "if not config.offline_traindir:\n",
    "    prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "    print(f\"Prefill dataset ({prefill} steps).\")\n",
    "    if hasattr(acts, \"discrete\"):\n",
    "        random_actor = OneHotDist(\n",
    "            torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "        )\n",
    "    else:\n",
    "        random_actor = torchd.independent.Independent(\n",
    "            torchd.uniform.Uniform(\n",
    "                torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def random_agent(o, d, s):\n",
    "        action = random_actor.sample()\n",
    "        logprob = random_actor.log_prob(action)\n",
    "        return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "    state = simulate(\n",
    "        random_agent,\n",
    "        train_envs,\n",
    "        train_eps,\n",
    "        config.traindir,\n",
    "        logger,\n",
    "        limit=config.dataset_size,\n",
    "        steps=prefill,\n",
    "    )\n",
    "    logger.step += prefill * config.action_repeat\n",
    "    print(f\"Logger: ({logger.step} steps).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate agent.\n",
      "dict_items([('observation', (16,))])\n",
      ".*\n",
      "$^\n",
      "cnn\n",
      "False\n",
      "None\n",
      "$^\n",
      "observation\n",
      "mlp\n",
      "True\n",
      "<re.Match object; span=(0, 11), match='observation'>\n",
      ".*\n",
      "observation\n",
      "Encoder CNN shapes: {}\n",
      "Encoder MLP shapes: {'observation': (16,)}\n",
      "v:  (16,)\n",
      "input_size:  16\n",
      "Decoder CNN shapes: {}\n",
      "Decoder MLP shapes: {'observation': (16,)}\n",
      "Optimizer model_opt has 3703824 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/wwwbwc016yxfhlbgfph7_xmc0000gn/T/ipykernel_88305/3308850042.py:748: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Simulate agent.\")\n",
    "    train_dataset = make_dataset(train_eps, config)\n",
    "    eval_dataset = make_dataset(eval_eps, config)\n",
    "    agent = Dreamer(\n",
    "        train_envs[0].observation_space,\n",
    "        train_envs[0].action_space,\n",
    "        config,\n",
    "        logger,\n",
    "        train_dataset,\n",
    "    ).to(config.device)\n",
    "    agent.requires_grad_(requires_grad=False)\n",
    "    if (logdir / \"latest.pt\").exists():\n",
    "        checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "        agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "        recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "        agent._should_pretrain._once = False\n",
    "\n",
    "    # make sure eval will be executed once after config.steps\n",
    "    while agent._step < config.steps + config.eval_every:\n",
    "    #     logger.write()\n",
    "        if config.eval_episode_num > 0:\n",
    "            print(\"Start evaluation.\")\n",
    "    #         eval_policy = funcpartial(agent, training=False)\n",
    "    #         simulate(\n",
    "    #             eval_policy,\n",
    "    #             eval_envs,\n",
    "    #             eval_eps,\n",
    "    #             config.evaldir,\n",
    "    #             logger,\n",
    "    #             is_eval=True,\n",
    "    #             episodes=config.eval_episode_num,\n",
    "    #         )\n",
    "            # if config.video_pred_log:\n",
    "                # video_pred = agent._wm.video_pred(next(eval_dataset))\n",
    "                # video_pred = agent._wm.video_pred(next(train_dataset))\n",
    "                # logger.video(\"eval_openl\", to_np(video_pred))\n",
    "        print(\"Start training.\")\n",
    "        # print(\"Number of training envs: \", len(train_envs))\n",
    "        # print(train_envs[0].observation_space)\n",
    "        print(\"Agent step: \", agent._step)\n",
    "        state = simulate(\n",
    "            agent,\n",
    "            train_envs,\n",
    "            train_eps,\n",
    "            config.traindir,\n",
    "            logger,\n",
    "            limit=config.dataset_size,\n",
    "            steps=config.eval_every,\n",
    "            state=state,\n",
    "        )\n",
    "        items_to_save = {\n",
    "            \"agent_state_dict\": agent.state_dict(),\n",
    "            \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "        }\n",
    "        torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "    for env in train_envs + eval_envs:\n",
    "        try:\n",
    "            env.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_save = {\n",
    "    \"agent_state_dict\": agent.state_dict(),\n",
    "    \"optims_state_dict\": recursively_collect_optim_state_dict(agent),\n",
    "}\n",
    "torch.save(items_to_save, logdir / \"latest_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent selection 0\n",
      "{'observation': array([  1.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,  50., 100.]), 'is_terminal': False, 'is_first': True}\n",
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# state = (latent, action)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m recon \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_wm\u001b[38;5;241m.\u001b[39mheads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m](feat)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmode()\n\u001b[0;32m---> 34\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcont\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m rew \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_wm\u001b[38;5;241m.\u001b[39mheads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m](feat)\u001b[38;5;241m.\u001b[39mmode()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon:\u001b[39m\u001b[38;5;124m\"\u001b[39m, recon)\n",
      "Cell \u001b[0;32mIn[5], line 610\u001b[0m, in \u001b[0;36mBernoulli.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/independent.py:107\u001b[0m, in \u001b[0;36mIndependent.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: _size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/distributions/distribution.py:175\u001b[0m, in \u001b[0;36mDistribution.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: _size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Generates a sample_shape shaped reparameterized sample or sample_shape\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    shaped batch of reparameterized samples if the distribution parameters\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    are batched.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = Poker(\n",
    "    \"universal_poker\",\n",
    ")\n",
    "\n",
    "obs = env.reset()\n",
    "print(obs)\n",
    "data = {}\n",
    "for key in obs.keys():\n",
    "    data[key] = []\n",
    "    data[key].append(obs[key])\n",
    "    data[key] = np.stack(data[key], 0)\n",
    "obs = data\n",
    "obs = agent._wm.preprocess(obs)\n",
    "embed = agent._wm.encoder(obs)\n",
    "# print(embed)\n",
    "print(embed.shape)\n",
    "# post, prior\n",
    "# post = new_stoch and new_deter\n",
    "latent, _ = agent._wm.dynamics.obs_step(\n",
    "    None,\n",
    "    None,\n",
    "    embed,\n",
    "    obs[\"is_first\"],\n",
    ")\n",
    "# print(latent.shape)\n",
    "\n",
    "feat = agent._wm.dynamics.get_feat(latent)\n",
    "action = torch.tensor(\n",
    "    [[1, 0, 0, 0]]\n",
    ")  # action from feature, which is the input to the actor\n",
    "# state = (latent, action)\n",
    "\n",
    "recon = agent._wm.heads[\"decoder\"](feat)[\"observation\"].mode()\n",
    "cont = agent._wm.heads[\"cont\"](feat).sample()\n",
    "rew = agent._wm.heads[\"reward\"](feat).mode()\n",
    "print(\"recon:\", recon)\n",
    "print(\"squared error\", torch.round((recon - obs[\"observation\"]) ** 2, decimals=3))\n",
    "print(\"cont:\", cont)\n",
    "print(\"rew:\", rew)\n",
    "\n",
    "latent, _ = agent._wm.dynamics.obs_step(\n",
    "    latent,\n",
    "    action,\n",
    "    embed,\n",
    "    obs[\"is_first\"],\n",
    ")\n",
    "\n",
    "# feat = agent._wm.dynamics.get_feat(latent)\n",
    "# recon = agent._wm.heads[\"decoder\"](feat)[\"observation\"].mode()\n",
    "# cont = agent._wm.heads[\"cont\"](feat).sample()\n",
    "# rew = agent._wm.heads[\"reward\"](feat).mode()\n",
    "# print(env.step(action))\n",
    "# print(\"recon:\", recon)\n",
    "# print(\"cont:\", cont)\n",
    "# print(\"rew:\", rew)\n",
    "\n",
    "# post, prior = agent._wm.dynamics.observe(embed, action, obs[\"is_first\"])\n",
    "# print(\"latent:\", latent)\n",
    "prior = agent._wm.dynamics.img_step(\n",
    "    latent,\n",
    "    action,\n",
    ")\n",
    "recon = agent._wm.heads[\"decoder\"](agent._wm.dynamics.get_feat(prior))[\n",
    "    \"observation\"\n",
    "].mode()\n",
    "cont = agent._wm.heads[\"cont\"](agent._wm.dynamics.get_feat(prior)).sample()\n",
    "rew = agent._wm.heads[\"reward\"](agent._wm.dynamics.get_feat(prior)).mode()\n",
    "print(env.step(action))\n",
    "# print(\"prior:\", prior)\n",
    "print(\"recon:\", recon)\n",
    "print(\"squared error\", torch.round((recon - obs[\"observation\"]) ** 2, decimals=3))\n",
    "print(\"cont:\", cont)\n",
    "print(\"rew:\", rew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
