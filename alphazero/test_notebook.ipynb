{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 3 2 7]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[ 1 -1  1 -1  1 -1  1]\n",
      "[1, -1, 1, -1, 1, -1, 1, 0, 0, 0, 0, 0, 0, 0, -1]\n",
      "15\n",
      "[ 1 -1  1 -1  1 -1  1 -1]\n",
      "[1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, -1]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices = np.random.choice(10, 5, replace=True)\n",
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(arr[indices])\n",
    "print(arr[-11:])\n",
    "reward_buffer = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, -1]\n",
    "size = 7\n",
    "game_start_index = 0\n",
    "reward = reward_buffer[size - 1]\n",
    "updated_rewards = np.empty((size - game_start_index,), int)\n",
    "updated_rewards[::2] = 1 * reward\n",
    "updated_rewards[1::2] = -1 * reward\n",
    "updated_rewards = np.flip(updated_rewards)\n",
    "print(updated_rewards)\n",
    "reward_buffer[game_start_index:size] = updated_rewards\n",
    "print(reward_buffer)\n",
    "game_start_index = 7\n",
    "size = 15\n",
    "print(len(reward_buffer))\n",
    "reward = reward_buffer[size - 1]\n",
    "updated_rewards = np.empty((size - game_start_index,), int)\n",
    "updated_rewards[::2] = 1 * reward\n",
    "updated_rewards[1::2] = -1 * reward\n",
    "updated_rewards = np.flip(updated_rewards)\n",
    "print(updated_rewards)\n",
    "reward_buffer[game_start_index:size] = updated_rewards\n",
    "print(reward_buffer)\n",
    "print(len(reward_buffer))\n",
    "overflow_reward = 1\n",
    "overflow_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_buffer = np.array([1, -1, 1, -1, 1, -1, 0])\n",
    "# reward_buffer[6] = [1, 1, 1, 1]\n",
    "# print(reward_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TicTacToeEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mclip(reward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_reward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_reward)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# env = ClipReward(gym.wrappers.AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mTicTacToeEnv\u001b[49m()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# env = gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mwrappers\u001b[38;5;241m.\u001b[39mFrameStack(env, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TicTacToeEnv' is not defined"
     ]
    }
   ],
   "source": [
    "# from alphazero_agent import AlphaZeroAgent\n",
    "import gymnasium as gym \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import gym_envs\n",
    "\n",
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env, min_reward, max_reward):\n",
    "        super().__init__(env)\n",
    "        self.min_reward = min_reward\n",
    "        self.max_reward = max_reward\n",
    "        self.reward_range = (min_reward, max_reward)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, self.min_reward, self.max_reward)\n",
    "\n",
    "\n",
    "# env = ClipReward(gym.wrappers.AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\n",
    "env = TicTacToeEnv()\n",
    "# env = gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\")\n",
    "env = gym.wrappers.FrameStack(env, 4)\n",
    "\n",
    "config = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'orthogonal',\n",
    "        'optimizer_function': tf.keras.optimizers.legacy.Adam,\n",
    "        'learning_rate': 0.2,\n",
    "        'adam_epsilon': 1e-7,\n",
    "        'clipnorm': 0.5,\n",
    "        # NORMALIZATION?\n",
    "        # REWARD CLIPPING\n",
    "        'num_epochs': 30,\n",
    "        'num_filters': 32,\n",
    "        'kernel_size': 3,\n",
    "        'stride': 1,\n",
    "        'num_res_blocks': 5,\n",
    "        'critic_conv_filters': 32,\n",
    "        'critic_conv_layers': 1,\n",
    "        'critic_dense_size': 32,\n",
    "        'critic_dense_layers': 1,\n",
    "        'actor_conv_filters': 32,\n",
    "        'actor_conv_layers': 1,\n",
    "        'actor_dense_size': 32,\n",
    "        'actor_dense_layers': 1,\n",
    "        'memory_size': 180,\n",
    "        'max_game_length': 9,\n",
    "        'batch_size': 9,\n",
    "        'dirichlet_alpha': 0.3,\n",
    "        'dirichlet_epsilon': 0.25,\n",
    "        'c_puct': 1,\n",
    "        'monte_carlo_simulations': 18,\n",
    "        'two_player': True,\n",
    "        'weight_decay': 1e-4,\n",
    "    }    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AlphaZeroAgent(env, config=config)\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.zeros((3, 9))\n",
    "array[0] = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_envs\n",
    "import gymnasium as gym\n",
    "env = gym.make('gym_envs/TicTacToe-v0')\n",
    "\n",
    "state, info = env.reset()\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(0)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(4)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(3)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(6)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(2)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(1)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "env.render()\n",
    "state, reward, terminated, truncated, info = env.step(7)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(8)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(5)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "env.render()\n",
    "\n",
    "\n",
    "env.reset()\n",
    "state, reward, terminated, truncated, info = env.step(0)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(3)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(7)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(4)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(2)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(6)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "state, reward, terminated, truncated, info = env.step(1)\n",
    "print(state)\n",
    "print(\"Turn: \", state[2][0][0])\n",
    "print(\"Legal moves: \", info['legal_moves'])\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "print(\"Reward:\", reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# regularizer = tf.keras.regularizers.L2(2)\n",
    "# print(regularizer(agent.model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "arr = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "\n",
    "print(arr/np.sum(arr))\n",
    "# print(tf.nn.softmax(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 00:45:26.403055: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-03-18 00:45:26.403077: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-03-18 00:45:26.403083: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-03-18 00:45:26.403120: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-18 00:45:26.403140: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125    0.06875    0.06625    0.1        0.1075     0.21125001\n",
      " 0.11875    0.1075     0.11875   ]\n",
      "Predicted Policy  [0.10922436 0.16137959 0.11553176 0.18414491 0.10025197 0.08096498\n",
      " 0.15973197 0.         0.0887704 ]\n",
      "Predicted Value  -0.023437311872839928\n",
      "Target Policy [0.0425  0.0475  0.04375 0.0925  0.06375 0.0475  0.095   0.      0.5675 ]\n",
      "Predicted Policy  [0.11568154 0.16067564 0.1401926  0.1731498  0.1333406  0.1268028\n",
      " 0.15015705 0.         0.        ]\n",
      "Predicted Value  -0.01720600388944149\n",
      "Target Policy [0.01375    0.90750003 0.0125     0.01625    0.01875    0.01375\n",
      " 0.0175     0.         0.        ]\n",
      "Predicted Policy  [0.13862373 0.         0.14558728 0.25548777 0.13297838 0.10247282\n",
      " 0.22485    0.         0.        ]\n",
      "Predicted Value  -0.03033909574151039\n",
      "Target Policy [0.02875    0.         0.02625    0.89375001 0.01375    0.02125\n",
      " 0.01625    0.         0.        ]\n",
      "Predicted Policy  [0.15905708 0.         0.21787506 0.         0.2055848  0.17912252\n",
      " 0.23836052 0.         0.        ]\n",
      "Predicted Value  -0.0015513189136981964\n",
      "Target Policy [0.02125    0.         0.02375    0.         0.91874999 0.0175\n",
      " 0.01875    0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125 0.0825  0.06375 0.0975  0.1     0.20375 0.11875 0.1275  0.105  ]\n",
      "Predicted Policy  [0.10206565 0.15794295 0.11663811 0.17713352 0.10460763 0.\n",
      " 0.15547232 0.09614801 0.08999184]\n",
      "Predicted Value  -0.009688995778560638\n",
      "Target Policy [0.04125    0.71249998 0.045      0.0475     0.05       0.\n",
      " 0.03375    0.035      0.035     ]\n",
      "Predicted Policy  [0.1214066  0.         0.14567702 0.17861898 0.13070586 0.\n",
      " 0.17117286 0.13041112 0.12200754]\n",
      "Predicted Value  0.03259317949414253\n",
      "Target Policy [0.01625 0.      0.01625 0.0175  0.90375 0.      0.01875 0.01375 0.01375]\n",
      "Predicted Policy  [0.13468213 0.         0.15537646 0.2684278  0.         0.\n",
      " 0.19255991 0.13574412 0.11320962]\n",
      "Predicted Value  -0.024981411173939705\n",
      "Target Policy [0.0275     0.         0.91500002 0.02125    0.         0.\n",
      " 0.01375    0.01125    0.01125   ]\n",
      "Predicted Policy  [0.18132327 0.         0.21940461 0.         0.         0.\n",
      " 0.26060486 0.17444946 0.16421781]\n",
      "Predicted Value  0.0384514182806015\n",
      "Target Policy [0.04       0.         0.0375     0.         0.         0.\n",
      " 0.88875002 0.0175     0.01625   ]\n",
      "Predicted Policy  [0.2551059  0.         0.30730987 0.         0.         0.\n",
      " 0.         0.2450503  0.19253393]\n",
      "Predicted Value  -0.0029427926056087017\n",
      "Target Policy [0.12375    0.         0.52249998 0.         0.         0.\n",
      " 0.         0.1525     0.20125   ]\n",
      "Predicted Policy  [0.34095183 0.         0.         0.         0.         0.\n",
      " 0.         0.34041575 0.31863248]\n",
      "Predicted Value  -0.03282277286052704\n",
      "Target Policy [0.07125 0.      0.      0.      0.      0.      0.      0.0875  0.84125]\n",
      "Predicted Policy  [0.47993952 0.         0.         0.         0.         0.\n",
      " 0.         0.52006054 0.        ]\n",
      "Predicted Value  -0.01856456883251667\n",
      "Target Policy [0.98000002 0.         0.         0.         0.         0.\n",
      " 0.         0.02       0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.09       0.0825     0.06875    0.10875    0.11125    0.19499999\n",
      " 0.11       0.11625    0.1175    ]\n",
      "Predicted Policy  [0.10680893 0.16177575 0.11442561 0.19509648 0.         0.08527815\n",
      " 0.1438249  0.10779541 0.08499479]\n",
      "Predicted Value  -0.01789434254169464\n",
      "Target Policy [0.02125    0.02875    0.02       0.80624998 0.         0.02375\n",
      " 0.03375    0.03625    0.03      ]\n",
      "Predicted Policy  [0.13350748 0.17020665 0.14848778 0.         0.         0.13021319\n",
      " 0.16931023 0.1252329  0.12304175]\n",
      "Predicted Value  0.0020803355146199465\n",
      "Target Policy [0.01875 0.90625 0.01625 0.      0.      0.01625 0.01625 0.01375 0.0125 ]\n",
      "Predicted Policy  [0.15414868 0.         0.18531467 0.         0.         0.13283904\n",
      " 0.24412832 0.1576349  0.1259344 ]\n",
      "Predicted Value  0.029313743114471436\n",
      "Target Policy [0.0375     0.         0.89499998 0.         0.         0.02375\n",
      " 0.01375    0.01875    0.01125   ]\n",
      "Predicted Policy  [0.20158522 0.         0.         0.         0.         0.18068911\n",
      " 0.2695554  0.18286893 0.16530144]\n",
      "Predicted Value  -0.0267373938113451\n",
      "Target Policy [0.04       0.         0.         0.         0.         0.02\n",
      " 0.02625    0.89999998 0.01375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125    0.07625    0.065      0.0875     0.10125    0.20874999\n",
      " 0.1175     0.1175     0.125     ]\n",
      "Predicted Policy  [0.09807834 0.15740131 0.10958577 0.18493138 0.11037225 0.08350524\n",
      " 0.15318878 0.1029369  0.        ]\n",
      "Predicted Value  0.017111310735344887\n",
      "Target Policy [0.065      0.045      0.10375    0.0625     0.06625    0.11375\n",
      " 0.05125    0.49250001 0.        ]\n",
      "Predicted Policy  [0.12102524 0.15123595 0.14496477 0.17169355 0.1328094  0.\n",
      " 0.1535287  0.12474237 0.        ]\n",
      "Predicted Value  0.03751685097813606\n",
      "Target Policy [0.01375    0.01375    0.01625    0.0175     0.015      0.\n",
      " 0.01375    0.91000003 0.        ]\n",
      "Predicted Policy  [0.11892974 0.19668096 0.14125653 0.2195999  0.1297602  0.\n",
      " 0.19377266 0.         0.        ]\n",
      "Predicted Value  -0.016926176846027374\n",
      "Target Policy [0.0225     0.86874998 0.02625    0.02875    0.03625    0.\n",
      " 0.0175     0.         0.        ]\n",
      "Predicted Policy  [0.15804935 0.         0.19151911 0.25081974 0.16880435 0.\n",
      " 0.23080745 0.         0.        ]\n",
      "Predicted Value  0.018892666324973106\n",
      "Target Policy [0.02125    0.         0.02625    0.02875    0.025      0.\n",
      " 0.89875001 0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125 0.0675  0.07    0.11    0.10625 0.2     0.1225  0.10625 0.11625]\n",
      "Predicted Policy  [0.10206565 0.15794295 0.11663811 0.17713352 0.10460763 0.\n",
      " 0.15547232 0.09614801 0.08999184]\n",
      "Predicted Value  -0.009688995778560638\n",
      "Target Policy [0.04125    0.68875003 0.05125    0.06625    0.0475     0.\n",
      " 0.035      0.035      0.035     ]\n",
      "Predicted Policy  [0.1214066  0.         0.14567702 0.17861898 0.13070586 0.\n",
      " 0.17117286 0.13041112 0.12200754]\n",
      "Predicted Value  0.03259317949414253\n",
      "Target Policy [0.01375    0.         0.02375    0.01625    0.90249997 0.\n",
      " 0.015      0.015      0.01375   ]\n",
      "Predicted Policy  [0.13468213 0.         0.15537646 0.2684278  0.         0.\n",
      " 0.19255991 0.13574412 0.11320962]\n",
      "Predicted Value  -0.024981411173939705\n",
      "Target Policy [0.0275     0.         0.91500002 0.02       0.         0.\n",
      " 0.01375    0.0125     0.01125   ]\n",
      "Predicted Policy  [0.15853494 0.         0.         0.27022347 0.         0.\n",
      " 0.25193757 0.16428408 0.15501994]\n",
      "Predicted Value  0.048070698976516724\n",
      "Target Policy [0.02375    0.         0.         0.91374999 0.         0.\n",
      " 0.035      0.0125     0.015     ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125 0.065   0.07    0.11375 0.10125 0.20375 0.115   0.10625 0.12375]\n",
      "Predicted Policy  [0.10206565 0.15794295 0.11663811 0.17713352 0.10460763 0.\n",
      " 0.15547232 0.09614801 0.08999184]\n",
      "Predicted Value  -0.009688995778560638\n",
      "Target Policy [0.06375    0.67374998 0.05125    0.055      0.05125    0.\n",
      " 0.035      0.035      0.035     ]\n",
      "Predicted Policy  [0.12272437 0.16147117 0.14485209 0.16436476 0.12985954 0.\n",
      " 0.15642802 0.         0.12030008]\n",
      "Predicted Value  0.025438137352466583\n",
      "Target Policy [0.03875    0.04125    0.01375    0.02125    0.0125     0.\n",
      " 0.03       0.         0.84249997]\n",
      "Predicted Policy  [0.13434125 0.         0.14144842 0.25823772 0.14317565 0.\n",
      " 0.20360169 0.         0.11919536]\n",
      "Predicted Value  -0.03354642540216446\n",
      "Target Policy [0.015      0.         0.01625    0.02       0.015      0.\n",
      " 0.01625    0.         0.91750002]\n",
      "Predicted Policy  [0.16360496 0.         0.18462811 0.24658105 0.18114378 0.\n",
      " 0.22404204 0.         0.        ]\n",
      "Predicted Value  -0.002977418014779687\n",
      "Target Policy [0.025      0.         0.03       0.89249998 0.03375    0.\n",
      " 0.01875    0.         0.        ]\n",
      "Predicted Policy  [0.18562613 0.         0.23967853 0.         0.23573096 0.\n",
      " 0.3389644  0.         0.        ]\n",
      "Predicted Value  -0.010610735043883324\n",
      "Target Policy [0.05125    0.         0.04625    0.         0.03625    0.\n",
      " 0.86624998 0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.09125    0.075      0.07       0.085      0.09       0.26499999\n",
      " 0.11625    0.10125    0.10625   ]\n",
      "Predicted Policy  [0.09611896 0.1614831  0.         0.19431582 0.10449855 0.08357508\n",
      " 0.16043593 0.10587127 0.09370126]\n",
      "Predicted Value  -0.020901842042803764\n",
      "Target Policy [0.04       0.52375001 0.         0.04375    0.03375    0.035\n",
      " 0.0875     0.0775     0.15875   ]\n",
      "Predicted Policy  [0.12771672 0.         0.         0.18602704 0.13677794 0.13578655\n",
      " 0.16326138 0.13002512 0.12040522]\n",
      "Predicted Value  0.00811206828802824\n",
      "Target Policy [0.01625 0.      0.      0.01625 0.90625 0.01375 0.01375 0.01875 0.015  ]\n",
      "Predicted Policy  [0.15528442 0.         0.         0.         0.17623654 0.12195107\n",
      " 0.2669101  0.14696173 0.13265607]\n",
      "Predicted Value  -0.024201039224863052\n",
      "Target Policy [0.0175     0.         0.         0.         0.90750003 0.01375\n",
      " 0.02125    0.0175     0.0225    ]\n",
      "Predicted Policy  [0.18578741 0.         0.         0.         0.         0.19500017\n",
      " 0.2640031  0.1768216  0.17838766]\n",
      "Predicted Value  0.003286966122686863\n",
      "Target Policy [0.03875    0.         0.         0.         0.         0.0375\n",
      " 0.89125001 0.01875    0.01375   ]\n",
      "Predicted Policy  [0.29933432 0.         0.         0.         0.         0.22421418\n",
      " 0.         0.25400886 0.22244261]\n",
      "Predicted Value  -0.04986996576189995\n",
      "Target Policy [0.0175     0.         0.         0.         0.         0.015\n",
      " 0.         0.95375001 0.01375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.09125    0.07125    0.065      0.1025     0.08375    0.21375\n",
      " 0.1375     0.10375    0.13124999]\n",
      "Predicted Policy  [0.1034933  0.         0.1119617  0.2122346  0.11701444 0.08681937\n",
      " 0.17063732 0.1024104  0.09542887]\n",
      "Predicted Value  0.00789598561823368\n",
      "Target Policy [0.025      0.         0.03625    0.74624997 0.0375     0.03125\n",
      " 0.04375    0.03625    0.04375   ]\n",
      "Predicted Policy  [0.13676283 0.         0.15267722 0.         0.14788553 0.13262488\n",
      " 0.17628045 0.1311286  0.12264056]\n",
      "Predicted Value  -0.0026200038846582174\n",
      "Target Policy [0.01375    0.         0.0175     0.         0.91374999 0.0125\n",
      " 0.015      0.01375    0.01375   ]\n",
      "Predicted Policy  [0.15414868 0.         0.18531467 0.         0.         0.13283904\n",
      " 0.24412832 0.1576349  0.1259344 ]\n",
      "Predicted Value  0.029313743114471436\n",
      "Target Policy [0.0275     0.         0.90249997 0.         0.         0.02875\n",
      " 0.015      0.015      0.01125   ]\n",
      "Predicted Policy  [0.21452567 0.         0.23340505 0.         0.         0.19192854\n",
      " 0.         0.18630174 0.17383899]\n",
      "Predicted Value  -0.010247889906167984\n",
      "Target Policy [0.02625 0.      0.03375 0.      0.      0.03    0.      0.875   0.035  ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.1        0.0675     0.0775     0.09       0.09       0.19625001\n",
      " 0.13500001 0.11875    0.125     ]\n",
      "Predicted Policy  [0.11255588 0.16274107 0.12700117 0.19654943 0.10890167 0.08619357\n",
      " 0.         0.1109551  0.09510212]\n",
      "Predicted Value  0.011775023303925991\n",
      "Target Policy [0.09875    0.13249999 0.11875    0.16875    0.125      0.1\n",
      " 0.         0.10125    0.155     ]\n",
      "Predicted Policy  [0.12781262 0.16093302 0.15160036 0.17706743 0.13843137 0.11916567\n",
      " 0.         0.         0.12498951]\n",
      "Predicted Value  -0.009744690731167793\n",
      "Target Policy [0.90499997 0.0175     0.01625    0.01875    0.015      0.01375\n",
      " 0.         0.         0.01375   ]\n",
      "Predicted Policy  [0.         0.21064588 0.1601865  0.2694421  0.13310872 0.10089874\n",
      " 0.         0.         0.12571813]\n",
      "Predicted Value  -0.02270214818418026\n",
      "Target Policy [0.         0.1225     0.1175     0.39750001 0.1175     0.1275\n",
      " 0.         0.         0.1175    ]\n",
      "Predicted Policy  [0.         0.         0.20876452 0.2716227  0.18721443 0.17063347\n",
      " 0.         0.         0.16176483]\n",
      "Predicted Value  0.002241582376882434\n",
      "Target Policy [0.         0.         0.03       0.88249999 0.025      0.02875\n",
      " 0.         0.         0.03375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Predicted Value  0.0\n",
      "Target Policy [0.10125    0.08       0.06625    0.1025     0.10625    0.20874999\n",
      " 0.12125    0.10625    0.1075    ]\n",
      "Predicted Policy  [0.11255588 0.16274107 0.12700117 0.19654943 0.10890167 0.08619357\n",
      " 0.         0.1109551  0.09510212]\n",
      "Predicted Value  0.011775023303925991\n",
      "Target Policy [0.09875 0.13    0.11875 0.17    0.125   0.1     0.      0.1025  0.155  ]\n",
      "Predicted Policy  [0.12878177 0.         0.14179239 0.18263592 0.14409341 0.14232542\n",
      " 0.         0.13116513 0.12920597]\n",
      "Predicted Value  -0.002304009161889553\n",
      "Target Policy [0.90750003 0.         0.01625    0.0175     0.01375    0.015\n",
      " 0.         0.01375    0.01625   ]\n",
      "Predicted Policy  [0.         0.         0.16933513 0.3057273  0.14454278 0.11309638\n",
      " 0.         0.1381029  0.12919554]\n",
      "Predicted Value  0.0012447816552594304\n",
      "Target Policy [0.      0.      0.115   0.465   0.08125 0.10625 0.      0.11125 0.12125]\n",
      "Predicted Policy  [0.         0.         0.22884849 0.         0.22752117 0.19094525\n",
      " 0.         0.17912124 0.17356382]\n",
      "Predicted Value  -0.00040625143446959555\n",
      "Target Policy [0.         0.         0.02375    0.         0.0425     0.01625\n",
      " 0.         0.02875    0.88875002]\n",
      "Predicted Policy  [0.         0.         0.2994073  0.         0.26079682 0.20499703\n",
      " 0.         0.23479886 0.        ]\n",
      "Predicted Value  0.008929268456995487\n",
      "Target Policy [0.         0.         0.1275     0.         0.37875    0.14\n",
      " 0.         0.35374999 0.        ]\n",
      "Predicted Policy  [0.         0.         0.3869936  0.         0.34094998 0.27205637\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  -0.0010668083559721708\n",
      "Target Policy [0.         0.         0.07875    0.         0.72250003 0.19875\n",
      " 0.         0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1, -1, 1]\n",
      "Value Loss  tf.Tensor(\n",
      "[0.9842409  0.9822217  1.0336645  0.93403256 0.95367503 0.9660704\n",
      " 0.9500741  1.0615987  0.9824177  1.0474236  1.1076277  1.0495414\n",
      " 0.9660704  1.0055177  0.9956568  1.0158542  1.0113802  0.96835726\n",
      " 0.931139   0.9715553  0.9660704  1.0679189  1.0557222  1.013986\n",
      " 1.0361085  1.0679189  1.0764414  0.9660704  0.9826896  1.0466256\n",
      " 0.95367503 1.0968792  1.0308876  1.0391861  1.0679189  1.0422407\n",
      " 1.021667   0.9934371  1.0422407  0.9660704  1.0194713  1.0260545\n",
      " 1.0594866  0.9824177  0.97658837 0.9660704  1.0071809  1.0194713\n",
      " 0.9927734  1.0308876  1.0064971  1.124718   0.9911074  1.0377898\n",
      " 0.93407166 1.124718   0.95367503 0.9660704  1.0391861  0.96388876\n",
      " 0.9904336  1.0290507  0.9660704  1.0680995  0.98060566 1.0158542\n",
      " 0.9255461  0.9640459  1.0377898  1.0296447  0.99504966 0.971339\n",
      " 0.9124879  0.88847154 1.0377898  1.05681    0.9625929  0.975094\n",
      " 1.0501438  0.9947669  0.97067    1.0785753  1.0503813  0.9660704\n",
      " 0.9822217  0.93407166 0.98184615 0.93407166 0.9826896  1.0615987\n",
      " 0.9124879  0.97546357 1.0557222  0.9625929  0.95367503 0.9728369\n",
      " 0.88847154 1.0158542  0.95367503 1.0294393  1.0290507  1.05681\n",
      " 0.9934371  1.0740529  0.9255461  1.0218574  1.0491809  1.0422407\n",
      " 1.0217347  0.9472399  1.1052102  1.000682   0.98060566 1.0422407\n",
      " 1.0422407  0.9842409  1.0786033  0.9826896  0.98873585 1.0466921\n",
      " 1.0785753  1.0422407  1.0361085  1.0052469  1.0679189  0.97658837\n",
      " 0.94223195 1.0260545  0.9807164  1.0712134  0.931139   1.0194713\n",
      " 1.0162897  1.0501438  1.0296447  0.95935893 1.0594866  1.0760032\n",
      " 0.9826896  0.9705239  1.0409212  0.9640459  0.9991879  1.0045986\n",
      " 0.95935893 0.9245755  1.0361085  0.9728369  1.0558938  0.9106334\n",
      " 1.0260545  1.1092335  1.0505868  1.0785753  1.1052102  1.0615987\n",
      " 1.0641093  0.9472399  0.9975121  0.9750899  1.0113802  0.97067\n",
      " 0.9705239  0.9987456  1.0524442  1.0308876  0.9927734  1.0503813\n",
      " 0.97546357 0.98427033 0.9625615  1.013986   0.9927734  0.9927734\n",
      " 1.013986   1.0557222  0.9150423  1.0296447  0.98184615 0.9705239\n",
      " 1.0308876  1.0044885  1.0466256  0.93407166 1.0294393  0.98427033\n",
      " 0.87823594 1.0045205  0.9285918  1.0501438  1.0524442  0.9927734\n",
      " 1.0505868  1.009266   0.9660704  1.0134425  0.9715553  1.0361085\n",
      " 1.0194713  0.9838418  0.959674   0.9822217  1.0764414  1.0390614\n",
      " 1.0236889  1.0216526  1.0194713  0.9715553  0.88365805 1.0470791\n",
      " 1.0215658  0.94223195 1.0570598  1.0466256  0.96388876 0.9500741\n",
      " 0.9927734  0.96388876 0.97658837 0.9500741  1.0216526  1.0064971\n",
      " 0.9947669  1.05681    1.013986   0.95367503 0.9947669  0.9826896\n",
      " 1.0409212  1.0158542  1.000682   1.0636238  0.9807164  1.0524442\n",
      " 0.9838418  1.0503813  0.9728369  1.0557222  1.0052469  1.0260545\n",
      " 0.931139   1.066723   0.98427033 1.0491809  1.0194713  1.0052469\n",
      " 0.9987456  1.0290507  1.0290507  1.0361085  1.0361085  1.0557222\n",
      " 1.0058349  0.9660704  0.97067    0.971339   0.95367503 1.0064971\n",
      " 1.000682   1.0005733  0.97546357 0.9500741  1.0217347  1.0503813\n",
      " 1.013986   1.0216526  1.0785753  1.0466256  1.0158542  1.0162897\n",
      " 1.0001018  1.035646   0.9728369  0.971339   0.9358756  0.9786644\n",
      " 1.0489538  1.0072529  1.0162897  0.99028075 1.05681    0.95367503\n",
      " 0.9927734  1.0524442  0.9106334  0.9027471  1.0968792  0.86097443\n",
      " 1.0422407  0.9715553  1.0295547  0.9632156  1.0495414  1.0636238\n",
      " 0.9506461  1.0466921  1.0491809  1.0119481  0.9640459  1.0785753\n",
      " 0.95935893 0.9842409  1.0474236  1.0524442  1.0293822  0.971339\n",
      " 0.9987456  0.98873585 1.0158542  0.9927734  1.0361085  0.9750899\n",
      " 0.9750899  0.97889143 1.1052102  1.0158542  0.9826896  0.9500741\n",
      " 0.9992009  1.0295547  0.9497709  1.0005733  1.0278106  1.0113802\n",
      " 1.0071809  1.0045205  1.0764414  1.0466256  1.089228   0.9934371\n",
      " 1.0295547  0.93407166 0.9728369  1.0570598  1.0594866  0.9106334\n",
      " 0.9842409  1.0489538  0.93407166 0.9750899  1.0761577  1.0194713\n",
      " 0.9660704  0.9826896  1.0422407  0.971339   0.97437197 1.0524442\n",
      " 1.05681    1.0064971  1.0216526  1.0215658  0.931139   0.93407166\n",
      " 1.0470971  0.9660704  1.0636238  1.0489538  1.0361085  0.9027471\n",
      " 1.009266   1.0361085  1.0377898  0.931139   1.0113802  1.0158542\n",
      " 0.9150423  0.99246925 1.1052102  0.975094   1.013986   0.88365805\n",
      " 0.88847154 0.9826896  0.97437197 1.0194713  1.1052102  1.0162897\n",
      " 0.9927734  1.1092335  1.013986   1.0293822  0.98060566 0.95367503\n",
      " 0.9927734  0.96835726 1.0474236  1.0422407  0.97546357 1.0524442\n",
      " 1.0422407  1.0409212  1.0503813  1.0217347  1.1052102  1.0582534\n",
      " 0.971339   1.0308876  1.089228   1.0278106  1.0474236  0.99689937\n",
      " 1.0294393  1.0361085  1.0495414  1.0290507  0.9150423  1.0295547\n",
      " 1.009266   0.9927734  1.0474863  1.0491809  1.0501438  0.88847154\n",
      " 1.0158542  1.0113802  0.9842409  1.0278106  1.0194713  0.9715553\n",
      " 0.97856534 0.8518315  0.9150423  0.93407166 1.0557222  0.98427033\n",
      " 0.93407166 0.9625615  1.0293822  1.1092335  0.97546357 0.96588427\n",
      " 1.0968792  0.93403256 0.959674   1.0217347  0.98427033 0.9660704\n",
      " 1.0295547  0.88847154 0.99504966 1.0470971  1.0064971  0.9124879\n",
      " 1.0474236  1.0336645  1.0158542  1.1052102  1.0680995  1.009266\n",
      " 1.009266   1.003565   0.931139   1.0045986  0.93407166 0.9500741\n",
      " 0.98306876 1.0466921  0.8518315  1.0113802  0.95367503 1.0044885\n",
      " 1.0361085  0.88847154 1.0422407  1.0524442  0.9632156  1.0518103\n",
      " 1.0460683  1.0296447  1.0764414  0.97546357 0.92770875 1.0594866\n",
      " 1.0361085  0.9992009  1.0012552  0.97658837 0.931139   0.971339\n",
      " 1.0059636  1.1092335  0.9737606  1.0764414  1.0217347  1.0134425\n",
      " 1.0474236  1.0489538  0.9927734  0.9625615  0.9934371  0.9956568\n",
      " 1.0844048  1.0194713  0.9715553  1.0466921  1.0391861  1.0460683\n",
      " 0.97437197 1.0055177  0.9027471  0.9824177  1.0570598  1.0064971\n",
      " 0.9660704  1.0764414  1.0064971  0.88365805 1.0293822  1.0524442\n",
      " 1.0764414  1.0134425  1.0336645  1.0582534  0.95863307 1.0194713\n",
      " 1.0844048  0.9660704  1.089228   1.0524442  1.0296447  1.1092335\n",
      " 1.0260545  0.88847154 0.9521836  1.035646   0.9728369  0.9660704\n",
      " 1.0390614  0.9285918  1.0570598  0.9992009  0.8518315  0.9245755\n",
      " 1.035646   0.9705239  1.0216526  0.971339   1.0308876  1.0570598\n",
      " 1.0503813  1.0495414  1.0760032  0.98427033 1.0308876  1.0045986\n",
      " 1.0296447  0.99504966 1.0218574  1.0557222  0.9508568  0.97658837\n",
      " 1.0158542  1.0761577  0.9472399  1.0422407  0.9508568  0.97658837\n",
      " 0.9750899  1.0377898 ], shape=(560,), dtype=float32)\n",
      "Policy Loss  tf.Tensor(\n",
      "[1.6239287  1.7566674  1.6386197  2.2556255  2.280675   2.2325826\n",
      " 2.0825431  1.7282363  1.8529702  2.2773352  1.7661699  1.4367988\n",
      " 2.2137039  2.0482688  1.4175307  2.2369106  1.8428499  0.44540954\n",
      " 1.2240952  1.9538437  2.2325826  1.8501232  1.9577477  1.4227586\n",
      " 2.267881   1.8501232  2.1421785  2.2859612  1.9113214  2.427506\n",
      " 2.2789402  1.6670328  2.234709   1.3002787  1.8501232  2.2743466\n",
      " 1.9147204  1.7371843  2.2743466  2.197441   2.214821   2.1836162\n",
      " 1.9591726  1.8529702  2.2748008  2.2859612  1.9905281  2.214821\n",
      " 2.2324767  2.234709   2.0957723  1.9118438  2.1012268  1.7227247\n",
      " 1.3167408  1.9118438  2.280675   2.2325826  1.3002787  1.6440331\n",
      " 0.68533826 1.5245159  2.1900733  1.787356   2.0721097  2.229837\n",
      " 2.3137383  1.4168429  1.7227247  1.6715622  1.819066   2.0263956\n",
      " 1.9656701  1.2183927  1.7227247  1.6054763  1.7386171  1.1578519\n",
      " 1.5169383  1.940602   1.7853053  1.2518914  1.9814174  2.28627\n",
      " 1.7566674  1.3167408  1.7617103  1.4460912  1.9113214  1.7282363\n",
      " 1.9656701  1.9229033  1.9577477  1.7386171  2.280675   2.1440086\n",
      " 1.2183927  2.2369106  2.280675   2.0149574  1.5245159  1.6054763\n",
      " 1.7371843  2.1534543  2.3137383  1.7075953  2.0950744  2.2743466\n",
      " 1.182585   1.7141861  1.7278042  1.9587113  2.0721097  2.2861285\n",
      " 2.217213   1.6239287  1.8874118  1.9113214  2.077005   1.703583\n",
      " 1.2518914  2.2743466  2.2719846  1.9490898  1.8501232  2.1806285\n",
      " 1.9598585  2.1836162  2.2787638  1.8543512  1.4799205  2.2847693\n",
      " 2.1142833  1.5169383  1.6715622  1.625552   1.9591726  2.0920353\n",
      " 1.9113214  1.6331761  2.1636152  1.4168429  1.714247   1.3641882\n",
      " 1.625552   1.7782634  2.267881   2.1440086  2.0884151  1.4891179\n",
      " 2.1836162  1.1912609  2.133201   1.2518914  1.7278042  1.7282363\n",
      " 2.0952427  1.7141861  2.0969946  2.0907786  1.8428499  1.7853053\n",
      " 1.6331761  2.0148091  1.9817451  2.234709   2.2819753  1.9814174\n",
      " 1.9229033  2.180008   1.7489331  1.4227586  2.2324767  2.2819753\n",
      " 1.4227586  1.9577477  1.745637   1.6715622  1.7617103  1.6331761\n",
      " 2.234709   1.7293893  2.427506   1.4460912  2.0149574  2.180008\n",
      " 0.5763352  1.3920093  1.9627931  1.5169383  1.9817451  2.2324767\n",
      " 2.133201   1.7099504  2.28627    1.958579   1.9538437  2.267881\n",
      " 2.2847693  2.0669076  1.8455758  1.7566674  2.1421785  1.8783672\n",
      " 2.2745407  1.8892019  2.2847693  1.9538437  1.0947293  1.4462498\n",
      " 2.181075   1.9598585  1.5839356  2.427506   1.6440331  2.0825431\n",
      " 2.2819753  1.6440331  2.1806285  2.0825431  1.8892019  2.0957723\n",
      " 1.940602   1.6054763  1.4227586  2.2789402  1.9566803  1.9113214\n",
      " 2.1636152  2.229837   1.9587113  1.8572073  2.2787638  1.5185984\n",
      " 2.0669076  1.9814174  2.207114   1.9577477  1.9490898  2.1836162\n",
      " 1.4799205  1.3205767  2.2778823  2.0950744  2.2847693  1.9490898\n",
      " 2.0148091  1.5245159  1.5245159  2.2243123  2.195197   1.9577477\n",
      " 1.6920514  2.2137039  1.7853053  2.0263956  2.2789402  2.0957723\n",
      " 1.9587113  1.5221598  1.9229033  2.0825431  1.182585   1.9814174\n",
      " 1.4227586  1.8892019  1.2518914  2.427506   2.229837   2.1142833\n",
      " 1.72133    1.6275657  2.207114   2.0263956  2.0167606  1.9882348\n",
      " 1.4633546  2.1888933  2.1142833  0.7051593  1.6054763  2.280675\n",
      " 2.2819753  1.5185984  1.4891179  1.1565541  1.6670328  1.4513264\n",
      " 2.2743466  1.9538437  1.8351312  1.2197132  1.4367988  1.8572073\n",
      " 0.92430913 1.703583   2.0950744  1.7016307  1.4168429  1.2518914\n",
      " 1.625552   1.6239287  2.2773352  1.5185984  2.1703815  2.0263956\n",
      " 2.0148091  2.077005   2.229837   2.2324767  2.2243123  2.0907786\n",
      " 2.0907786  1.3030702  1.7278042  2.2369106  1.9113214  2.0825431\n",
      " 1.4591401  1.8351312  1.9940112  1.5221598  1.8240776  1.1978451\n",
      " 1.9905281  1.3920093  2.0891535  2.427506   1.9299057  1.7371843\n",
      " 1.8351312  1.4460912  2.207114   1.5839356  1.9591726  1.4891179\n",
      " 1.6239287  1.9777966  1.3167408  2.0907786  2.367735   2.214821\n",
      " 2.2859612  1.9113214  2.2861285  2.0263956  1.4384155  1.9817451\n",
      " 1.6054763  2.0957723  1.8892019  2.181075   1.4799205  1.3167408\n",
      " 2.0627723  2.2325826  1.8572073  1.9777966  2.195197   1.1565541\n",
      " 1.7099504  2.267881   1.7227247  1.4799205  1.8428499  2.2369106\n",
      " 1.745637   2.1282039  1.7278042  1.1578519  1.4227586  1.0947293\n",
      " 1.2183927  1.9113214  1.4384155  2.2847693  1.7278042  2.1142833\n",
      " 2.2819753  1.1912609  1.4227586  2.1703815  2.0721097  2.2789402\n",
      " 2.2324767  0.44540954 2.2773352  2.2861285  1.9229033  1.5185984\n",
      " 2.2861285  2.0924342  1.9814174  1.182585   1.7278042  1.7887924\n",
      " 2.0263956  2.234709   1.9299057  1.8240776  2.1944547  1.5612743\n",
      " 2.0149574  2.267881   1.4367988  1.5245159  1.745637   1.8351312\n",
      " 1.7099504  2.2324767  1.867321   2.0950744  1.5169383  1.2183927\n",
      " 2.229837   1.8428499  1.6239287  1.8240776  2.2847693  1.9538437\n",
      " 1.9192507  1.7643065  1.745637   1.4460912  1.9577477  2.2373343\n",
      " 1.3167408  1.7489331  2.1703815  1.1912609  1.9229033  2.1459494\n",
      " 1.6670328  2.2556255  1.8455758  1.182585   2.2778823  2.28627\n",
      " 1.8351312  1.2183927  1.819066   2.0627723  2.0957723  1.9656701\n",
      " 2.1944547  1.6386197  2.2369106  1.7278042  1.787356   1.7099504\n",
      " 1.7099504  1.7636033  1.2240952  1.3641882  1.3167408  2.0825431\n",
      " 1.5514926  1.703583   1.7643065  1.8428499  2.2789402  1.7293893\n",
      " 2.267881   1.2183927  2.2861285  1.9817451  1.2197132  2.0877414\n",
      " 1.952998   1.6715622  2.0891535  1.9229033  1.8410845  1.9591726\n",
      " 2.267881   1.4591401  2.1193774  2.2748008  1.4799205  2.0263956\n",
      " 1.9983662  1.1912609  2.0388112  2.0891535  1.182585   1.958579\n",
      " 2.2773352  1.4633546  2.2324767  1.7489331  1.7371843  1.4175307\n",
      " 1.770755   2.2847693  1.9538437  1.703583   1.3002787  1.952998\n",
      " 1.4384155  2.0482688  1.1565541  1.8529702  1.5839356  2.0957723\n",
      " 2.28627    2.1421785  2.0957723  1.0947293  2.1703815  1.9817451\n",
      " 2.0891535  1.958579   1.6386197  1.7887924  2.3027072  2.214821\n",
      " 1.770755   2.2325826  1.9299057  1.9817451  1.6715622  1.1912609\n",
      " 2.1836162  1.2183927  2.00646    1.6275657  2.1440086  2.2137039\n",
      " 1.8783672  1.9627931  1.5839356  1.4591401  1.7643065  1.7782634\n",
      " 1.6275657  1.6331761  1.8892019  2.0263956  2.234709   1.5839356\n",
      " 1.9814174  1.4367988  1.7978274  2.2778823  2.234709   1.3641882\n",
      " 1.6715622  1.819066   1.7075953  1.9577477  1.9892347  2.2790565\n",
      " 2.229837   2.367735   1.7141861  2.2743466  1.9892347  2.1806285\n",
      " 2.0907786  1.7227247 ], shape=(560,), dtype=float32)\n",
      "L2 Loss  tf.Tensor(0.10779216, shape=(), dtype=float32)\n",
      "Loss  tf.Tensor(2.9765809, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step  2\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57125002\n",
      " 0.05125    0.00875    0.00875   ]\n",
      "Predicted Policy  [4.92727679e-07 5.98915387e-04 1.13545735e-04 5.55238798e-02\n",
      " 0.00000000e+00 1.61536708e-02 3.74369975e-08 3.40242230e-04\n",
      " 9.27269220e-01]\n",
      "Predicted Value  0.9999228715896606\n",
      "Target Policy [0.75       0.02       0.13124999 0.04125    0.         0.02\n",
      " 0.00625    0.005      0.02625   ]\n",
      "Predicted Policy  [1.1218580e-03 2.5457483e-02 0.0000000e+00 1.9333862e-01 0.0000000e+00\n",
      " 1.0923699e-01 3.8161274e-04 1.9705629e-02 6.5075779e-01]\n",
      "Predicted Value  0.9761841893196106\n",
      "Target Policy [0.71625 0.04    0.      0.11    0.      0.0775  0.02625 0.00875 0.02125]\n",
      "Predicted Policy  [0.0000000e+00 3.6781971e-04 0.0000000e+00 4.8554108e-02 0.0000000e+00\n",
      " 1.2845799e-02 1.2620733e-08 1.9923771e-04 9.3803298e-01]\n",
      "Predicted Value  0.9999606013298035\n",
      "Target Policy [0.      0.21375 0.      0.0625  0.      0.6875  0.00625 0.005   0.025  ]\n",
      "Predicted Policy  [0.0000000e+00 1.2437474e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.7578617e-02 5.2440981e-05 9.3472609e-03 8.9058417e-01]\n",
      "Predicted Value  0.9935754537582397\n",
      "Target Policy [0.         0.14875001 0.         0.         0.         0.22875001\n",
      " 0.105      0.00625    0.51125002]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57375002\n",
      " 0.04625    0.01125    0.00875   ]\n",
      "Predicted Policy  [8.8917778e-07 8.4126805e-04 1.6936104e-04 0.0000000e+00 8.5947914e-03\n",
      " 2.0261640e-02 7.3556684e-08 4.6268798e-04 9.6966928e-01]\n",
      "Predicted Value  0.9998782873153687\n",
      "Target Policy [0.0625     0.81625003 0.04375    0.         0.01875    0.02\n",
      " 0.005      0.0075     0.02625   ]\n",
      "Predicted Policy  [1.6275302e-03 0.0000000e+00 1.6324563e-02 0.0000000e+00 9.8103635e-02\n",
      " 1.3185771e-01 5.7976606e-04 2.7195258e-02 7.2431147e-01]\n",
      "Predicted Value  0.9714788794517517\n",
      "Target Policy [0.07375    0.         0.0725     0.         0.09125    0.66374999\n",
      " 0.0675     0.0075     0.02375   ]\n",
      "Predicted Policy  [1.3697645e-07 0.0000000e+00 4.9185212e-05 0.0000000e+00 0.0000000e+00\n",
      " 1.1869400e-02 8.2541529e-09 1.6552047e-04 9.8791575e-01]\n",
      "Predicted Value  0.9999660849571228\n",
      "Target Policy [0.435      0.         0.34999999 0.         0.         0.17749999\n",
      " 0.0075     0.005      0.025     ]\n",
      "Predicted Policy  [1.0662819e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 7.3761992e-02 2.2419330e-05 6.8224701e-03 9.1928649e-01]\n",
      "Predicted Value  0.9963095784187317\n",
      "Target Policy [0.13249999 0.         0.         0.         0.         0.73374999\n",
      " 0.1        0.00625    0.0275    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57375002\n",
      " 0.04625    0.00875    0.01125   ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.01625    0.86750001 0.03125    0.0325     0.01875    0.\n",
      " 0.00375    0.005      0.025     ]\n",
      "Predicted Policy  [0.00206021 0.         0.01741227 0.2206453  0.09419914 0.\n",
      " 0.00075082 0.02939486 0.6355374 ]\n",
      "Predicted Value  0.963878333568573\n",
      "Target Policy [0.0275     0.         0.64249998 0.2        0.07       0.\n",
      " 0.03125    0.0075     0.02125   ]\n",
      "Predicted Policy  [2.2504003e-07 0.0000000e+00 0.0000000e+00 5.1257923e-02 5.1053609e-03\n",
      " 0.0000000e+00 1.5844140e-08 2.2797640e-04 9.4340849e-01]\n",
      "Predicted Value  0.9999551177024841\n",
      "Target Policy [0.91000003 0.         0.         0.0325     0.02       0.\n",
      " 0.0025     0.01       0.025     ]\n",
      "Predicted Policy  [1.6410184e-03 0.0000000e+00 0.0000000e+00 7.1376008e-01 2.3577085e-01\n",
      " 0.0000000e+00 4.5361309e-04 4.8374433e-02 0.0000000e+00]\n",
      "Predicted Value  0.9890990853309631\n",
      "Target Policy [0.00875    0.         0.         0.02375    0.01375    0.\n",
      " 0.0125     0.94125003 0.        ]\n",
      "Predicted Policy  [2.2347765e-06 0.0000000e+00 0.0000000e+00 9.1852307e-01 8.1474558e-02\n",
      " 0.0000000e+00 1.2264961e-07 0.0000000e+00 0.0000000e+00]\n",
      "Predicted Value  0.9999718070030212\n",
      "Target Policy [0.94375002 0.         0.         0.0375     0.01625    0.\n",
      " 0.0025     0.         0.        ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 7.9775995e-01 2.0216572e-01\n",
      " 0.0000000e+00 7.4342257e-05 0.0000000e+00 0.0000000e+00]\n",
      "Predicted Value  0.9972577095031738\n",
      "Target Policy [0.         0.         0.         0.51749998 0.27000001 0.\n",
      " 0.21250001 0.         0.        ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9999958e-01\n",
      " 0.0000000e+00 4.3350613e-07 0.0000000e+00 0.0000000e+00]\n",
      "Predicted Value  0.9999893307685852\n",
      "Target Policy [0.    0.    0.    0.    0.995 0.    0.005 0.    0.   ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57499999\n",
      " 0.04625    0.01       0.00875   ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.01625    0.85000002 0.0225     0.03375    0.0425     0.\n",
      " 0.00375    0.005      0.02625   ]\n",
      "Predicted Policy  [0.00316525 0.0431512  0.         0.22892703 0.10233217 0.\n",
      " 0.00125916 0.03563376 0.5855315 ]\n",
      "Predicted Value  0.954247772693634\n",
      "Target Policy [0.0275  0.04875 0.      0.815   0.0575  0.      0.02625 0.005   0.02   ]\n",
      "Predicted Policy  [2.4659241e-07 4.5028582e-04 0.0000000e+00 0.0000000e+00 5.8253845e-03\n",
      " 0.0000000e+00 1.7408075e-08 2.4158121e-04 9.9348247e-01]\n",
      "Predicted Value  0.9999509453773499\n",
      "Target Policy [0.50875002 0.36125001 0.         0.         0.0925     0.\n",
      " 0.0075     0.005      0.025     ]\n",
      "Predicted Policy  [2.0877190e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.9724104e-02\n",
      " 0.0000000e+00 4.7615697e-05 1.0718495e-02 9.2930102e-01]\n",
      "Predicted Value  0.9946455955505371\n",
      "Target Policy [0.29875001 0.         0.         0.         0.44874999 0.\n",
      " 0.2225     0.00375    0.02625   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57499999\n",
      " 0.04625    0.00875    0.01      ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.02125 0.84875 0.04    0.0325  0.02    0.      0.00625 0.005   0.02625]\n",
      "Predicted Policy  [0.00206021 0.         0.01741227 0.2206453  0.09419914 0.\n",
      " 0.00075082 0.02939486 0.6355374 ]\n",
      "Predicted Value  0.963878333568573\n",
      "Target Policy [0.0375     0.         0.64999998 0.2        0.05625    0.\n",
      " 0.02625    0.00875    0.02125   ]\n",
      "Predicted Policy  [1.6033529e-07 0.0000000e+00 5.5578461e-05 4.6954095e-02 0.0000000e+00\n",
      " 0.0000000e+00 1.0146625e-08 1.9158164e-04 9.5279860e-01]\n",
      "Predicted Value  0.9999633431434631\n",
      "Target Policy [0.38124999 0.         0.4425     0.14125    0.         0.\n",
      " 0.00375    0.00625    0.025     ]\n",
      "Predicted Policy  [1.1443154e-04 0.0000000e+00 0.0000000e+00 1.6094711e-01 0.0000000e+00\n",
      " 0.0000000e+00 2.4598001e-05 6.6899355e-03 8.3222389e-01]\n",
      "Predicted Value  0.9958613514900208\n",
      "Target Policy [0.41499999 0.         0.         0.52499998 0.         0.\n",
      " 0.0275     0.00625    0.02625   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57625002\n",
      " 0.04625    0.00875    0.00875   ]\n",
      "Predicted Policy  [9.0702451e-07 0.0000000e+00 1.6638027e-04 6.2633790e-02 8.2452223e-03\n",
      " 2.0351984e-02 7.6947607e-08 4.8008747e-04 9.0812153e-01]\n",
      "Predicted Value  0.9998745918273926\n",
      "Target Policy [0.02375    0.         0.025      0.02375    0.86874998 0.02375\n",
      " 0.005      0.00375    0.02625   ]\n",
      "Predicted Policy  [1.09649857e-03 0.00000000e+00 1.14914365e-02 1.95846334e-01\n",
      " 0.00000000e+00 1.10852927e-01 3.50546063e-04 1.88718624e-02\n",
      " 6.61490381e-01]\n",
      "Predicted Value  0.9781454205513\n",
      "Target Policy [0.03       0.         0.03       0.80500001 0.         0.0775\n",
      " 0.0275     0.0075     0.0225    ]\n",
      "Predicted Policy  [1.83333867e-07 0.00000000e+00 6.03417429e-05 0.00000000e+00\n",
      " 0.00000000e+00 1.36588942e-02 1.30654385e-08 1.99700662e-04\n",
      " 9.86080885e-01]\n",
      "Predicted Value  0.9999530911445618\n",
      "Target Policy [0.78375 0.      0.0225  0.      0.      0.15375 0.0075  0.005   0.0275 ]\n",
      "Predicted Policy  [1.11840396e-04 0.00000000e+00 3.43731977e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.16764947e-05 6.83578290e-03\n",
      " 9.89593327e-01]\n",
      "Predicted Value  0.9968022704124451\n",
      "Target Policy [0.33000001 0.         0.36750001 0.         0.         0.\n",
      " 0.26875001 0.0075     0.02625   ]\n",
      "Predicted Policy  [5.39051861e-08 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.88525825e-09 1.05626685e-04\n",
      " 9.99894261e-01]\n",
      "Predicted Value  0.999980092048645\n",
      "Target Policy [0.95999998 0.         0.         0.         0.         0.\n",
      " 0.00875    0.00625    0.025     ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 5.2177365e-06 3.2893391e-03 9.9670541e-01]\n",
      "Predicted Value  0.9986818432807922\n",
      "Target Policy [0.         0.         0.         0.         0.         0.\n",
      " 0.96499997 0.00875    0.02625   ]\n",
      "Predicted Policy  [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 7.013391e-05 9.999299e-01]\n",
      "Predicted Value  0.9999878406524658\n",
      "Target Policy [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01875    0.98124999]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57499999\n",
      " 0.04625    0.00875    0.01      ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.01625    0.87875003 0.01625    0.0325     0.01875    0.\n",
      " 0.0075     0.00375    0.02625   ]\n",
      "Predicted Policy  [0.00206021 0.         0.01741227 0.2206453  0.09419914 0.\n",
      " 0.00075082 0.02939486 0.6355374 ]\n",
      "Predicted Value  0.963878333568573\n",
      "Target Policy [0.0275     0.         0.60250002 0.2        0.115      0.\n",
      " 0.0275     0.00625    0.02125   ]\n",
      "Predicted Policy  [2.2504003e-07 0.0000000e+00 0.0000000e+00 5.1257923e-02 5.1053609e-03\n",
      " 0.0000000e+00 1.5844140e-08 2.2797640e-04 9.4340849e-01]\n",
      "Predicted Value  0.9999551177024841\n",
      "Target Policy [0.89749998 0.         0.         0.04375    0.01625    0.\n",
      " 0.00875    0.00875    0.025     ]\n",
      "Predicted Policy  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.83400959e-01\n",
      " 6.17562644e-02 0.00000000e+00 1.28007538e-04 1.32573815e-02\n",
      " 7.41457403e-01]\n",
      "Predicted Value  0.9893253445625305\n",
      "Target Policy [0.         0.         0.         0.31125    0.14125    0.\n",
      " 0.085      0.00625    0.45625001]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57499999\n",
      " 0.04625    0.01       0.00875   ]\n",
      "Predicted Policy  [1.9097606e-06 1.2701291e-03 2.7721663e-04 6.9477879e-02 1.0432255e-02\n",
      " 2.3992544e-02 0.0000000e+00 6.8179215e-04 8.9386630e-01]\n",
      "Predicted Value  0.9998001456260681\n",
      "Target Policy [0.10375    0.10375    0.10125    0.12125    0.12125    0.10375\n",
      " 0.         0.11625    0.22875001]\n",
      "Predicted Policy  [0.00301515 0.03573787 0.0193382  0.20105259 0.09322409 0.1182223\n",
      " 0.         0.         0.5294098 ]\n",
      "Predicted Value  0.9473817944526672\n",
      "Target Policy [0.07875    0.02625    0.04125    0.41999999 0.19125    0.17125\n",
      " 0.         0.         0.07125   ]\n",
      "Predicted Policy  [2.3067781e-07 4.3406471e-04 7.2294417e-05 4.7590330e-02 0.0000000e+00\n",
      " 1.2713151e-02 0.0000000e+00 0.0000000e+00 9.3918991e-01]\n",
      "Predicted Value  0.9999532699584961\n",
      "Target Policy [0.14624999 0.1425     0.18625    0.08375    0.         0.14624999\n",
      " 0.         0.         0.29499999]\n",
      "Predicted Policy  [0.00091559 0.04498316 0.01638481 0.6348273  0.         0.30288914\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.9923318028450012\n",
      "Target Policy [0.14875001 0.15625    0.25874999 0.25375    0.         0.1825\n",
      " 0.         0.         0.        ]\n",
      "Predicted Policy  [6.2093191e-06 2.2872740e-02 3.3135533e-03 0.0000000e+00 0.0000000e+00\n",
      " 9.7380757e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Predicted Value  0.999982476234436\n",
      "Target Policy [0.07125    0.07875    0.09375    0.         0.         0.75625002\n",
      " 0.         0.         0.        ]\n",
      "Predicted Policy  [0.00472329 0.7708393  0.22443742 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.9985383749008179\n",
      "Target Policy [0.18000001 0.48374999 0.33625001 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "Predicted Policy  [0.00129332 0.         0.99870676 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.9999909400939941\n",
      "Target Policy [0.0075     0.         0.99250001 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57375002\n",
      " 0.04625    0.01       0.01      ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.01875    0.83249998 0.01625    0.0475     0.05125    0.\n",
      " 0.00375    0.00375    0.02625   ]\n",
      "Predicted Policy  [0.00206021 0.         0.01741227 0.2206453  0.09419914 0.\n",
      " 0.00075082 0.02939486 0.6355374 ]\n",
      "Predicted Value  0.963878333568573\n",
      "Target Policy [0.03625    0.         0.64125001 0.2        0.07       0.\n",
      " 0.02625    0.005      0.02125   ]\n",
      "Predicted Policy  [2.2504003e-07 0.0000000e+00 0.0000000e+00 5.1257923e-02 5.1053609e-03\n",
      " 0.0000000e+00 1.5844140e-08 2.2797640e-04 9.4340849e-01]\n",
      "Predicted Value  0.9999551177024841\n",
      "Target Policy [0.89999998 0.         0.         0.045      0.01625    0.\n",
      " 0.00625    0.0075     0.025     ]\n",
      "Predicted Policy  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.83400959e-01\n",
      " 6.17562644e-02 0.00000000e+00 1.28007538e-04 1.32573815e-02\n",
      " 7.41457403e-01]\n",
      "Predicted Value  0.9893253445625305\n",
      "Target Policy [0.         0.         0.         0.27875    0.15000001 0.\n",
      " 0.06125    0.0075     0.5025    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.10769542 0.1104171  0.10975769 0.11311129 0.11293018 0.11287638\n",
      " 0.10568353 0.11192612 0.11560226]\n",
      "Predicted Value  0.029582686722278595\n",
      "Target Policy [0.05625    0.05625    0.055      0.12375    0.06875    0.57125002\n",
      " 0.04625    0.01       0.0125    ]\n",
      "Predicted Policy  [7.4202399e-07 7.7491126e-04 1.5304977e-04 6.3327417e-02 7.7261534e-03\n",
      " 0.0000000e+00 6.3145933e-08 4.4230494e-04 9.2757535e-01]\n",
      "Predicted Value  0.9998986124992371\n",
      "Target Policy [0.01625    0.84500003 0.02125    0.0325     0.05125    0.\n",
      " 0.00375    0.005      0.025     ]\n",
      "Predicted Policy  [0.00206021 0.         0.01741227 0.2206453  0.09419914 0.\n",
      " 0.00075082 0.02939486 0.6355374 ]\n",
      "Predicted Value  0.963878333568573\n",
      "Target Policy [0.04375    0.         0.63875002 0.2        0.05625    0.\n",
      " 0.0325     0.0075     0.02125   ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 7.9352605e-05 5.0898522e-02 5.2823573e-03\n",
      " 0.0000000e+00 1.9975419e-08 2.4670517e-04 9.4349307e-01]\n",
      "Predicted Value  0.9999473094940186\n",
      "Target Policy [0.         0.         0.88375002 0.05       0.0275     0.\n",
      " 0.0075     0.00625    0.025     ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8288957e-01 5.2609436e-02\n",
      " 0.0000000e+00 7.1103350e-05 1.0920647e-02 7.5350922e-01]\n",
      "Predicted Value  0.9920164346694946\n",
      "Target Policy [0.         0.         0.         0.46125001 0.2775     0.\n",
      " 0.23125    0.00625    0.02375   ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8533174e-03\n",
      " 0.0000000e+00 5.2434794e-09 1.2508262e-04 9.9602163e-01]\n",
      "Predicted Value  0.9999752640724182\n",
      "Target Policy [0.         0.         0.         0.         0.95999998 0.\n",
      " 0.00875    0.00625    0.025     ]\n",
      "Predicted Policy  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.0826518e-06 3.1506310e-03 9.9684626e-01]\n",
      "Predicted Value  0.9989818334579468\n",
      "Target Policy [0.         0.         0.         0.         0.         0.\n",
      " 0.96749997 0.00625    0.02625   ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1, -1, 1]\n",
      "Value Loss  tf.Tensor(\n",
      "[3.99989557e+00 7.19197502e-04 3.99985123e+00 3.00963222e-07\n",
      " 3.97051740e+00 1.02673425e-10 3.98525167e+00 1.97624104e-05\n",
      " 5.38364375e-09 1.43533185e-10 3.99992895e+00 2.81410450e-09\n",
      " 3.87064576e+00 7.06691594e-10 3.80529380e+00 8.13454331e-04\n",
      " 3.99991131e+00 3.98061728e+00 3.99496055e+00 8.13454331e-04\n",
      " 6.28439523e-11 2.06827977e-09 3.98299217e+00 1.00507995e-03\n",
      " 3.99993515e+00 1.30468436e-07 3.99951315e+00 4.71482053e-07\n",
      " 2.04589596e-05 2.13652220e-06 3.23592673e-08 3.99985123e+00\n",
      " 3.03322167e-09 1.25559427e-05 1.02673425e-10 3.99980211e+00\n",
      " 1.48139776e-08 3.33321019e-04 3.99985313e+00 3.96156526e+00\n",
      " 1.09937415e-03 2.60799334e-06 5.88003350e-05 3.99995232e+00\n",
      " 1.17524951e-06 3.97375131e+00 3.23592673e-08 3.95248485e+00\n",
      " 2.43872478e-10 3.96925139e+00 8.00268666e-04 5.93960081e-09\n",
      " 3.99952030e+00 7.58305418e-10 3.86847186e+00 1.46403778e-10\n",
      " 3.99928045e+00 3.88672924e+00 3.99945545e+00 7.58305418e-10\n",
      " 2.44826078e-03 3.82324505e+00 3.90117455e+00 5.93960081e-09\n",
      " 3.96988702e+00 1.70391701e-10 3.88764405e+00 3.23592673e-08\n",
      " 3.98361826e+00 7.11333215e-09 3.33321019e-04 3.95741558e+00\n",
      " 3.23592673e-08 3.99920082e+00 3.95741558e+00 3.80529380e+00\n",
      " 1.43961962e-08 6.39420978e-05 3.23592673e-08 3.80452847e+00\n",
      " 2.08131169e-07 1.92553685e-07 3.97383881e+00 5.02268449e-10\n",
      " 5.38364375e-09 3.99996376e+00 2.40163445e-10 3.23592673e-08\n",
      " 3.33321019e-04 1.57272098e-08 3.99928045e+00 2.08131169e-07\n",
      " 4.06712170e-05 1.06300391e-09 1.87239530e-05 3.99928045e+00\n",
      " 1.57272098e-08 1.89226086e-03 3.99951315e+00 1.01303967e-05\n",
      " 1.92553685e-07 1.92553685e-07 3.99994564e+00 1.02794253e-08\n",
      " 1.91188292e-06 3.98361826e+00 9.97948746e-09 3.82789159e+00\n",
      " 7.58305418e-10 3.99994612e+00 3.80529380e+00 3.96425533e+00\n",
      " 3.97756481e+00 4.84337818e-07 3.98249817e+00 3.86847186e+00\n",
      " 3.99998093e+00 8.00268666e-04 5.55111512e-11 3.96925139e+00\n",
      " 3.99986410e+00 3.97853303e+00 1.92553685e-07 3.23592673e-08\n",
      " 3.97129703e+00 1.12610010e-09 1.43961962e-08 3.99995375e+00\n",
      " 8.00268666e-04 3.99991035e+00 3.99992847e+00 1.15427667e-09\n",
      " 2.08131169e-07 2.40163445e-10 3.97756481e+00 1.06300391e-09\n",
      " 2.32830644e-10 3.23592673e-08 3.99524832e+00 3.88764405e+00\n",
      " 5.02268449e-10 3.96425533e+00 3.99993515e+00 3.90502572e+00\n",
      " 2.27405650e-10 1.95599625e-09 3.96010089e+00 3.78680086e+00\n",
      " 8.00268666e-04 1.70391701e-10 3.23592673e-08 2.40163445e-10\n",
      " 3.88764405e+00 7.18388549e-09 3.23678455e-06 2.69523426e-09\n",
      " 4.48043025e-09 2.40163445e-10 3.98525167e+00 2.29206876e-10\n",
      " 3.98062396e+00 1.12610010e-09 1.57272098e-08 1.09937415e-03\n",
      " 3.99995232e+00 1.48139776e-08 1.89226086e-03 1.02794253e-08\n",
      " 3.74880910e+00 6.38877751e-09 3.00963222e-07 3.96705532e+00\n",
      " 3.99949837e+00 4.48043025e-09 4.10693701e-10 1.73973774e-06\n",
      " 2.81410450e-09 5.93960081e-09 3.76405358e+00 3.99979210e+00\n",
      " 3.96991634e+00 1.71951342e-10 3.99986410e+00 3.98525167e+00\n",
      " 6.14818418e-10 1.06300391e-09 3.98062396e+00 1.30468436e-07\n",
      " 3.13845771e-06 3.03322167e-09 2.24538468e-08 3.00963222e-07\n",
      " 1.05103481e-10 5.93960081e-09 8.13454331e-04 3.99991274e+00\n",
      " 3.99991035e+00 3.96070933e+00 1.01303967e-05 3.99995995e+00\n",
      " 1.29608679e-09 3.99985027e+00 1.57272098e-08 3.98249817e+00\n",
      " 3.76405358e+00 1.20752830e-09 3.88764405e+00 3.23592673e-08\n",
      " 3.99985027e+00 3.99984360e+00 3.74434376e+00 3.99984360e+00\n",
      " 3.86847186e+00 2.01442063e-09 2.32830644e-10 1.02673425e-10\n",
      " 3.99101377e+00 1.73973774e-06 3.23592673e-08 8.00268666e-04\n",
      " 3.99995375e+00 3.99952030e+00 1.05103481e-10 3.99979210e+00\n",
      " 1.92553685e-07 3.99984360e+00 8.13454331e-04 3.99991131e+00\n",
      " 1.15427667e-09 1.09937415e-03 1.02673425e-10 4.05876222e-10\n",
      " 3.87064576e+00 3.63797881e-10 1.70391701e-10 3.99920082e+00\n",
      " 3.85681844e+00 6.38877751e-09 3.99995136e+00 3.99985123e+00\n",
      " 2.32830644e-10 5.55111512e-11 3.88764405e+00 3.99995375e+00\n",
      " 1.01303967e-05 3.85681844e+00 3.91541839e+00 4.31460330e-06\n",
      " 1.46403778e-10 3.97537208e+00 3.99101377e+00 4.31460330e-06\n",
      " 1.87938554e-10 1.67463384e-06 1.30477047e-03 3.98061728e+00\n",
      " 9.97948746e-09 3.88764405e+00 3.87064576e+00 3.99988747e+00\n",
      " 3.23592673e-08 1.48139776e-08 3.86847186e+00 1.13010401e-09\n",
      " 1.17524951e-06 3.33321019e-04 3.99940062e+00 1.02794253e-08\n",
      " 1.94532390e-10 2.41097787e-05 3.97756481e+00 3.97375131e+00\n",
      " 1.43961962e-08 3.99949837e+00 1.42108547e-10 3.98062396e+00\n",
      " 3.99993515e+00 1.57272098e-08 3.81908417e+00 3.99949837e+00\n",
      " 3.23592673e-08 3.88764405e+00 3.74880910e+00 3.96070933e+00\n",
      " 3.99978781e+00 2.24538468e-08 3.88764405e+00 3.99992180e+00\n",
      " 3.23592673e-08 3.63797881e-10 3.81543398e+00 1.67293734e-10\n",
      " 2.69753090e-03 1.01307762e-09 3.97129703e+00 2.32830644e-10\n",
      " 2.13164654e-07 1.29608679e-09 3.99995327e+00 1.70391701e-10\n",
      " 1.09937415e-03 4.69846384e-11 3.97434258e+00 3.99949837e+00\n",
      " 3.98062396e+00 3.99996376e+00 3.97285414e+00 3.99993515e+00\n",
      " 3.99951315e+00 2.32830644e-10 9.97948746e-09 1.20752830e-09\n",
      " 3.98153639e+00 2.91350148e-06 3.23592673e-08 1.44611079e-09\n",
      " 3.99994612e+00 1.44611079e-09 3.99417708e-08 3.98061728e+00\n",
      " 3.90502572e+00 3.99592781e+00 3.87064576e+00 3.23592673e-08\n",
      " 1.70391701e-10 3.88764405e+00 1.12610010e-09 8.00268666e-04\n",
      " 3.81564641e+00 3.99951315e+00 3.98062396e+00 1.12610010e-09\n",
      " 2.24538468e-08 3.99951315e+00 4.10693701e-10 3.97375131e+00\n",
      " 3.33321019e-04 1.70391701e-10 7.11333215e-09 1.06300391e-09\n",
      " 3.78680086e+00 5.54312152e-10 3.99951315e+00 5.02268449e-10\n",
      " 3.88672924e+00 3.99991131e+00 1.70391701e-10 2.24538468e-08\n",
      " 1.02794253e-08 3.99992847e+00 3.84211612e+00 3.99989557e+00\n",
      " 1.87543992e-05 7.97199391e-08 5.02268449e-10 3.23592673e-08\n",
      " 3.98153639e+00 1.70618719e-09 4.48043025e-09 1.02258555e-05\n",
      " 3.99998093e+00 2.24538468e-08 3.81908417e+00 3.97434258e+00\n",
      " 3.99989128e+00 3.86847186e+00 3.99978447e+00 2.91350148e-06\n",
      " 3.76405358e+00 3.99985123e+00 3.99989557e+00 1.17524951e-06\n",
      " 3.88288045e+00 3.88288045e+00 3.99951315e+00 3.99995995e+00\n",
      " 1.02794253e-08 2.06827977e-09 3.99928045e+00 4.10693701e-10\n",
      " 3.97756481e+00 3.81908417e+00 1.07196200e-07 2.84533286e-10\n",
      " 3.85681844e+00 4.31460330e-06 2.81410450e-09 1.12610010e-09\n",
      " 1.01307762e-09 3.99949837e+00 3.57008645e-10 3.14586046e-09\n",
      " 3.80452847e+00 5.02268449e-10 1.06300391e-09 3.99997187e+00\n",
      " 3.23592673e-08 1.06300391e-09 1.12610010e-09 3.99995375e+00\n",
      " 3.86847186e+00 1.70391701e-10 2.60799334e-06 3.99997187e+00\n",
      " 2.24538468e-08 7.97199391e-08 3.98153639e+00 3.23592673e-08\n",
      " 2.01442063e-09 3.96425533e+00 3.99951315e+00 4.05876222e-10\n",
      " 3.99978781e+00 3.99993896e+00 3.96705532e+00 3.23678455e-06\n",
      " 3.97129703e+00 4.70720352e-10 9.97948746e-09 3.99992943e+00\n",
      " 3.99995232e+00 2.13164654e-07 4.84337818e-07 3.99996948e+00\n",
      " 3.96918821e+00 3.00963222e-07 1.15427667e-09 3.82324505e+00\n",
      " 7.00815519e-07 1.00507995e-03 1.67293734e-10 1.48139776e-08\n",
      " 3.99991131e+00 5.55111512e-11 2.32830644e-10 3.97383881e+00\n",
      " 3.85681844e+00 1.17524951e-06 3.98249817e+00 3.63797881e-10\n",
      " 3.99952030e+00 3.99991274e+00 2.23975860e-07 3.98144484e+00\n",
      " 1.57272098e-08 3.96705532e+00 3.99496055e+00 3.99940062e+00\n",
      " 3.99978924e+00 3.99989557e+00 1.67293734e-10 1.06304279e-03\n",
      " 3.98796415e+00 1.43961962e-08 3.99995136e+00 3.97285414e+00\n",
      " 3.99996376e+00 5.38364375e-09 1.68875158e-05 3.86847186e+00\n",
      " 3.86847186e+00 1.29608679e-09 1.97195077e-05 3.23592673e-08\n",
      " 1.12610010e-09 6.08920914e-10 1.67293734e-10 3.63797881e-10\n",
      " 1.52377345e-06 3.99940062e+00 3.96124744e+00 3.97756481e+00\n",
      " 1.06300391e-09 2.40635600e-09 1.20752830e-09 3.98578095e+00\n",
      " 1.57272098e-08 3.99951315e+00 2.13652220e-06 1.05103481e-10\n",
      " 3.97317052e+00 1.55225521e-09 2.50142591e-07 2.91350148e-06\n",
      " 3.30152261e-09 1.70391701e-10 1.89226086e-03 2.04589596e-05\n",
      " 2.24538468e-08 2.13164654e-07 4.84337818e-07 1.57272098e-08\n",
      " 3.99989128e+00 3.99986935e+00 9.97948746e-09 2.01442063e-09\n",
      " 4.05876222e-10 3.74434376e+00 3.99984360e+00 1.09937415e-03\n",
      " 3.98061728e+00 3.99992847e+00 3.80529380e+00 9.09494702e-11\n",
      " 3.99951315e+00 3.99928045e+00 1.38955571e-07 3.33321019e-04\n",
      " 1.02449249e-09 3.99991035e+00 1.70391701e-10 1.05103481e-10\n",
      " 4.05876222e-10 1.89226086e-03 1.02673425e-10 3.99928045e+00\n",
      " 3.99981308e+00 5.93960081e-09 1.70391701e-10 1.09937415e-03\n",
      " 3.14900390e-05 3.82789159e+00 3.99970865e+00 7.58305418e-10\n",
      " 3.80452847e+00 3.99949837e+00 1.43961962e-08 3.96991634e+00\n",
      " 3.97129703e+00 3.99978161e+00 3.99992847e+00 3.99952030e+00\n",
      " 3.97476101e+00 7.58305418e-10 1.06300391e-09 3.99993896e+00\n",
      " 2.23975860e-07 3.99991131e+00 3.86847186e+00 5.38364375e-09\n",
      " 1.02794253e-08 2.24538468e-08 3.99994612e+00 1.20752830e-09\n",
      " 9.89630067e-09 1.43961962e-08 5.02268449e-10 7.57296448e-09\n",
      " 3.97375131e+00 2.24538468e-08 3.99985123e+00 3.99524832e+00\n",
      " 3.99981213e+00 3.98062396e+00 1.02794253e-08 5.93960081e-09\n",
      " 5.93960081e-09 7.52015694e-06 8.13454331e-04 3.97853303e+00], shape=(560,), dtype=float32)\n",
      "Policy Loss  tf.Tensor(\n",
      "[14.018244    2.534996    3.3084311   2.1809356   7.6411114   1.1822685\n",
      " 10.185393    0.5852074  12.43854     5.478065   10.274954   12.504453\n",
      "  3.5353994   6.1839013   3.08394     3.5781868   1.1758723   8.65641\n",
      "  3.6716309   3.6310077   1.5941205   2.1112137   6.269689    2.502257\n",
      " 10.752262    3.9716694   7.947427   10.059819    3.203073    1.1717484\n",
      "  7.633973    3.3084311  13.400423    3.1906724   1.1822685   5.6905675\n",
      "  4.3695107   2.771539    4.949565    2.4935224   2.3238735   5.7963977\n",
      "  3.4968572   9.483111    4.177432    4.040226    7.066695    3.8553858\n",
      "  8.426072    0.88552356  2.354813    7.5601616   7.8484917   3.7566257\n",
      "  1.9741216   5.0968986   6.733986    3.5682726   6.8716917   5.6374397\n",
      "  2.8901067   2.9838643   2.1945915   4.449758    3.2045329   9.829367\n",
      "  1.9765041   7.633973    8.710247    5.097519    2.771539    7.176302\n",
      "  6.8305697   6.736269    7.176302    3.08394     6.9093447   4.9616556\n",
      "  7.638623    3.0946972   4.0345373   0.04275291  5.1409917   9.491202\n",
      " 12.43854     6.6011477   8.909882    6.6567764   2.771539    7.870469\n",
      "  7.624833    4.0345373   9.304634    8.421635    5.74356     6.791629\n",
      "  6.8844814   3.024801    7.947427    9.751151    0.04275291  0.04275291\n",
      " 15.528621    7.058933    5.603591    8.710247   13.076842    2.9793854\n",
      "  3.7566257   7.546575    3.08394     2.8886366   5.4676685   8.21958\n",
      "  8.70307     2.253003    6.5234537   2.354813   11.005314    0.88552356\n",
      "  5.676598    8.553518    0.04275291  7.633973    2.234332    3.6734276\n",
      "  7.0193357   0.3391564   2.354813    5.8202205   8.618637    3.7808783\n",
      "  4.0345373   4.054789    5.4676685   5.74407     9.072402    7.633973\n",
      "  3.5616527   2.093097    9.491202    2.8886366  10.752262    3.922449\n",
      "  0.31910217  0.78216     2.5783167   1.8694885   2.354813    9.176317\n",
      "  7.6112013   5.3652406   1.9765041  13.534372   11.3742695  13.120895\n",
      "  7.3912354   8.909882   10.185393    1.8287538   8.43322     3.6734276\n",
      "  7.3344088   2.047085    9.483111    4.319579    3.024801    7.051836\n",
      "  1.9139953   7.676465    2.1809356   8.896709    6.8493032   7.3912354\n",
      "  7.6887736   1.2565159  12.504453    7.1129065   2.4617143   5.4064455\n",
      "  8.780165    7.5090256   5.676598   10.185393    5.6322007  13.273557\n",
      "  8.43322     3.9716694   7.8424106  13.400423    6.5897055   2.1809356\n",
      "  5.3997183   7.1129065   3.6310077  11.55455     5.8202205   7.337453\n",
      "  9.751151    1.5192639  14.73523     8.775481    7.3344088   8.70307\n",
      "  2.4617143  12.995083    1.9765041   7.638623    8.775481    7.7124276\n",
      "  2.8222752   7.7124276   2.0518486   4.605444   11.865238    1.1822685\n",
      "  1.9393697   1.2565159   7.629483    2.354813    0.3391564   6.7440143\n",
      "  5.3997183   5.4064455   0.04275291  7.7124276   3.6310077   1.1758723\n",
      "  3.7808783   2.047085    1.1822685   7.889003    3.5353994   3.7345448\n",
      "  8.907896    6.736269    3.2702634   7.676465   15.637658    3.3084311\n",
      "  7.68356    11.005314    1.9868628   0.3391564   9.751151    3.2984188\n",
      "  3.745588    6.456873    5.0968986   4.6013823   1.9393697   6.456873\n",
      "  4.1120596  10.217289    3.338091    9.918012   13.076842    2.431085\n",
      "  3.5353994   5.7878337   7.633973    6.875864    2.0518486   0.9025799\n",
      "  4.177432    2.6858692   7.16897     4.3300724   0.7704771   4.456822\n",
      "  5.4676685   4.040226    6.9093447   4.2776837   6.083762    8.43322\n",
      " 10.752262    7.3345585   3.403195    7.0979776   7.066695    2.093097\n",
      "  1.9139953   7.337453    5.2914786   6.839677    2.3906808   0.9567946\n",
      "  6.8305697   3.7345448   3.1620317   8.825689    2.312107    3.3840306\n",
      "  2.234332    8.846564    0.09764788  9.537511    2.5825858  10.158531\n",
      "  2.3238735   1.9678113   2.9730666   7.3365116   5.5998073   6.6011477\n",
      "  6.1189237  10.752262    6.667037    9.072402   13.076842   12.995083\n",
      "  9.869656    4.3528214   7.066695    3.5469816   7.546575    3.5469816\n",
      "  6.609415    9.918012    3.922449    3.5402334   3.5353994   6.6567764\n",
      " 10.158531    2.3906808   3.6734276   2.009974    2.778029    7.947427\n",
      "  8.43322     3.6734276   6.3156123   4.346695    7.6887736   4.040226\n",
      "  2.6858692  10.158531    5.097519    8.421635    1.8694885   3.225004\n",
      "  4.346695    5.888534    3.5338705   1.1758723   8.907896    6.3156123\n",
      "  5.464151    8.618637    3.3093252  14.018244    5.206483    0.12622008\n",
      "  9.491202    6.358695    9.869656   14.035212    7.3912354   7.8343697\n",
      "  6.5234537   6.3156123   3.403195    2.9730666   0.6152388   2.3897278\n",
      "  5.4778094   4.3528214   3.0151653   3.3084311  14.018244    4.177432\n",
      "  6.280788    6.280788    6.667037    1.5192639   7.051836    2.1112137\n",
      "  6.733986    7.6887736   5.4676685   3.403195    1.2973187   9.42978\n",
      "  3.424488    6.456873   12.504453    3.6734276   3.3840306   7.3365116\n",
      "  0.9131043  14.173846    3.0946972   5.888534    5.74407     8.04711\n",
      "  6.8305697   5.74407     3.6734276   0.3391564   2.0518486  10.158531\n",
      "  5.7963977   8.04711     6.7990904   0.12622008  9.869656    7.638623\n",
      "  4.605444    2.8886366   7.947427    7.889003    5.2914786   4.779255\n",
      "  8.922627   11.3742695   2.234332    5.7935247  13.076842    5.129863\n",
      "  4.122815    0.09764788  8.21958     1.5930102   7.664633    2.1809356\n",
      "  5.7110415   2.9838643   4.547351    2.502257    8.582153    6.875864\n",
      "  1.1758723  11.005314    8.846564    5.1409917   3.362678    4.177432\n",
      "  8.70307     3.7345448   7.8484917  11.55455     0.12416673  8.426468\n",
      "  7.870469    8.922627    3.6716309   4.198042    5.427482   14.018244\n",
      "  8.582153    3.4626045   2.9606338   7.0193357  15.637658    6.1189237\n",
      "  6.6011477  12.949861   10.214464    2.3897278   2.0518486   9.537511\n",
      "  8.78332     6.8305697   4.1132765   6.8123837   8.582153    3.7345448\n",
      " 12.247712    7.16897     2.9746027   5.4676685   5.74407     3.4390626\n",
      " 12.995083    6.9825664   6.8844814   7.3550744   1.1717484   5.3997183\n",
      "  4.027222   12.554857    7.2333283   4.3528214  11.587003    8.907896\n",
      "  3.024801    3.203073    6.7990904   0.09764788  8.21958     7.3285503\n",
      "  0.6152388   5.710798   13.076842    4.605444    7.889003    2.8222752\n",
      "  7.7124276   2.047085    9.918012    8.618637    3.08394     0.4845856\n",
      "  7.947427    6.733986    4.0348067   2.771539   13.293782    5.8202205\n",
      "  9.829367    5.3997183   7.889003    3.024801    1.1822685   7.624833\n",
      "  4.821626    7.5601616   9.829367    2.047085    5.20676     2.9793854\n",
      "  1.4696019   5.6374397   3.0946972   6.8493032   6.981786    8.780165\n",
      "  2.234332    9.220563    8.618637    7.8484917   2.781512    5.6374397\n",
      " 13.273557    4.779255    0.12416673  1.1758723   2.253003   12.949861\n",
      "  6.958395    6.7990904   7.546575   12.995083    5.223368    6.9093447\n",
      "  5.813373   13.5332575   4.040226    6.7990904   3.3084311   3.5616527\n",
      "  8.31015     8.43322     5.464151    7.060384    6.927378    7.4850903\n",
      "  3.6310077   8.553518  ], shape=(560,), dtype=float32)\n",
      "L2 Loss  tf.Tensor(0.10781602, shape=(), dtype=float32)\n",
      "Loss  tf.Tensor(7.723556, shape=(), dtype=float32)\n",
      "Training Step  3\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.06625    0.08625    0.54250002 0.07125    0.07125    0.08\n",
      " 0.04625    0.0175     0.01875   ]\n",
      "Predicted Policy  [0.10989948 0.13903098 0.1443643  0.1461023  0.15246697 0.\n",
      " 0.1054005  0.12679523 0.0759402 ]\n",
      "Predicted Value  0.11112900823354721\n",
      "Target Policy [0.04125    0.0375     0.80000001 0.04       0.0425     0.\n",
      " 0.0125     0.01375    0.0125    ]\n",
      "Predicted Policy  [0.13457231 0.14376463 0.14654048 0.14864282 0.15107381 0.\n",
      " 0.13594198 0.13946398 0.        ]\n",
      "Predicted Value  0.03393550589680672\n",
      "Target Policy [0.01375    0.015      0.015      0.01375    0.01375    0.\n",
      " 0.02375    0.90499997 0.        ]\n",
      "Predicted Policy  [0.1360828  0.17144206 0.18237343 0.18441695 0.19302002 0.\n",
      " 0.13266468 0.         0.        ]\n",
      "Predicted Value  0.10894650220870972\n",
      "Target Policy [0.91374999 0.01625    0.01625    0.02       0.02       0.\n",
      " 0.01375    0.         0.        ]\n",
      "Predicted Policy  [0.         0.19697452 0.20385288 0.20526728 0.21448112 0.\n",
      " 0.17942427 0.         0.        ]\n",
      "Predicted Value  0.05296631157398224\n",
      "Target Policy [0.         0.86624998 0.03375    0.0375     0.03       0.\n",
      " 0.0325     0.         0.        ]\n",
      "Predicted Policy  [0.         0.         0.26240438 0.26766658 0.28470752 0.\n",
      " 0.18522152 0.         0.        ]\n",
      "Predicted Value  0.11968614906072617\n",
      "Target Policy [0.         0.         0.05       0.0725     0.86500001 0.\n",
      " 0.0125     0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.0775     0.07875    0.52999997 0.0725     0.07       0.08\n",
      " 0.0525     0.02125    0.0175    ]\n",
      "Predicted Policy  [0.11295278 0.13989557 0.14604077 0.14478688 0.         0.13928834\n",
      " 0.10710416 0.13085468 0.07907689]\n",
      "Predicted Value  0.10092668980360031\n",
      "Target Policy [0.02375    0.025      0.02375    0.86124998 0.         0.03\n",
      " 0.01125    0.015      0.01      ]\n",
      "Predicted Policy  [0.13954447 0.15120414 0.1540351  0.         0.         0.15263355\n",
      " 0.13688329 0.14475964 0.12093983]\n",
      "Predicted Value  0.03435675799846649\n",
      "Target Policy [0.01875    0.90499997 0.015      0.         0.         0.015\n",
      " 0.01375    0.01625    0.01625   ]\n",
      "Predicted Policy  [0.15827586 0.         0.21327402 0.         0.         0.19622295\n",
      " 0.14413522 0.1834771  0.10461479]\n",
      "Predicted Value  0.13670893013477325\n",
      "Target Policy [0.035      0.         0.03625    0.         0.         0.89125001\n",
      " 0.0125     0.015      0.01      ]\n",
      "Predicted Policy  [0.20195277 0.         0.23742074 0.         0.         0.\n",
      " 0.18883057 0.21548188 0.15631406]\n",
      "Predicted Value  0.061611566692590714\n",
      "Target Policy [0.05       0.         0.02875    0.         0.         0.\n",
      " 0.025      0.88375002 0.0125    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.07375    0.08       0.52749997 0.0775     0.07375    0.0825\n",
      " 0.04875    0.0175     0.01875   ]\n",
      "Predicted Policy  [0.10921741 0.13932428 0.         0.14542729 0.15387963 0.13927686\n",
      " 0.10730931 0.12800775 0.07755745]\n",
      "Predicted Value  0.0897010788321495\n",
      "Target Policy [0.83749998 0.0275     0.         0.03125    0.0325     0.03125\n",
      " 0.01375    0.015      0.01125   ]\n",
      "Predicted Policy  [0.         0.14555871 0.         0.14957255 0.15123901 0.14750265\n",
      " 0.13780397 0.14160413 0.12671897]\n",
      "Predicted Value  0.021933315321803093\n",
      "Target Policy [0.         0.01625    0.         0.015      0.02125    0.90750003\n",
      " 0.0125     0.015      0.0125    ]\n",
      "Predicted Policy  [0.         0.19110975 0.         0.19780308 0.20922631 0.\n",
      " 0.1349902  0.16960242 0.09726821]\n",
      "Predicted Value  0.12420125305652618\n",
      "Target Policy [0.         0.89749998 0.         0.03       0.035      0.\n",
      " 0.01125    0.01375    0.0125    ]\n",
      "Predicted Policy  [0.         0.         0.         0.22642164 0.22280179 0.\n",
      " 0.19047104 0.19833665 0.16196889]\n",
      "Predicted Value  0.042833466082811356\n",
      "Target Policy [0.     0.     0.     0.04   0.0375 0.     0.0325 0.0125 0.8775]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.07375 0.07875 0.53625 0.06875 0.07375 0.08    0.0525  0.0175  0.01875]\n",
      "Predicted Policy  [0.10921741 0.13932428 0.         0.14542729 0.15387963 0.13927686\n",
      " 0.10730931 0.12800775 0.07755745]\n",
      "Predicted Value  0.0897010788321495\n",
      "Target Policy [0.03125    0.83749998 0.         0.0325     0.02875    0.03125\n",
      " 0.01375    0.01375    0.01125   ]\n",
      "Predicted Policy  [0.13935636 0.         0.         0.15069048 0.15430072 0.14687079\n",
      " 0.1383319  0.14388803 0.12656166]\n",
      "Predicted Value  0.019898027181625366\n",
      "Target Policy [0.01625 0.      0.      0.01625 0.02125 0.90625 0.01375 0.01375 0.0125 ]\n",
      "Predicted Policy  [0.15160312 0.         0.         0.20771454 0.21451464 0.\n",
      " 0.14541283 0.17742689 0.10332794]\n",
      "Predicted Value  0.11317706853151321\n",
      "Target Policy [0.0225  0.      0.      0.90125 0.0375  0.      0.0125  0.0125  0.01375]\n",
      "Predicted Policy  [0.1947155  0.         0.         0.         0.23810314 0.\n",
      " 0.19496933 0.20670794 0.16550402]\n",
      "Predicted Value  0.049733035266399384\n",
      "Target Policy [0.03       0.         0.         0.         0.03875    0.\n",
      " 0.02625    0.01625    0.88875002]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.04875    0.07375    0.61250001 0.0575     0.05       0.08\n",
      " 0.0425     0.01875    0.01625   ]\n",
      "Predicted Policy  [0.10710204 0.13316968 0.13920487 0.1405006  0.14542338 0.1341831\n",
      " 0.         0.12380562 0.07661071]\n",
      "Predicted Value  0.08704416453838348\n",
      "Target Policy [0.12625    0.13375001 0.1275     0.17125    0.20874999 0.07625\n",
      " 0.         0.075      0.08125   ]\n",
      "Predicted Policy  [0.13742615 0.14490822 0.14707048 0.         0.1550123  0.14786774\n",
      " 0.         0.14298493 0.12473018]\n",
      "Predicted Value  0.02912905067205429\n",
      "Target Policy [0.01625    0.0175     0.015      0.         0.01375    0.01625\n",
      " 0.         0.01875    0.90249997]\n",
      "Predicted Policy  [0.13551131 0.16716152 0.1770705  0.         0.18910518 0.17054121\n",
      " 0.         0.16061023 0.        ]\n",
      "Predicted Value  0.1053137332201004\n",
      "Target Policy [0.1675     0.16500001 0.16625001 0.         0.1425     0.14\n",
      " 0.         0.21875    0.        ]\n",
      "Predicted Policy  [0.178547   0.20125398 0.2038564  0.         0.21540485 0.20093785\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.047773491591215134\n",
      "Target Policy [0.02       0.02       0.91250002 0.         0.025      0.0225\n",
      " 0.         0.         0.        ]\n",
      "Predicted Policy  [0.19841573 0.2532633  0.         0.         0.29196763 0.25635332\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.11595210433006287\n",
      "Target Policy [0.13       0.1225     0.         0.         0.35374999 0.39375001\n",
      " 0.         0.         0.        ]\n",
      "Predicted Policy  [0.29090577 0.3365039  0.         0.         0.37259027 0.\n",
      " 0.         0.         0.        ]\n",
      "Predicted Value  0.06066076084971428\n",
      "Target Policy [0.23875    0.18875    0.         0.         0.57249999 0.\n",
      " 0.         0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.06       0.0675     0.62124997 0.0575     0.04875    0.06875\n",
      " 0.0425     0.01625    0.0175    ]\n",
      "Predicted Policy  [0.10921741 0.13932428 0.         0.14542729 0.15387963 0.13927686\n",
      " 0.10730931 0.12800775 0.07755745]\n",
      "Predicted Value  0.0897010788321495\n",
      "Target Policy [0.03125 0.84625 0.      0.0325  0.03125 0.02375 0.0125  0.0125  0.01   ]\n",
      "Predicted Policy  [0.13935636 0.         0.         0.15069048 0.15430072 0.14687079\n",
      " 0.1383319  0.14388803 0.12656166]\n",
      "Predicted Value  0.019898027181625366\n",
      "Target Policy [0.01625 0.      0.      0.015   0.02125 0.90625 0.01375 0.015   0.0125 ]\n",
      "Predicted Policy  [0.15508308 0.         0.         0.20747869 0.         0.19910783\n",
      " 0.15010709 0.1825654  0.10565796]\n",
      "Predicted Value  0.12009565532207489\n",
      "Target Policy [0.02875 0.      0.      0.90125 0.      0.03    0.01375 0.015   0.01125]\n",
      "Predicted Policy  [0.1981286  0.         0.         0.         0.         0.22766691\n",
      " 0.19587997 0.21458046 0.16374412]\n",
      "Predicted Value  0.048297230154275894\n",
      "Target Policy [0.02875    0.         0.         0.         0.         0.0425\n",
      " 0.89875001 0.015      0.015     ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.07    0.07875 0.5575  0.06875 0.06125 0.0775  0.04625 0.0175  0.0225 ]\n",
      "Predicted Policy  [0.11295278 0.13989557 0.14604077 0.14478688 0.         0.13928834\n",
      " 0.10710416 0.13085468 0.07907689]\n",
      "Predicted Value  0.10092668980360031\n",
      "Target Policy [0.02    0.0225  0.025   0.8725  0.      0.02375 0.0125  0.01375 0.01   ]\n",
      "Predicted Policy  [0.13954447 0.15120414 0.1540351  0.         0.         0.15263355\n",
      " 0.13688329 0.14475964 0.12093983]\n",
      "Predicted Value  0.03435675799846649\n",
      "Target Policy [0.01625 0.90625 0.015   0.      0.      0.01625 0.0175  0.01625 0.0125 ]\n",
      "Predicted Policy  [0.15827586 0.         0.21327402 0.         0.         0.19622295\n",
      " 0.14413522 0.1834771  0.10461479]\n",
      "Predicted Value  0.13670893013477325\n",
      "Target Policy [0.0325     0.         0.89499998 0.         0.         0.03125\n",
      " 0.0125     0.01625    0.0125    ]\n",
      "Predicted Policy  [0.20036763 0.         0.         0.         0.         0.22949941\n",
      " 0.1965847  0.21347933 0.16006891]\n",
      "Predicted Value  0.042481664568185806\n",
      "Target Policy [0.04375    0.         0.         0.         0.         0.04\n",
      " 0.01875    0.88499999 0.0125    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.07375 0.08    0.53625 0.07125 0.07375 0.08    0.04875 0.01875 0.0175 ]\n",
      "Predicted Policy  [0.10989948 0.13903098 0.1443643  0.1461023  0.15246697 0.\n",
      " 0.1054005  0.12679523 0.0759402 ]\n",
      "Predicted Value  0.11112900823354721\n",
      "Target Policy [0.04125 0.78625 0.04    0.04375 0.05    0.      0.01375 0.01375 0.01125]\n",
      "Predicted Policy  [0.13755067 0.         0.15050171 0.15354915 0.15516491 0.\n",
      " 0.13678761 0.14216933 0.12427665]\n",
      "Predicted Value  0.039657559245824814\n",
      "Target Policy [0.01625    0.         0.02375    0.0225     0.89125001 0.\n",
      " 0.0175     0.015      0.01375   ]\n",
      "Predicted Policy  [0.15571667 0.         0.20511924 0.20354587 0.         0.\n",
      " 0.14754102 0.18226692 0.1058102 ]\n",
      "Predicted Value  0.1298132985830307\n",
      "Target Policy [0.025      0.         0.91874999 0.01875    0.         0.\n",
      " 0.01125    0.01375    0.0125    ]\n",
      "Predicted Policy  [0.19374943 0.         0.         0.2403137  0.         0.\n",
      " 0.19510093 0.2106573  0.16017866]\n",
      "Predicted Value  0.07302559912204742\n",
      "Target Policy [0.02625    0.         0.         0.91500002 0.         0.\n",
      " 0.03125    0.015      0.0125    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.05625    0.08       0.57999998 0.06875    0.065      0.075\n",
      " 0.0425     0.01625    0.01625   ]\n",
      "Predicted Policy  [0.10921741 0.13932428 0.         0.14542729 0.15387963 0.13927686\n",
      " 0.10730931 0.12800775 0.07755745]\n",
      "Predicted Value  0.0897010788321495\n",
      "Target Policy [0.84125 0.02875 0.      0.03    0.0275  0.03    0.01375 0.015   0.01375]\n",
      "Predicted Policy  [0.         0.14555871 0.         0.14957255 0.15123901 0.14750265\n",
      " 0.13780397 0.14160413 0.12671897]\n",
      "Predicted Value  0.021933315321803093\n",
      "Target Policy [0.      0.01625 0.      0.01625 0.01625 0.90625 0.0175  0.015   0.0125 ]\n",
      "Predicted Policy  [0.         0.19110975 0.         0.19780308 0.20922631 0.\n",
      " 0.1349902  0.16960242 0.09726821]\n",
      "Predicted Value  0.12420125305652618\n",
      "Target Policy [0.      0.0275  0.      0.03    0.90625 0.      0.01125 0.01125 0.01375]\n",
      "Predicted Policy  [0.         0.21726501 0.         0.23071246 0.         0.\n",
      " 0.19154677 0.20410956 0.15636614]\n",
      "Predicted Value  0.0696249008178711\n",
      "Target Policy [0.         0.0425     0.         0.04125    0.         0.\n",
      " 0.0375     0.01375    0.86500001]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11110391 0.11105371 0.11105321 0.11121661 0.11132352 0.11110368\n",
      " 0.1109966  0.1112624  0.11088642]\n",
      "Predicted Value  -0.00011397706839488819\n",
      "Target Policy [0.07375 0.08    0.53625 0.0725  0.0675  0.0825  0.04875 0.02    0.01875]\n",
      "Predicted Policy  [0.10921741 0.13932428 0.         0.14542729 0.15387963 0.13927686\n",
      " 0.10730931 0.12800775 0.07755745]\n",
      "Predicted Value  0.0897010788321495\n",
      "Target Policy [0.83749998 0.02875    0.         0.03       0.03125    0.0325\n",
      " 0.01375    0.0125     0.01375   ]\n",
      "Predicted Policy  [0.         0.14555871 0.         0.14957255 0.15123901 0.14750265\n",
      " 0.13780397 0.14160413 0.12671897]\n",
      "Predicted Value  0.021933315321803093\n",
      "Target Policy [0.      0.01625 0.      0.01875 0.015   0.90875 0.0175  0.0125  0.01125]\n",
      "Predicted Policy  [0.         0.18803117 0.         0.197581   0.         0.19615866\n",
      " 0.14052    0.17727295 0.10043633]\n",
      "Predicted Value  0.11850282549858093\n",
      "Target Policy [0.         0.0325     0.         0.0375     0.         0.89499998\n",
      " 0.0125     0.01375    0.00875   ]\n",
      "Predicted Policy  [0.         0.21665724 0.         0.22531933 0.         0.\n",
      " 0.19154449 0.20614412 0.16033483]\n",
      "Predicted Value  0.048285458236932755\n",
      "Target Policy [0.         0.03375    0.         0.02875    0.         0.\n",
      " 0.91000003 0.01375    0.01375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Value Loss  tf.Tensor(\n",
      "[1.2583514  0.7613767  0.76418495 1.0808879  0.83348835 1.1961261\n",
      " 1.0808879  1.1262938  1.1331846  1.1199528  1.1237606  1.1582793\n",
      " 1.069989   0.7452716  0.6957173  0.8083971  0.7623906  0.75602895\n",
      " 1.0882971  0.790318   0.9323781  1.2360198  1.1453586  1.1642418\n",
      " 0.7575025  0.76855135 0.92356    0.8525042  0.8436914  0.8394208\n",
      " 0.7940113  0.83348835 1.1461505  1.0697951  1.1393691  0.9477516\n",
      " 0.7610452  0.74923426 0.7575025  0.7978505  1.1385331  1.205339\n",
      " 0.7613767  0.72421795 0.7610452  0.84028316 0.8138218  0.83465946\n",
      " 0.8436914  0.853629   1.040192   1.0962722  0.82864416 1.2391632\n",
      " 1.0853423  0.86381376 0.90735227 1.1526673  0.7843847  0.91986656\n",
      " 0.77018034 0.769405   0.899743   0.7073003  1.2573233  0.8239363\n",
      " 1.0458947  0.7753123  1.1029058  0.75602895 0.7206102  0.79392856\n",
      " 0.8068583  0.77437127 1.1256211  1.0853423  0.8386098  1.2058271\n",
      " 0.7613767  1.0443478  0.7610452  0.7962391  0.84528273 1.1237606\n",
      " 0.8068583  0.76418495 0.8068583  1.1531383  0.79649013 0.7962391\n",
      " 1.1253203  0.8270776  1.040192   0.8386098  1.2297624  0.7613767\n",
      " 0.74397093 0.8240814  1.0629237  1.0808879  0.81872904 0.7900916\n",
      " 0.8036585  0.7131856  0.79649013 0.769405   0.8083328  1.1409985\n",
      " 0.75995874 1.2770897  0.7604268  0.79392856 0.7915001  1.0419983\n",
      " 0.7610452  1.1385331  0.9477516  0.80121946 1.1237606  1.2421635\n",
      " 0.8240814  0.86381376 1.1504908  1.2763388  0.7581845  0.7932178\n",
      " 1.1234313  0.81017894 0.83348835 0.8325696  1.296912   1.2138466\n",
      " 0.7452716  0.94259036 1.1461505  0.7479294  0.7787959  1.2444586\n",
      " 1.2425086  0.7067245  1.0458947  1.1242565  0.7610452  1.2360198\n",
      " 0.78154063 0.8525042  0.954493   0.75722486 0.94072604 0.9323781\n",
      " 1.1874484  0.8219447  0.76855135 1.1929244  1.3417816  1.2230006\n",
      " 0.8525042  0.83075124 0.83348835 0.79162264 1.079479   0.7452716\n",
      " 0.8138218  1.1929244  1.0954     0.8068583  0.8138218  1.1114682\n",
      " 0.8386098  0.7900916  0.79392856 0.8436914  1.0591068  0.8138218\n",
      " 0.75722486 1.2097813  1.1441319  0.8077883  0.83791804 0.75118405\n",
      " 0.82864416 1.296912   1.1206926  0.81029564 0.769405   1.0536501\n",
      " 1.116502   1.1961261  0.86258894 0.6957173  1.3594687  1.0536501\n",
      " 0.7452716  0.8083328  1.2296644  0.78896266 0.9154378  1.0875016\n",
      " 1.2573233  0.8310011  1.086982   0.83348835 0.8968728  1.181665\n",
      " 0.89250416 0.84028316 1.1929244  1.0853423  1.072809   0.7452716\n",
      " 1.121559   0.78896266 0.8855137  0.8138218  0.7206102  0.86381376\n",
      " 0.79109675 0.92356    1.3417816  0.7100352  1.1461505  1.2346077\n",
      " 0.8436914  1.0853423  1.0942819  0.7940113  0.7581845  1.0853423\n",
      " 1.1961261  0.82864416 1.1393691  1.0978292  0.7961112  1.0760751\n",
      " 1.072809   0.7508323  1.2573233  1.0536501  0.79109675 0.8436914\n",
      " 1.1531383  1.0458947  0.8083328  0.86381376 1.4041218  0.79162264\n",
      " 1.2399911  0.75118405 1.1234313  0.8240814  0.853283   0.8436914\n",
      " 1.090605   1.205339   0.7073003  0.8209331  1.2399911  0.7386177\n",
      " 0.7131856  1.1131524  0.8968728  1.1253203  1.0481694  1.0647626\n",
      " 0.7131856  0.9442367  0.7940113  0.79162264 1.0735663  0.76418495\n",
      " 0.7978505  0.82523775 1.1385331  0.79109675 0.82864416 1.1461505\n",
      " 0.8436914  1.2557198  0.7435535  1.0566041  0.8068583  1.0853423\n",
      " 0.82864416 0.7452716  1.1382833  0.90735227 1.0989273  0.7131856\n",
      " 0.7073003  0.79649013 0.7613767  1.1029058  0.7613767  1.0808879\n",
      " 0.8239363  0.86581665 0.7864549  0.8968728  0.853629   1.1256211\n",
      " 0.8083328  0.86381376 0.7822465  1.0458947  0.82864416 0.86381376\n",
      " 0.79158753 0.7452716  1.1874484  1.0536501  0.8166613  1.0536501\n",
      " 0.76855135 1.2391623  0.74397093 0.8433926  0.8408242  1.0533603\n",
      " 0.9181517  1.2360198  1.3023251  1.205339   1.0458947  0.7613767\n",
      " 0.82864416 0.8083328  1.0458947  0.75722486 0.749126   0.7452716\n",
      " 1.0853423  0.8080408  0.74397093 0.7992544  1.2705365  1.0962722\n",
      " 0.827722   0.8436914  0.82124835 0.8068583  0.80121946 0.7728764\n",
      " 0.7863903  0.75722486 1.0853423  0.8710737  0.77018034 0.7864549\n",
      " 0.7100352  0.8239363  0.8436914  1.136812   0.8083328  1.0697951\n",
      " 0.8083328  0.8083328  1.079479   0.9318037  0.77853084 1.0978292\n",
      " 0.7900916  0.83348835 1.1253203  1.2875905  0.8386098  1.0942819\n",
      " 0.86728394 1.2391623  0.76454663 1.239895   1.0647626  1.1665077\n",
      " 0.84028316 0.8386098  0.7610452  1.3594687  1.1131524  0.8710737\n",
      " 1.2391623  1.301828   1.1256211  0.8377755  1.0954     0.7206102\n",
      " 0.9477516  1.1253203  0.81017894 0.84528273 1.1385331  1.261869\n",
      " 1.205339   0.82864416 0.8253177  1.1695844  1.2875905  0.76855135\n",
      " 1.1518534  0.8240814  0.8394208  1.1009936  1.0536501  0.8199368\n",
      " 1.1019394  1.1582793  1.0647626  0.7131856  0.80033576 0.7961112\n",
      " 0.85988986 0.9477516  0.86381376 1.0610846  0.8783682  1.2444586\n",
      " 1.0954     1.1393691  1.2425086  1.2181332  0.76855135 0.7073003\n",
      " 0.7962391  1.3261068  1.1256211  0.75940675 0.7915001  0.79162264\n",
      " 1.1099844  0.8240814  0.853629   0.7206102  0.9154378  0.9154378\n",
      " 0.8068583  1.079479   0.8922785  1.0536501  1.3417816  1.1665077\n",
      " 1.1958038  1.2472943  0.83348835 0.7836731  1.0853423  1.1362139\n",
      " 1.090605   0.77437127 0.7529435  1.1253203  1.2262963  1.0536501\n",
      " 0.77437127 0.7452716  1.1099844  1.1755841  0.7131856  1.1105273\n",
      " 0.7701484  1.0735663  0.8083328  1.2346077  0.79158753 0.7932178\n",
      " 1.0780442  0.8436914  0.7669296  0.8823866  1.2583514  0.7479294\n",
      " 0.8083328  0.7863903  1.2491549  0.8325696  1.1929244  0.7131856\n",
      " 1.0853423  0.75118405 0.82864416 0.7610452  0.954493   0.75722486\n",
      " 1.0536501  0.8270776  0.7479294  1.2346077  1.1929244  0.7262943\n",
      " 0.7836731  0.8083328  1.0536501  1.2705365  0.8386098  1.0536501\n",
      " 1.0647626  0.9477516  0.83348835 1.1531383  1.1554     0.8083328\n",
      " 1.4041218  0.7581845  1.1513839  1.0962722  0.7900916  0.7822465\n",
      " 1.0591068  1.0882971  0.73185563 1.0566041  1.0808879  1.1393691\n",
      " 0.8436914  1.0443478  0.8922785  1.296912   1.040192   1.1513839\n",
      " 0.7880824  1.0536501  0.76855135 0.9477516  0.7822465  0.79109675\n",
      " 0.8083328  1.040192   0.78896266 0.83348835 1.1929244  1.2888626\n",
      " 0.7386177  0.7206102  0.7575025  0.769405   0.8083328  0.8240814\n",
      " 0.7863903  0.86381376 0.8080408  0.954493   0.7852519  1.1453586\n",
      " 0.83348835 0.7131856  1.1256211  0.7262943  0.9372692  0.8208015\n",
      " 0.8856422  0.899743   0.954493   0.75995874 0.7864549  1.1881812\n",
      " 1.2770897  1.0577654  0.8068583  0.73185563 0.7940178  1.0817887\n",
      " 0.6957173  1.1881812 ], shape=(560,), dtype=float32)\n",
      "Policy Loss  tf.Tensor(\n",
      "[1.386882   1.5079861  1.8486382  2.0619287  2.2509823  1.7623589\n",
      " 2.0642536  1.864902   1.723273   1.7699594  1.7819257  1.7789172\n",
      " 2.084006   2.0064154  1.4738523  2.0321274  1.4570699  1.4933765\n",
      " 2.0782316  0.51436716 2.0965602  1.7209992  1.367134   1.6369282\n",
      " 1.8514667  1.7107018  2.0645213  1.6505063  2.2518528  1.802735\n",
      " 1.6935484  2.1132183  2.1788478  2.1044798  1.8373415  2.0461326\n",
      " 1.7892008  0.8970635  1.8514667  0.43406627 1.7708815  2.178283\n",
      " 1.5079861  1.4003304  1.7091562  1.9746003  2.2180882  1.3549991\n",
      " 2.2657814  1.4134502  2.0688558  1.8175678  2.2102463  1.801292\n",
      " 2.0446632  2.1793585  1.9888691  1.7898221  1.6030717  1.9940143\n",
      " 1.5232462  1.5775979  1.8224622  1.2746329  1.6039474  1.9211519\n",
      " 2.1033955  1.5628749  1.789311   1.4933765  1.3949802  1.9347132\n",
      " 2.0004475  1.6214671  1.7361712  2.0408046  2.2177758  1.138608\n",
      " 1.5028012  2.0992053  1.791348   1.8202537  0.7902272  1.7819257\n",
      " 1.9307485  2.0975494  1.9307485  1.8511101  1.6555879  2.1038895\n",
      " 1.8385551  2.3833113  2.0688558  2.283038   1.9275678  1.5079861\n",
      " 1.5087794  2.1723323  2.056191   2.0653968  2.1313794  2.2187366\n",
      " 1.5009614  1.4338084  1.6555879  1.4985889  2.1314197  1.7291567\n",
      " 1.4900763  1.4711295  1.7308924  2.0290487  0.67630506 2.084362\n",
      " 1.7910802  1.7708815  2.0461326  2.0752876  1.7819257  1.4213469\n",
      " 2.172148   2.1793585  1.7200081  0.9189975  1.5347881  1.9756758\n",
      " 1.8355163  1.9823527  2.2509823  1.178318   1.4469826  2.0155447\n",
      " 1.9134245  2.0738664  2.2072613  0.9701763  1.8499589  2.00769\n",
      " 1.8155149  1.5232579  2.103164   1.8441286  1.7892008  1.7209992\n",
      " 1.5629485  1.6505063  2.103339   1.8559046  2.1142602  2.0965602\n",
      " 2.1782193  2.075762   1.7812431  2.2676313  1.0625257  1.6209825\n",
      " 1.6505063  1.2903396  2.2494135  2.0506625  2.06455    1.7133131\n",
      " 2.2230003  2.2099555  2.04671    2.017311   2.2180882  1.7985451\n",
      " 2.2177758  2.209951   2.0290487  2.243349   2.0805926  2.1197271\n",
      " 1.815809   1.9860079  1.7200387  1.2767875  1.8579082  0.99075174\n",
      " 2.2102463  1.4469826  1.7720659  0.60786694 1.5775979  2.035049\n",
      " 1.381417   1.7623589  0.7858242  1.4701753  0.9892334  2.0345354\n",
      " 1.8429902  2.2727156  2.0361235  1.723101   2.0757618  1.8273453\n",
      " 1.6039474  1.3052047  1.7970845  2.2517948  1.8674304  2.126617\n",
      " 1.8589298  1.9746003  2.2676313  2.0445309  2.0746336  1.7087287\n",
      " 1.6958905  2.0485256  1.785933   2.2567225  1.4794954  2.2054584\n",
      " 1.9714539  2.0671437  1.0625257  1.4175324  2.1788478  2.1265283\n",
      " 2.2657814  2.0496078  1.843829   1.6935484  1.5856756  2.0446632\n",
      " 1.7623589  2.2066078  1.8376677  1.7981417  1.7014227  2.0344415\n",
      " 2.0746336  1.0520962  1.6039474  2.0468574  1.9714539  2.2657814\n",
      " 1.7433598  2.1028275  2.2823367  2.1781983  1.124073   2.0506625\n",
      " 1.8822122  0.99075174 1.8355163  2.2136178  1.5131755  2.245788\n",
      " 1.8165241  2.1643     1.2746329  0.7901926  1.8822122  1.4643446\n",
      " 1.4531337  1.8438181  1.8679043  1.8385551  2.1109018  2.0524788\n",
      " 1.4531337  2.0852208  1.6935484  2.0506625  2.0519774  2.0975494\n",
      " 0.43406627 1.9010103  1.7708815  1.9714539  2.1131773  2.2072613\n",
      " 2.247224   1.8556237  1.4420013  2.0788178  2.0004475  2.0496078\n",
      " 2.2066078  1.9134245  1.7636583  1.9888691  1.6629231  1.4531337\n",
      " 1.2746329  1.6555879  1.5079861  1.789311   1.5546315  2.0634806\n",
      " 1.9211519  2.0103555  1.7976803  1.8679043  1.4134502  1.7361712\n",
      " 2.1204028  2.2570426  1.9897332  2.1028275  2.1131773  2.2054584\n",
      " 0.94872624 1.9134245  2.1782193  2.047731   1.42782    2.0345354\n",
      " 1.7145432  1.8348502  1.5087794  1.4094702  1.4465795  2.1093402\n",
      " 2.0430846  1.7209992  1.5027066  2.1643     2.103164   1.5079861\n",
      " 2.1035907  2.2010574  2.103164   1.7331057  1.4076196  1.9134245\n",
      " 2.0446632  2.0604465  1.5087794  1.9973898  1.4250289  1.8175678\n",
      " 0.74432284 2.2657814  1.6400106  2.017311   2.082726   1.7583497\n",
      " 1.9231708  1.8559046  2.0496078  1.4135263  1.5232462  1.7976803\n",
      " 1.4175324  1.9246733  2.2621589  1.8108509  2.1662772  2.1044798\n",
      " 2.2727156  2.1700354  2.0693436  2.0477767  2.0130947  1.8105536\n",
      " 2.125784   2.2289286  1.837953   1.6276655  2.2177758  1.843829\n",
      " 1.6608002  1.7890806  2.0090137  1.5690829  2.0519488  1.3502668\n",
      " 1.9746003  2.2177758  1.7910802  0.9892334  1.8434675  1.4135263\n",
      " 1.8348502  1.5974927  1.8574289  1.2114317  2.04671    1.3949802\n",
      " 2.0461326  1.837953   1.9823527  0.7902272  1.7708815  1.714742\n",
      " 2.1200938  2.2102463  1.4871497  2.204265   1.6276655  1.7812431\n",
      " 1.3698355  2.2696037  1.802735   1.7643565  2.0451427  1.9403567\n",
      " 1.6874598  1.7789172  2.0519488  1.469904   1.8190249  1.7014227\n",
      " 1.615469   2.0461326  2.1782677  2.1464162  1.4822587  2.00769\n",
      " 2.0463862  1.8376677  1.8155149  1.5873815  1.7812431  1.2746329\n",
      " 1.8202537  1.418993   1.8577952  1.863967   0.67630506 2.0506625\n",
      " 1.7733067  2.172148   1.4134502  1.3949802  2.0757618  2.0757618\n",
      " 2.0004475  2.0672712  1.9684566  2.047731   1.0625257  1.3502668\n",
      " 1.6274832  2.3929915  2.1132183  1.3436416  2.0446632  1.794168\n",
      " 1.8165241  1.7211628  1.5116903  1.837953   2.065658   2.0451427\n",
      " 1.6235405  1.7133131  1.7733067  2.1644726  1.5434347  1.747871\n",
      " 1.609528   2.0519774  2.2823367  2.1265283  0.94872624 1.8183999\n",
      " 2.042398   2.2640843  1.8850175  1.8380264  1.386882   0.9701763\n",
      " 2.1266665  1.9231708  1.7504053  1.178318   2.1722443  1.469904\n",
      " 2.0408046  1.058805   2.105145   1.7910802  2.103339   1.815809\n",
      " 2.0345354  2.3833113  0.9701763  2.2194748  2.120141   1.4418464\n",
      " 1.3436416  2.210291   2.03793    1.4250289  2.283038   2.036039\n",
      " 2.0524788  2.0461326  2.2677054  1.8511101  1.6809646  2.1314197\n",
      " 1.124073   1.5333654  1.7430031  1.818402   2.209951   2.0068839\n",
      " 2.0418153  2.0782316  1.0633291  2.0788178  2.0653968  1.8373415\n",
      " 2.276144   2.0984318  1.9739052  1.4469826  2.0688558  1.6791315\n",
      " 1.7778442  2.0408955  1.7107018  2.0363576  1.8894053  1.9714539\n",
      " 2.1662772  2.0685287  1.9168919  2.2509823  2.1722443  1.104122\n",
      " 1.4676722  1.5035979  1.8514667  1.5527465  2.1662772  2.1724124\n",
      " 1.9231708  2.2140124  2.0604465  2.103339   0.67087454 1.367134\n",
      " 2.1132183  1.469904   1.7361712  1.444656   2.0663075  1.9490157\n",
      " 1.8242961  1.8224622  2.103339   1.4880458  1.8289809  2.348981\n",
      " 1.4711295  2.114582   2.017311   1.0633291  1.3950803  1.7858192\n",
      " 1.4738523  2.348981  ], shape=(560,), dtype=float32)\n",
      "L2 Loss  tf.Tensor(0.10782345, shape=(), dtype=float32)\n",
      "Loss  tf.Tensor(2.8663342, shape=(), dtype=float32)\n",
      "Training Step  4\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.73624998\n",
      " 0.02375    0.00875    0.01125   ]\n",
      "Predicted Policy  [0.0553131  0.16310143 0.10223701 0.27088818 0.21180041 0.\n",
      " 0.05858038 0.11762253 0.02045698]\n",
      "Predicted Value  0.9714086055755615\n",
      "Target Policy [0.73000002 0.05       0.10875    0.0475     0.04       0.\n",
      " 0.0075     0.01       0.00625   ]\n",
      "Predicted Policy  [0.         0.1554471  0.14321089 0.17483455 0.1661736  0.\n",
      " 0.12360874 0.14367454 0.09305058]\n",
      "Predicted Value  0.4707619249820709\n",
      "Target Policy [0.         0.0325     0.0375     0.07125    0.80874997 0.\n",
      " 0.03125    0.01       0.00875   ]\n",
      "Predicted Policy  [0.         0.21406773 0.13185215 0.40600464 0.         0.\n",
      " 0.06912719 0.15803789 0.02091037]\n",
      "Predicted Value  0.9845067858695984\n",
      "Target Policy [0.         0.77749997 0.1075     0.08875    0.         0.\n",
      " 0.00875    0.01125    0.00625   ]\n",
      "Predicted Policy  [0.         0.         0.21011008 0.3005541  0.         0.\n",
      " 0.16919623 0.21704055 0.10309903]\n",
      "Predicted Value  0.6568946838378906\n",
      "Target Policy [0.      0.      0.08625 0.84375 0.      0.      0.045   0.01375 0.01125]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.06375 0.04375 0.04625 0.04125 0.04125 0.72125 0.02375 0.00875 0.01   ]\n",
      "Predicted Policy  [0.0553131  0.16310143 0.10223701 0.27088818 0.21180041 0.\n",
      " 0.05858038 0.11762253 0.02045698]\n",
      "Predicted Value  0.9714086055755615\n",
      "Target Policy [0.72750002 0.05       0.10875    0.05       0.03875    0.\n",
      " 0.01       0.01       0.005     ]\n",
      "Predicted Policy  [0.         0.1554471  0.14321089 0.17483455 0.1661736  0.\n",
      " 0.12360874 0.14367454 0.09305058]\n",
      "Predicted Value  0.4707619249820709\n",
      "Target Policy [0.         0.0325     0.0375     0.055      0.82999998 0.\n",
      " 0.025      0.01125    0.00875   ]\n",
      "Predicted Policy  [0.         0.18362483 0.11649674 0.2999941  0.24298517 0.\n",
      " 0.         0.13433659 0.02256256]\n",
      "Predicted Value  0.9723510146141052\n",
      "Target Policy [0.         0.16625001 0.16249999 0.17625    0.22499999 0.\n",
      " 0.         0.15875    0.11125   ]\n",
      "Predicted Policy  [0.         0.2270061  0.19288972 0.28758997 0.         0.\n",
      " 0.         0.20071116 0.09180308]\n",
      "Predicted Value  0.7290645241737366\n",
      "Target Policy [0.         0.0425     0.25749999 0.1025     0.         0.\n",
      " 0.         0.10375    0.49375001]\n",
      "Predicted Policy  [0.         0.243521   0.1608948  0.41189262 0.         0.\n",
      " 0.         0.1836916  0.        ]\n",
      "Predicted Value  0.9705289006233215\n",
      "Target Policy [0.      0.44125 0.27875 0.125   0.      0.      0.      0.155   0.     ]\n",
      "Predicted Policy  [0.         0.         0.26439866 0.44523585 0.         0.\n",
      " 0.         0.29036546 0.        ]\n",
      "Predicted Value  0.7854312062263489\n",
      "Target Policy [0.         0.         0.32124999 0.34999999 0.         0.\n",
      " 0.         0.32875001 0.        ]\n",
      "Predicted Policy  [0.         0.         0.45878842 0.         0.         0.\n",
      " 0.         0.5412116  0.        ]\n",
      "Predicted Value  0.9789459705352783\n",
      "Target Policy [0.         0.         0.51625001 0.         0.         0.\n",
      " 0.         0.48374999 0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.73624998\n",
      " 0.02375    0.01       0.01      ]\n",
      "Predicted Policy  [0.         0.15237206 0.10147033 0.2506884  0.20010832 0.09453616\n",
      " 0.06182003 0.11637691 0.02262776]\n",
      "Predicted Value  0.9619408845901489\n",
      "Target Policy [0.         0.51125002 0.14       0.14       0.13       0.05625\n",
      " 0.0075     0.01       0.005     ]\n",
      "Predicted Policy  [0.         0.1634844  0.14587457 0.         0.17854014 0.14303221\n",
      " 0.1250657  0.14919502 0.09480796]\n",
      "Predicted Value  0.47254472970962524\n",
      "Target Policy [0.         0.07125    0.08375    0.         0.76625001 0.0375\n",
      " 0.02125    0.01125    0.00875   ]\n",
      "Predicted Policy  [0.         0.         0.16739751 0.         0.36219165 0.15024191\n",
      " 0.0945708  0.19486974 0.03072843]\n",
      "Predicted Value  0.9763429760932922\n",
      "Target Policy [0.         0.         0.84500003 0.         0.0725     0.05\n",
      " 0.01       0.01125    0.01125   ]\n",
      "Predicted Policy  [0.         0.         0.23515122 0.         0.         0.2288725\n",
      " 0.17907542 0.24990371 0.10699719]\n",
      "Predicted Value  0.7502987384796143\n",
      "Target Policy [0.         0.         0.88875002 0.         0.         0.03375\n",
      " 0.05125    0.015      0.01125   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.74000001\n",
      " 0.01875    0.01125    0.01      ]\n",
      "Predicted Policy  [0.0553131  0.16310143 0.10223701 0.27088818 0.21180041 0.\n",
      " 0.05858038 0.11762253 0.02045698]\n",
      "Predicted Value  0.9714086055755615\n",
      "Target Policy [0.72624999 0.05       0.10875    0.05       0.04       0.\n",
      " 0.01       0.01       0.005     ]\n",
      "Predicted Policy  [0.         0.1554471  0.14321089 0.17483455 0.1661736  0.\n",
      " 0.12360874 0.14367454 0.09305058]\n",
      "Predicted Value  0.4707619249820709\n",
      "Target Policy [0.         0.0325     0.035      0.06375    0.82625002 0.\n",
      " 0.02125    0.0125     0.00875   ]\n",
      "Predicted Policy  [0.         0.19589065 0.         0.32829455 0.25531667 0.\n",
      " 0.06505819 0.1344762  0.02096377]\n",
      "Predicted Value  0.9778358340263367\n",
      "Target Policy [0.         0.055      0.         0.85874999 0.05875    0.\n",
      " 0.01       0.01       0.0075    ]\n",
      "Predicted Policy  [0.         0.23519541 0.         0.30960646 0.         0.\n",
      " 0.15367493 0.20707591 0.09444728]\n",
      "Predicted Value  0.7301841974258423\n",
      "Target Policy [0.         0.0975     0.         0.15875    0.         0.\n",
      " 0.04125    0.01375    0.68875003]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.74000001\n",
      " 0.01875    0.01       0.01125   ]\n",
      "Predicted Policy  [0.05833315 0.16460668 0.         0.2652744  0.21104361 0.09693412\n",
      " 0.06251238 0.11989936 0.02139631]\n",
      "Predicted Value  0.9679678678512573\n",
      "Target Policy [0.04125    0.04375    0.         0.14875001 0.67874998 0.0625\n",
      " 0.01       0.01       0.005     ]\n",
      "Predicted Policy  [0.12721966 0.16822585 0.         0.         0.18098731 0.1452183\n",
      " 0.12868623 0.15491256 0.09475001]\n",
      "Predicted Value  0.4742460250854492\n",
      "Target Policy [0.08375    0.80250001 0.         0.         0.03       0.03625\n",
      " 0.025      0.0125     0.01      ]\n",
      "Predicted Policy  [0.09391431 0.         0.         0.         0.4042403  0.16082144\n",
      " 0.10120704 0.20794857 0.03186831]\n",
      "Predicted Value  0.979209840297699\n",
      "Target Policy [0.03875    0.         0.         0.         0.0775     0.85374999\n",
      " 0.01       0.01125    0.00875   ]\n",
      "Predicted Policy  [0.17349914 0.         0.         0.         0.305225   0.\n",
      " 0.17933252 0.23271824 0.10922508]\n",
      "Predicted Value  0.6813755035400391\n",
      "Target Policy [0.5625     0.         0.         0.         0.28999999 0.\n",
      " 0.12625    0.0125     0.00875   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.73624998\n",
      " 0.02375    0.00875    0.01125   ]\n",
      "Predicted Policy  [0.0553131  0.16310143 0.10223701 0.27088818 0.21180041 0.\n",
      " 0.05858038 0.11762253 0.02045698]\n",
      "Predicted Value  0.9714086055755615\n",
      "Target Policy [0.72750002 0.05       0.10875    0.05       0.04       0.\n",
      " 0.00875    0.01       0.005     ]\n",
      "Predicted Policy  [0.         0.1554471  0.14321089 0.17483455 0.1661736  0.\n",
      " 0.12360874 0.14367454 0.09305058]\n",
      "Predicted Value  0.4707619249820709\n",
      "Target Policy [0.      0.03875 0.0375  0.07125 0.81    0.      0.02125 0.01125 0.01   ]\n",
      "Predicted Policy  [0.         0.18362483 0.11649674 0.2999941  0.24298517 0.\n",
      " 0.         0.13433659 0.02256256]\n",
      "Predicted Value  0.9723510146141052\n",
      "Target Policy [0.         0.16249999 0.16625001 0.18000001 0.22750001 0.\n",
      " 0.         0.1575     0.10625   ]\n",
      "Predicted Policy  [0.         0.2270061  0.19288972 0.28758997 0.         0.\n",
      " 0.         0.20071116 0.09180308]\n",
      "Predicted Value  0.7290645241737366\n",
      "Target Policy [0.         0.0425     0.04875    0.1025     0.         0.\n",
      " 0.         0.74000001 0.06625   ]\n",
      "Predicted Policy  [0.         0.2924414  0.18770842 0.48372194 0.         0.\n",
      " 0.         0.         0.0361282 ]\n",
      "Predicted Value  0.9690197110176086\n",
      "Target Policy [0.         0.01625    0.0125     0.02125    0.         0.\n",
      " 0.         0.         0.94999999]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.74124998\n",
      " 0.0175     0.01125    0.01      ]\n",
      "Predicted Policy  [0.05850833 0.17785959 0.1141231  0.32143345 0.         0.10643114\n",
      " 0.06363196 0.13760269 0.02040968]\n",
      "Predicted Value  0.9783280491828918\n",
      "Target Policy [0.74000001 0.07125    0.06125    0.06375    0.         0.03375\n",
      " 0.0125     0.01125    0.00625   ]\n",
      "Predicted Policy  [0.12574923 0.         0.15187539 0.20189178 0.         0.14483131\n",
      " 0.12696405 0.15984327 0.08884497]\n",
      "Predicted Value  0.5364193320274353\n",
      "Target Policy [0.03125 0.      0.03375 0.0475  0.      0.84375 0.0225  0.0125  0.00875]\n",
      "Predicted Policy  [0.07637329 0.         0.15033753 0.48803928 0.         0.\n",
      " 0.07909723 0.18209371 0.02405885]\n",
      "Predicted Value  0.9852814674377441\n",
      "Target Policy [0.83499998 0.         0.07       0.06625    0.         0.\n",
      " 0.01       0.0125     0.00625   ]\n",
      "Predicted Policy  [0.         0.         0.21011008 0.3005541  0.         0.\n",
      " 0.16919623 0.21704055 0.10309903]\n",
      "Predicted Value  0.6568946838378906\n",
      "Target Policy [0.         0.         0.0925     0.83625001 0.         0.\n",
      " 0.04625    0.015      0.01      ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.73750001\n",
      " 0.0225     0.01       0.01      ]\n",
      "Predicted Policy  [0.0553131  0.16310143 0.10223701 0.27088818 0.21180041 0.\n",
      " 0.05858038 0.11762253 0.02045698]\n",
      "Predicted Value  0.9714086055755615\n",
      "Target Policy [0.0575  0.77625 0.055   0.05    0.03875 0.      0.00875 0.01    0.00375]\n",
      "Predicted Policy  [0.1237509  0.         0.14474851 0.18543614 0.17609058 0.\n",
      " 0.12526019 0.15121384 0.0934999 ]\n",
      "Predicted Value  0.4788952171802521\n",
      "Target Policy [0.03375    0.         0.03875    0.0625     0.82249999 0.\n",
      " 0.0225     0.01125    0.00875   ]\n",
      "Predicted Policy  [0.07637329 0.         0.15033753 0.48803928 0.         0.\n",
      " 0.07909723 0.18209371 0.02405885]\n",
      "Predicted Value  0.9852814674377441\n",
      "Target Policy [0.83249998 0.         0.07       0.065      0.         0.\n",
      " 0.01125    0.0125     0.00875   ]\n",
      "Predicted Policy  [0.         0.         0.21011008 0.3005541  0.         0.\n",
      " 0.16919623 0.21704055 0.10309903]\n",
      "Predicted Value  0.6568946838378906\n",
      "Target Policy [0.         0.         0.085      0.85000002 0.         0.\n",
      " 0.04375    0.0125     0.00875   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.0475     0.04375    0.04625    0.04125    0.04125    0.73874998\n",
      " 0.02125    0.01       0.01      ]\n",
      "Predicted Policy  [0.05475307 0.14607584 0.09796013 0.24414301 0.19282264 0.09150043\n",
      " 0.05908953 0.11365531 0.        ]\n",
      "Predicted Value  0.9608308672904968\n",
      "Target Policy [0.00875    0.01125    0.01       0.01375    0.0125     0.00875\n",
      " 0.00875    0.92624998 0.        ]\n",
      "Predicted Policy  [0.11993315 0.15404251 0.13812569 0.17095771 0.1612809  0.13439946\n",
      " 0.12126055 0.         0.        ]\n",
      "Predicted Value  0.4276043176651001\n",
      "Target Policy [0.13249999 0.06125    0.06125    0.0525     0.045      0.61374998\n",
      " 0.03375    0.         0.        ]\n",
      "Predicted Policy  [0.06150681 0.18148272 0.11689541 0.3207563  0.25410083 0.\n",
      " 0.06525791 0.         0.        ]\n",
      "Predicted Value  0.975853443145752\n",
      "Target Policy [0.05375    0.73374999 0.0575     0.07875    0.06625    0.\n",
      " 0.01       0.         0.        ]\n",
      "Predicted Policy  [0.15281871 0.         0.18718208 0.26192212 0.24293356 0.\n",
      " 0.15514354 0.         0.        ]\n",
      "Predicted Value  0.6106927990913391\n",
      "Target Policy [0.0775     0.         0.63       0.14749999 0.10625    0.\n",
      " 0.03875    0.         0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11112201 0.11131847 0.11079841 0.111843   0.11182246 0.11084545\n",
      " 0.11044853 0.11189979 0.10990189]\n",
      "Predicted Value  0.011041858233511448\n",
      "Target Policy [0.06375    0.04375    0.04625    0.04125    0.04125    0.72624999\n",
      " 0.01875    0.01       0.00875   ]\n",
      "Predicted Policy  [0.06751921 0.1919439  0.12578668 0.         0.2577227  0.11615057\n",
      " 0.07393149 0.14096223 0.02598325]\n",
      "Predicted Value  0.9666059613227844\n",
      "Target Policy [0.6825  0.13625 0.055   0.      0.05375 0.04125 0.0125  0.01125 0.0075 ]\n",
      "Predicted Policy  [0.         0.16235967 0.14664239 0.         0.17987128 0.14038229\n",
      " 0.12812425 0.15033698 0.09228311]\n",
      "Predicted Value  0.5138665437698364\n",
      "Target Policy [0.         0.0375     0.03125    0.         0.055      0.82999998\n",
      " 0.02375    0.0125     0.01      ]\n",
      "Predicted Policy  [0.         0.24179378 0.14712334 0.         0.33348012 0.\n",
      " 0.08330882 0.16802223 0.02627177]\n",
      "Predicted Value  0.9773160815238953\n",
      "Target Policy [0.         0.80124998 0.09875    0.         0.0725     0.\n",
      " 0.0125     0.01       0.005     ]\n",
      "Predicted Policy  [0.         0.         0.21098824 0.         0.29322445 0.\n",
      " 0.16787772 0.22140343 0.1065062 ]\n",
      "Predicted Value  0.6948606371879578\n",
      "Target Policy [0.         0.         0.09       0.         0.83375001 0.\n",
      " 0.0475     0.01625    0.0125    ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Value Loss  tf.Tensor(\n",
      "[3.89578843e+00 9.21283499e-04 3.90617728e+00 2.23848486e+00\n",
      " 2.94297817e-04 1.02605368e-03 7.61285264e-05 3.88066578e+00\n",
      " 2.26490831e+00 7.35283941e-02 3.84921145e+00 1.69180986e-03\n",
      " 2.68250122e-04 3.36583592e-02 3.90517831e+00 2.82552064e-04\n",
      " 1.40234113e-01 2.36058426e+00 1.53422565e-03 4.69670864e-04\n",
      " 3.92322922e+00 1.11516181e-03 1.53422565e-03 1.02787002e-04\n",
      " 3.86421704e+00 1.98815469e-04 4.71130647e-02 2.08603191e+00\n",
      " 2.23267126e+00 2.26773307e-04 3.35663462e+00 1.69180986e-03\n",
      " 2.81730533e+00 4.98791188e-02 1.57142954e-03 5.64509407e-02\n",
      " 3.91065884e+00 3.91508818e+00 2.68366742e+00 3.86751580e+00\n",
      " 2.01781058e+00 1.11516181e-03 3.89532065e+00 2.23848486e+00\n",
      " 1.69180986e-03 2.36058426e+00 2.26773307e-04 6.34481839e-04\n",
      " 2.04831004e+00 2.62778878e+00 3.84921145e+00 3.94817758e+00\n",
      " 2.70648551e+00 2.32756065e-04 2.75036262e-04 2.60345578e+00\n",
      " 2.32756065e-04 3.86422181e+00 3.91065884e+00 1.40234113e-01\n",
      " 4.69670864e-04 2.21006645e-04 3.87023282e+00 8.88309849e-04\n",
      " 2.66708040e+00 2.66249132e+00 1.34056143e-04 2.36058426e+00\n",
      " 1.01863628e-03 2.23848486e+00 5.14557469e-04 7.33966008e-02\n",
      " 4.35821916e-04 3.94817758e+00 8.30903824e-04 2.82552064e-04\n",
      " 4.53497805e-02 3.83716536e+00 2.45063424e-01 1.52117468e-03\n",
      " 2.03935523e-02 1.69582793e-03 8.53946840e-04 1.69180986e-03\n",
      " 3.08295178e+00 3.83716536e+00 2.00084776e-01 5.59654785e-04\n",
      " 9.70288063e-04 1.01863628e-03 2.80092984e-01 2.08603191e+00\n",
      " 6.89738838e-04 2.75443721e+00 3.08295178e+00 5.74327016e-04\n",
      " 1.57142954e-03 2.87842959e-01 1.20944438e-04 2.82659078e+00\n",
      " 1.24150014e-03 3.92943597e+00 1.54489493e-02 1.53422565e-03\n",
      " 2.62778878e+00 3.84300637e+00 2.05556498e-04 3.32125084e-04\n",
      " 1.24150014e-03 2.87842959e-01 3.68274923e-04 2.90583634e+00\n",
      " 2.53858089e-01 3.94305515e+00 2.64369464e+00 2.64369464e+00\n",
      " 2.20408630e+00 2.16838789e+00 9.77010727e-02 1.52117468e-03\n",
      " 1.21507436e-01 1.33038849e-01 1.24150014e-03 2.64548492e+00\n",
      " 1.02787002e-04 2.36058426e+00 1.96203619e-04 3.87951088e+00\n",
      " 2.16838789e+00 1.69180986e-03 4.93095964e-02 2.79454303e+00\n",
      " 2.01781058e+00 2.05556498e-04 2.68250122e-04 2.25861788e+00\n",
      " 6.12665492e-04 1.10365479e-04 2.26773307e-04 1.96155667e-01\n",
      " 9.05456778e-04 2.72135735e+00 2.20408630e+00 3.32125084e-04\n",
      " 1.01863628e-03 2.17340159e+00 2.26773307e-04 8.30903824e-04\n",
      " 1.57142954e-03 1.96203619e-04 1.96203619e-04 2.56806874e+00\n",
      " 3.35663462e+00 4.20556702e-02 1.17571197e-01 8.22926871e-04\n",
      " 1.52117468e-03 7.61845033e-04 1.24150014e-03 3.89213705e+00\n",
      " 2.08603191e+00 2.68416381e+00 2.53858089e-01 2.20408630e+00\n",
      " 2.31903890e-04 2.17359047e-02 2.73286521e-01 1.20944438e-04\n",
      " 1.20944438e-04 4.08472680e-02 1.06900174e-03 9.05862898e-02\n",
      " 2.14996020e-04 9.21283499e-04 1.11516181e-03 1.98815469e-04\n",
      " 1.44850079e-03 2.14180303e+00 2.64548492e+00 3.32125084e-04\n",
      " 1.57142954e-03 2.72135735e+00 2.75443721e+00 2.27321029e+00\n",
      " 1.44850079e-03 2.81787099e-04 3.94500589e+00 2.25861788e+00\n",
      " 2.76301026e+00 7.53473118e-02 3.86030173e+00 3.89604068e+00\n",
      " 4.69670864e-04 3.33197069e+00 4.91250248e-04 2.17340159e+00\n",
      " 2.66249132e+00 5.05740605e-02 2.18509624e-04 2.83378315e+00\n",
      " 2.75443721e+00 2.36058426e+00 1.52117468e-03 5.64509407e-02\n",
      " 2.60674024e+00 2.16838789e+00 4.69670864e-04 1.11516181e-03\n",
      " 4.24273685e-02 2.56806874e+00 3.93718123e+00 9.32865718e-04\n",
      " 2.88291144e+00 2.16838789e+00 3.84485745e+00 1.96155667e-01\n",
      " 1.91825078e-04 3.88298392e+00 1.24150014e-03 4.69670864e-04\n",
      " 2.19942842e-04 1.02605368e-03 1.24150014e-03 2.19492173e+00\n",
      " 7.61845033e-04 1.02329589e-01 3.93270135e+00 1.57142954e-03\n",
      " 9.77010727e-02 2.26217651e+00 2.23267126e+00 8.24961513e-02\n",
      " 2.18713140e+00 1.17571197e-01 2.95242548e-01 1.11516181e-03\n",
      " 3.05120420e+00 3.92943597e+00 1.02787002e-04 2.16635206e-04\n",
      " 8.54016514e-04 2.83378315e+00 5.74327016e-04 1.78233910e-04\n",
      " 3.92689991e+00 1.17571197e-01 1.69180986e-03 2.62778878e+00\n",
      " 3.86030173e+00 1.52117468e-03 1.24150014e-03 2.08603191e+00\n",
      " 3.89578843e+00 2.45063424e-01 2.18713140e+00 4.26079147e-04\n",
      " 2.82552064e-04 4.69670864e-04 3.90517831e+00 2.05556498e-04\n",
      " 3.87703848e+00 7.37663060e-02 9.77010727e-02 2.18509624e-04\n",
      " 3.88645196e+00 1.14146516e-01 1.09238527e-03 2.23267126e+00\n",
      " 1.53422565e-03 2.68416381e+00 3.36583592e-02 8.85689706e-02\n",
      " 3.89993572e+00 3.32125084e-04 9.21283499e-04 3.12589693e+00\n",
      " 1.02605368e-03 2.80347991e+00 8.85689706e-02 4.69670864e-04\n",
      " 2.77937579e+00 3.90809441e+00 2.75036262e-04 2.45063424e-01\n",
      " 2.26490831e+00 2.11923814e+00 2.67768598e+00 9.77010727e-02\n",
      " 2.82590437e+00 2.95242548e-01 5.65190217e-04 5.74327016e-04\n",
      " 2.16838789e+00 2.05556498e-04 3.06437671e-01 2.03805399e+00\n",
      " 2.26490831e+00 2.68416381e+00 1.33038849e-01 1.30790286e-03\n",
      " 2.20408630e+00 3.86030173e+00 3.89578843e+00 5.69678321e-02\n",
      " 2.12179351e+00 1.11628871e-03 2.63684893e+00 6.12054835e-04\n",
      " 4.35821916e-04 2.18221402e+00 1.24150014e-03 9.82539277e-05\n",
      " 1.98815469e-04 3.94817758e+00 5.69678321e-02 3.32125084e-04\n",
      " 2.26490831e+00 3.83884549e+00 2.03805399e+00 3.94423127e+00\n",
      " 7.69679667e-04 2.01781058e+00 2.66249132e+00 2.23848486e+00\n",
      " 2.04831004e+00 1.57142954e-03 3.35663462e+00 8.17471242e-04\n",
      " 6.32938147e-02 3.90593123e+00 3.96782494e+00 3.36014581e+00\n",
      " 1.02605368e-03 3.86753869e+00 5.69901988e-02 1.74155124e-02\n",
      " 2.18509624e-04 2.95242548e-01 2.75036262e-04 2.76301026e+00\n",
      " 1.44850079e-03 3.86422181e+00 2.19492173e+00 1.53422565e-03\n",
      " 2.36058426e+00 2.14936709e+00 1.11516181e-03 2.27321029e+00\n",
      " 2.13948750e+00 1.53422565e-03 2.23848486e+00 1.34056143e-04\n",
      " 2.75469685e+00 5.26065491e-02 6.43107865e-04 2.62778878e+00\n",
      " 1.00972620e-03 2.60345578e+00 2.05556498e-04 8.30903824e-04\n",
      " 2.95242548e-01 1.02787002e-04 2.58707047e+00 4.69670864e-04\n",
      " 8.17471242e-04 1.57142954e-03 5.69678321e-02 2.72135735e+00\n",
      " 3.89194751e+00 2.70898533e+00 1.54489493e-02 8.17471242e-04\n",
      " 2.41606069e+00 2.60345578e+00 2.53858089e-01 5.83056186e-04\n",
      " 1.34056143e-04 2.23848486e+00 1.11516181e-03 3.36014581e+00\n",
      " 6.59380630e-02 9.05456778e-04 1.54489493e-02 1.57142954e-03\n",
      " 1.17571197e-01 1.74155124e-02 9.21283499e-04 4.91250248e-04\n",
      " 5.26065491e-02 1.11516181e-03 4.95407206e-04 1.44850079e-03\n",
      " 1.47766307e-01 2.26773307e-04 2.25861788e+00 1.02605368e-03\n",
      " 9.05862898e-02 1.44850079e-03 3.32125084e-04 2.26773307e-04\n",
      " 2.61391401e+00 2.46501248e-02 3.32125084e-04 2.61391401e+00\n",
      " 2.23848486e+00 2.16635206e-04 1.18012575e-03 2.99353743e+00\n",
      " 2.66959310e+00 2.90583634e+00 2.62848258e+00 4.26079147e-04\n",
      " 2.80092984e-01 3.87536073e+00 4.20827098e-04 8.17471242e-04\n",
      " 1.36822462e-04 3.86753869e+00 3.92228293e+00 2.66249132e+00\n",
      " 3.89281583e+00 2.64548492e+00 8.54016514e-04 3.90085244e+00\n",
      " 3.90193367e+00 2.66249132e+00 4.26079147e-04 2.00084776e-01\n",
      " 6.12054835e-04 1.44850079e-03 2.10867310e+00 2.23267126e+00\n",
      " 3.34421471e-02 2.64369464e+00 2.34003687e+00 2.09361935e+00\n",
      " 7.61845033e-04 3.92222619e+00 3.27636808e-01 3.89016867e+00\n",
      " 1.54489493e-02 8.30903824e-04 2.82702351e+00 3.55595519e-04\n",
      " 2.31822562e+00 2.26773307e-04 2.66959310e+00 3.87289810e+00\n",
      " 1.69180986e-03 2.85225641e-02 2.63684893e+00 2.41606069e+00\n",
      " 3.88429761e+00 2.03805399e+00 1.36822462e-04 2.62778878e+00\n",
      " 2.68949008e+00 3.89016867e+00 1.48028344e-01 2.75443721e+00\n",
      " 2.36058426e+00 2.64548492e+00 2.80347991e+00 1.91825078e-04\n",
      " 1.82894114e-02 3.86751580e+00 2.26490831e+00 2.68250122e-04\n",
      " 3.68274923e-04 3.32125084e-04 2.19942842e-04 2.01781058e+00\n",
      " 2.26490831e+00 1.24150014e-03 2.90583634e+00 1.57142954e-03\n",
      " 4.35821916e-04 2.17359047e-02 3.83716536e+00 7.61285264e-05\n",
      " 2.23267126e+00 2.58707047e+00 3.90714240e+00 3.86753869e+00\n",
      " 4.71130647e-02 2.88793826e+00 2.18221402e+00 2.95242548e-01\n",
      " 1.69180986e-03 2.04223488e-02 2.27321029e+00 2.13948750e+00\n",
      " 2.08603191e+00 2.66708040e+00 5.59654785e-04 3.05332112e+00\n",
      " 2.68949008e+00 2.76301026e+00 3.87772298e+00 2.16838789e+00\n",
      " 2.31822562e+00 2.72664428e-01 6.84311390e-02 8.68587871e-04\n",
      " 2.01969981e+00 3.91242290e+00 2.60345578e+00 3.87703848e+00\n",
      " 1.06900174e-03 2.26490831e+00 3.12589693e+00 7.69679667e-04\n",
      " 4.26079147e-04 1.44207897e-03 1.44850079e-03 2.08603191e+00\n",
      " 1.53422565e-03 2.81787099e-04 1.44850079e-03 3.06354570e+00\n",
      " 1.47766307e-01 3.92428327e+00 1.24150014e-03 2.08603191e+00\n",
      " 2.70898533e+00 2.61391401e+00 2.94144440e+00 3.83716536e+00\n",
      " 2.13699365e+00 2.66249132e+00 3.05120420e+00 2.70898533e+00\n",
      " 4.34250484e-04 2.45063424e-01 2.18221402e+00 1.78233910e-04\n",
      " 2.78209060e-01 2.19492173e+00 9.21283499e-04 1.53422565e-03\n",
      " 2.88291144e+00 2.58415705e-04 2.61391401e+00 1.98815469e-04\n",
      " 3.87703848e+00 2.82989949e-01 1.20944438e-04 3.36583592e-02\n",
      " 1.24150014e-03 2.26217651e+00 1.93764828e-02 9.32865718e-04\n",
      " 3.95323396e+00 2.14180303e+00 1.53422565e-03 2.67768598e+00\n",
      " 3.86030173e+00 3.83716536e+00 2.41085148e+00 3.86030173e+00], shape=(560,), dtype=float32)\n",
      "Policy Loss  tf.Tensor(\n",
      "[2.2237074  2.1758616  3.6252449  1.8009162  1.3701186  2.404274\n",
      " 1.2466916  2.875136   1.8861315  1.8635833  2.3622572  2.0666633\n",
      " 3.4571247  1.4419757  1.1709125  1.7250476  1.9229616  1.9406922\n",
      " 2.3148043  2.6042216  1.0422885  1.6600981  2.2175212  0.83247703\n",
      " 2.0127285  1.144642   1.3678732  1.9884464  2.111061   1.1192607\n",
      " 0.92477244 2.209206   1.4430182  1.3947071  2.4194794  1.803125\n",
      " 2.0125992  1.9894242  1.6783559  1.4148238  2.198362   1.6515758\n",
      " 1.4567928  1.8338337  2.2113848  1.9583614  1.1192607  1.7205371\n",
      " 1.9715059  1.8478968  2.3622572  1.2411357  1.7992144  3.1204014\n",
      " 1.5485739  1.8013216  3.1204014  1.2302859  2.0125992  1.9229616\n",
      " 2.164465   1.2250199  1.3699303  1.6642593  1.8768194  1.9685911\n",
      " 0.90851855 1.9406922  1.8037932  1.8067153  2.075675   1.702597\n",
      " 1.6690161  1.2411357  2.994263   1.7012215  0.8309544  2.5105565\n",
      " 1.8792878  2.0620146  0.46514025 2.1154947  2.3260853  2.44664\n",
      " 1.9699132  2.385535   1.9709342  2.2591     2.3698153  1.7934604\n",
      " 2.1561522  2.1005204  2.3875082  1.8506044  1.9699132  1.2541276\n",
      " 2.519749   2.1622558  0.66424197 1.9389927  2.1933107  1.3690219\n",
      " 0.6510838  2.3641798  1.8245924  2.271513   1.0366746  1.2250948\n",
      " 2.4088671  2.1622558  3.0830328  1.8610303  1.8676575  1.7304332\n",
      " 1.9334245  1.9334245  2.0186517  1.861887   1.7955222  1.5738667\n",
      " 1.9637219  1.9635943  2.6144087  1.8098029  1.4362117  2.162784\n",
      " 1.8033282  2.1715755  1.861887   2.1810684  1.3419825  1.8042942\n",
      " 2.1970897  1.2258883  3.4571247  2.0326385  1.788231   0.8547038\n",
      " 1.1192607  1.9037151  2.2755082  1.8313552  2.0307193  1.2866292\n",
      " 1.7934604  2.1046438  1.544863   2.994263   2.4754176  1.8033282\n",
      " 1.3642977  1.7766546  0.92477244 0.9100456  1.7702032  2.115035\n",
      " 1.5738667  2.204001   2.2378361  1.9485387  2.1005204  1.5165827\n",
      " 1.804916   2.0186517  1.2218945  0.7060141  2.0251942  1.3230278\n",
      " 0.66424197 1.3250816  2.6574168  1.701564   1.8262928  2.1185946\n",
      " 1.8441589  1.1598914  2.6135108  2.163096   1.4960067  1.6386827\n",
      " 2.0513055  1.8313552  1.8515433  1.8080678  2.591261   1.7690653\n",
      " 1.027977   2.0326385  1.5961066  1.5262923  2.3924108  2.4505494\n",
      " 2.4108515  0.97907704 2.3009315  2.1046438  1.9689181  1.4684037\n",
      " 1.0814309  1.6077758  1.8515433  2.162784   1.5738667  1.8057535\n",
      " 1.8052912  1.8645931  2.7122517  2.2864685  1.8483835  1.641682\n",
      " 1.2036777  2.0331476  1.8522953  1.8645931  2.1288853  1.9037151\n",
      " 1.036132   2.541076   2.1933107  2.308609   0.797323   2.588908\n",
      " 2.0507307  1.9328673  2.2055073  1.8699967  1.2261193  2.4754176\n",
      " 1.7969084  2.0529501  2.111061   1.4239062  1.9856172  1.7702032\n",
      " 2.1588993  1.8449655  1.347419   1.3690219  0.8105631  2.0438492\n",
      " 1.872478   1.5971489  1.2541276  0.8194268  2.3646233  1.7702032\n",
      " 2.44664    1.8478968  2.1244574  2.0620146  2.2378361  1.9884464\n",
      " 2.2237074  1.8288046  2.0066032  2.106129   1.7012215  2.7122517\n",
      " 1.1709125  1.0333552  1.746906   1.3879097  1.7969084  1.1332136\n",
      " 2.481354   1.9590249  1.8202505  2.0080245  2.4350533  1.5165827\n",
      " 1.4419757  1.8341683  1.8715461  1.6386827  2.1758616  1.9761809\n",
      " 2.404274   1.698174   1.8341683  2.6042216  1.9329602  1.3523815\n",
      " 1.5485739  1.8288046  1.8861315  1.9907666  1.7660105  1.7955222\n",
      " 1.7245007  2.1588993  2.181659   1.3300681  1.8645931  1.4679904\n",
      " 2.1389043  2.1187553  1.8451471  1.5165827  1.9635943  2.3386424\n",
      " 2.0197678  2.1244574  2.2237074  1.4076198  2.158079   1.9678967\n",
      " 1.6759276  1.3181506  1.668113   1.8672231  2.0507307  1.3942995\n",
      " 1.144642   1.2411357  1.4076198  1.8028786  1.8861315  1.7132888\n",
      " 2.0747228  2.0761633  2.0830276  2.198362   1.9685911  1.8067153\n",
      " 1.9715059  2.5081277  0.92477244 1.6782765  1.5532167  2.2636395\n",
      " 1.1497637  0.9059582  2.404274   2.1391113  1.3758898  0.2016119\n",
      " 1.9918061  2.158183   1.5485739  1.5162942  2.591261   1.2302859\n",
      " 1.9328673  2.4350533  1.9416165  2.1617177  2.621538   2.1637914\n",
      " 2.1015303  2.6487794  1.8067153  0.90851855 1.6041404  0.6761108\n",
      " 3.2539134  1.8490559  3.5206938  1.8403728  1.3002632  2.9695077\n",
      " 2.1588993  0.8105631  1.9657779  2.6042216  2.4720433  2.4754176\n",
      " 1.4076198  1.8313552  3.1817446  1.766447   0.6510838  1.6782765\n",
      " 2.077894   1.8403728  1.8676575  2.2801425  0.90851855 1.8763922\n",
      " 2.4723537  0.9059582  1.6811762  1.5758823  0.6510838  2.210704\n",
      " 1.7828716  0.2016119  2.1185946  2.306387   0.6761108  2.445485\n",
      " 2.5414898  2.591261   2.3116987  1.1192607  2.0326385  2.404274\n",
      " 1.701564   2.224191   1.2866292  1.1192607  1.9083357  1.4493234\n",
      " 1.8028786  1.5000093  1.8067153  1.5301322  1.9756577  1.5541607\n",
      " 1.8454819  1.8610303  1.6830356  2.106129   2.1561522  1.3984264\n",
      " 1.5775623  2.447595   0.8360952  2.219774   1.8445548  1.9689181\n",
      " 1.5826234  1.8098029  1.5503502  1.1627218  1.8009938  1.9689181\n",
      " 2.106129   1.9709342  1.3181506  2.591261   2.2702103  2.0080245\n",
      " 1.5853488  1.9334245  2.049843   2.1844835  2.204001   1.718615\n",
      " 2.1043675  1.5607141  0.6510838  2.994263   1.4920111  0.7643427\n",
      " 2.094417   1.360728   1.8441845  2.1991358  2.0666633  0.9047881\n",
      " 1.6919743  2.0665188  1.5594246  2.0747228  0.8360952  1.8245924\n",
      " 1.7505376  1.5642583  1.943727   1.8506044  1.9416165  1.4960067\n",
      " 1.698174   1.0361598  1.3460526  1.4148238  1.8369659  3.4571247\n",
      " 3.10419    1.6386827  0.797323   2.198362   1.8512007  2.6144087\n",
      " 1.8610303  2.519749   1.668113   0.7060141  2.2113848  1.2466916\n",
      " 2.1034007  1.9660767  1.8530848  2.6214426  1.9603617  1.7725295\n",
      " 1.8672231  2.158183   2.1813707  1.2720681  1.8080678  2.1015303\n",
      " 2.059622   1.8768194  2.1971445  1.3674018  1.7505376  1.5961066\n",
      " 2.0973759  1.8645931  2.0838873  2.149754   1.7819309  1.3811088\n",
      " 2.1195486  1.1434114  1.8416102  1.746906   2.6574168  1.8451471\n",
      " 1.9761809  1.8688606  2.106129   1.8313919  2.6014006  1.9884464\n",
      " 2.2175212  1.7690653  2.6135108  1.7263848  2.3116987  1.4063954\n",
      " 2.1239433  1.9906318  1.766447   1.9072329  1.5738101  2.5105565\n",
      " 2.0842457  1.9685911  1.347419   1.766447   1.6205326  1.8288046\n",
      " 1.8672231  0.8194268  1.9866638  1.9328673  2.1758616  2.4350533\n",
      " 1.7422705  1.1148962  1.9083357  1.3891823  1.746906   2.1785984\n",
      " 1.3230278  1.4419757  2.1256301  2.0529501  0.69774544 2.0331476\n",
      " 2.2183764  2.163096   2.4669766  1.7660105  2.4007654  2.2113848\n",
      " 1.9591088  2.2925115 ], shape=(560,), dtype=float32)\n",
      "L2 Loss  tf.Tensor(0.10782219, shape=(), dtype=float32)\n",
      "Loss  tf.Tensor(3.3027558, shape=(), dtype=float32)\n",
      "Training Step  5\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.4325  0.08    0.07375 0.07625 0.07625 0.0675  0.07375 0.06625 0.05375]\n",
      "Predicted Policy  [0.         0.12838314 0.1199139  0.12726103 0.12602101 0.12310548\n",
      " 0.12482307 0.1282434  0.12224899]\n",
      "Predicted Value  0.014244070276618004\n",
      "Target Policy [0.         0.74124998 0.03375    0.04375    0.03125    0.0325\n",
      " 0.03625    0.04       0.04125   ]\n",
      "Predicted Policy  [0.         0.         0.14083958 0.14395101 0.14316219 0.14252016\n",
      " 0.1434586  0.14450866 0.14155987]\n",
      "Predicted Value  -4.041358261019923e-05\n",
      "Target Policy [0.         0.         0.01625    0.01375    0.91000003 0.015\n",
      " 0.015      0.0175     0.0125    ]\n",
      "Predicted Policy  [0.         0.         0.16056865 0.17316094 0.         0.16459559\n",
      " 0.1652846  0.17213584 0.1642544 ]\n",
      "Predicted Value  0.012313746847212315\n",
      "Target Policy [0.      0.      0.90875 0.025   0.      0.02375 0.0125  0.015   0.015  ]\n",
      "Predicted Policy  [0.         0.         0.19748272 0.2021295  0.         0.20007075\n",
      " 0.         0.20217465 0.19814233]\n",
      "Predicted Value  0.0023328354582190514\n",
      "Target Policy [0.         0.         0.025      0.02375    0.         0.035\n",
      " 0.         0.035      0.88125002]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.44499999 0.08       0.07375    0.07375    0.08125    0.07\n",
      " 0.06125    0.05875    0.05625   ]\n",
      "Predicted Policy  [0.12505169 0.12859419 0.12050732 0.         0.12850043 0.12295003\n",
      " 0.12484349 0.12697122 0.12258165]\n",
      "Predicted Value  0.013729075901210308\n",
      "Target Policy [0.04    0.72375 0.0525  0.      0.045   0.04    0.0325  0.03125 0.035  ]\n",
      "Predicted Policy  [0.14288369 0.         0.14258564 0.         0.14485888 0.14141233\n",
      " 0.14179765 0.14484608 0.1416158 ]\n",
      "Predicted Value  0.0022951613646000624\n",
      "Target Policy [0.01375    0.         0.01625    0.         0.015      0.90750003\n",
      " 0.0175     0.01625    0.01375   ]\n",
      "Predicted Policy  [0.16760969 0.         0.15980563 0.         0.17065607 0.\n",
      " 0.16790973 0.16996576 0.16405314]\n",
      "Predicted Value  0.016251547262072563\n",
      "Target Policy [0.0275     0.         0.91624999 0.         0.01875    0.\n",
      " 0.01375    0.0125     0.01125   ]\n",
      "Predicted Policy  [0.20098947 0.         0.         0.         0.20203874 0.\n",
      " 0.20068868 0.2002241  0.19605903]\n",
      "Predicted Value  0.004243824165314436\n",
      "Target Policy [0.01875    0.         0.         0.         0.91750002 0.\n",
      " 0.03625    0.0125     0.015     ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.44874999 0.07875    0.0775     0.07125    0.0725     0.06375\n",
      " 0.07125    0.05875    0.0575    ]\n",
      "Predicted Policy  [0.         0.12838314 0.1199139  0.12726103 0.12602101 0.12310548\n",
      " 0.12482307 0.1282434  0.12224899]\n",
      "Predicted Value  0.014244070276618004\n",
      "Target Policy [0.         0.76749998 0.03       0.035      0.0325     0.03125\n",
      " 0.025      0.04       0.03875   ]\n",
      "Predicted Policy  [0.         0.         0.14083958 0.14395101 0.14316219 0.14252016\n",
      " 0.1434586  0.14450866 0.14155987]\n",
      "Predicted Value  -4.041358261019923e-05\n",
      "Target Policy [0.         0.         0.01625    0.01375    0.91250002 0.015\n",
      " 0.015      0.01375    0.01375   ]\n",
      "Predicted Policy  [0.         0.         0.16056865 0.17316094 0.         0.16459559\n",
      " 0.1652846  0.17213584 0.1642544 ]\n",
      "Predicted Value  0.012313746847212315\n",
      "Target Policy [0.         0.         0.025      0.03625    0.         0.89749998\n",
      " 0.0125     0.0125     0.01625   ]\n",
      "Predicted Policy  [0.         0.         0.19564156 0.20303886 0.         0.\n",
      " 0.20060065 0.20445651 0.19626236]\n",
      "Predicted Value  0.003130203578621149\n",
      "Target Policy [0.         0.         0.03375    0.03125    0.         0.\n",
      " 0.02625    0.015      0.89375001]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.35499999 0.105      0.08       0.0875     0.085      0.0725\n",
      " 0.07625    0.065      0.07375   ]\n",
      "Predicted Policy  [0.1257992  0.13045667 0.11984821 0.12714225 0.         0.12146635\n",
      " 0.12424064 0.12910971 0.12193696]\n",
      "Predicted Value  0.017681505531072617\n",
      "Target Policy [0.02       0.02125    0.0225     0.86374998 0.         0.02\n",
      " 0.01625    0.01875    0.0175    ]\n",
      "Predicted Policy  [0.14475031 0.1444522  0.14133261 0.         0.         0.14298224\n",
      " 0.14244604 0.14366686 0.14036968]\n",
      "Predicted Value  -0.0005273917340673506\n",
      "Target Policy [0.90750003 0.02125    0.01375    0.         0.         0.01375\n",
      " 0.01375    0.01375    0.01625   ]\n",
      "Predicted Policy  [0.         0.17503355 0.15910235 0.         0.         0.16269153\n",
      " 0.16914427 0.1706568  0.16337147]\n",
      "Predicted Value  0.014763442799448967\n",
      "Target Policy [0.         0.90750003 0.02375    0.         0.         0.02375\n",
      " 0.01375    0.015      0.01625   ]\n",
      "Predicted Policy  [0.         0.         0.19739258 0.         0.         0.2012686\n",
      " 0.20260689 0.20308354 0.19564842]\n",
      "Predicted Value  0.005664799362421036\n",
      "Target Policy [0.         0.         0.0375     0.         0.         0.02875\n",
      " 0.03375    0.01375    0.88625002]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.4375  0.07625 0.07375 0.0825  0.08875 0.06625 0.06625 0.05625 0.0525 ]\n",
      "Predicted Policy  [0.12486077 0.12676264 0.12012218 0.12839662 0.12624961 0.12270815\n",
      " 0.         0.12802844 0.12287159]\n",
      "Predicted Value  0.011270382441580296\n",
      "Target Policy [0.10875    0.1025     0.11125    0.13124999 0.15000001 0.15000001\n",
      " 0.         0.12125    0.125     ]\n",
      "Predicted Policy  [0.14274223 0.14389686 0.14238803 0.14309193 0.14353792 0.\n",
      " 0.         0.14373536 0.14060764]\n",
      "Predicted Value  -0.0006430407520383596\n",
      "Target Policy [0.015   0.01375 0.015   0.015   0.01625 0.      0.      0.02125 0.90375]\n",
      "Predicted Policy  [0.1635929  0.16840622 0.16251975 0.16837601 0.16787554 0.\n",
      " 0.         0.1692295  0.        ]\n",
      "Predicted Value  0.011925237253308296\n",
      "Target Policy [0.1525     0.14       0.1375     0.13375001 0.12       0.\n",
      " 0.         0.31625    0.        ]\n",
      "Predicted Policy  [0.19903888 0.         0.19689703 0.20363921 0.19931173 0.\n",
      " 0.         0.20111315 0.        ]\n",
      "Predicted Value  0.0023159270640462637\n",
      "Target Policy [0.02625    0.         0.0275     0.025      0.0225     0.\n",
      " 0.         0.89875001 0.        ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.47999999 0.06875    0.07       0.075      0.0775     0.0575\n",
      " 0.0625     0.055      0.05375   ]\n",
      "Predicted Policy  [0.         0.12838314 0.1199139  0.12726103 0.12602101 0.12310548\n",
      " 0.12482307 0.1282434  0.12224899]\n",
      "Predicted Value  0.014244070276618004\n",
      "Target Policy [0.         0.73500001 0.0325     0.03625    0.03125    0.0425\n",
      " 0.0325     0.04375    0.04625   ]\n",
      "Predicted Policy  [0.         0.         0.14083958 0.14395101 0.14316219 0.14252016\n",
      " 0.1434586  0.14450866 0.14155987]\n",
      "Predicted Value  -4.041358261019923e-05\n",
      "Target Policy [0.         0.         0.01375    0.01625    0.91374999 0.01375\n",
      " 0.015      0.015      0.0125    ]\n",
      "Predicted Policy  [0.         0.         0.16056865 0.17316094 0.         0.16459559\n",
      " 0.1652846  0.17213584 0.1642544 ]\n",
      "Predicted Value  0.012313746847212315\n",
      "Target Policy [0.      0.      0.02375 0.025   0.      0.90625 0.01375 0.01375 0.0175 ]\n",
      "Predicted Policy  [0.         0.         0.19564156 0.20303886 0.         0.\n",
      " 0.20060065 0.20445651 0.19626236]\n",
      "Predicted Value  0.003130203578621149\n",
      "Target Policy [0.      0.      0.0275  0.0275  0.      0.      0.025   0.01625 0.90375]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.44749999 0.1        0.07       0.07375    0.0725     0.06875\n",
      " 0.06125    0.05       0.05625   ]\n",
      "Predicted Policy  [0.         0.12838314 0.1199139  0.12726103 0.12602101 0.12310548\n",
      " 0.12482307 0.1282434  0.12224899]\n",
      "Predicted Value  0.014244070276618004\n",
      "Target Policy [0.         0.78250003 0.0325     0.0325     0.0275     0.02875\n",
      " 0.03       0.025      0.04125   ]\n",
      "Predicted Policy  [0.         0.         0.14083958 0.14395101 0.14316219 0.14252016\n",
      " 0.1434586  0.14450866 0.14155987]\n",
      "Predicted Value  -4.041358261019923e-05\n",
      "Target Policy [0.      0.      0.01375 0.02    0.90875 0.015   0.015   0.01375 0.01375]\n",
      "Predicted Policy  [0.         0.         0.16056865 0.17316094 0.         0.16459559\n",
      " 0.1652846  0.17213584 0.1642544 ]\n",
      "Predicted Value  0.012313746847212315\n",
      "Target Policy [0.         0.         0.03125    0.02875    0.         0.89875001\n",
      " 0.01125    0.0125     0.0175    ]\n",
      "Predicted Policy  [0.         0.         0.19564156 0.20303886 0.         0.\n",
      " 0.20060065 0.20445651 0.19626236]\n",
      "Predicted Value  0.003130203578621149\n",
      "Target Policy [0.         0.         0.025      0.025      0.         0.\n",
      " 0.03625    0.01375    0.89999998]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.44624999 0.09       0.07375    0.075      0.0725     0.06375\n",
      " 0.065      0.05375    0.06      ]\n",
      "Predicted Policy  [0.12505169 0.12859419 0.12050732 0.         0.12850043 0.12295003\n",
      " 0.12484349 0.12697122 0.12258165]\n",
      "Predicted Value  0.013729075901210308\n",
      "Target Policy [0.04875    0.72000003 0.04625    0.         0.04       0.0425\n",
      " 0.03375    0.0375     0.03125   ]\n",
      "Predicted Policy  [0.14288369 0.         0.14258564 0.         0.14485888 0.14141233\n",
      " 0.14179765 0.14484608 0.1416158 ]\n",
      "Predicted Value  0.0022951613646000624\n",
      "Target Policy [0.015   0.      0.015   0.      0.015   0.91125 0.01375 0.015   0.015  ]\n",
      "Predicted Policy  [0.16760969 0.         0.15980563 0.         0.17065607 0.\n",
      " 0.16790973 0.16996576 0.16405314]\n",
      "Predicted Value  0.016251547262072563\n",
      "Target Policy [0.02625    0.         0.91374999 0.         0.0225     0.\n",
      " 0.0125     0.0125     0.0125    ]\n",
      "Predicted Policy  [0.20098947 0.         0.         0.         0.20203874 0.\n",
      " 0.20068868 0.2002241  0.19605903]\n",
      "Predicted Value  0.004243824165314436\n",
      "Target Policy [0.02375    0.         0.         0.         0.91750002 0.\n",
      " 0.0325     0.0125     0.01375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.35624999 0.09       0.0925     0.085      0.08       0.08875\n",
      " 0.0775     0.06875    0.06125   ]\n",
      "Predicted Policy  [0.12471491 0.12816614 0.         0.12609792 0.12573266 0.12296347\n",
      " 0.12347677 0.12662242 0.12222568]\n",
      "Predicted Value  0.015944749116897583\n",
      "Target Policy [0.03       0.79500002 0.         0.0325     0.0325     0.03125\n",
      " 0.02875    0.025      0.025     ]\n",
      "Predicted Policy  [0.14368346 0.         0.         0.14369388 0.14344858 0.14127447\n",
      " 0.14203933 0.1442887  0.14157155]\n",
      "Predicted Value  -0.0017491424223408103\n",
      "Target Policy [0.015      0.         0.         0.0175     0.015      0.90750003\n",
      " 0.01625    0.015      0.01375   ]\n",
      "Predicted Policy  [0.16614571 0.         0.         0.17057967 0.16703933 0.\n",
      " 0.16335413 0.1705706  0.16231057]\n",
      "Predicted Value  0.014425147324800491\n",
      "Target Policy [0.025      0.         0.         0.025      0.90750003 0.\n",
      " 0.01375    0.0125     0.01625   ]\n",
      "Predicted Policy  [0.20220482 0.         0.         0.2027257  0.         0.\n",
      " 0.19807704 0.19991313 0.1970793 ]\n",
      "Predicted Value  0.0002745827951002866\n",
      "Target Policy [0.04       0.         0.         0.0325     0.         0.\n",
      " 0.0275     0.015      0.88499999]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11143049 0.11110936 0.11071824 0.11121672 0.11128241 0.11079987\n",
      " 0.11103825 0.11151128 0.11089341]\n",
      "Predicted Value  -0.00034931578557007015\n",
      "Target Policy [0.39625001 0.08625    0.07875    0.08875    0.08125    0.07\n",
      " 0.07375    0.06125    0.06375   ]\n",
      "Predicted Policy  [0.12505169 0.12859419 0.12050732 0.         0.12850043 0.12295003\n",
      " 0.12484349 0.12697122 0.12258165]\n",
      "Predicted Value  0.013729075901210308\n",
      "Target Policy [0.05375    0.69875002 0.0425     0.         0.04875    0.04125\n",
      " 0.04125    0.03875    0.035     ]\n",
      "Predicted Policy  [0.14288369 0.         0.14258564 0.         0.14485888 0.14141233\n",
      " 0.14179765 0.14484608 0.1416158 ]\n",
      "Predicted Value  0.0022951613646000624\n",
      "Target Policy [0.01375    0.         0.01625    0.         0.01875    0.90499997\n",
      " 0.0175     0.015      0.01375   ]\n",
      "Predicted Policy  [0.16760969 0.         0.15980563 0.         0.17065607 0.\n",
      " 0.16790973 0.16996576 0.16405314]\n",
      "Predicted Value  0.016251547262072563\n",
      "Target Policy [0.03625 0.      0.90625 0.      0.02    0.      0.0125  0.0125  0.0125 ]\n",
      "Predicted Policy  [0.20098947 0.         0.         0.         0.20203874 0.\n",
      " 0.20068868 0.2002241  0.19605903]\n",
      "Predicted Value  0.004243824165314436\n",
      "Target Policy [0.02375    0.         0.         0.         0.91750002 0.\n",
      " 0.0325     0.0125     0.01375   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Value Loss  tf.Tensor(\n",
      "[0.9762918  1.0259316  0.99672395 0.9747721  1.0087682  1.0204966\n",
      " 0.9937283  0.99417526 1.0017123  1.0142672  0.99488115 0.9775862\n",
      " 0.96494967 1.0073876  0.9997704  1.0263419  0.97778904 1.00781\n",
      " 0.9777471  0.97549254 0.99852973 0.9732933  1.0046711  0.9728574\n",
      " 0.9669894  0.9729181  0.9937283  0.9744004  0.97171474 0.9688619\n",
      " 0.9952356  0.99585366 0.969633   0.9719304  0.9937283  1.003477\n",
      " 0.97398144 0.9750713  1.0087682  1.0131423  0.98888415 1.02211\n",
      " 0.95721537 0.9755655  0.9727303  1.003477   0.9901294  0.97729146\n",
      " 0.96621656 0.96992    0.9744004  1.0306118  0.9669894  0.969633\n",
      " 1.0004175  0.9702311  0.97069114 0.9992626  0.99488115 1.0027611\n",
      " 1.0371946  0.9711834  0.99209255 0.95721537 1.0025578  1.0071957\n",
      " 0.9683648  0.9697352  0.9984751  0.9693461  1.0177537  0.9755655\n",
      " 1.0025578  1.0060025  0.9683648  0.9947657  0.9727303  1.0276467\n",
      " 0.9688619  0.9775862  0.9960892  1.0317005  0.9875485  0.9952356\n",
      " 1.0008488  0.97778904 0.9937283  1.0045955  1.0111673  0.97398144\n",
      " 1.020016   1.0045955  1.0182514  1.0062336  1.0062915  0.99812835\n",
      " 0.9669894  1.0025578  0.99417526 0.992447   0.9775862  1.0073876\n",
      " 0.99014294 0.97398144 0.99894553 0.9688619  1.0036633  0.9862528\n",
      " 0.9683648  0.9744004  0.998312   0.99894553 0.97069114 0.9775862\n",
      " 0.9697352  0.9744004  0.9858741  0.96379215 0.9700022  0.9937283\n",
      " 0.9809283  0.9775862  0.96205896 0.9762918  1.0001197  0.9937283\n",
      " 1.0019684  1.0297287  0.9719304  0.99209255 0.9732933  0.9697352\n",
      " 0.9984751  1.008528   1.004063   0.969469   0.9811587  0.9775862\n",
      " 1.0087682  0.9846339  1.0090265  0.9744004  0.9960892  0.9992626\n",
      " 1.0041549  1.0275222  0.98469865 1.0273243  1.0121894  0.99585366\n",
      " 0.9660934  1.0087682  1.0077095  0.9775862  0.9747721  0.96457684\n",
      " 0.9744004  0.97269785 0.9999192  0.9811587  1.0017123  1.0087682\n",
      " 0.9997704  0.9715488  0.9862528  0.99894553 0.97398144 1.0276467\n",
      " 0.97269785 0.9732933  0.98603094 1.0073876  1.0131423  1.0182698\n",
      " 0.9693461  1.0087682  0.9727303  0.9664444  0.9937283  0.9960892\n",
      " 1.022285   0.96494967 0.99589354 0.9683648  0.99756116 0.99518734\n",
      " 0.9927763  1.0062702  0.9775862  0.9991198  0.97398144 1.0025578\n",
      " 1.0142672  1.0279837  0.97171474 1.0308354  0.9700022  0.99894553\n",
      " 0.967761   0.9649881  0.9649881  0.9978544  0.976133   0.9994779\n",
      " 0.9992626  1.0122217  0.9719304  0.9755126  0.9734707  0.9649199\n",
      " 0.9646368  0.95749027 0.9940837  0.99894553 1.0004699  0.9952356\n",
      " 1.0008062  1.0060619  0.96494967 0.96205896 0.9963246  1.0042051\n",
      " 0.9654201  0.9960892  1.0073876  1.0245351  1.0297287  0.99792063\n",
      " 0.9893815  0.9587953  0.97171474 0.9675144  1.022285   1.0102392\n",
      " 0.9755243  0.9887092  0.96879417 0.9994733  1.000734   0.9965047\n",
      " 0.97398144 0.9701546  1.0124489  1.0025835  0.9846702  0.9983613\n",
      " 0.9770658  0.98993415 0.9755655  0.99352175 1.0274311  0.9754538\n",
      " 1.007492   0.99485976 0.97171474 0.9715488  1.0045339  0.99518734\n",
      " 0.96413153 1.0249777  0.9969728  1.0017123  1.0025835  0.97171474\n",
      " 0.98469865 1.0046699  0.97729146 0.99014294 0.9952356  1.0182514\n",
      " 1.0308354  0.96879417 0.9750235  0.97171474 0.96494967 1.0004699\n",
      " 1.0316305  1.0041549  1.0106919  1.0130125  0.9719304  0.99734926\n",
      " 0.96379215 0.9727303  1.0308354  0.97729146 1.0041767  0.9937283\n",
      " 1.0045955  0.97926486 1.0017123  1.0084523  0.9775862  1.0026423\n",
      " 0.9744004  0.9646368  0.9960892  0.9937283  0.9728501  0.9997704\n",
      " 0.9778949  1.0258404  1.0041549  1.0177537  1.0041549  0.97398144\n",
      " 0.9693461  0.9744004  0.9912701  0.96992    0.99482304 1.0042051\n",
      " 0.9715488  1.0311227  1.0132445  1.0259316  0.9999192  0.9873408\n",
      " 0.96205896 0.9937283  0.98469865 0.9932224  0.9683648  1.0030318\n",
      " 0.9660806  1.0317005  1.0087044  0.99894553 1.0276467  0.9762918\n",
      " 0.97171474 1.0087682  0.9744004  1.0055004  0.9734707  1.0317005\n",
      " 0.9688619  1.0026423  0.9775862  0.9811587  1.0308354  0.9719304\n",
      " 0.9649199  0.9949073  0.9693461  0.9978544  1.0058297  0.9683648\n",
      " 0.9727303  0.99488115 0.9660934  0.96494967 0.9983613  0.97398144\n",
      " 0.99263966 0.9744004  0.9762918  1.0117732  0.9953774  0.98603094\n",
      " 0.969633   1.0073876  0.9727303  0.95721537 0.98713166 1.0019684\n",
      " 0.97171474 0.97171474 0.9775862  0.9664444  1.0317005  0.9857562\n",
      " 0.9732933  1.0059727  0.97482353 1.0037342  0.9719304  1.0084523\n",
      " 0.99582654 1.0011443  1.0258404  0.9904153  1.0025578  0.99921507\n",
      " 0.97398144 0.99707854 1.0045339  1.0127308  1.0087682  0.9732933\n",
      " 0.9811587  0.99488115 0.9893043  1.0039299  0.969633   0.96205896\n",
      " 0.98469865 0.98458046 1.0036633  1.0173781  0.9744004  0.9960892\n",
      " 0.998037   1.0311311  1.0028987  1.0184584  0.96315277 1.0111673\n",
      " 0.96532315 1.0056341  0.98412323 0.984648   0.969633   0.9775862\n",
      " 0.9937283  0.9910921  0.9702311  1.0041549  0.9974454  0.9937283\n",
      " 0.9960892  0.9719304  0.969633   0.9744004  0.98469865 1.0004175\n",
      " 1.0084523  0.9997704  0.9934718  1.0045955  0.9994733  0.9702311\n",
      " 0.969633   0.9940837  1.0239878  1.0087682  0.99707854 0.99063027\n",
      " 0.9711834  0.98458046 0.9949073  0.9683648  1.0063623  0.9968775\n",
      " 0.9654761  0.9734707  0.9700022  1.0039163  1.0321437  0.9732933\n",
      " 0.99518734 0.9984751  0.9750713  0.9683648  1.0025578  0.9937283\n",
      " 0.95721537 1.0050931  0.9753304  1.0421501  1.008528   1.0084523\n",
      " 0.9775862  0.9597757  1.0177677  0.9940207  1.0023661  0.98458046\n",
      " 1.0182698  0.9775862  0.98469865 1.0308354  1.0117732  0.99734926\n",
      " 1.0102243  1.0076736  0.9937283  1.0008062  0.9755243  1.0306118\n",
      " 1.0017123  1.0016894  1.0025578  0.9937283  0.98022616 1.0087682\n",
      " 0.9937283  0.98603094 0.9937283  0.9762918  0.96205896 0.97398144\n",
      " 1.0170157  1.0238566  0.97729146 1.0283463  1.0276467  0.97171474\n",
      " 0.96879417 0.9912701  0.9851686  1.0039299  0.9937283  0.9747721\n",
      " 0.9688619  0.96494967 0.9712208  0.99209255 0.99894553 0.9884494\n",
      " 0.99488115 1.0026423  0.96494967 1.0015467  1.0182698  0.9809283\n",
      " 0.9770658  0.99309886 0.97171474 0.95721537 0.9933664  0.9828235\n",
      " 0.9734707  0.9688619  0.9683648  0.9905655  0.9649881  0.9960892\n",
      " 1.0189582  0.99792063 1.0025835  1.0202847  0.99713564 0.969633\n",
      " 0.9996155  0.95193875 0.9762918  0.96879417 0.983886   1.0007058\n",
      " 0.96413153 1.0080128  0.9902363  0.9696829  1.0321437  1.0062915\n",
      " 0.9649881  0.9990492  0.9734707  1.0055004  0.9649881  0.95193875\n",
      " 0.969633   1.0025578  0.9937283  0.9660934  0.9701385  1.003477\n",
      " 0.9660934  1.02211   ], shape=(560,), dtype=float32)\n",
      "Policy Loss  tf.Tensor(\n",
      "[1.9493983  2.1788402  1.8022141  1.620093   2.0693626  1.0842944\n",
      " 2.1968794  1.9230134  2.0691273  1.7738534  1.7815828  2.1939244\n",
      " 2.1765516  2.0726724  2.0757136  1.6089561  1.9364445  1.7738757\n",
      " 1.6323944  1.5846783  1.802201   1.9076806  1.7750721  1.0917568\n",
      " 1.9395937  1.9700183  2.1831584  2.1830065  2.1944408  1.9274069\n",
      " 1.6144749  2.0792942  2.192541   1.5553529  2.1834228  1.7972544\n",
      " 1.5688324  1.6169636  2.0697846  1.7955018  1.6057065  1.9598808\n",
      " 1.6152636  1.9743762  2.1974592  1.7973295  2.0753174  1.626234\n",
      " 1.5594602  1.3818965  2.1920037  1.0962474  1.9250525  2.1842713\n",
      " 1.8006225  1.6164955  1.9180762  2.068938   1.7852297  1.7780519\n",
      " 1.610556   1.9663363  1.3895746  1.616383   2.069294   1.7939365\n",
      " 2.1754022  1.9208661  1.7875389  1.9112031  1.6165359  1.9743137\n",
      " 2.0696187  1.77921    2.196126   1.3746958  2.1989353  2.1797237\n",
      " 1.9384482  2.1789498  1.7752383  2.2077484  0.68956405 1.6019162\n",
      " 2.0789714  1.9355552  2.1812449  2.0725143  1.9229968  1.5616789\n",
      " 1.9646937  2.0705187  1.9592953  1.786993   2.1970563  1.3729285\n",
      " 1.9221007  2.069294   1.9233491  2.0760608  2.198151   2.0757964\n",
      " 1.6130478  1.5835776  2.0724256  1.9212954  1.7775673  1.7950692\n",
      " 2.2104094  2.1969342  2.0799146  2.0715954  1.9183283  2.1789498\n",
      " 1.9751629  2.196333   1.6285495  1.9355167  1.9236702  2.1831002\n",
      " 1.9594837  2.1909657  1.6128057  1.9493983  2.0748749  2.1832454\n",
      " 1.3866253  1.5827945  1.5721815  1.3909719  1.9055296  1.9210931\n",
      " 1.7875389  1.7823098  1.7965213  1.9374948  1.6356833  2.19895\n",
      " 2.0700934  1.7949505  1.5985296  2.1830065  1.7750654  2.068938\n",
      " 2.079406   1.9231123  1.9323051  1.5795747  1.6149483  2.0792942\n",
      " 1.6127899  2.0700934  2.0730717  2.1975598  1.6296687  1.6334147\n",
      " 2.1969342  1.979612   2.0741258  1.6356833  2.0691273  2.0693626\n",
      " 2.0757136  1.943584   1.7950692  2.0716052  1.5796902  2.1797237\n",
      " 1.9638097  1.913744   1.9221293  2.0713835  1.7955018  1.6209823\n",
      " 1.8962606  2.0717728  2.210148   1.6229593  2.1832454  1.7752383\n",
      " 1.6329937  2.1953974  2.0742235  2.2085035  1.3802747  1.9392948\n",
      " 2.076518   1.7857229  2.1909657  1.7914914  1.5824647  2.0667322\n",
      " 1.7738534  1.9275224  2.1780434  2.1974244  1.9701298  2.0808706\n",
      " 1.9112     1.9349498  1.9351808  1.7678517  1.9694988  2.0752861\n",
      " 2.0688732  1.789185   1.5553529  1.9275444  1.9354161  1.6402293\n",
      " 1.9230576  1.0944124  1.7767916  2.0697722  2.0870032  1.6018572\n",
      " 1.7824863  2.0791001  2.1912723  1.6128057  1.79034    1.784054\n",
      " 1.6090049  1.7750907  2.0724695  1.6035159  1.5827945  2.0759542\n",
      " 1.381335   1.9272728  2.1901624  1.9202262  1.6329937  1.769086\n",
      " 1.9352717  1.8152615  2.2046828  1.7929443  2.072963   2.0791967\n",
      " 1.5688324  1.9093674  1.0954127  1.7897034  1.6224929  0.69350404\n",
      " 1.39323    1.789794   1.9743762  1.7712694  1.5832975  1.9304993\n",
      " 1.7921832  2.078318   2.1946902  1.943584   1.79157    1.9392948\n",
      " 1.6187356  1.9191445  2.0811281  2.0775719  1.7897034  2.1963768\n",
      " 1.9317377  2.080548   1.6275854  1.6130478  1.6018572  1.9592953\n",
      " 2.1904538  2.215483   1.930794   2.194426   2.195641   2.0870032\n",
      " 1.9387066  2.079016   1.7691771  1.7677891  1.5646143  0.6912013\n",
      " 1.929924   2.1967833  2.188807   1.5805885  0.684533   2.1834228\n",
      " 2.0721133  1.9295262  2.0709546  1.7789978  2.1942887  1.7918226\n",
      " 2.1956062  1.9230576  1.7752383  2.1968794  1.6256068  2.0757136\n",
      " 1.6230887  1.6194764  2.078845   1.6165359  2.079016   1.5616789\n",
      " 1.9111403  2.1830065  2.069562   1.3818965  1.3775314  1.7796131\n",
      " 1.943584   1.953804   1.6006578  2.1788402  2.0761285  1.6016222\n",
      " 1.6128057  2.1967888  1.9323051  2.0705388  2.1754022  2.0799253\n",
      " 1.9337114  2.1987138  1.0985246  2.0697722  2.1975653  1.9493983\n",
      " 2.1948078  2.0697846  2.1975002  2.0800338  1.8953333  2.1974282\n",
      " 1.937396   1.7918226  2.191252   1.6356833  2.182966   1.5643181\n",
      " 1.6402293  1.7910831  1.8966411  1.7678517  1.7816361  2.1956003\n",
      " 2.1974592  1.7776784  1.6127899  2.198938   0.69350404 1.5690194\n",
      " 2.0770843  2.197916   1.9561981  1.9197991  1.7845118  1.922274\n",
      " 2.1827507  2.0726724  2.1974592  1.6168225  1.6083997  1.3866253\n",
      " 2.1944408  2.1903148  2.1939244  1.6099323  2.2077484  1.382544\n",
      " 1.9055296  2.0761786  1.5985566  1.7925422  1.5687044  1.7789978\n",
      " 1.7796266  0.69286644 1.6194764  1.3810178  2.0693197  2.0801125\n",
      " 1.5688324  1.0886981  1.79157    1.9292835  2.0716298  1.9126644\n",
      " 1.6386259  1.7776784  1.8087678  1.7817951  2.1931777  1.632193\n",
      " 1.9262906  1.9249247  1.7775673  1.1066673  2.1830065  1.7752208\n",
      " 1.7868379  1.8968953  1.7877855  1.6199737  1.5619618  1.9230417\n",
      " 1.0949662  2.0782506  0.69304746 1.789494   2.1826477  2.1798854\n",
      " 2.1951113  1.7846208  1.6164955  2.0791225  2.0693197  2.183115\n",
      " 1.7752383  1.5853555  2.192541   2.1982827  1.9323051  1.8006225\n",
      " 1.7840221  2.0757136  1.3863971  2.0717714  1.7929443  1.5956603\n",
      " 2.196751   1.7767153  1.9675804  2.0693626  1.0886981  1.7916315\n",
      " 1.9672968  1.9247549  1.7910831  2.1885707  2.0826135  1.3866516\n",
      " 1.0907533  1.9191222  1.9701298  1.7747192  2.1997514  1.9076806\n",
      " 1.9347516  1.7875389  1.6179333  2.1754022  2.0667322  2.196904\n",
      " 1.616383   1.779682   1.9315704  1.6029639  1.7823098  1.7763643\n",
      " 2.1932054  1.5710329  1.9346298  1.7893069  1.7909151  1.9241415\n",
      " 1.6209823  2.1789498  1.9262906  2.1973953  1.9197327  0.6912013\n",
      " 1.6039865  1.779663   2.1811926  1.7940193  1.9171153  1.0962474\n",
      " 2.0710871  2.0799263  2.0667322  2.1812449  1.6133789  2.0697846\n",
      " 2.1967888  1.922274   2.1832454  1.9561981  1.6115091  1.5794152\n",
      " 1.0948837  1.5865239  1.6266295  1.930736   2.186109   2.1780434\n",
      " 2.2155733  2.071419   1.94759    1.7817951  2.1831002  1.620093\n",
      " 1.9384482  2.2127502  1.0875736  1.3895746  2.0715954  0.677578\n",
      " 1.7815828  1.7919619  2.1669998  1.7829982  1.6209823  1.9544752\n",
      " 1.3889934  1.3758698  2.1857176  1.616383   1.7863421  1.622048\n",
      " 1.9191222  1.9384482  2.212934   1.6095346  1.9348708  1.7752383\n",
      " 1.6213244  2.0761049  1.7897034  1.6171306  1.7846369  2.1827507\n",
      " 1.7953506  1.625786   1.9561981  2.220457   1.5936834  0.6905759\n",
      " 1.6456844  1.3490177  1.5889755  1.9260575  2.1997514  2.1812449\n",
      " 1.9351808  2.0575223  1.9191222  2.0800338  1.9348708  1.625786\n",
      " 2.1925004  2.0676944  2.1831002  1.6127899  1.9316788  1.7973295\n",
      " 1.6141341  1.931632  ], shape=(560,), dtype=float32)\n",
      "L2 Loss  tf.Tensor(0.10781395, shape=(), dtype=float32)\n",
      "Loss  tf.Tensor(2.9541636, shape=(), dtype=float32)\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "MCTS Policy  [0.5725  0.0925  0.09    0.07125 0.06125 0.04375 0.0375  0.01625 0.015  ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "MCTS Policy  [0.7725  0.05625 0.0675  0.035   0.02875 0.01375 0.01375 0.0125 ]\n",
      "Predicted Policy  [0.         0.         0.13851303 0.14528607 0.14674787 0.14113133\n",
      " 0.14280154 0.1461881  0.13933204]\n",
      "Predicted Value  0.024510707706212997\n",
      "MCTS Policy  [0.01625 0.0175  0.90625 0.01625 0.01625 0.01375 0.01375]\n",
      "Predicted Policy  [0.         0.         0.15438454 0.1820547  0.         0.15570068\n",
      " 0.16050214 0.18657398 0.16078396]\n",
      "Predicted Value  0.25019127130508423\n",
      "MCTS Policy  [0.02875 0.9     0.03    0.0125  0.01375 0.015  ]\n",
      "Predicted Policy  [0.         0.         0.19540629 0.         0.         0.19909944\n",
      " 0.20225607 0.20964712 0.19359104]\n",
      "Predicted Value  0.036925844848155975\n",
      "MCTS Policy  [0.03375 0.03125 0.035   0.015   0.885  ]\n",
      "score:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/alphazero/videos/alphazero folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/alphazero/videos/alphazero/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/alphazero/videos/alphazero/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/alphazero/videos/alphazero/rl-video-episode-0.mp4\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "Training Step  6\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.63875002 0.08       0.07875    0.05125    0.0525     0.04\n",
      " 0.0325     0.01375    0.0125    ]\n",
      "Predicted Policy  [0.12181813 0.13532658 0.         0.12847258 0.13319096 0.11421715\n",
      " 0.1181306  0.135137   0.11370697]\n",
      "Predicted Value  0.24026232957839966\n",
      "Target Policy [0.85874999 0.0275     0.         0.02875    0.02125    0.025\n",
      " 0.0125     0.0125     0.01375   ]\n",
      "Predicted Policy  [0.         0.14372437 0.         0.1447406  0.14558217 0.14081831\n",
      " 0.14136027 0.1452399  0.13853438]\n",
      "Predicted Value  0.025068670511245728\n",
      "Target Policy [0.      0.01625 0.      0.01625 0.02    0.90125 0.01875 0.01375 0.01375]\n",
      "Predicted Policy  [0.         0.17801048 0.         0.16945907 0.17607716 0.\n",
      " 0.15351938 0.17501159 0.1479223 ]\n",
      "Predicted Value  0.2351093292236328\n",
      "Target Policy [0.         0.03125    0.         0.89499998 0.035      0.\n",
      " 0.01125    0.015      0.0125    ]\n",
      "Predicted Policy  [0.         0.20307277 0.         0.         0.20653805 0.\n",
      " 0.19936089 0.20067884 0.19034946]\n",
      "Predicted Value  0.05138448253273964\n",
      "Target Policy [0.         0.03875    0.         0.         0.0525     0.\n",
      " 0.03375    0.0125     0.86250001]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.58749998 0.09125    0.0875     0.06875    0.055      0.0425\n",
      " 0.03875    0.01625    0.0125    ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.05375    0.77249998 0.0675     0.035      0.0275\n",
      " 0.015      0.015      0.01375   ]\n",
      "Predicted Policy  [0.         0.14447469 0.         0.14484829 0.14589855 0.14085087\n",
      " 0.14143877 0.14424737 0.13824144]\n",
      "Predicted Value  0.0198910441249609\n",
      "Target Policy [0.         0.01625    0.         0.01625    0.90750003 0.01625\n",
      " 0.015      0.01375    0.015     ]\n",
      "Predicted Policy  [0.         0.17781048 0.         0.17351365 0.         0.15172723\n",
      " 0.16198927 0.18038172 0.15457769]\n",
      "Predicted Value  0.23552022874355316\n",
      "Target Policy [0.         0.035      0.         0.89499998 0.         0.02875\n",
      " 0.01375    0.01375    0.01375   ]\n",
      "Predicted Policy  [0.         0.20832944 0.         0.         0.         0.19528757\n",
      " 0.19783758 0.2065429  0.1920025 ]\n",
      "Predicted Value  0.03570069000124931\n",
      "Target Policy [0.         0.03875    0.         0.         0.         0.03125\n",
      " 0.03       0.015      0.88499999]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.59249997 0.09125    0.08       0.0625     0.06125    0.04375\n",
      " 0.03875    0.01375    0.01625   ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.      0.77625 0.05375 0.065   0.03375 0.02625 0.0175  0.01375 0.01375]\n",
      "Predicted Policy  [0.         0.         0.13851303 0.14528607 0.14674787 0.14113133\n",
      " 0.14280154 0.1461881  0.13933204]\n",
      "Predicted Value  0.024510707706212997\n",
      "Target Policy [0.      0.      0.01625 0.01625 0.90625 0.0175  0.01625 0.01375 0.01375]\n",
      "Predicted Policy  [0.         0.         0.15438454 0.1820547  0.         0.15570068\n",
      " 0.16050214 0.18657398 0.16078396]\n",
      "Predicted Value  0.25019127130508423\n",
      "Target Policy [0.         0.         0.03       0.89375001 0.         0.0375\n",
      " 0.01125    0.0125     0.015     ]\n",
      "Predicted Policy  [0.         0.         0.19540629 0.         0.         0.19909944\n",
      " 0.20225607 0.20964712 0.19359104]\n",
      "Predicted Value  0.036925844848155975\n",
      "Target Policy [0.         0.         0.03875    0.         0.         0.02875\n",
      " 0.03125    0.015      0.88625002]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.54750001 0.10375    0.09       0.0825     0.06125    0.04375\n",
      " 0.0375     0.0175     0.01625   ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.05375    0.78250003 0.06125    0.03       0.0325\n",
      " 0.01375    0.01375    0.0125    ]\n",
      "Predicted Policy  [0.         0.14447469 0.         0.14484829 0.14589855 0.14085087\n",
      " 0.14143877 0.14424737 0.13824144]\n",
      "Predicted Value  0.0198910441249609\n",
      "Target Policy [0.         0.0175     0.         0.01625    0.90499997 0.015\n",
      " 0.02       0.0125     0.01375   ]\n",
      "Predicted Policy  [0.         0.17781048 0.         0.17351365 0.         0.15172723\n",
      " 0.16198927 0.18038172 0.15457769]\n",
      "Predicted Value  0.23552022874355316\n",
      "Target Policy [0.         0.035      0.         0.89625001 0.         0.03\n",
      " 0.01375    0.0125     0.0125    ]\n",
      "Predicted Policy  [0.         0.20832944 0.         0.         0.         0.19528757\n",
      " 0.19783758 0.2065429  0.1920025 ]\n",
      "Predicted Value  0.03570069000124931\n",
      "Target Policy [0.      0.03625 0.      0.      0.      0.03125 0.0375  0.015   0.88   ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.5575  0.095   0.09125 0.0725  0.06625 0.04375 0.04375 0.015   0.015  ]\n",
      "Predicted Policy  [0.12516987 0.         0.11414586 0.13327934 0.13709757 0.1168365\n",
      " 0.12007792 0.13764705 0.11574584]\n",
      "Predicted Value  0.24121719598770142\n",
      "Target Policy [0.02       0.         0.02375    0.88375002 0.01625    0.015\n",
      " 0.015      0.01375    0.0125    ]\n",
      "Predicted Policy  [0.1446062  0.         0.14158754 0.14678559 0.         0.1408769\n",
      " 0.13993827 0.14725783 0.13894768]\n",
      "Predicted Value  0.05094628036022186\n",
      "Target Policy [0.03125    0.         0.83999997 0.03125    0.         0.035\n",
      " 0.03625    0.01375    0.0125    ]\n",
      "Predicted Policy  [0.17529008 0.         0.1557052  0.         0.         0.16060898\n",
      " 0.16579737 0.18532108 0.1572772 ]\n",
      "Predicted Value  0.20645540952682495\n",
      "Target Policy [0.92000002 0.         0.0175     0.         0.         0.01875\n",
      " 0.015      0.015      0.01375   ]\n",
      "Predicted Policy  [0.         0.         0.2004306  0.         0.         0.19358177\n",
      " 0.1992462  0.20982616 0.19691524]\n",
      "Predicted Value  0.07617303729057312\n",
      "Target Policy [0.         0.         0.035      0.         0.         0.03375\n",
      " 0.89875001 0.01375    0.01875   ]\n",
      "Predicted Policy  [0.         0.         0.23548877 0.         0.         0.24435036\n",
      " 0.         0.2799933  0.2401676 ]\n",
      "Predicted Value  0.20244808495044708\n",
      "Target Policy [0.         0.         0.0175     0.         0.         0.0175\n",
      " 0.         0.01625    0.94875002]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [-1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.56999999 0.0925     0.09       0.06875    0.06125    0.0475\n",
      " 0.03875    0.0175     0.01375   ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.78874999 0.05375    0.05625    0.035      0.02625\n",
      " 0.015      0.01375    0.01125   ]\n",
      "Predicted Policy  [0.         0.         0.13851303 0.14528607 0.14674787 0.14113133\n",
      " 0.14280154 0.1461881  0.13933204]\n",
      "Predicted Value  0.024510707706212997\n",
      "Target Policy [0.         0.         0.0175     0.01625    0.90499997 0.02125\n",
      " 0.015      0.0125     0.0125    ]\n",
      "Predicted Policy  [0.         0.         0.15084067 0.17655072 0.18512237 0.15447745\n",
      " 0.         0.17784391 0.15516491]\n",
      "Predicted Value  0.22633622586727142\n",
      "Target Policy [0.         0.         0.10375    0.50875002 0.0925     0.08625\n",
      " 0.         0.0975     0.11125   ]\n",
      "Predicted Policy  [0.         0.         0.19657908 0.         0.20887057 0.1968923\n",
      " 0.         0.20470102 0.19295707]\n",
      "Predicted Value  0.034046970307826996\n",
      "Target Policy [0.         0.         0.025      0.         0.87625003 0.02625\n",
      " 0.         0.03625    0.03625   ]\n",
      "Predicted Policy  [0.         0.         0.23557815 0.         0.         0.23328228\n",
      " 0.         0.28404996 0.24708964]\n",
      "Predicted Value  0.25613075494766235\n",
      "Target Policy [0.         0.         0.435      0.         0.         0.12125\n",
      " 0.         0.14624999 0.29750001]\n",
      "Predicted Policy  [0.         0.         0.         0.         0.         0.3281647\n",
      " 0.         0.35064474 0.32119054]\n",
      "Predicted Value  0.042305607348680496\n",
      "Target Policy [0.   0.   0.   0.   0.   0.06 0.   0.06 0.88]\n",
      "Initial Rewards [0, 0, 0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.5575  0.095   0.09125 0.07125 0.06625 0.04375 0.0425  0.01625 0.01625]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.05375    0.77125001 0.0675     0.0325     0.0325\n",
      " 0.0125     0.015      0.015     ]\n",
      "Predicted Policy  [0.         0.14447469 0.         0.14484829 0.14589855 0.14085087\n",
      " 0.14143877 0.14424737 0.13824144]\n",
      "Predicted Value  0.0198910441249609\n",
      "Target Policy [0.      0.01625 0.      0.0175  0.90875 0.015   0.0175  0.0125  0.0125 ]\n",
      "Predicted Policy  [0.         0.17781048 0.         0.17351365 0.         0.15172723\n",
      " 0.16198927 0.18038172 0.15457769]\n",
      "Predicted Value  0.23552022874355316\n",
      "Target Policy [0.         0.03       0.         0.89749998 0.         0.035\n",
      " 0.01125    0.0125     0.01375   ]\n",
      "Predicted Policy  [0.         0.20832944 0.         0.         0.         0.19528757\n",
      " 0.19783758 0.2065429  0.1920025 ]\n",
      "Predicted Value  0.03570069000124931\n",
      "Target Policy [0.         0.03375    0.         0.         0.         0.03125\n",
      " 0.035      0.015      0.88499999]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.57249999 0.1        0.0925     0.07125    0.055      0.0425\n",
      " 0.0375     0.01375    0.015     ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.05375    0.77249998 0.0675     0.035      0.0275\n",
      " 0.01375    0.01625    0.01375   ]\n",
      "Predicted Policy  [0.         0.14447469 0.         0.14484829 0.14589855 0.14085087\n",
      " 0.14143877 0.14424737 0.13824144]\n",
      "Predicted Value  0.0198910441249609\n",
      "Target Policy [0.         0.02       0.         0.015      0.90499997 0.0175\n",
      " 0.01625    0.0125     0.01375   ]\n",
      "Predicted Policy  [0.         0.17781048 0.         0.17351365 0.         0.15172723\n",
      " 0.16198927 0.18038172 0.15457769]\n",
      "Predicted Value  0.23552022874355316\n",
      "Target Policy [0.         0.03       0.         0.025      0.         0.90499997\n",
      " 0.0125     0.0125     0.015     ]\n",
      "Predicted Policy  [0.         0.20728976 0.         0.20387758 0.         0.\n",
      " 0.19531296 0.20566961 0.18785007]\n",
      "Predicted Value  0.05147967487573624\n",
      "Target Policy [0.         0.085      0.         0.04375    0.         0.\n",
      " 0.03625    0.0125     0.82249999]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n",
      "Target Policy [0.58249998 0.1        0.09125    0.07125    0.0525     0.0425\n",
      " 0.0325     0.01375    0.01375   ]\n",
      "Predicted Policy  [0.         0.13620886 0.11292205 0.13036062 0.13524923 0.11426947\n",
      " 0.12016404 0.13665591 0.11416987]\n",
      "Predicted Value  0.24161982536315918\n",
      "Target Policy [0.         0.04125    0.80250001 0.05625    0.03       0.03\n",
      " 0.01375    0.01375    0.0125    ]\n",
      "Predicted Policy  [0.         0.14447469 0.         0.14484829 0.14589855 0.14085087\n",
      " 0.14143877 0.14424737 0.13824144]\n",
      "Predicted Value  0.0198910441249609\n",
      "Target Policy [0.         0.015      0.         0.01625    0.90750003 0.01625\n",
      " 0.01625    0.015      0.01375   ]\n",
      "Predicted Policy  [0.         0.17781048 0.         0.17351365 0.         0.15172723\n",
      " 0.16198927 0.18038172 0.15457769]\n",
      "Predicted Value  0.23552022874355316\n",
      "Target Policy [0.         0.03625    0.         0.89249998 0.         0.03125\n",
      " 0.01125    0.0125     0.01625   ]\n",
      "Predicted Policy  [0.         0.20832944 0.         0.         0.         0.19528757\n",
      " 0.19783758 0.2065429  0.1920025 ]\n",
      "Predicted Value  0.03570069000124931\n",
      "Target Policy [0.     0.0425 0.     0.     0.     0.03   0.03   0.0175 0.88  ]\n",
      "Initial Rewards [0, 0, 0, 0, 1]\n",
      "Updated Rewards [1, -1, 1, -1, 1]\n",
      "Predicted Policy  [0.11150451 0.11125997 0.11037945 0.11144686 0.11162298 0.11064539\n",
      " 0.11069179 0.11177345 0.11067563]\n",
      "Predicted Value  0.0037358980625867844\n"
     ]
    }
   ],
   "source": [
    "from alphazero_agent import AlphaZeroAgent\n",
    "# from alphazero_agent import AlphaZeroAgent\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym_envs\n",
    "\n",
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env, min_reward, max_reward):\n",
    "        super().__init__(env)\n",
    "        self.min_reward = min_reward\n",
    "        self.max_reward = max_reward\n",
    "        self.reward_range = (min_reward, max_reward)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, self.min_reward, self.max_reward)\n",
    "\n",
    "\n",
    "# env = ClipReward(gym.wrappers.AtariPreprocessing(gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\"), terminal_on_life_loss=True), -1, 1) # as recommended by the original paper, should already include max pooling\n",
    "# env = TicTacToeEnv(render_mode=\"rgb_array\")\n",
    "# env = gym.make(\"MsPacmanNoFrameskip-v4\", render_mode=\"rgb_array\")\n",
    "# env = gym.wrappers.FrameStack(env, 4)\n",
    "env = gym.make('gym_envs/TicTacToe-v0', render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "# MODEL SEEMS TO BE UNDERFITTING SO TRY AND GET IT TO OVERFIT THEN FIND A HAPPY MEDIUM\n",
    "# 1. INCREASE THE NUMBER OF RESIDUAL BLOCKS\n",
    "# 2. INCREASE THE NUMBER OF FILTERS\n",
    "# 3. DECREASE REGULARIZATION\n",
    "# 4. TRY DECREASING LEARNING RATE (maybe its that whole thing where the policy goes to like 1 0 0 0 0... etc and then goes back on the third training step, so maybe the learning rate is too high)\n",
    "# 5. TO OVERFIT USE LESS DATA (but that is probably just a bad idea)\n",
    "# config = {\n",
    "#         'activation': 'relu',\n",
    "#         'kernel_initializer': 'glorot_uniform',\n",
    "#         'optimizer': tf.keras.optimizers.legacy.Adam,\n",
    "#         'learning_rate': 0.001, # 0.00001 could maybe increase by a factor of 10 or 100 and try to do some weights regularization\n",
    "#         'adam_epsilon': 3.25e-6,\n",
    "#         'clipnorm': None,\n",
    "#         # NORMALIZATION?\n",
    "#         # REWARD CLIPPING\n",
    "#         'training_steps': 40,\n",
    "#         'num_filters': 256,\n",
    "#         'kernel_size': 3,\n",
    "#         'stride': 1,\n",
    "#         'num_res_blocks': 20,\n",
    "#         'critic_conv_filters': 32, # 1\n",
    "#         'critic_conv_layers': 1,\n",
    "#         'critic_dense_size': 256,\n",
    "#         'critic_dense_layers': 1,\n",
    "#         'actor_conv_filters': 32, # \n",
    "#         'actor_conv_layers': 1,\n",
    "#         'actor_dense_size': 0,\n",
    "#         'actor_dense_layers': 0,\n",
    "#         'replay_buffer_size': 800, # IN GAMES\n",
    "#         'replay_batch_size': 50, # IN MOVES\n",
    "#         'root_dirichlet_alpha': 0.5, # 2 in theory?\n",
    "#         'root_exploration_fraction': 0, # 0.25 in paper\n",
    "#         'pb_c_base': 500,\n",
    "#         'pb_c_init': 2,\n",
    "#         'num_simulations': 200,\n",
    "#         # 'two_player': True,\n",
    "#         'weight_decay': 0.00, # could try setting this to something other than 0 and increasing learning rate\n",
    "#         'num_sampling_moves': 0, \n",
    "#         'initial_temperature': 1,\n",
    "#         'exploitation_temperature': 0.1,\n",
    "#         'value_loss_factor': 1, # could try setting this to something other than 1\n",
    "#         'games_per_generation': 10, # times 8 from augmentation\n",
    "#     }\n",
    "\n",
    "config = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'glorot_uniform',\n",
    "        'optimizer': tf.keras.optimizers.legacy.Adam,\n",
    "        'min_learning_rate': 0.0005, #0.0001 # 0.00001 could maybe increase by a factor of 10 or 100 and try to do some weights regularization\n",
    "        'max_learning_rate': 0.0005, #0.0001\n",
    "        'number_of_lr_cycles': 1, # this will determine the step size based on training steps\n",
    "        # STILL ADD A SCHEDULE FOR BASE LEARNING RATE (MIN LEARNING RATE)\n",
    "        'adam_epsilon': 3.25e-6,\n",
    "        'clipnorm': None,\n",
    "        # NORMALIZATION?\n",
    "        # REWARD CLIPPING\n",
    "        'training_steps': 100, # alpha zero did 700,000, the lessons from alpha zero did 40 generations but 1000 batches per generation, so 40,000 batches (they just had a cyclical learning rate per generation (also they trained twice on the same data every generation))\n",
    "        'num_filters': 256,\n",
    "        'kernel_size': 3,\n",
    "        'stride': 1,\n",
    "        'num_res_blocks': 20,\n",
    "        'critic_conv_filters': 32, # 1\n",
    "        'critic_conv_layers': 1,\n",
    "        'critic_dense_size': 256,\n",
    "        'critic_dense_layers': 1,\n",
    "        'actor_conv_filters': 32, # \n",
    "        'actor_conv_layers': 1,\n",
    "        'actor_dense_size': 0,\n",
    "        'actor_dense_layers': 0,\n",
    "        'replay_buffer_size': 800, # IN GAMES\n",
    "        'replay_batch_size': 560, # SHOULD BE ROUGHLY SAME AS AVERAGE MOVE PER GENERATION (SO LIKE 7 TIMES NUMBER OF GAMES PLAYED PER GENERATION) <- what was used in the original paper (they played 44M games, 50 moves per game and sampled 700,000 minibatches of size 4096 (so thats like sampling 1 time per move roughly but this was also happening with parrallel data collection i believe))\n",
    "        'games_per_generation': 10, # times 8 from augmentation\n",
    "        'root_dirichlet_alpha': 2.0, # Less than 1 more random, greater than one more flat # 2 in theory? # 0.3 in alphazero for chess # TRY CHANGING (MAYBE LOWER? (IT SEEMS TO PLAY THE SAME LINE OVER AND OVER AGAIN <- so we want a lesss flat distribution maybe)\n",
    "        'root_exploration_fraction': 0.25, # 0.25 in paper\n",
    "        'pb_c_base': 20000, # Seems unimportant to be honest (increases puct the more simulations there are)\n",
    "        'pb_c_init': 1.25, # 1.25 in paper # MAYBE HIGHER? (IT SEEMS TO PLAY THE SAME LINE OVER AND OVER AGAIN)\n",
    "        'num_simulations': 800, # INCREASE THIS since the model is missing 1 move wins (and also 2 and 3 move wins (it wins by luck)))\n",
    "        # 'two_player': True,\n",
    "        'weight_decay': 0.00001, # could try setting this to something other than 0 and increasing learning rate\n",
    "        'num_sampling_moves': 4, \n",
    "        'initial_temperature': 1,\n",
    "        'exploitation_temperature': 0.1,\n",
    "        'value_loss_factor': 1, # could try setting this to something other than 1\n",
    "    }\n",
    "\n",
    "agent = AlphaZeroAgent(env, config=config, name=\"alphazero\")\n",
    "agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
