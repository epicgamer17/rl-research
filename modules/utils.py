from dataclasses import dataclass
import itertools
import math
import torch
import torch.nn.init as init
from torch import nn, Tensor


def support_to_scalar(
    probabilities: torch.Tensor, support_size: int, eps: float = 0.001
):
    """
    Convert categorical probabilities over the support [-support_size .. +support_size]
    into scalar(s) using the inverse of the MuZero transformation.

    Args:
        probabilities: Tensor of shape (L,) or (B, L) where L == 2*support_size + 1.
        support_size: integer support size.
        eps: small epsilon used by MuZero (default 0.001).

    Returns:
        Tensor of shape () (scalar) if input was 1D, or (B,) for batched input.
    """
    if probabilities.dim() == 1:
        probs = probabilities.unsqueeze(0)  # shape (1, L)
        squeeze_out = True
    else:
        probs = probabilities
        squeeze_out = False

    batch, L = probs.shape
    assert L == 2 * support_size + 1, "probabilities length must equal 2*support_size+1"

    device = probs.device
    dtype = probs.dtype

    support = torch.arange(
        -support_size, support_size + 1, device=device, dtype=dtype
    ).unsqueeze(
        0
    )  # (1, L)
    z = torch.sum(
        probs * support, dim=1
    )  # expected value on transformed scale, shape (B,)

    # inverse transform from MuZero appendix:
    # f^{-1}(z) = sign(z) * ( ((sqrt(1 + 4*eps*(|z| + 1 + eps)) - 1) / (2*eps))^2 - 1 )
    sign = torch.sign(z)
    abs_z = torch.abs(z)
    inner = 1.0 + 4.0 * eps * (abs_z + 1.0 + eps)
    inv = sign * (((torch.sqrt(inner) - 1.0) / (2.0 * eps)) ** 2 - 1.0)

    if squeeze_out:
        return inv.squeeze(0)
    return inv  # shape (B,)


def scalar_to_support(x: torch.Tensor | float, support_size: int, eps: float = 0.001):
    """
    Convert scalar(s) into a categorical (2*support_size+1)-vector on the MuZero transformed scale.

    Args:
        x: scalar (float or 0-dim tensor) or 1D tensor of shape (B,).
        support_size: integer support size.
        eps: small epsilon used by MuZero (default 0.001).

    Returns:
        Tensor of shape (L,) (if input scalar) or (B, L) for batched inputs,
        where L == 2*support_size + 1. Values are non-negative and sum to 1 per row.
    """
    if not torch.is_tensor(x):
        x = torch.tensor(x, dtype=torch.float32)

    x = x.to(dtype=torch.float32)
    squeeze_input = False
    if x.dim() == 0:
        x = x.unsqueeze(0)  # (1,)
        squeeze_input = True

    device = x.device
    batch = x.shape[0]
    L = 2 * support_size + 1

    # forward transform from MuZero appendix:
    # f(x) = sign(x) * (sqrt(|x| + 1) - 1) + eps * x
    sign = torch.sign(x)
    abs_x = torch.abs(x)
    x_trans = sign * (torch.sqrt(abs_x + 1.0) - 1.0) + eps * x

    # clamp into support range
    x_trans = torch.clamp(x_trans, -support_size, support_size)

    floor = torch.floor(x_trans)
    prob = x_trans - floor  # fractional part, in [0,1)

    out = torch.zeros((batch, L), device=device, dtype=torch.float32)

    idx_lower = (floor + support_size).long()  # index for floor
    idx_upper = idx_lower + 1  # index for floor+1 (may be out of bounds)

    batch_idx = torch.arange(batch, device=device)

    # assign (1 - frac) to floor bin
    out[batch_idx, idx_lower] = 1.0 - prob

    # assign frac to upper bin only if upper bin is within range
    valid_upper_mask = idx_upper <= (L - 1)
    if valid_upper_mask.any():
        valid_batch_idx = batch_idx[valid_upper_mask]
        valid_upper_idx = idx_upper[valid_upper_mask]
        valid_prob = prob[valid_upper_mask]
        out[valid_batch_idx, valid_upper_idx] = valid_prob

    # for cases where floor == support_size (i.e., at upper boundary), all mass already on lower bin
    if squeeze_input:
        return out.squeeze(0)  # shape (L,)
    return out  # shape (B, L)


# def support_to_scalar(probabilities, support_size):
#     """
#     Transform a categorical representation (1D probs vector)
#     into a scalar.
#     """
#     assert probabilities.dim() == 1, "probabilities must be 1D"
#     assert probabilities.shape[0] == 2 * support_size + 1, "shape mismatch"

#     # support values from -support_size to +support_size
#     support = torch.arange(
#         -support_size,
#         support_size + 1,
#         device=probabilities.device,
#         dtype=torch.float32,
#     )
#     x = torch.sum(support * probabilities)

#     # Invert the scaling (from paper appendix)
#     x = torch.sign(x) * (
#         ((torch.sqrt(1 + 4 * 0.001 * (torch.abs(x) + 1 + 0.001)) - 1) / (2 * 0.001))
#         ** 2
#         - 1
#     )
#     return x


# def scalar_to_support(x, support_size):
#     # raise NotImplementedError  # "this is bugged and outputs a uniform instead of a 2-hot"
#     """
#     Transform a scalar (float or 0D tensor)
#     into categorical probs (1D tensor of length 2*support_size+1).
#     """
#     if not torch.is_tensor(x):
#         x = torch.tensor(x, dtype=torch.float32)

#     # Reduce the scale
#     x = torch.sign(x) * (torch.sqrt(torch.abs(x) + 1) - 1) + 0.001 * x

#     # Clamp into support range
#     x = torch.clamp(x, -support_size, support_size)

#     floor = torch.floor(x)
#     prob = x - floor

#     probabilities = torch.zeros(2 * support_size + 1, device=x.device)

#     # distribute mass between floor and floor+1
#     probabilities[int(floor + support_size)] = 1 - prob
#     if floor + 1 <= support_size:
#         probabilities[int(floor + support_size + 1)] = prob

#     # probabilities = torch.softmax(logits, dim=0)
#     return probabilities


# FOR BATCHED INPUTS
# def support_to_scalar(probabilities, support_size):
#     """
#     Transform a categorical representation to a scalar
#     See paper appendix Network Architecture
#     """
#     # Decode to a scalar
#     # print(probabilities.shape)
#     support = (
#         torch.tensor([x for x in range(-support_size, support_size + 1)])
#         .expand(probabilities.shape)
#         .float()
#         .to(device=probabilities.device)
#     )
#     x = torch.sum(support * probabilities, dim=1, keepdim=True)

#     # Invert the scaling (defined in https://arxiv.org/abs/1805.11593)
#     x = torch.sign(x) * (
#         ((torch.sqrt(1 + 4 * 0.001 * (torch.abs(x) + 1 + 0.001)) - 1) / (2 * 0.001))
#         ** 2
#         - 1
#     )
#     return x


# def scalar_to_support(x, support_size):
#     """
#     Transform a scalar to a categorical representation with (2 * support_size + 1) categories
#     See paper appendix Network Architecture
#     """
#     # Reduce the scale (defined in https://arxiv.org/abs/1805.11593)
#     x = torch.sign(x) * (torch.sqrt(torch.abs(x) + 1) - 1) + 0.001 * x

#     # Encode on a vector
#     x = torch.clamp(x, -support_size, support_size)
#     floor = x.floor()
#     prob = x - floor
#     logits = torch.zeros(x.shape[0], x.shape[1], 2 * support_size + 1).to(x.device)
#     logits.scatter_(
#         2, (floor + support_size).long().unsqueeze(-1), (1 - prob).unsqueeze(-1)
#     )
#     indexes = floor + support_size + 1
#     prob = prob.masked_fill_(2 * support_size < indexes, 0.0)
#     indexes = indexes.masked_fill_(2 * support_size < indexes, 0.0)
#     logits.scatter_(2, indexes.long().unsqueeze(-1), prob.unsqueeze(-1))
#     probabilities = logits.softmax(dim=2)
#     # print(probabilities.shape)
#     return probabilities


def scale_gradient(tensor, scale):
    """
    Scales the gradient for the backward pass without changing the forward pass.
    Args:
        tensor (torch.Tensor): The input tensor.
        scale (float): The scaling factor for the gradient.
    """
    return tensor * scale + tensor.detach() * (1 - scale)


def zero_weights_initializer(m: nn.Module) -> None:
    """Initializes the weights and biases of a layer to zero."""
    if hasattr(m, "weight") and m.weight is not None:
        init.constant_(m.weight, 0.0)
    if hasattr(m, "bias") and m.bias is not None:
        init.constant_(m.bias, 0.0)


_epsilon = 1e-7


def categorical_crossentropy(predicted: torch.Tensor, target: torch.Tensor, axis=-1):
    assert torch.allclose(
        torch.sum(predicted, dim=axis, keepdim=True),
        torch.ones_like(torch.sum(predicted, dim=axis, keepdim=True)),
    ), f"Predicted probabilities do not sum to 1: sum = {torch.sum(predicted, dim=axis, keepdim=True)}, for predicted = {predicted}"
    assert predicted.shape == target.shape, f"{predicted.shape} = { target.shape}"

    predicted = (predicted + _epsilon) / torch.sum(
        predicted + _epsilon, dim=axis, keepdim=True
    )
    log_prob = torch.log(predicted)
    return -torch.sum(log_prob * target, axis=axis)


class CategoricalCrossentropyLoss:
    def __init__(self, from_logits=False, axis=-1):
        self.from_logits = from_logits
        self.axis = axis

    def __call__(self, predicted, target):
        return categorical_crossentropy(predicted, target, self.axis)

    def __eq__(self, other):
        if not isinstance(other, CategoricalCrossentropyLoss):
            return False
        return self.from_logits == other.from_logits and self.axis == other.axis


def kl_divergence(predicted: torch.Tensor, target: torch.Tensor, axis=-1):
    assert predicted.shape == target.shape, f"{predicted.shape} = { target.shape}"
    assert torch.allclose(
        torch.sum(predicted, dim=axis, keepdim=True),
        torch.ones_like(torch.sum(predicted, dim=axis, keepdim=True)),
    ), f"Predicted probabilities do not sum to 1: sum = {torch.sum(predicted, dim=axis, keepdim=True)}, for predicted = {predicted}"
    assert torch.allclose(
        torch.sum(target, dim=axis, keepdim=True),
        torch.ones_like(torch.sum(target, dim=axis, keepdim=True)),
    ), f"Predicted probabilities do not sum to 1: sum = {torch.sum(target, dim=axis, keepdim=True)}, for predicted = {target}"
    # 1. Add epsilon prevents 0/0 errors
    # 2. Normalize BOTH to ensure they sum to 1.0
    predicted = (predicted + _epsilon) / torch.sum(
        predicted + _epsilon, dim=axis, keepdim=True
    )
    target = (target + _epsilon) / torch.sum(target + _epsilon, dim=axis, keepdim=True)

    # 3. Compute KL: sum(target * log(target / predicted))
    # Splitting the log is numerically more stable: target * (log(target) - log(predicted))
    return torch.sum(target * (torch.log(target) - torch.log(predicted)), dim=axis)


class KLDivergenceLoss:
    def __init__(self, from_logits=False, axis=-1):
        self.from_logits = from_logits
        self.axis = axis

    def __call__(self, predicted, target):
        return kl_divergence(predicted, target, self.axis)

    def __eq__(self, other):
        if not isinstance(other, KLDivergenceLoss):
            return False
        return self.from_logits == other.from_logits and self.axis == other.axis


def huber(predicted: torch.Tensor, target: torch.Tensor, axis=-1, delta: float = 1.0):
    assert predicted.shape == target.shape, f"{predicted.shape} = { target.shape}"
    diff = torch.abs(predicted - target)
    return torch.where(
        diff < delta, 0.5 * diff**2, delta * (diff - 0.5 * delta)
    ).view(-1)


class HuberLoss:
    def __init__(self, axis=-1, delta: float = 1.0):
        self.axis = axis
        self.delta = delta

    def __call__(self, predicted, target):
        return huber(predicted, target, axis=self.axis, delta=self.delta)

    def __eq__(self, other):
        if not isinstance(other, HuberLoss):
            return False
        return self.axis == other.axis and self.delta == other.delta


def mse(predicted: torch.Tensor, target: torch.Tensor):
    assert predicted.shape == target.shape, f"{predicted.shape} = { target.shape}"
    return (predicted - target) ** 2


class MSELoss:
    def __init__(self):
        pass

    def __call__(self, predicted, target):
        return mse(predicted, target)

    def __eq__(self, other):
        return isinstance(other, MSELoss)


from typing import Any, Callable, Optional, Tuple

Loss = Callable[[torch.Tensor, torch.Tensor], torch.Tensor]


def calculate_padding(i: int, k: int, s: int) -> Tuple[int, int]:
    """Calculate both padding sizes along 1 dimension for a given input length, kernel length, and stride

    Args:
        i (int): input length
        k (int): kernel length
        s (int): stride

    Returns:
        (p_1, p_2): where p_1 = p_2 - 1 for uneven padding and p_1 == p_2 for even padding
    """

    p = (i - 1) * s - i + k
    p_1 = p // 2
    p_2 = (p + 1) // 2
    return (p_1, p_2)


def calculate_same_padding(i, k, s) -> Tuple[None | Tuple[int], None | str | Tuple]:
    """Calculate pytorch inputs for same padding
    Args:
        i (int, int) or int: (h, w) or (w, w)
        k (int, int) or int: (k_h, k_w) or (k, k)
        s (int, int) or int: (s_h, s_w) or (s, s)
    Returns:
        Tuple[manual_pad_padding, torch_conv2d_padding_input]: Either the manual padding that must be applied (first element of tuple) or the input to the torch padding argument of the Conv2d layer
    """

    if s == 1:
        return None, "same"
    h, w = unpack(i)
    k_h, k_w = unpack(k)
    s_h, s_w = unpack(s)
    p_h = calculate_padding(h, k_h, s_h)
    p_w = calculate_padding(w, k_w, s_w)
    if p_h[0] == p_h[1] and p_w[0] == p_w[1]:
        return None, (p_h[0], p_w[0])
    else:
        # not torch compatiable, manually pad with torch.nn.functional.pad
        return (*p_w, *p_h), None


def generate_layer_widths(widths: list[int], max_num_layers: int) -> list[Tuple[int]]:
    """Create all possible combinations of widths for a given number of layers"""
    width_combinations = []

    for i in range(0, max_num_layers):
        width_combinations.extend(itertools.combinations_with_replacement(widths, i))

    return width_combinations


def prepare_kernel_initializers(kernel_initializer: str, output_layer: bool = False):
    if kernel_initializer == "pytorch_default":
        return None
    if kernel_initializer == "glorot_uniform":
        return nn.init.xavier_uniform_
    elif kernel_initializer == "glorot_normal":
        return nn.init.xavier_normal_
    elif kernel_initializer == "he_uniform":
        # return lambda tensor: nn.init.kaiming_uniform_(tensor, nonlinearity="relu")
        return nn.init.kaiming_uniform_
    elif kernel_initializer == "he_normal":
        # return lambda tensor: nn.init.kaiming_normal_(tensor, nonlinearity="relu")
        return nn.init.kaiming_normal_
    elif kernel_initializer == "variance_baseline":
        return VarianceScaling()
    elif kernel_initializer == "variance_0.1":
        return VarianceScaling(scale=0.1)
    elif kernel_initializer == "variance_0.3":
        return VarianceScaling(scale=0.3)
    elif kernel_initializer == "variance_0.8":
        return VarianceScaling(scale=0.8)
    elif kernel_initializer == "variance_3":
        return VarianceScaling(scale=3)
    elif kernel_initializer == "variance_5":
        return VarianceScaling(scale=5)
    elif kernel_initializer == "variance_10":
        return VarianceScaling(scale=10)
    # TODO
    # elif kernel_initializer == "lecun_uniform":
    #     return LecunUniform(seed=np.random.seed())
    # elif kernel_initializer == "lecun_normal":
    #     return LecunNormal(seed=np.random.seed())
    elif kernel_initializer == "orthogonal":
        return nn.init.orthogonal_

    raise ValueError(f"Invalid kernel initializer: {kernel_initializer}")


def prepare_activations(activation: str):
    # print("Activation to prase: ", activation)
    if activation == "linear":
        return nn.Identity()
    elif activation == "relu":
        return nn.ReLU()
    elif activation == "relu6":
        return nn.ReLU6()
    elif activation == "sigmoid":
        return nn.Sigmoid()
    elif activation == "softplus":
        return nn.Softplus()
    elif activation == "soft_sign":
        return nn.Softsign()
    elif activation == "silu" or activation == "swish":
        return nn.SiLU()
    elif activation == "tanh":
        return nn.Tanh()
    # elif activation == "log_sigmoid":
    #     return nn.LogSigmoid()
    elif activation == "hard_sigmoid":
        return nn.Hardsigmoid()
    # elif activation == "hard_silu" or activation == "hard_swish":
    #     return nn.Hardswish()
    # elif activation == "hard_tanh":
    #     return nn.Hardtanh()
    elif activation == "elu":
        return nn.ELU()
    # elif activation == "celu":
    #     return nn.CELU()
    elif activation == "selu":
        return nn.SELU()
    elif activation == "gelu":
        return nn.GELU()
    # elif activation == "glu":
    #     return nn.GLU()

    raise ValueError(f"Activation {activation} not recognized")


def calc_units(shape):
    shape = tuple(shape)
    if len(shape) == 1:
        return shape + shape
    if len(shape) == 2:
        # dense layer -> (in_channels, out_channels)
        return shape
    else:
        # conv_layer (Assuming convolution kernels (2D, 3D, or more).
        # kernel shape: (input_depth, depth, ...)
        in_units = shape[1]
        out_units = shape[0]
        c = 1
        for dim in shape[2:]:
            c *= dim
        return (c * in_units, c * out_units)


class VarianceScaling:
    def __init__(self, scale=0.1, mode="fan_in", distribution="uniform"):
        self.scale = scale
        self.mode = mode
        self.distribution = distribution

        assert mode == "fan_in" or mode == "fan_out" or mode == "fan_avg"
        assert distribution == "uniform", "only uniform distribution is supported"

    def __call__(self, tensor: Tensor) -> None:
        with torch.no_grad():
            scale = self.scale
            shape = tensor.shape
            in_units, out_units = calc_units(shape)
            if self.mode == "fan_in":
                scale /= in_units
            elif self.mode == "fan_out":
                scale /= out_units
            else:
                scale /= (in_units + out_units) / 2

            limit = math.sqrt(3.0 * scale)
            return tensor.uniform_(-limit, limit)


# modules/network_utils.py (New File)
from torch import nn
from typing import Literal


def build_normalization_layer(
    norm_type: Literal["batch", "layer", "none"], num_features: int, dim: int
) -> nn.Module:
    """
    Builds the specified normalization layer.

    Args:
        norm_type: The type of normalization ('batch', 'layer', 'none').
        num_features: The number of features (channels for conv, width for dense).
        dim: The dimension of the input tensor (2 for conv/2D, 1 for dense/1D).
    """
    if norm_type == "batch":
        if dim == 2:
            return nn.BatchNorm2d(num_features)
        elif dim == 1:
            # Batch norm for 1D (Dense) layers
            return nn.BatchNorm1d(num_features)
        else:
            raise ValueError(f"Batch norm for {dim}D not supported.")
    elif norm_type == "layer":
        # nn.LayerNorm expects a list of shape for LayerNorm on last dim(s).
        # We assume the layer is applied across the feature dimension.
        return nn.LayerNorm(num_features)
    elif norm_type == "none":
        return nn.Identity()
    else:
        raise ValueError(f"Unknown normalization type: {norm_type}")


# Existing unpack function from your original code (in utils)
def unpack(x: int | Tuple):
    # ... (same as your original implementation)
    if isinstance(x, Tuple):
        assert len(x) == 2
        return x
    else:
        try:
            x = int(x)
            return x, x
        except Exception as e:
            print(f"error converting {x} to int: ", e)


def _normalize_hidden_state(S: torch.Tensor) -> torch.Tensor:
    """Normalizes the hidden state tensor as described in the paper."""
    # (B, *)
    # Handles both (B, W) for dense and (B, C, H, W) for spatial

    if S.dim() == 2:
        # Case: (B, W) - Dense layer output
        S_norm = S
        dim = 1
    elif S.dim() == 4:
        # Case: (B, C, H, W) - Spatial output. Normalize over spatial dimensions (H*W) for each channel.
        # Reshape to (B*C, H*W) or (B, C, H*W)
        B, C, H, W = S.shape
        S_norm = S.view(B, C, H * W)  # (B, C, H*W)
        dim = 2  # Normalize across H*W dimension for each channel
    else:
        # Not a standard MuZero shape, return unnormalized to be safe
        return S

    min_hidden_state = S_norm.min(dim=dim, keepdim=True)[0]
    max_hidden_state = S_norm.max(dim=dim, keepdim=True)[0]

    if S.dim() == 4:
        # For spatial normalization, restore original dimensions after min/max
        min_hidden_state = min_hidden_state.unsqueeze(-1)  # (B, C, 1, 1)
        max_hidden_state = max_hidden_state.unsqueeze(-1)

    scale_hidden_state = max_hidden_state - min_hidden_state

    # Handle the case where min == max
    scale_hidden_state[scale_hidden_state < 1e-5] = (
        1.0  # Or use += 1e-5 if that's the original intent
    )

    hidden_state = (S - min_hidden_state) / scale_hidden_state
    return hidden_state


@dataclass
class NetworkOutput:
    """
    Standardized output class for the network.
    Now includes q_values for MaxQSelectionStrategy.
    """

    value: Optional[float] = None
    reward: Optional[float] = None
    to_play: Optional[float] = None
    policy_logits: Optional[torch.Tensor] = None
    hidden_state: Optional[torch.Tensor] = None
    q_values: Optional[torch.Tensor] = None
