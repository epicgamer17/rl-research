{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e409e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from fourier_scaffold import FourierScaffold\n",
    "from data_utils import load_mnist_dataset, prepare_data, determine_input_size\n",
    "from graph_utils import plot_imgs_side_by_side\n",
    "from matplotlib import pyplot as plt\n",
    "from hippocampal_sensory_layers import (\n",
    "    ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars,\n",
    ")\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "shapes = [(5, 5), (7, 7)]\n",
    "whitened = True\n",
    "D = 400\n",
    "scaffold = FourierScaffold(\n",
    "    shapes=torch.tensor(shapes), D=D, device=device, _skip_K_calc=True\n",
    ")\n",
    "N = 500\n",
    "dataset = load_mnist_dataset()\n",
    "input_size = determine_input_size(dataset)\n",
    "obs, _ = prepare_data(dataset, N * 2, device=device, preprocess_sensory=whitened)\n",
    "noise = torch.zeros_like(obs).uniform_(-0.5, 0.5)\n",
    "noisy_obs = obs + noise\n",
    "layer = ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "    input_size, D, 0, epsilon_hs=0.01, epsilon_sh=0.01, device=device\n",
    ")\n",
    "noise_only = torch.zeros_like(obs[0]).uniform_(-0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"learned\", \"noisy learned\", \"unseen\", \"noisy unseen\", \"pure noise\"]\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(16, 3.2))\n",
    "plot_imgs_side_by_side(\n",
    "    imgs=[\n",
    "        img.reshape(28, 28).cpu()\n",
    "        for img in [obs[0], noisy_obs[0], obs[N], noisy_obs[N], noise_only]\n",
    "    ],\n",
    "    axs=axs,\n",
    "    titles=titles,\n",
    "    fig=fig,\n",
    "    use_first_img_scale=False\n",
    ")\n",
    "fig.suptitle(\n",
    "    \"images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e08d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "gbook = scaffold.gbook().T\n",
    "for i in tqdm(range(N)):\n",
    "    layer.learn(gbook[i], obs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, figsize=(16, 3.2))\n",
    "\n",
    "entropies = [\n",
    "    scaffold.entropy(layer.hippocampal_from_sensory(s))\n",
    "    for s in [\n",
    "        obs[0],\n",
    "        noisy_obs[0],\n",
    "        obs[N],\n",
    "        noisy_obs[N],\n",
    "        noise_only.flatten(),\n",
    "    ]\n",
    "]\n",
    "\n",
    "plot_imgs_side_by_side(\n",
    "    imgs=[\n",
    "        scaffold.get_all_probabilities(layer.hippocampal_from_sensory(img)).abs().cpu()\n",
    "        for img in [\n",
    "            obs[0],\n",
    "            noisy_obs[0],\n",
    "            obs[N],\n",
    "            noisy_obs[N],\n",
    "            noise_only.flatten(),\n",
    "        ]\n",
    "    ],\n",
    "    axs=axs,\n",
    "    titles=[f\"{name},H={entropy:.3f}\" for name, entropy in zip(titles, entropies)],\n",
    "    fig=fig,\n",
    "    use_first_img_scale=False\n",
    ")\n",
    "fig.suptitle(\n",
    "    f\"distributions from first image, noisy first image, first unlearned image, noisy first unlearned image, and pure noise\\nwhitened={whitened},shapes={shapes}, D={D}, num imgs={N}, noise=uniform(-0.5,0.5)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b521cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_batched(P_batch: torch.Tensor):\n",
    "    return P_batch.norm(dim=(1)) ** 2\n",
    "\n",
    "\n",
    "def entropy(P: torch.Tensor):\n",
    "    return P.norm() ** 2\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "titles = [\n",
    "    \"obs seen\",\n",
    "    \"obs unseen\",\n",
    "    \"noisy obs seen\",\n",
    "    \"noist obs unseen\",\n",
    "]\n",
    "subsets = [\n",
    "    obs[:N],\n",
    "    obs[N : N * 2],\n",
    "    noisy_obs[:N],\n",
    "    noisy_obs[N : N * 2],\n",
    "]\n",
    "\n",
    "\n",
    "for title, subset in zip(titles, subsets):\n",
    "    ax.scatter(\n",
    "        torch.arange(N),\n",
    "        entropy_batched(layer.hippocampal_from_sensory(subset)).cpu(),  # (Npatts)\n",
    "        label=title,\n",
    "        s=5,\n",
    "    )\n",
    "\n",
    "ax.axhline(\n",
    "    y=entropy(layer.hippocampal_from_sensory(noise_only.flatten())[0]).cpu(),\n",
    "    label=\"noise\",\n",
    "    linestyle=\":\",\n",
    ")\n",
    "# ax.axhline(\n",
    "#     y=expected_number_active,\n",
    "#     label=\"expected number active\",\n",
    "# )\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"img\")\n",
    "ax.set_ylabel(f\"H calculated by H=||P||^2 for s->P\")\n",
    "ax.legend()\n",
    "fig.suptitle(\n",
    "    f\"entropy for learned, noisy learned, unlearned, noisy unlearned images with pure noise baseline\\nwhitened={whitened},shapes={shapes}, D={D}, num imgs={N}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "titles = [\n",
    "    \"obs seen\",\n",
    "    \"obs unseen\",\n",
    "    \"noisy obs seen\",\n",
    "    \"noist obs unseen\",\n",
    "]\n",
    "subsets = [\n",
    "    obs[:N],\n",
    "    obs[N : N * 2],\n",
    "    noisy_obs[:N],\n",
    "    noisy_obs[N : N * 2],\n",
    "]\n",
    "\n",
    "\n",
    "for title, subset in zip(titles, subsets):\n",
    "    ax.scatter(\n",
    "        torch.arange(N),\n",
    "        entropy_batched(layer.hippocampal_from_sensory(subset)).cpu(),  # (Npatts)\n",
    "        label=title,\n",
    "        s=5,\n",
    "    )\n",
    "\n",
    "ax.axhline(\n",
    "    y=entropy(layer.hippocampal_from_sensory(noise_only.flatten())[0]).cpu(),\n",
    "    label=\"noise\",\n",
    "    linestyle=\":\",\n",
    ")\n",
    "# ax.axhline(\n",
    "#     y=expected_number_active,\n",
    "#     label=\"expected number active\",\n",
    "# )\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"img\")\n",
    "ax.set_ylabel(f\"H calculated by H=||P||^2 for s->P\")\n",
    "ax.set_ylim(0,10)\n",
    "ax.legend()\n",
    "fig.suptitle(\n",
    "    f\"entropy for learned, noisy learned, unlearned, noisy unlearned images with pure noise baseline\\nwhitened={whitened},shapes={shapes}, D={D}, num imgs={N}, noise=uniform(-0.50, 0.50)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c05eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
