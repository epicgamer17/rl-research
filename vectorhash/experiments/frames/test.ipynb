{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from fourier_scaffold import FourierScaffold\n",
    "from vectorhash_functions import generate_1d_gaussian_kernel\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shapes = [(3, 3), (5, 5)]\n",
    "\n",
    "\n",
    "def gen_Q_degenerate(n, N_patts):\n",
    "    return torch.complex(\n",
    "        torch.cat([torch.eye(n), torch.zeros((n, N_patts - n))], dim=1),\n",
    "        torch.zeros(n, N_patts),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def verify_frame_properties(D, n, epsilon, omega, N_patts):\n",
    "    print(\n",
    "        f\"Verifying with D={D}, n={n}, epsilon={epsilon}, omega={omega}, N_patts={N_patts}\"\n",
    "    )\n",
    "    if n >= D:\n",
    "        print(\n",
    "            \"Note: The inverse failure is expected when n < D. The current configuration (n >= D) may result in a successful inverse calculation.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    scaffold = FourierScaffold(\n",
    "        shapes=torch.tensor(shapes), D=D, _skip_K_calc=True, _skip_gs_calc=True\n",
    "    )\n",
    "    Phi_n = scaffold.gbook()\n",
    "    # print((Phi_n.conj().T @ Phi_n).abs())\n",
    "\n",
    "    Q_n = gen_Q_degenerate(n, N_patts)\n",
    "    H_noiseless = Phi_n @ Q_n.T\n",
    "\n",
    "    print(\"Attempting to calculate the inverse of H_n H_n*...\")\n",
    "    matrix_to_invert = H_noiseless @ H_noiseless.T.conj()\n",
    "    try:\n",
    "        torch.linalg.inv(matrix_to_invert)\n",
    "        print(\"Inverse calculation SUCCEEDED. This is expected if n >= D.\")\n",
    "    except torch.linalg.LinAlgError:\n",
    "        print(\n",
    "            \"Inverse calculation FAILED. This confirms the theoretical result that H_n H_n* is non-invertible when n < D.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    eigvals_noiseless = torch.linalg.eigvalsh(matrix_to_invert).flip(0)[:n]\n",
    "    print(eigvals_noiseless)\n",
    "    lower_bound_noiseless = max(1 - (n - 1) * epsilon, 0)\n",
    "    upper_bound_noiseless = 1 + (n - 1) * epsilon\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(eigvals_noiseless, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.axvline(\n",
    "        lower_bound_noiseless,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"Theoretical Lower Bound\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        upper_bound_noiseless,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"Theoretical Upper Bound\",\n",
    "    )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noiseless $H_nH_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    delta_H = torch.randn(D, n)\n",
    "\n",
    "    norm_bound = math.sqrt(n * epsilon * omega)\n",
    "    if torch.linalg.norm(delta_H, \"fro\") > 0:\n",
    "        delta_H = delta_H / torch.linalg.norm(delta_H, \"fro\") * norm_bound\n",
    "\n",
    "    H_noisy = H_noiseless + delta_H\n",
    "\n",
    "    matrix_to_invert_noisy = H_noisy @ H_noisy.T.conj()\n",
    "    eigvals_noisy = torch.linalg.eigvalsh(matrix_to_invert_noisy).flip(0)[:n]\n",
    "    print(eigvals_noisy)\n",
    "    lower_bound_noisy = max(1 - (n - 1) * epsilon - math.sqrt(n) * epsilon * omega, 0)\n",
    "    upper_bound_noisy = 1 + (n - 1) * epsilon + math.sqrt(n) * epsilon * omega\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(eigvals_noisy, bins=20, color=\"lightgreen\", edgecolor=\"black\")\n",
    "    plt.axvline(\n",
    "        lower_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Lower Bound\"\n",
    "    )\n",
    "    plt.axvline(\n",
    "        upper_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Upper Bound\"\n",
    "    )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noisy $\\\\tilde{H}_n\\\\tilde{H}_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# D > n is required for inverse failure.\n",
    "# D = 2000  # Dimension of vectors g(k)\n",
    "# n = 50  # Number of patterns, n < D\n",
    "# delta = 1 - 0.01\n",
    "# epsilon = math.sqrt(\n",
    "#     (2 / D) * math.log(2 / delta)\n",
    "# )  # Small quasi-orthogonality perturbation\n",
    "# Npatts = torch.prod(torch.tensor(shapes))\n",
    "# omega = epsilon * Npatts  # A constant for the noise bound\n",
    "\n",
    "# verify_frame_properties(D, n, epsilon, omega, Npatts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ebcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_Q_gaussian(n, N_patts, sigma):\n",
    "    print(n, N_patts, sigma)\n",
    "    Q_real = torch.empty((n, N_patts))\n",
    "    Q_imag = torch.zeros((n, N_patts))\n",
    "    for j in range(n):\n",
    "        shift = j + (N_patts - 1) // 2\n",
    "        Q_real[j] = generate_1d_gaussian_kernel((N_patts - 1) // 2, 0, sigma).roll(\n",
    "            shift\n",
    "        )\n",
    "    Q = torch.complex(Q_real, Q_imag)\n",
    "\n",
    "    return Q\n",
    "\n",
    "#print(gen_Q_gaussian(11, 225, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_frame_properties_gaussian(D, n, epsilon, omega, N_patts):\n",
    "    print(\n",
    "        f\"Verifying with D={D}, n={n}, epsilon={epsilon}, omega={omega}, N_patts={N_patts}\"\n",
    "    )\n",
    "    if n >= D:\n",
    "        print(\n",
    "            \"Note: The inverse failure is expected when n < D. The current configuration (n >= D) may result in a successful inverse calculation.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    scaffold = FourierScaffold(\n",
    "        shapes=torch.tensor(shapes), D=D, _skip_K_calc=True, _skip_gs_calc=True\n",
    "    )\n",
    "    Phi_n = scaffold.gbook()\n",
    "    # print((Phi_n.conj().T @ Phi_n).abs())\n",
    "\n",
    "    Q_n = gen_Q_gaussian(n, N_patts, 1)\n",
    "    H_noiseless = Phi_n @ Q_n.T\n",
    "\n",
    "    print(\"Attempting to calculate the inverse of H_n H_n*...\")\n",
    "    matrix_to_invert = H_noiseless @ H_noiseless.T.conj()\n",
    "    try:\n",
    "        torch.linalg.inv(matrix_to_invert)\n",
    "        print(\"Inverse calculation SUCCEEDED. This is expected if n >= D.\")\n",
    "    except torch.linalg.LinAlgError:\n",
    "        print(\n",
    "            \"Inverse calculation FAILED. This confirms the theoretical result that H_n H_n* is non-invertible when n < D.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    eigvals_noiseless = torch.linalg.eigvalsh(matrix_to_invert).flip(0)[:n]\n",
    "    print(eigvals_noiseless)\n",
    "    lower_bound_noiseless = max(1 - (n - 1) * epsilon, 0)\n",
    "    upper_bound_noiseless = 1 + (n - 1) * epsilon\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(eigvals_noiseless, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    # plt.axvline(\n",
    "    #     lower_bound_noiseless,\n",
    "    #     color=\"red\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     label=\"Theoretical Lower Bound\",\n",
    "    # )\n",
    "    # plt.axvline(\n",
    "    #     upper_bound_noiseless,\n",
    "    #     color=\"red\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     label=\"Theoretical Upper Bound\",\n",
    "    # )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noiseless $H_nH_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    delta_H = torch.randn(D, n)\n",
    "\n",
    "    norm_bound = math.sqrt(n * epsilon * omega)\n",
    "    if torch.linalg.norm(delta_H, \"fro\") > 0:\n",
    "        delta_H = delta_H / torch.linalg.norm(delta_H, \"fro\") * norm_bound\n",
    "\n",
    "    H_noisy = H_noiseless + delta_H\n",
    "\n",
    "    matrix_to_invert_noisy = H_noisy @ H_noisy.T.conj()\n",
    "    eigvals_noisy = torch.linalg.eigvalsh(matrix_to_invert_noisy).flip(0)[:n]\n",
    "    print(eigvals_noisy)\n",
    "    lower_bound_noisy = max(1 - (n - 1) * epsilon - math.sqrt(n) * epsilon * omega, 0)\n",
    "    upper_bound_noisy = 1 + (n - 1) * epsilon + math.sqrt(n) * epsilon * omega\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(eigvals_noisy, bins=20, color=\"lightgreen\", edgecolor=\"black\")\n",
    "    # plt.axvline(\n",
    "    #     lower_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Lower Bound\"\n",
    "    # )\n",
    "    # plt.axvline(\n",
    "    #     upper_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Upper Bound\"\n",
    "    # )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noisy $\\\\tilde{H}_n\\\\tilde{H}_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(matrix_to_invert @ matrix_to_invert.pinverse())\n",
    "    print(matrix_to_invert_noisy @ matrix_to_invert_noisy.pinverse())\n",
    "\n",
    "def verify_frame_properties_gaussian_regularized(D, n, epsilon, omega, N_patts, llambda):\n",
    "    print(\n",
    "        f\"Verifying with D={D}, n={n}, epsilon={epsilon}, omega={omega}, N_patts={N_patts}\"\n",
    "    )\n",
    "    if n >= D:\n",
    "        print(\n",
    "            \"Note: The inverse failure is expected when n < D. The current configuration (n >= D) may result in a successful inverse calculation.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    scaffold = FourierScaffold(\n",
    "        shapes=torch.tensor(shapes), D=D, _skip_K_calc=True, _skip_gs_calc=True\n",
    "    )\n",
    "    Phi_n = scaffold.gbook()\n",
    "    # print((Phi_n.conj().T @ Phi_n).abs())\n",
    "\n",
    "    Q_n = gen_Q_gaussian(n, N_patts, 1)\n",
    "    H_noiseless = Phi_n @ Q_n.T\n",
    "\n",
    "    print(\"Attempting to calculate the inverse of H_n H_n*...\")\n",
    "    matrix_to_invert = H_noiseless @ H_noiseless.T.conj() + llambda * torch.complex(\n",
    "        torch.eye(D), torch.zeros(D, D)\n",
    "    )\n",
    "    try:\n",
    "        torch.linalg.inv(matrix_to_invert)\n",
    "        print(\"Inverse calculation SUCCEEDED. This is expected if n >= D.\")\n",
    "    except torch.linalg.LinAlgError:\n",
    "        print(\n",
    "            \"Inverse calculation FAILED. This confirms the theoretical result that H_n H_n* is non-invertible when n < D.\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    eigvals_noiseless = torch.linalg.eigvalsh(matrix_to_invert).flip(0)[:n]\n",
    "    print(eigvals_noiseless)\n",
    "    lower_bound_noiseless = max(1 - (n - 1) * epsilon, 0)\n",
    "    upper_bound_noiseless = 1 + (n - 1) * epsilon\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(eigvals_noiseless, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    # plt.axvline(\n",
    "    #     lower_bound_noiseless,\n",
    "    #     color=\"red\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     label=\"Theoretical Lower Bound\",\n",
    "    # )\n",
    "    # plt.axvline(\n",
    "    #     upper_bound_noiseless,\n",
    "    #     color=\"red\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     label=\"Theoretical Upper Bound\",\n",
    "    # )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noiseless $H_nH_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    delta_H = torch.randn(D, n)\n",
    "\n",
    "    norm_bound = math.sqrt(n * epsilon * omega)\n",
    "    if torch.linalg.norm(delta_H, \"fro\") > 0:\n",
    "        delta_H = delta_H / torch.linalg.norm(delta_H, \"fro\") * norm_bound\n",
    "\n",
    "    H_noisy = H_noiseless + delta_H\n",
    "\n",
    "    matrix_to_invert_noisy = H_noisy @ H_noisy.T.conj() + llambda * torch.complex(\n",
    "        torch.eye(D), torch.zeros(D, D)\n",
    "    )\n",
    "\n",
    "    eigvals_noisy = torch.linalg.eigvalsh(matrix_to_invert_noisy).flip(0)[:n]\n",
    "    print(eigvals_noisy)\n",
    "    lower_bound_noisy = max(1 - (n - 1) * epsilon - math.sqrt(n) * epsilon * omega, 0)\n",
    "    upper_bound_noisy = 1 + (n - 1) * epsilon + math.sqrt(n) * epsilon * omega\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(eigvals_noisy, bins=20, color=\"lightgreen\", edgecolor=\"black\")\n",
    "    # plt.axvline(\n",
    "    #     lower_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Lower Bound\"\n",
    "    # )\n",
    "    # plt.axvline(\n",
    "    #     upper_bound_noisy, color=\"blue\", linestyle=\"--\", label=\"Theoretical Upper Bound\"\n",
    "    # )\n",
    "    plt.title(\"Eigenvalue Spectrum of Noisy $\\\\tilde{H}_n\\\\tilde{H}_n^*$\")\n",
    "    plt.xlabel(\"Eigenvalue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(matrix_to_invert @ matrix_to_invert.pinverse())\n",
    "    print(matrix_to_invert_noisy @ matrix_to_invert_noisy.pinverse())\n",
    "\n",
    "\n",
    "# Run the verification with example parameters\n",
    "# D > n is required for inverse failure.\n",
    "D = 2000  # Dimension of vectors g(k)\n",
    "n = 50  # Number of patterns, n < D\n",
    "delta = 1 - 0.01\n",
    "epsilon = math.sqrt(\n",
    "    (2 / D) * math.log(2 / delta)\n",
    ")  # Small quasi-orthogonality perturbation\n",
    "Npatts = torch.prod(torch.tensor(shapes))\n",
    "omega = epsilon * Npatts  # A constant for the noise bound\n",
    "\n",
    "verify_frame_properties_gaussian(D, n, epsilon, omega, Npatts.item())\n",
    "verify_frame_properties_gaussian_regularized(D, n, epsilon, omega, Npatts.item(), llambda=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c20cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
