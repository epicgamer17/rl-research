{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23283d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6621a5e",
   "metadata": {},
   "source": [
    "Test N_h needed to achieve max capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matrix_initializers import SparseMatrixInitializer\n",
    "from clean_scaffold import GridHippocampalScaffold\n",
    "from vectorhash import build_initializer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cfb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_pcont(pflip, ptrue):\n",
    "    if pflip == 0:\n",
    "        return ptrue\n",
    "    pinit = ptrue + pflip * torch.randn(*ptrue.shape)\n",
    "    return pinit\n",
    "\n",
    "\n",
    "def test_model_capacity(\n",
    "    grid_scaffold: GridHippocampalScaffold,\n",
    "    initializer: SparseMatrixInitializer,\n",
    "    Npatts_list,\n",
    "    nruns,\n",
    "    pflip,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a tuple: `(err_gcpc, num_correct)`, with shapes `(len(Npatts_list), nruns)`\n",
    "    \"\"\"\n",
    "    err_gcpc = -1 * torch.ones(len(Npatts_list), nruns)\n",
    "    num_correct = -1 * torch.ones(len(Npatts_list), nruns)\n",
    "    k = 0\n",
    "    for Npatts in tqdm(Npatts_list):\n",
    "        scores = torch.zeros((nruns, Npatts))\n",
    "        for i in range(nruns):\n",
    "            # train scaffold\n",
    "            grid_scaffold.W_hg = initializer(grid_scaffold.W_hg.shape)\n",
    "            grid_scaffold.H = grid_scaffold.hippocampal_from_grid(grid_scaffold.G)\n",
    "            grid_scaffold.W_gh = grid_scaffold._W_gh(\n",
    "                noisy=True,\n",
    "                noisy_std=pflip,\n",
    "                Npatts=Npatts,\n",
    "            )\n",
    "\n",
    "            test_patts = torch.arange(Npatts)\n",
    "\n",
    "            # Testing\n",
    "            ptrue = grid_scaffold.H[test_patts]  # (len(test_patts), N_h))\n",
    "            p_noisy = corrupt_pcont(pflip, ptrue)\n",
    "            p_recovered = grid_scaffold.hippocampal_from_grid(\n",
    "                grid_scaffold.get_onehot(\n",
    "                    grid_scaffold.grid_from_hippocampal(p_noisy)[0]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            score = (\n",
    "                torch.linalg.vector_norm(ptrue - p_recovered, dim=1) / grid_scaffold.N_h\n",
    "            )  # (Npatts, N_h) -> (Npatts)\n",
    "            scores[i] = score\n",
    "\n",
    "            # print(cleanup_vectorized.shape)\n",
    "\n",
    "        err_gcpc[k] = torch.mean(scores)\n",
    "        num_correct[k] = torch.sum((scores < 0.01).int())\n",
    "        k += 1\n",
    "    return err_gcpc, num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8543e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(ax, title, xlabel, ylabel):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    # ax.legend(loc=\"best\")\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "import matplotlib\n",
    "def color_interp(c1,c2,n): \n",
    "    c1=np.array(matplotlib.colors.to_rgb(c1))\n",
    "    c2=np.array(matplotlib.colors.to_rgb(c2))\n",
    "    return [matplotlib.colors.to_hex((1-mix)*c1 + mix*c2) for mix in np.arange(0, 1, 1/n)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb99e4",
   "metadata": {},
   "source": [
    "2d vs 3d capactiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_configurations = [\n",
    "    [(3, 3, 3), (4, 4, 4)],\n",
    "    [(5, 5), (9, 9)],\n",
    "]\n",
    "\n",
    "Npatts_list = torch.arange(100, 1800, 400)\n",
    "N_h_list = torch.arange(100, 2000, 50)\n",
    "percent_nonzero_relu = 0.2\n",
    "nruns = 2\n",
    "relu = True\n",
    "\n",
    "print(f\"Npatts_list: {Npatts_list}\")\n",
    "print(f\"N_h_list: {N_h_list}\")\n",
    "\n",
    "err_gcpc = -1 * torch.ones(\n",
    "    len(shape_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "num_correct = -1 * torch.ones(\n",
    "    len(shape_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "\n",
    "for k, shape in enumerate(shape_configurations):\n",
    "    print(shape)\n",
    "    for i, N_h in enumerate(N_h_list):\n",
    "        print(f\"Testing N_h={N_h}\")\n",
    "        initializer, relu_theta, _ = build_initializer(\n",
    "            shape, \"by_sparsity\", percent_nonzero_relu=percent_nonzero_relu, device=device\n",
    "        )\n",
    "        gs = GridHippocampalScaffold(\n",
    "            shapes=shape,\n",
    "            N_h=N_h,\n",
    "            sparse_matrix_initializer=initializer,\n",
    "            relu_theta=relu_theta,\n",
    "            sanity_check=False,\n",
    "            device=device,\n",
    "            relu=relu,\n",
    "        )\n",
    "        err, n_correct = test_model_capacity(gs, initializer, Npatts_list, nruns, 0)\n",
    "        print(f\"corrent: {n_correct}, err: {err}\")\n",
    "        err_gcpc[k, i] = err\n",
    "        num_correct[k, i] = n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_gcpc = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# num_correct = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# plot err vs stuff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,9))\n",
    "for k, shape_config in enumerate(shape_configurations):\n",
    "\n",
    "    if k == 0:\n",
    "        colors = color_interp(\"#00FFFF\", \"#0000FF\", len(Npatts_list))\n",
    "    else:\n",
    "        colors = color_interp(\"#FF00FF\", \"#FF0000\", len(Npatts_list))\n",
    "    for p, N_p in enumerate(Npatts_list):\n",
    "        avg_err = np.mean(err_gcpc[k, :, p].numpy(), axis=-1)  # mean error over runs\n",
    "        std_err = np.std(err_gcpc[k, :, p].numpy(), axis=-1)  # std dev over runs\n",
    "\n",
    "        # if k==0:\n",
    "        #     color='red'\n",
    "        # else:\n",
    "        #     color='blue'\n",
    "        ax.errorbar(N_h_list, avg_err, yerr=std_err, fmt=\"o--\", color=colors[p], label=f\"error N_patts={N_p}, shape_config={shape_config}\")\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"percent_nonzero_relu={percent_nonzero_relu}\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"average absolute hippocampal error |h_true - h_recovered| / N_h\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657882a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('scaffold_result_2d_vs_3d_err.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errthresh = 0.02  # Some tiny nonzero value above possible floating point error\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for k, shape_config in enumerate(shape_configurations):\n",
    "    if k == 0: max_capacity=1728 \n",
    "    else: max_capacity=2025\n",
    "    capacity = -1 * np.ones((len(N_h_list), nruns))\n",
    "    valid = err_gcpc[k] <= errthresh  # bool\n",
    "\n",
    "    if k ==0:\n",
    "        color='r'\n",
    "    else:\n",
    "        color='b'\n",
    "\n",
    "    for N_h in range(len(N_h_list)):\n",
    "        # Original conservative\n",
    "        for r in range(nruns):\n",
    "            lst = torch.argwhere(valid[N_h, :, r] == False)\n",
    "            # lst = np.argwhere(valid[Np,:] == False)\n",
    "            if len(lst) == 0:\n",
    "                # print(\"full capacity\")\n",
    "                capacity[N_h, r] = 1\n",
    "            else:\n",
    "                bef_err = lst[0] - 1\n",
    "                bef_err = bef_err * (bef_err > 0)  # Don't want to return -1 if lst[0]=0\n",
    "                capacity[N_h, r] = Npatts_list[bef_err[0]] / max_capacity\n",
    "\n",
    "    avg_cap = np.mean(capacity, axis=1)  # mean error over runs\n",
    "    # std_cap = stats.sem(capacity, axis=1)    # std dev over runs\n",
    "    std_cap = np.std(capacity, axis=1)  # std dev over runs\n",
    "\n",
    "\n",
    "    ax.errorbar(N_h_list, avg_cap, yerr=std_cap, fmt=\"ko--\", color=color, label=f\"2D grid code network shape_config={shape_config}\")\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"percent_nonzero_relu={percent_nonzero_relu}; errthresh={errthresh};\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"percentage of patterns (out of number of patterns) correctly recovered\",\n",
    ")\n",
    "# savefig(fig, ax, f\"{results_dir}/{filename}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('scaffold_result_2d_vs_3d_capacity.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e35eb",
   "metadata": {},
   "source": [
    "Test sparsity methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4eed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 2\n",
    "\n",
    "shapes = [(3, 3, 3), (4, 4, 4)]\n",
    "max_p = torch.prod(torch.tensor(shapes)).item()\n",
    "\n",
    "Npatts_list = torch.arange(100, max_p, max((max_p - 100) // 4, 100))\n",
    "N_h_list = torch.arange(400, 2000, 400)\n",
    "sparsity_configurations = [\"by_scaling\", \"by_sparsity\"]\n",
    "percent_nonzero_relu = 0.2\n",
    "relu = True\n",
    "\n",
    "print(f\"Npatts_list: {Npatts_list}\")\n",
    "print(f\"N_h_list: {N_h_list}\")\n",
    "\n",
    "err_gcpc = -1 * torch.ones(\n",
    "    len(sparsity_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "num_correct = -1 * torch.ones(\n",
    "    len(sparsity_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "\n",
    "for k, sparsity_config in enumerate(sparsity_configurations):\n",
    "    for i, N_h in enumerate(N_h_list):\n",
    "        print(f\"Testing N_h={N_h}\")\n",
    "        initializer, relu_theta, _ = build_initializer(\n",
    "            shapes=shapes,\n",
    "            initalization_method=sparsity_config,\n",
    "            percent_nonzero_relu=percent_nonzero_relu,\n",
    "            device=device,\n",
    "        )\n",
    "        gs = GridHippocampalScaffold(\n",
    "            shapes=shapes,\n",
    "            N_h=N_h,\n",
    "            sparse_matrix_initializer=initializer,\n",
    "            relu_theta=relu_theta,\n",
    "            sanity_check=False,\n",
    "            device=device,\n",
    "            relu=relu,\n",
    "        )\n",
    "        err, n_correct = test_model_capacity(gs, initializer, Npatts_list, nruns, 0)\n",
    "        print(f\"corrent: {n_correct}, err: {err}\")\n",
    "        err_gcpc[k, i] = err\n",
    "        num_correct[k, i] = n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e410390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_gcpc = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# num_correct = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# plot err vs stuff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for k, sparsity_config in enumerate(sparsity_configurations):\n",
    "    if k == 0:\n",
    "        colors = color_interp(\"#00FFFF\", \"#0000FF\", len(Npatts_list))\n",
    "    else:\n",
    "        colors = color_interp(\"#FF00FF\", \"#FF0000\", len(Npatts_list))\n",
    "\n",
    "    for p, N_p in enumerate(Npatts_list):\n",
    "        avg_err = np.mean(err_gcpc[k, :, p].numpy(), axis=-1)  # mean error over runs\n",
    "        std_err = np.std(err_gcpc[k, :, p].numpy(), axis=-1)  # std dev over runs\n",
    "\n",
    "        if k == 0:\n",
    "            color = \"red\"\n",
    "        else:\n",
    "            color = \"blue\"\n",
    "        ax.errorbar(\n",
    "            N_h_list,\n",
    "            avg_err,\n",
    "            yerr=std_err,\n",
    "            fmt=\"ko--\",\n",
    "            color=colors[p],\n",
    "            label=f\"error N_patts={N_p}, sparsity_method={sparsity_config}\",\n",
    "        )\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"percent_nonzero_relu={percent_nonzero_relu}, shapes={shapes}\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"average absolute hippocampal error |h_true - h_recovered| / N_h\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"scaffold_sparsity_vs_scaling_init_err.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ea8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "errthresh = 0.025  # Some tiny nonzero value above possible floating point error\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for k, sparsity_config in enumerate(sparsity_configurations):\n",
    "    capacity = -1 * np.ones((len(N_h_list), nruns))\n",
    "    valid = err_gcpc[k] <= errthresh  # bool\n",
    "\n",
    "    for N_h in range(len(N_h_list)):\n",
    "        # Original conservative\n",
    "        for r in range(nruns):\n",
    "            lst = torch.argwhere(valid[N_h, :, r] == False)\n",
    "            # lst = np.argwhere(valid[Np,:] == False)\n",
    "            if len(lst) == 0:\n",
    "                # print(\"full capacity\")\n",
    "                capacity[N_h, r] = 3**3 * 4**3\n",
    "            else:\n",
    "                bef_err = lst[0] - 1\n",
    "                bef_err = bef_err * (bef_err > 0)  # Don't want to return -1 if lst[0]=0\n",
    "                capacity[N_h, r] = Npatts_list[bef_err[0]]\n",
    "\n",
    "    avg_cap = np.mean(capacity, axis=1)  # mean error over runs\n",
    "    # std_cap = stats.sem(capacity, axis=1)    # std dev over runs\n",
    "    std_cap = np.std(capacity, axis=1)  # std dev over runs\n",
    "\n",
    "    ax.errorbar(\n",
    "        N_h_list,\n",
    "        avg_cap,\n",
    "        yerr=std_cap,\n",
    "        fmt=\"ko--\",\n",
    "        label=f\"2D grid code network sparsity_method={sparsity_config}\",\n",
    "    )\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"Grid cells={50}; Grid periods={[3,4,5]}; errthresh={errthresh};\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"number of patterns\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e22a7",
   "metadata": {},
   "source": [
    "Test sparsity effect on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes= [(3, 3, 3), (4, 4, 4)]\n",
    "Npatts_list = torch.arange(100, 1800, 400)\n",
    "N_h_list = torch.arange(100, 2000, 500)\n",
    "percent_nonzero_relus = [0.2, 0.4, 0.6, 0.8]\n",
    "nruns = 2\n",
    "relu = True\n",
    "\n",
    "print(f\"Npatts_list: {Npatts_list}\")\n",
    "print(f\"N_h_list: {N_h_list}\")\n",
    "\n",
    "err_gcpc = -1 * torch.ones(\n",
    "    len(percent_nonzero_relus), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "num_correct = -1 * torch.ones(\n",
    "    len(percent_nonzero_relus), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "\n",
    "for k, percent_nonzero_relu in enumerate(percent_nonzero_relus):\n",
    "    for i, N_h in enumerate(N_h_list):\n",
    "        print(f\"Testing percent_nonzero_relu={percent_nonzero_relu}\")\n",
    "        initializer, relu_theta, _ = build_initializer(\n",
    "            shape, \"by_sparsity\", percent_nonzero_relu=percent_nonzero_relu, device=device\n",
    "        )\n",
    "        gs = GridHippocampalScaffold(\n",
    "            shapes=shape,\n",
    "            N_h=N_h,\n",
    "            sparse_matrix_initializer=initializer,\n",
    "            relu_theta=relu_theta,\n",
    "            sanity_check=False,\n",
    "            device=device,\n",
    "            relu=relu,\n",
    "        )\n",
    "        err, n_correct = test_model_capacity(gs, initializer, Npatts_list, nruns, 0)\n",
    "        print(f\"corrent: {n_correct}, err: {err}\")\n",
    "        err_gcpc[k, i] = err\n",
    "        num_correct[k, i] = n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a84ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_gcpc = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# num_correct = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# plot err vs stuff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for k, percent_nonzero_relu in enumerate(percent_nonzero_relus):\n",
    "    if k == 0:\n",
    "        colors = color_interp(\"#00FFFF\", \"#0000FF\", len(Npatts_list))\n",
    "    else:\n",
    "        colors = color_interp(\"#FF00FF\", \"#FF0000\", len(Npatts_list))\n",
    "\n",
    "    for p, N_p in enumerate(Npatts_list):\n",
    "        avg_err = np.mean(err_gcpc[k, :, p].numpy(), axis=-1)  # mean error over runs\n",
    "        std_err = np.std(err_gcpc[k, :, p].numpy(), axis=-1)  # std dev over runs\n",
    "\n",
    "        if k == 0:\n",
    "            color = \"red\"\n",
    "        else:\n",
    "            color = \"blue\"\n",
    "        ax.errorbar(\n",
    "            N_h_list,\n",
    "            avg_err,\n",
    "            yerr=std_err,\n",
    "            fmt=\"ko--\",\n",
    "            color=colors[p],\n",
    "            label=f\"error N_patts={N_p}, target_h_sparsity={percent_nonzero_relu}\",\n",
    "        )\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"sparsity method=by_sparsity; shapes={shapes}\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"average absolute hippocampal error |h_true - h_recovered| / N_h\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('scaffold_result_varying_sparsity_err.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cba88",
   "metadata": {},
   "source": [
    "N_h scales with num modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e645635",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_configurations = [\n",
    "    [(12,12,12),],\n",
    "    [(3,3,3),(4,4,4)],\n",
    "    [(2,2,2),(3,3,3),(9,1,1)],\n",
    "]\n",
    "\n",
    "Npatts_list = torch.arange(100, 1700, 50)\n",
    "N_h_list = torch.arange(100, 1000, 200)\n",
    "percent_nonzero_relu = 0.2\n",
    "nruns = 2\n",
    "relu = True\n",
    "\n",
    "print(f\"Npatts_list: {Npatts_list}\")\n",
    "print(f\"N_h_list: {N_h_list}\")\n",
    "\n",
    "err_gcpc = -1 * torch.ones(\n",
    "    len(shape_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "num_correct = -1 * torch.ones(\n",
    "    len(shape_configurations), len(N_h_list), len(Npatts_list), nruns\n",
    ")\n",
    "\n",
    "for k, shape in enumerate(shape_configurations):\n",
    "    print(shape)\n",
    "    for i, N_h in enumerate(N_h_list):\n",
    "        print(f\"Testing N_h={N_h}\")\n",
    "        initializer, relu_theta, _ = build_initializer(\n",
    "            shape, \"by_sparsity\", percent_nonzero_relu=percent_nonzero_relu, device=device\n",
    "        )\n",
    "        gs = GridHippocampalScaffold(\n",
    "            shapes=shape,\n",
    "            N_h=N_h,\n",
    "            sparse_matrix_initializer=initializer,\n",
    "            relu_theta=relu_theta,\n",
    "            sanity_check=False,\n",
    "            device=device,\n",
    "            relu=relu,\n",
    "        )\n",
    "        err, n_correct = test_model_capacity(gs, initializer, Npatts_list, nruns, 0)\n",
    "        print(f\"corrent: {n_correct}, err: {err}\")\n",
    "        err_gcpc[k, i] = err\n",
    "        num_correct[k, i] = n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_gcpc = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# num_correct = -1 * torch.ones(len(sparsity_methods), len(N_h_list), len(Npatts_list), nruns)\n",
    "# plot err vs stuff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,9))\n",
    "for k, shape_config in enumerate(shape_configurations):\n",
    "\n",
    "    if k == 0:\n",
    "        color = 'red'\n",
    "    elif k==1:\n",
    "        color = 'b'\n",
    "    else:\n",
    "        color='g'\n",
    "    for p, N_p in enumerate(Npatts_list):\n",
    "        avg_err = np.mean(err_gcpc[k, :, p].numpy(), axis=-1)  # mean error over runs\n",
    "        std_err = np.std(err_gcpc[k, :, p].numpy(), axis=-1)  # std dev over runs\n",
    "\n",
    "        # if k==0:\n",
    "        #     color='red'\n",
    "        # else:\n",
    "        #     color='blue'\n",
    "        ax.errorbar(N_h_list, avg_err, yerr=std_err, fmt=\"o--\", color=color, label=f\"shape_config={shape_config}\" if p == 0 else None)\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"percent_nonzero_relu={percent_nonzero_relu}; sparsity_method=by_sparsity\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"average absolute hippocampal error |h_true - h_recovered| / N_h\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('scaffold_result_num_modules_err.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "errthresh = 0.03  # Some tiny nonzero value above possible floating point error\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for k, shape_config in enumerate(shape_configurations):\n",
    "    if k == 0: max_capacity=1728 \n",
    "    else: max_capacity=2025\n",
    "    capacity = -1 * np.ones((len(N_h_list), nruns))\n",
    "    valid = err_gcpc[k] <= errthresh  # bool\n",
    "\n",
    "    if k ==0:\n",
    "        color='r'\n",
    "    else:\n",
    "        color='b'\n",
    "\n",
    "    for N_h in range(len(N_h_list)):\n",
    "        # Original conservative\n",
    "        for r in range(nruns):\n",
    "            lst = torch.argwhere(valid[N_h, :, r] == False)\n",
    "            # lst = np.argwhere(valid[Np,:] == False)\n",
    "            if len(lst) == 0:\n",
    "                # print(\"full capacity\")\n",
    "                capacity[N_h, r] = 1\n",
    "            else:\n",
    "                bef_err = lst[0] - 1\n",
    "                bef_err = bef_err * (bef_err > 0)  # Don't want to return -1 if lst[0]=0\n",
    "                capacity[N_h, r] = Npatts_list[bef_err[0]] / max_capacity\n",
    "\n",
    "    avg_cap = np.mean(capacity, axis=1)  # mean error over runs\n",
    "    # std_cap = stats.sem(capacity, axis=1)    # std dev over runs\n",
    "    std_cap = np.std(capacity, axis=1)  # std dev over runs\n",
    "\n",
    "\n",
    "    ax.errorbar(N_h_list, avg_cap, yerr=std_cap, fmt=\"ko--\", color=color, label=f\"2D grid code network shape_config={shape_config}\")\n",
    "add_labels(\n",
    "    ax,\n",
    "    f\"percent_nonzero_relu={percent_nonzero_relu}; errthresh={errthresh}; sparsity_method=by_sparsity\",\n",
    "    \"number of hippocampal cells\",\n",
    "    \"percentage of patterns (out of number of patterns) correctly recovered\",\n",
    ")\n",
    "# savefig(fig, ax, f\"{results_dir}/{filename}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('scaffold_result_num_modules_capacity.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
