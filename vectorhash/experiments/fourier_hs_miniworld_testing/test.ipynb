{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4691ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from hippocampal_sensory_layers import ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars\n",
    "from fourier_scaffold import FourierScaffold\n",
    "from preprocessing_cnn import RescalePreprocessing, SequentialPreprocessing, GrayscaleAndFlattenPreprocessing\n",
    "from experiments.fourier_miniworld_gridsearch.room_env import RoomExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a47c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 400\n",
    "shapes_primes = [(3,), (5,)]\n",
    "shapes_nonprimes = [((3,), (7,), (9,))]\n",
    "device = \"cuda\"\n",
    "\n",
    "scaffold_primes = FourierScaffold(\n",
    "    shapes=torch.tensor(shapes_primes), D=D, device=device, _skip_K_calc=True\n",
    ")\n",
    "scaffold_nonprimes = FourierScaffold(\n",
    "    shapes=torch.tensor(shapes_nonprimes), D=D, device=device, _skip_K_calc=True\n",
    ")\n",
    "env = RoomExperiment([3, 0, 3], 0, True, True)\n",
    "preprocessing = SequentialPreprocessing(\n",
    "    [RescalePreprocessing(0.5), GrayscaleAndFlattenPreprocessing(device=device)]\n",
    ")\n",
    "\n",
    "# output_shape = (60,80) # 1\n",
    "output_shape = (10, 10)  # 0.5\n",
    "# output_shape = (15, 20)  # 0.25\n",
    "\n",
    "Npatts = 20\n",
    "N_s = 100  # np.prod(output_shape)\n",
    "sbook = torch.sign(torch.randn(Npatts, N_s, device=device))\n",
    "print(f\"N_s: {N_s}\")\n",
    "layer_primes = (\n",
    "    ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "        input_size=N_s,\n",
    "        N_h=D,\n",
    "        hidden_layer_factor=0,\n",
    "        epsilon_hs=0.1,\n",
    "        epsilon_sh=0.1,\n",
    "        device=device,\n",
    "    )\n",
    ")\n",
    "layer_nonprimes = (\n",
    "    ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "        input_size=N_s,\n",
    "        N_h=D,\n",
    "        hidden_layer_factor=0,\n",
    "        epsilon_hs=0.1,\n",
    "        epsilon_sh=0.1,\n",
    "        device=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from graph_utils import plot_imgs_side_by_side\n",
    "\n",
    "NONE = 3\n",
    "FORWARD = 2\n",
    "RIGHT = 1\n",
    "LEFT = 0\n",
    "\n",
    "\n",
    "def primes_P_from_s(img):\n",
    "    g_avg = layer_primes.hippocampal_from_sensory(img)[0]  # (N_h)\n",
    "    P = torch.outer(g_avg, g_avg.conj())\n",
    "    return P\n",
    "\n",
    "\n",
    "def primes_s_from_P(P):\n",
    "    g_avg = P @ scaffold_primes.g_s\n",
    "    s = layer_primes.sensory_from_hippocampal(g_avg)\n",
    "    return s\n",
    "\n",
    "def nonprimes_P_from_s(img):\n",
    "    g_avg = layer_nonprimes.hippocampal_from_sensory(img)[0]  # (N_h)\n",
    "    P = torch.outer(g_avg, g_avg.conj())\n",
    "    return P\n",
    "\n",
    "\n",
    "def nonprimes_s_from_P(P):\n",
    "    g_avg = P @ scaffold_nonprimes.g_s\n",
    "    s = layer_nonprimes.sensory_from_hippocampal(g_avg)\n",
    "    return s\n",
    "\n",
    "\n",
    "def similarity(P1, P2):\n",
    "    return (P1 * P2).sum().abs() / (P1.norm() * P2.norm())\n",
    "\n",
    "\n",
    "def similarity_batch(P1s, P2s):\n",
    "    P1s = P1s.flatten(1)\n",
    "    P2s = P1s.flatten(1)\n",
    "    return (P1s * P2s).sum(dim=1).abs() / (P1s.norm(dim=1) * P2s.norm(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe14df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no smoothing test\n",
    "first_img = sbook[0] #preprocessing.encode(obs)\n",
    "first_P = scaffold_primes.P.clone()\n",
    "layer_primes.learn(scaffold_primes.g_avg(), first_img)\n",
    "layer_nonprimes.learn(scaffold_nonprimes.g_avg(), first_img)\n",
    "\n",
    "N = 10\n",
    "primes_results_first_P = torch.zeros(N)\n",
    "primes_results_recent_P = torch.zeros(N)\n",
    "\n",
    "primes_recent_imgs_true = torch.zeros(N, N_s)\n",
    "primes_recent_imgs_recovered = torch.zeros(N, N_s)\n",
    "primes_first_imgs_recovered = torch.zeros(N, N_s)\n",
    "\n",
    "primes_recovered_recent_P_Hs = torch.zeros(N)\n",
    "primes_recovered_first_P_Hs = torch.zeros(N)\n",
    "\n",
    "nonprimes_results_first_P = torch.zeros(N)\n",
    "nonprimes_results_recent_P = torch.zeros(N)\n",
    "\n",
    "nonprimes_recent_imgs_true = torch.zeros(N, N_s)\n",
    "nonprimes_recent_imgs_recovered = torch.zeros(N, N_s)\n",
    "nonprimes_first_imgs_recovered = torch.zeros(N, N_s)\n",
    "\n",
    "nonprimes_recovered_recent_P_Hs = torch.zeros(N)\n",
    "nonprimes_recovered_first_P_Hs = torch.zeros(N)\n",
    "\n",
    "# 1. store image\n",
    "# 2. calculate s->P->s for first image\n",
    "# 2. calculate s->P->s for new image\n",
    "\n",
    "for j in range(N):\n",
    "    img = sbook[j]  # preprocessing.encode(obs)\n",
    "\n",
    "    layer_primes.learn(scaffold_primes.g_avg(), img)\n",
    "    layer_nonprimes.learn(scaffold_nonprimes.g_avg(), img)\n",
    "\n",
    "    primes_results_first_P[j] = similarity(first_P, primes_P_from_s(first_img))\n",
    "    primes_results_recent_P[j] = similarity(scaffold_primes.P, primes_P_from_s(img))\n",
    "    primes_first_imgs_recovered[j] = primes_s_from_P(primes_P_from_s(first_img))\n",
    "    primes_recent_imgs_true[j] = img\n",
    "    primes_recent_imgs_recovered[j] = primes_s_from_P(primes_P_from_s(img))\n",
    "    nonprimes_results_first_P[j] = similarity(first_P, nonprimes_P_from_s(first_img))\n",
    "    nonprimes_results_recent_P[j] = similarity(\n",
    "        scaffold_nonprimes.P, nonprimes_P_from_s(img)\n",
    "    )\n",
    "    nonprimes_first_imgs_recovered[j] = nonprimes_s_from_P(\n",
    "        nonprimes_P_from_s(first_img)\n",
    "    )\n",
    "    nonprimes_recent_imgs_true[j] = img\n",
    "    nonprimes_recent_imgs_recovered[j] = nonprimes_s_from_P(nonprimes_P_from_s(img))\n",
    "    # print(env.agent.pos)\n",
    "\n",
    "    primes_recovered_recent_P_Hs[j] = primes_P_from_s(img).norm() ** 2\n",
    "    primes_recovered_first_P_Hs[j] = primes_P_from_s(first_img).norm() ** 2\n",
    "    scaffold_primes.velocity_shift(torch.tensor([1]))\n",
    "    nonprimes_recovered_recent_P_Hs[j] = nonprimes_P_from_s(img).norm() ** 2\n",
    "    nonprimes_recovered_first_P_Hs[j] = nonprimes_P_from_s(first_img).norm() ** 2\n",
    "    scaffold_nonprimes.velocity_shift(torch.tensor([1]))\n",
    "\n",
    "print(primes_results_first_P)\n",
    "print(primes_results_recent_P)\n",
    "print(primes_recovered_recent_P_Hs)\n",
    "print(primes_recovered_first_P_Hs)\n",
    "print(nonprimes_results_first_P)\n",
    "print(nonprimes_results_recent_P)\n",
    "print(nonprimes_recovered_recent_P_Hs)\n",
    "print(nonprimes_recovered_first_P_Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=N, ncols=3, figsize=(10, 30))\n",
    "\n",
    "for j in range(N):\n",
    "    plot_imgs_side_by_side(\n",
    "        axs=axes[j],\n",
    "        imgs=[\n",
    "            primes_recent_imgs_true[j].cpu().resize(*output_shape),\n",
    "            nonprimes_recent_imgs_recovered[j].cpu().resize(*output_shape),\n",
    "            primes_recent_imgs_recovered[j].cpu().resize(*output_shape),\n",
    "        ],\n",
    "        titles=[\"original\", \"recovered nonprimes\", \"recovered primes\"],\n",
    "        use_first_img_scale=False,\n",
    "        fig=fig,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=N, ncols=3, figsize=(10, 30))\n",
    "\n",
    "for j in range(N):\n",
    "    plot_imgs_side_by_side(\n",
    "        axs=axes[j],\n",
    "        imgs=[\n",
    "            first_img.cpu().resize(*output_shape),\n",
    "            nonprimes_first_imgs_recovered[j].cpu().resize(*output_shape),\n",
    "            primes_first_imgs_recovered[j].cpu().resize(*output_shape),\n",
    "        ],\n",
    "        titles=[\"original\", \"nonprime recovered\", \"prime recovered\"],\n",
    "        use_first_img_scale=False,\n",
    "        fig=fig,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084d010",
   "metadata": {},
   "source": [
    "# Entropy calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0321b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "N = 1000\n",
    "D = 200\n",
    "N_s = 100\n",
    "shapes_primes = [(3,), (5,), (7,), (11,)]\n",
    "dim_sizes = np.prod(shapes_primes, axis=0)\n",
    "combinations = [np.arange(dim_sizes[i]) for i in range(len(shapes_primes[0]))]\n",
    "\n",
    "H = 0\n",
    "j = 0\n",
    "for k_tuple in itertools.product(*combinations):\n",
    "    for d, k_d in enumerate(k_tuple):\n",
    "        for i, m_i in enumerate(shapes_primes):\n",
    "            # print(f\"H += lg({m_i[d]} / gcd({k_d}, {m_i[d]}))\")\n",
    "            H += math.log2(m_i[d] / math.gcd(k_d, m_i[d]))\n",
    "            j += 1\n",
    "            if j >= N:\n",
    "                continue\n",
    "\n",
    "    if j >= N:\n",
    "        break\n",
    "\n",
    "print(D*H)\n",
    "print(D * H / N)\n",
    "print(D * H / N_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e219c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d37558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
