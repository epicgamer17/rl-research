{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4691ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from hippocampal_sensory_layers import (\n",
    "    ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars,\n",
    "    ComplexExactPseudoInverseHippocampalSensoryLayerComplexScalars,\n",
    "    HippocampalSensoryLayer,\n",
    ")\n",
    "from fourier_scaffold import FourierScaffold\n",
    "from preprocessing_cnn import (\n",
    "    Preprocessor,\n",
    "    RescalePreprocessing,\n",
    "    SequentialPreprocessing,\n",
    "    GrayscaleAndFlattenPreprocessing,\n",
    ")\n",
    "from experiments.fourier_miniworld_gridsearch.room_env import RoomExperiment\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from graph_utils import plot_imgs_side_by_side\n",
    "from agent import TrueData\n",
    "from tqdm import tqdm\n",
    "\n",
    "forward_20 = [2] * 20\n",
    "right_60_deg = [1] * 20\n",
    "loop_path = (forward_20 + right_60_deg) * 6 + forward_20\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e219c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer_iterative_no_hidden(sbook, D, device, gbook):\n",
    "    layer = (\n",
    "        ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "            input_size=sbook.shape[1],\n",
    "            N_h=D,\n",
    "            hidden_layer_factor=0,\n",
    "            epsilon_sh=0.1,\n",
    "            epsilon_hs=0.1,\n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "\n",
    "def make_layer_iterative(sbook, D, device, gbook):\n",
    "    layer = (\n",
    "        ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "            input_size=sbook.shape[1],\n",
    "            N_h=D,\n",
    "            hidden_layer_factor=1,\n",
    "            epsilon_sh=0.1,\n",
    "            epsilon_hs=0.1,\n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "\n",
    "def make_layer_analytic(sbook, D, device, gbook):\n",
    "    layer = ComplexExactPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "        input_size=sbook.shape[1],\n",
    "        N_patts=len(gbook),\n",
    "        hbook=gbook,\n",
    "        N_h=D,\n",
    "        device=device,\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "\n",
    "shapes_list = [\n",
    "    [(3, 3, 3), (5, 5, 5)],\n",
    "    # [(5, 5, 5), (7, 7, 7)],\n",
    "    # [(7, 7, 7), (9, 9, 9)],\n",
    "]\n",
    "\n",
    "D_list = [2000]\n",
    "D_reshape_size_map = {\n",
    "    2000: (40, 50),\n",
    "    800: (20, 40),\n",
    "    300: (15, 20),\n",
    "}\n",
    "\n",
    "layers_list = [\n",
    "    (\"iterative no hidden\", make_layer_iterative_no_hidden),\n",
    "    # (\"iterative hidden\", make_layer_iterative_no_hidden),\n",
    "    (\"analytic\", make_layer_iterative_no_hidden),\n",
    "]\n",
    "\n",
    "preprocessing_list = [\n",
    "    SequentialPreprocessing(\n",
    "        transforms=[\n",
    "            RescalePreprocessing(0.25),\n",
    "            GrayscaleAndFlattenPreprocessing(device),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "# g_rescaling_list = [True, False]\n",
    "g_rescaling_list = [False]\n",
    "sbook_rand_list = [True, False]\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    return RoomExperiment([3, 0, 3], 0)\n",
    "\n",
    "\n",
    "def make_gbook(D, shapes):\n",
    "    scaffold = FourierScaffold(\n",
    "        D=D, shapes=torch.tensor(shapes), _skip_K_calc=True, _skip_gs_calc=True\n",
    "    )\n",
    "    return scaffold.gbook()\n",
    "\n",
    "\n",
    "def make_data(\n",
    "    path: list[int],\n",
    "    scaffold: FourierScaffold,\n",
    "    preprocessing: Preprocessor,\n",
    "    noise_dist=None,\n",
    "):\n",
    "    env = make_env()\n",
    "\n",
    "    def get_true_pos():\n",
    "        p_x, p_y, p_z = env.get_wrapper_attr(\"agent\").pos\n",
    "        angle = env.get_wrapper_attr(\"agent\").dir\n",
    "        p = torch.tensor([p_x, p_z, angle]).float().to(device)\n",
    "        return p\n",
    "\n",
    "    def _env_reset():\n",
    "        obs, info = env.reset()\n",
    "        img = obs\n",
    "        processed_img = preprocessing.encode(img)\n",
    "        p = get_true_pos()\n",
    "        return processed_img, p\n",
    "\n",
    "    def _obs_postpreprocess(step_tuple, action):\n",
    "        obs, reward, terminated, truncated, info = step_tuple\n",
    "        img = obs\n",
    "        processed_img = preprocessing.encode(img)\n",
    "        p = get_true_pos()\n",
    "        return processed_img, p\n",
    "\n",
    "    start_img, start_pos = _env_reset()\n",
    "    v_cumulative = torch.zeros(3, device=device)\n",
    "\n",
    "    true_data = TrueData(start_pos)\n",
    "\n",
    "    true_positions = [true_data.true_position.clone()]\n",
    "    gbook = [scaffold.P @ scaffold.g_s]\n",
    "    sbook = [start_img]\n",
    "\n",
    "    for i, action in enumerate(path):\n",
    "        ### env-specific observation processing\n",
    "        step_tuple = env.step(action)\n",
    "\n",
    "        ### this is the sensory input not flattened yet\n",
    "        new_img, new_pos = _obs_postpreprocess(step_tuple, action)\n",
    "\n",
    "        ### calculation of noisy input\n",
    "        dp = new_pos - true_data.true_position\n",
    "        true_data.true_position = new_pos\n",
    "        noisy_dp = new_pos\n",
    "        if noise_dist != None:\n",
    "            noisy_dp += noise_dist.sample(3)\n",
    "\n",
    "        dt = 1\n",
    "        v = (dp / dt) * scaffold.scale_factor\n",
    "        v_cumulative += v\n",
    "\n",
    "        if v_cumulative.norm(p=float(\"inf\")) < 1:\n",
    "            continue\n",
    "\n",
    "        scaffold.velocity_shift(v)\n",
    "        scaffold.smooth()\n",
    "        scaffold.sharpen()\n",
    "        g_avg = scaffold.P @ scaffold.g_s\n",
    "        true_positions += [true_data.true_position.clone()]\n",
    "        gbook += [g_avg]\n",
    "        sbook += [new_img]\n",
    "        v_cumulative = torch.zeros(3, device=device)\n",
    "\n",
    "    return torch.vstack(true_positions), torch.vstack(gbook), torch.vstack(sbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d37558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module shapes:  tensor([[3, 3, 3],\n",
      "        [5, 5, 5]])\n",
      "N_g (D) :  2000\n",
      "M       :  2\n",
      "d       :  3\n",
      "N_patts :  3375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, preprocessing \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(preprocessing_list):\n\u001b[1;32m    127\u001b[0m     scaffold \u001b[38;5;241m=\u001b[39m FourierScaffold(shapes\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(shapes), D\u001b[38;5;241m=\u001b[39mD, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 128\u001b[0m     true_positions, gbook, sbook \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaffold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l, g_rescaling \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(g_rescaling_list):\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m g_rescaling:\n",
      "Cell \u001b[0;32mIn[6], line 118\u001b[0m, in \u001b[0;36mmake_data\u001b[0;34m(path, scaffold, preprocessing, noise_dist)\u001b[0m\n\u001b[1;32m    114\u001b[0m sbook \u001b[38;5;241m=\u001b[39m [start_img]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(path):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m### env-specific observation processing\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     step_tuple \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m### this is the sensory input not flattened yet\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     new_img, new_pos \u001b[38;5;241m=\u001b[39m _obs_postpreprocess(step_tuple, action)\n",
      "File \u001b[0;32m~/Projects/rl-research/vectorhash/experiments/fourier_hs_miniworld_testing/../../experiments/fourier_miniworld_gridsearch/room_env.py:103\u001b[0m, in \u001b[0;36mRoomExperiment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 103\u001b[0m     obs, reward, termination, truncation, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mred_box):\n\u001b[1;32m    106\u001b[0m         reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/miniworld/miniworld.py:717\u001b[0m, in \u001b[0;36mMiniWorldEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mcarrying\u001b[38;5;241m.\u001b[39mdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mdir\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# Generate the current camera image\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# If the maximum time step count is reached\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_episode_steps:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/miniworld/miniworld.py:1221\u001b[0m, in \u001b[0;36mMiniWorldEnv.render_obs\u001b[0;34m(self, frame_buffer)\u001b[0m\n\u001b[1;32m   1209\u001b[0m glLoadIdentity()\n\u001b[1;32m   1210\u001b[0m gluLookAt(\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# Eye position\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mcam_pos,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m   1219\u001b[0m )\n\u001b[0;32m-> 1221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_world\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/miniworld/miniworld.py:1084\u001b[0m, in \u001b[0;36mMiniWorldEnv._render_world\u001b[0;34m(self, frame_buffer, render_agent)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;66;03m# Resolve the rendered image into a numpy array\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mframe_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/miniworld/opengl.py:378\u001b[0m, in \u001b[0;36mFrameBuffer.resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m glBindFramebuffer(GL_FRAMEBUFFER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_fbo)\n\u001b[1;32m    377\u001b[0m glPixelStorei(GL_PACK_ALIGNMENT, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 378\u001b[0m \u001b[43mglReadPixels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGL_RGB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGL_UNSIGNED_BYTE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGLubyte\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Unbind the frame buffer\u001b[39;00m\n\u001b[1;32m    389\u001b[0m glBindFramebuffer(GL_FRAMEBUFFER, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/pyglet/gl/lib.py:87\u001b[0m, in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGLException\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrcheck\u001b[39m(result, func, arguments):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _debug_gl_trace:\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_layer(\n",
    "    layer: HippocampalSensoryLayer,\n",
    "    hbook: torch.Tensor,\n",
    "    sbook: torch.Tensor,\n",
    "    large: bool,\n",
    "):\n",
    "    err_l1_first_img_s_h_s = -torch.ones(len(sbook))\n",
    "    err_l1_last_img_s_h_s = -torch.ones(len(sbook))\n",
    "    avg_accumulated_err_l2 = -torch.ones(len(sbook))\n",
    "    first_img = sbook[0]\n",
    "\n",
    "    gbook_recovered = torch.zeros_like(gbook_)\n",
    "    recovered_first_imgs = torch.zeros_like(sbook)\n",
    "    recovered_last_imgs = torch.zeros_like(sbook)\n",
    "\n",
    "    for i in tqdm(range(len(sbook))):\n",
    "        h_ = hbook[i]\n",
    "        if large:\n",
    "            h = torch.einsum(\"i,j->ij\", h_, h_.conj()).flatten()\n",
    "        else:\n",
    "            h = h_\n",
    "\n",
    "        s = sbook[i]\n",
    "        layer.learn(h, s)\n",
    "\n",
    "        gbook_recovered[i] = layer.hippocampal_from_sensory(s)\n",
    "        recovered_first_imgs[i] = layer.sensory_from_hippocampal(\n",
    "            layer.hippocampal_from_sensory(first_img)\n",
    "        )[0]\n",
    "        recovered_last_imgs[i] = layer.sensory_from_hippocampal(\n",
    "            layer.hippocampal_from_sensory(s)\n",
    "        )[0]\n",
    "\n",
    "        err_l1_first_img_s_h_s[i] = torch.mean(\n",
    "            torch.abs(\n",
    "                layer.sensory_from_hippocampal(\n",
    "                    layer.hippocampal_from_sensory(first_img)\n",
    "                )[0]\n",
    "                - first_img\n",
    "            )\n",
    "        )\n",
    "\n",
    "        err_l1_last_img_s_h_s[i] = torch.mean(\n",
    "            torch.abs(\n",
    "                layer.sensory_from_hippocampal(\n",
    "                    layer.hippocampal_from_sensory(sbook[i])\n",
    "                )[0]\n",
    "                - sbook[i]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        avg_accumulated_err_l2[i] = torch.mean(\n",
    "            (\n",
    "                layer.sensory_from_hippocampal(\n",
    "                    layer.hippocampal_from_sensory(sbook[: i + 1])\n",
    "                )\n",
    "                - sbook[: i + 1]\n",
    "            )\n",
    "            ** 2\n",
    "        )\n",
    "        if (\n",
    "            # err_l1_first_img_s_h_s[i] > 10e5\n",
    "            # or avg_accumulated_err_l2[i] > 10e5\n",
    "            torch.any(torch.isnan(err_l1_first_img_s_h_s[i]))\n",
    "            or torch.any(torch.isnan(avg_accumulated_err_l2[i]))\n",
    "        ):\n",
    "            break\n",
    "\n",
    "    return (\n",
    "        err_l1_first_img_s_h_s,\n",
    "        err_l1_last_img_s_h_s,\n",
    "        avg_accumulated_err_l2,\n",
    "        recovered_first_imgs,\n",
    "        recovered_last_imgs,\n",
    "        gbook_recovered,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_avg_acc_l2_err_on_ax(ax: Axes, avg_accumulated_err_l2: torch.Tensor, label):\n",
    "    x = torch.arange(0, len(avg_accumulated_err_l2[0]))\n",
    "    mean = avg_accumulated_err_l2.mean(dim=0)\n",
    "    std = avg_accumulated_err_l2.std(dim=0)\n",
    "    ax.plot(x, mean, label=label)\n",
    "    ax.fill_between(x, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_first_img_l1_err_on_ax(ax: Axes, err_l1_first_img_s_h_s: torch.Tensor, label):\n",
    "    x = torch.arange(0, len(err_l1_first_img_s_h_s[0]))\n",
    "    mean = err_l1_first_img_s_h_s.mean(dim=0)\n",
    "    std = err_l1_first_img_s_h_s.std(dim=0)\n",
    "    ax.plot(x, mean, label=label)\n",
    "    ax.fill_between(x, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_last_img_l1_err_on_ax(ax: Axes, err_l1_last_img_s_h_s: torch.Tensor, label):\n",
    "    x = torch.arange(0, len(err_l1_last_img_s_h_s[0]))\n",
    "    mean = err_l1_last_img_s_h_s.mean(dim=0)\n",
    "    std = err_l1_last_img_s_h_s.std(dim=0)\n",
    "    ax.plot(x, mean, label=label)\n",
    "    ax.fill_between(x, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def set_ax_titles(ax: Axes, title, xtitle, ytitle):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xtitle)\n",
    "    ax.set_ylabel(ytitle)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def add_vertical_bar_on_ax(ax: Axes, x):\n",
    "    ax.axvline(x=x, color=\"b\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "def add_horizontal_bar_on_ax(ax: Axes, y, label):\n",
    "    ax.axhline(y=y, color=\"k\", linestyle=\"--\", label=label)\n",
    "\n",
    "\n",
    "for i, D in enumerate(D_list):\n",
    "    for j, shapes in enumerate(shapes_list):\n",
    "        for k, preprocessing in enumerate(preprocessing_list):\n",
    "            scaffold = FourierScaffold(shapes=torch.tensor(shapes), D=D, device=device)\n",
    "            true_positions, gbook, sbook = make_data(loop_path, scaffold, preprocessing)\n",
    "            for l, g_rescaling in enumerate(g_rescaling_list):\n",
    "                if g_rescaling:\n",
    "                    gbook_ = gbook * 1e6\n",
    "                else:\n",
    "                    gbook_ = gbook\n",
    "                for m, sbook_rand in enumerate(sbook_rand_list):\n",
    "                    if sbook_rand:\n",
    "                        sbook_ = torch.sign(torch.randn_like(sbook))\n",
    "                    else:\n",
    "                        sbook_ = sbook\n",
    "\n",
    "                    for n, [layer_name, layer_constr] in enumerate(layers_list):\n",
    "                        layer = layer_constr(sbook_, D, device, gbook_)\n",
    "                        (\n",
    "                            err_l1_first_img_s_h_s,\n",
    "                            err_l1_last_img_s_h_s,\n",
    "                            avg_accumulated_err_l2,\n",
    "                            recovered_first_imgs,\n",
    "                            recovered_last_imgs,\n",
    "                            gbook_recovered,\n",
    "                        ) = test_layer(layer, gbook_, sbook_, False)\n",
    "\n",
    "                        fig, axs = plt.subplots(\n",
    "                            nrows=len(recovered_first_imgs), ncols=5, figsize=(20, 48)\n",
    "                        )\n",
    "\n",
    "                        plot_imgs_side_by_side(\n",
    "                            imgs=[\n",
    "                                recovered_first_imgs[i].cpu().reshape(15, 20)\n",
    "                                for i in range(len(recovered_first_imgs))\n",
    "                            ],\n",
    "                            titles=[f\"recovered sbook[0]\" for j in range(len(sbook_))],\n",
    "                            axs=axs[:, 0],\n",
    "                            fig=fig,\n",
    "                            use_first_img_scale=True,\n",
    "                        )\n",
    "                        plot_imgs_side_by_side(\n",
    "                            imgs=[\n",
    "                                sbook_[i].cpu().reshape(15, 20)\n",
    "                                for i in range(len(sbook_))\n",
    "                            ],\n",
    "                            titles=[f\"sbook[{j}]\" for j in range(len(sbook_))],\n",
    "                            axs=axs[:, 1],\n",
    "                            fig=fig,\n",
    "                            use_first_img_scale=True,\n",
    "                        )\n",
    "                        plot_imgs_side_by_side(\n",
    "                            imgs=[\n",
    "                                recovered_last_imgs[i].cpu().reshape(15, 20)\n",
    "                                for i in range(len(recovered_last_imgs))\n",
    "                            ],\n",
    "                            titles=[\n",
    "                                f\"recovered sbook[{j}]\" for j in range(len(sbook_))\n",
    "                            ],\n",
    "                            axs=axs[:, 2],\n",
    "                            fig=fig,\n",
    "                            use_first_img_scale=True,\n",
    "                        )\n",
    "                        plot_imgs_side_by_side(\n",
    "                            imgs=[\n",
    "                                gbook_[i].cpu().reshape(D_reshape_size_map[D]).real\n",
    "                                for i in range(len(gbook_))\n",
    "                            ],\n",
    "                            titles=[f\"Re(gbook[{j}])\" for j in range(len(sbook_))],\n",
    "                            axs=axs[:, 3],\n",
    "                            fig=fig,\n",
    "                            use_first_img_scale=True,\n",
    "                        )\n",
    "                        plot_imgs_side_by_side(\n",
    "                            imgs=[\n",
    "                                gbook_recovered[i]\n",
    "                                .cpu()\n",
    "                                .reshape(D_reshape_size_map[D])\n",
    "                                .real\n",
    "                                for i in range(len(gbook_recovered))\n",
    "                            ],\n",
    "                            titles=[\n",
    "                                f\"Re(gbook_recovered[{j}])\" for j in range(len(sbook_))\n",
    "                            ],\n",
    "                            axs=axs[:, 4],\n",
    "                            fig=fig,\n",
    "                            use_first_img_scale=True,\n",
    "                        )\n",
    "                        fig.suptitle(\n",
    "                            f\"layer_type={layer_name}, D={D}, downscaling=0.25, g_rescaling={g_rescaling}, rand_sbook={sbook_rand}, shapes={shapes}\"\n",
    "                        )\n",
    "                        fig.savefig(\n",
    "                            f\"D={D}-layer={layer_name}-rescaling={g_rescaling}-rand_sbook={sbook_rand}.png\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454a9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
