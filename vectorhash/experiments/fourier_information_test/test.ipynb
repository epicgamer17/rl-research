{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be93865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from hippocampal_sensory_layers import (\n",
    "    ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars,\n",
    "    ComplexExactPseudoInverseHippocampalSensoryLayerComplexScalars,\n",
    ")\n",
    "from fourier_scaffold import FourierScaffold\n",
    "\n",
    "device = \"cuda\"\n",
    "runs = 10\n",
    "Ns = 1000\n",
    "Npatts_total = 200 \n",
    "sbook_all = torch.sign(torch.randn(runs, Npatts_total, Ns, device=device))\n",
    "Npatts_list = torch.arange(5, Npatts_total + 1)  # H = 100\n",
    "###### CONFIG 1: test MI/D dependence #####\n",
    "# Note: iterative vs analytic pseudoinverse makes no difference\n",
    "D_list = [100,200,300]\n",
    "ps_types = ['iterative']\n",
    "shape_configs = [\n",
    "    # [(3,), (5,), (7,),(11,)],\n",
    "    # [(3, 3), (5, 5), (7, 7)],\n",
    "    [(3, 3, 3), (5,5,5)],\n",
    "    # [(3, 3, 3), (7,7,7)],\n",
    "    # [(11, 13, 17), (23, 29, 31)],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def run_test(shapes, layer_type, D_list, Npatts_list, sbook):\n",
    "    errors = torch.zeros(len(D_list), len(Npatts_list))\n",
    "\n",
    "    for k, D in enumerate(D_list):\n",
    "        scaffold = FourierScaffold(shapes, D=D, _skip_K_calc=True, device=device)\n",
    "        gbook = scaffold.gbook().T\n",
    "\n",
    "        if layer_type == \"analytic\":\n",
    "            layer = ComplexExactPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "                input_size=Ns,\n",
    "                N_h=D,\n",
    "                N_patts=Npatts_total,\n",
    "                hbook=gbook[:Npatts_total],\n",
    "                device=device,\n",
    "            )\n",
    "        elif layer_type == \"iterative\":\n",
    "            layer = ComplexIterativeBidirectionalPseudoInverseHippocampalSensoryLayerComplexScalars(\n",
    "                input_size=Ns,\n",
    "                N_h=D,\n",
    "                epsilon_hs=0.1,\n",
    "                epsilon_sh=0.1,\n",
    "                hidden_layer_factor=0,\n",
    "                device=device,\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"invalid layer type\")\n",
    "\n",
    "        i = 0\n",
    "        for l, Npatts in enumerate(Npatts_list):\n",
    "            for j in range(i, Npatts):\n",
    "                layer.learn(gbook[i], sbook[i])\n",
    "                i += 1\n",
    "\n",
    "            true = sbook[:Npatts]\n",
    "            input = (\n",
    "                torch.complex(sbook[:Npatts], torch.zeros_like(sbook[:Npatts]))\n",
    "                if layer_type == \"analytic\"\n",
    "                else true\n",
    "            )\n",
    "            recovered = layer.sensory_from_hippocampal(\n",
    "                layer.hippocampal_from_sensory(input)\n",
    "            )\n",
    "            error = torch.abs(true.real - torch.sign(recovered.real))\n",
    "            pflip = error.mean() / 2\n",
    "            errors[k, l] = pflip\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2320c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(runs, len(shape_configs), len(ps_types), len(D_list), len(Npatts_list))\n",
    "\n",
    "for i in range(runs):\n",
    "    for j, shape_config in enumerate(shape_configs):\n",
    "        for k, layer_type in enumerate(ps_types):\n",
    "            print(f\"run {i+1}/{runs}, shapes={shape_config}, layer_type={layer_type} \")\n",
    "            results[i, j, k] = run_test(torch.tensor(shape_config), layer_type, D_list, Npatts_list, sbook_all[i])\n",
    "            print(results[i, j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = torch.zeros(runs, len(shape_configs), 2, len(Npatts_list))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "\n",
    "def build_title():\n",
    "    parts = [f\"Ns={Ns}\", f\"runs={runs}\"]\n",
    "    if len(shape_configs) == 1:\n",
    "        parts.append(f\"shapes={shape_configs[0]}\")\n",
    "    if len(ps_types) == 1:\n",
    "        parts.append(f\"ps_method={ps_types[0]}\")\n",
    "    if len(D_list) == 1:\n",
    "        parts.append(f\"D={D_list[0]}\")\n",
    "    return \", \".join(parts)\n",
    "\n",
    "\n",
    "def build_label(shape_config, ps_type, D):\n",
    "    parts = []\n",
    "    if len(shape_configs) != 1:\n",
    "        parts.append(f\"shapes={shape_config}\")\n",
    "    if len(ps_types) != 1:\n",
    "        parts.append(f\"ps_method={ps_type}\")\n",
    "    if len(D_list) != 1:\n",
    "        parts.append(f\"D={D}\")\n",
    "    return \", \".join(parts)\n",
    "\n",
    "\n",
    "for i, shape_config in enumerate(shape_configs):\n",
    "    for k, D in enumerate(D_list):\n",
    "        for l, method in enumerate(ps_types):  # , \"analytic\"]):\n",
    "            m = 1 - (2 * results[:, i, 0, k])  # % of correct bits, p(correct)\n",
    "            a = (1 + m) / 2  #\n",
    "            b = (1 - m) / 2  # sor(a))\n",
    "            b = torch.abs(torch.tensor(b)).cpu()\n",
    "            S = -a * torch.log2(a) - b * torch.log2(\n",
    "                b\n",
    "            )  # H(.) = -P(Y=1) lg P(Y=1) - P(Y=0) lg P(Y=0)\n",
    "            S = torch.where(m == 1, torch.zeros_like(S), S)\n",
    "            MI = 1 - S\n",
    "\n",
    "            ax.plot(\n",
    "                Npatts_list,\n",
    "                MI.mean(dim=0),\n",
    "                label=build_label(shape_config, method, D)\n",
    "            )\n",
    "            ax.fill_between(\n",
    "                Npatts_list,\n",
    "                MI.mean(dim=0) - MI.std(dim=0),\n",
    "                MI.mean(dim=0) + MI.std(dim=0),\n",
    "                # label=build_label(shape_config, method, D),\n",
    "                alpha=0.5,\n",
    "            )\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"N_patts\")\n",
    "ax.set_ylabel(\"MI per sensory bit\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xticks(torch.arange(0, 200 + 1, 5))\n",
    "ax.grid()\n",
    "ax.set_title(build_title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "print(f\"|X| = {Npatts_total}, Ns = {Ns}\")\n",
    "for Ns in [100, 1000]:\n",
    "    for D in D_list:\n",
    "        print(f\"--------------[D = {D}, Ns = {Ns}]---------------\")\n",
    "        for shapes in shape_configs:\n",
    "            dim_sizes = np.prod(shapes, axis=0)\n",
    "            combinations = [np.arange(dim_sizes[i]) for i in range(len(shapes[0]))]\n",
    "            H = 0\n",
    "            j = 0\n",
    "            for k_tuple in itertools.product(*combinations):\n",
    "                for d, k_d in enumerate(k_tuple):\n",
    "                    for i, m_i in enumerate(shapes):\n",
    "                        # print(f\"H += lg({m_i[d]} / gcd({k_d}, {m_i[d]}))\")\n",
    "                        H += math.log2(m_i[d] / math.gcd(k_d, m_i[d]))\n",
    "                        j += 1\n",
    "                        if j >= Npatts_total:\n",
    "                            continue\n",
    "\n",
    "                if j >= Npatts_total:\n",
    "                    break\n",
    "\n",
    "            # print(f\"   ------------------shapes={shapes}-------------------------------------\")\n",
    "            print(f\"   H(X)    = {D*H:.3f}\")\n",
    "            print(f\"   E[H(X)] = {D * H / Npatts_total:.3f}\")\n",
    "            print(f\"   E[#]    = {math.floor(D * H / Ns)}      (imgs perfectly stored (MI/input bit=1))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acedbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('periodic-vs-shapes-333-555.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5841c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
