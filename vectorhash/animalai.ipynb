{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from animalai.environment import AnimalAIEnvironment\n",
    "from wrappers import CustomUnityToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai_seed = 0\n",
    "port = 5005 + random.randint(\n",
    "    0, 1000\n",
    ")  # uses a random port to avoid problems if a previous version exits slowly\n",
    "env_path = \"/Users/Ile-Maurice/Desktop/MacOS/MacOS\"\n",
    "configuration_file = \"./animal_ai_environments/yroom.yaml\"\n",
    "watch = True\n",
    "\n",
    "aai_env = AnimalAIEnvironment(\n",
    "    file_name=env_path,  # Path to the environment\n",
    "    seed=aai_seed,  # seed for the pseudo random generators\n",
    "    arenas_configurations=configuration_file,\n",
    "    play=False,  # note that this is set to False for training\n",
    "    base_port=port,  # the port to use for communication between python and the Unity environment\n",
    "    inference=watch,  # set to True if you want to watch the agent play\n",
    "    useCamera=True,  # set to False if you don't want to use the camera (no visual observations)\n",
    "    resolution=84,\n",
    "    useRayCasts=False,  # set to True if you want to use raycasts\n",
    "    no_graphics=False,  # set to True if you don't want to use the graphics ('headless' mode)\n",
    "    timescale=1,\n",
    ")\n",
    "\n",
    "env = CustomUnityToGymWrapper(\n",
    "    aai_env, uint8_visual=False, allow_multiple_obs=True, flatten_branched=True\n",
    ")  # the wrapper for the environment\n",
    "\n",
    "# # fix for error generated by the gym wrapper on line 241, python3.10/site-packages/mlagents_envs/rpc_utils.py in _observation_to_np_array\n",
    "# # use img = img.reshape(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.action_space)\n",
    "# 0 - nothing\n",
    "# 1 - rotate right by 6 degrees\n",
    "# 2 - rotate left by 6 degrees\n",
    "# 3 - accelerate forward\n",
    "# 4 - accelerate forward and rotate CW by 6 degrees\n",
    "# 5 - accelerate forward and rotate CCW by 6 degrees\n",
    "# 6 - accelerate backward\n",
    "# 7 - accelerate backward and rotate CW by 6 degrees\n",
    "# 8 - accelerate backward and rotate CCW by 6 degrees\n",
    "\n",
    "\n",
    "print(env.observation_space) # see python3.10/site-packages/animalai/environment.py, line 202\n",
    "# Box(84, 84, 3) - rgb image\n",
    "# Box(-inf, inf, (7,)) - (health; v1, v2, v3; p1, p2, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(60):\n",
    "#     obs, reward, done, info = env.step(1)\n",
    "#     print(\"health:\", obs[1][1])\n",
    "#     print(\"vel:\", obs[1][1:4]) # (v?, v?, v forward/backard relative to starting orientation)\n",
    "#     print(\"pos:\", obs[1][4:7]) # (p?, p?, p forward/backard relative to starting orientation)\n",
    "\n",
    "# for i in range(30):\n",
    "#     obs, reward, done, info = env.step(4)\n",
    "#     obs, reward, done, info = env.step(7)\n",
    "#     print(\"health:\", obs[1][1])\n",
    "#     print(\"vel:\", obs[1][1:4])\n",
    "#     print(\"pos:\", obs[1][4:7])\n",
    "\n",
    "obs, reward, done, info = env.step(3)\n",
    "print(\"obs[0] shape\", obs[0].shape)\n",
    "print(\"obs[0][0] \", obs[0][0])\n",
    "print(\"health:\", obs[1][1])\n",
    "print(\"vel:\", obs[1][1:4])\n",
    "print(\"pos:\", obs[1][4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_sparsity\n",
      "module shapes:  [(3, 3, 4), (4, 4, 5)]\n",
      "N_g     :  116\n",
      "N_patts :  2880\n",
      "N_h     :  1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743977024.262150 7214941 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "torch.Size([84, 84])\n",
      "torch.Size([7056])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1178) tensor(-2.5700) tensor(1.7223)\n",
      "h_from_s max, min, mean tensor(6.1160) tensor(-2.5693) tensor(1.7217)\n",
      "h_from_s_denoised max, min, mean tensor(6.1174) tensor(-2.5698) tensor(1.7223)\n",
      "avg nonzero/greaterzero h from book: tensor(1200) tensor(1086)\n",
      "avg nonzero/greaterzero h from s: tensor(1200) tensor(1086)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1200) tensor(1086)\n",
      "mse/cosinesimilarity h from book and h from s tensor(4.3209e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(1.7193e-08) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.8811e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(8.8492e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.8248e-07) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ile-Maurice/Desktop/rl-research-main/rl-research/vectorhash/vectorhash.py:74: UserWarning: Using a target size (torch.Size([1, 1200])) that is different to the input size (torch.Size([1200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s),\n",
      "/Users/Ile-Maurice/Desktop/rl-research-main/rl-research/vectorhash/vectorhash.py:81: UserWarning: Using a target size (torch.Size([1, 1200])) that is different to the input size (torch.Size([1200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s_denoised),\n",
      "/Users/Ile-Maurice/Desktop/rl-research-main/rl-research/vectorhash/vectorhash.py:97: UserWarning: Using a target size (torch.Size([1, 7056])) that is different to the input size (torch.Size([7056])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s),\n",
      "/Users/Ile-Maurice/Desktop/rl-research-main/rl-research/vectorhash/vectorhash.py:104: UserWarning: Using a target size (torch.Size([1, 7056])) that is different to the input size (torch.Size([7056])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s_denoised),\n",
      "/Users/Ile-Maurice/Desktop/rl-research-main/rl-research/vectorhash/vectorhash.py:111: UserWarning: Using a target size (torch.Size([1, 7056])) that is different to the input size (torch.Size([7056])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h),\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from animalai.environment import AnimalAIEnvironment\n",
    "from wrappers import CustomUnityToGymWrapper\n",
    "from animalai_agent import AnimalAIVectorhashAgent\n",
    "from vectorhash import build_vectorhash_architecture\n",
    "import random\n",
    "\n",
    "### vhash\n",
    "shapes = [(3,3,4), (4,4,5)]\n",
    "model = build_vectorhash_architecture(shapes, N_h=1200, input_size=84*84, initalization_method=\"by_sparsity\", shift=\"conv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### animalai\n",
    "aai_seed = 0\n",
    "port = 5005 + random.randint(\n",
    "    0, 1000\n",
    ")  # uses a random port to avoid problems if a previous version exits slowly\n",
    "env_path = \"/Users/Ile-Maurice/Desktop/MacOS/MacOS\"\n",
    "configuration_file = \"./animal_ai_environments/yroom.yaml\"\n",
    "watch = True\n",
    "\n",
    "aai_env = AnimalAIEnvironment(\n",
    "    file_name=env_path,  # Path to the environment\n",
    "    seed=aai_seed,  # seed for the pseudo random generators\n",
    "    arenas_configurations=configuration_file,\n",
    "    play=False,  # note that this is set to False for training\n",
    "    base_port=port,  # the port to use for communication between python and the Unity environment\n",
    "    inference=False,  # set to True if you want to watch the agent play\n",
    "    useCamera=True,  # set to False if you don't want to use the camera (no visual observations)\n",
    "    resolution=84,\n",
    "    useRayCasts=False,  # set to True if you want to use raycasts\n",
    "    no_graphics=False,  # set to True if you don't want to use the graphics ('headless' mode)\n",
    "    timescale=0.1,\n",
    ")\n",
    "\n",
    "env = CustomUnityToGymWrapper(\n",
    "    aai_env, uint8_visual=False, allow_multiple_obs=True, flatten_branched=True\n",
    ")  # the wrapper for the environment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### agent\n",
    "agent = AnimalAIVectorhashAgent(model, env)\n",
    "agent.vectorhash.certainty = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([9.9999e-01, 2.6822e-06, 2.6822e-06]), tensor([9.9999e-01, 2.6822e-06, 6.3949e-12, 2.6822e-06])]\n",
      "[tensor([9.9999e-01, 2.6822e-06, 2.6822e-06]), tensor([9.9999e-01, 2.6822e-06, 6.3949e-12, 2.6822e-06])]\n",
      "[tensor([3.1974e-12, 2.6822e-06, 1.0000e+00, 2.2235e-18]), tensor([9.9396e-25, 2.2235e-18, 3.1974e-12, 2.6822e-06, 1.0000e+00])]\n",
      "tensor(5.9195e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "tensor(5.9195e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "tensor(3.0356e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "tensor(5.9195e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "tensor(5.9195e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "tensor(3.0356e-06)\n",
      "tensor([-4, -3, -2, -1,  0,  1,  2,  3,  4,  5], dtype=torch.int32)\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(2.3305) tensor(1.2079) tensor(1.7225)\n",
      "h_from_s max, min, mean tensor(2.9485) tensor(0.8226) tensor(1.7220)\n",
      "h_from_s_denoised max, min, mean tensor(4.5481) tensor(-0.5456) tensor(1.7344)\n",
      "avg nonzero/greaterzero h from book: tensor(1200) tensor(1200)\n",
      "avg nonzero/greaterzero h from s: tensor(1200) tensor(1200)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1200) tensor(1193)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0561) tensor([0.9908])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(0.4161) tensor([0.9384])\n",
      "mse/cosinesimilarity s and s from h from s tensor(0.0013) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0006) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h tensor(0.0019) tensor([0.9967])\n",
      "HIII\n",
      "tensor([[0.0290, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277,\n",
      "         0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277,\n",
      "         0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277,\n",
      "         0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277, 0.0277,\n",
      "         0.0128, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
      "         0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125]])\n"
     ]
    }
   ],
   "source": [
    "agent.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.1921e-05), tensor(1.1921e-05), tensor(5.9605e-06))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.calculate_position_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_path(path):\n",
    "    # takes in as input list of actions\n",
    "    errs = []\n",
    "    for i in path:\n",
    "        agent.step(i)\n",
    "        errs.append(agent.calculate_position_err())\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
