{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 -0.0 1.0 -0.0 1.7320508075688772 0.0\n",
      "UPDATE SCALING BY SCHWARZ ERROR False\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  2000\n"
     ]
    }
   ],
   "source": [
    "from vectorhash_imported import *\n",
    "from vectorhash_convered import *\n",
    "from nd_scaffold import GridScaffold\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "lambdas = [3, 4, 5]\n",
    "shapes = [(i, i) for i in lambdas]\n",
    "percent_nonzero_relu = 0.5  #\n",
    "W_gh_var = 1\n",
    "sparse_initialization = 0.1\n",
    "T = 0.1\n",
    "W_hg_std = math.sqrt(W_gh_var)\n",
    "W_hg_mean = -W_hg_std * norm.ppf(1 - percent_nonzero_relu) / math.sqrt(len(lambdas))\n",
    "h_normal_mean = len(lambdas) * W_hg_mean\n",
    "h_normal_std = math.sqrt(len(lambdas)) * W_hg_std\n",
    "relu_theta = math.sqrt((1 - sparse_initialization) * len(lambdas)) * norm.ppf(\n",
    "    1 - percent_nonzero_relu\n",
    ")\n",
    "num_imgs = 500\n",
    "\n",
    "print(\n",
    "    percent_nonzero_relu, W_hg_mean, W_hg_std, h_normal_mean, h_normal_std, relu_theta\n",
    ")\n",
    "\n",
    "GS = GridScaffold(\n",
    "    shapes=shapes,\n",
    "    N_h=2000,\n",
    "    input_size=784,\n",
    "    device=None,\n",
    "    learned_pseudo=\"bidirectional\",\n",
    "    hidden_layer_factor=0,\n",
    "    stationary=True,\n",
    "    epsilon_sh=0.0001,\n",
    "    epsilon_hs=255,\n",
    "    sparse_matrix_initializer=SparseMatrixBySparsityInitializer(\n",
    "        sparsity=sparse_initialization, device=\"cpu\"\n",
    "    ),\n",
    "    # relu_theta=0,\n",
    "    # sparse_matrix_initializer=SparseMatrixByScalingInitializer(\n",
    "    #     scale=W_hg_std, mean=W_hg_mean, device=\"cpu\"\n",
    "    # ),\n",
    "    relu_theta=relu_theta,\n",
    "    T=T,\n",
    "    # h fix\n",
    "    calculate_update_scaling_method=\"n_h\",\n",
    "    use_h_fix=False,  # true if norm scaling, false 25/32, true 21/32 11/32\n",
    "    h_normal_mean=h_normal_mean,\n",
    "    h_normal_std=h_normal_std,\n",
    "    # epsilon=0.01,\n",
    "    scaling_updates=False,  # only relevant when using hebbian false 21/32, true 15/32 7/32\n",
    "    sanity_check=False,\n",
    "    # dream_fix=1,\n",
    "    # zero_tol=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:672: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3729.)\n",
      "  1 + input.T @ self.inhibition_matrix_hs @ input\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:861: UserWarning: Using a target size (torch.Size([1, 2000])) that is different to the input size (torch.Size([2000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s),\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:868: UserWarning: Using a target size (torch.Size([1, 2000])) that is different to the input size (torch.Size([2000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s_denoised),\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:878: UserWarning: Using a target size (torch.Size([1, 784])) that is different to the input size (torch.Size([784])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s),\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:885: UserWarning: Using a target size (torch.Size([1, 784])) that is different to the input size (torch.Size([784])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s_denoised),\n",
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:892: UserWarning: Using a target size (torch.Size([1, 784])) that is different to the input size (torch.Size([784])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h),\n",
      "  1%|▏         | 7/500 [00:00<00:15, 31.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1086) tensor(0.) tensor(0.6511)\n",
      "h_from_s max, min, mean tensor(6.0425) tensor(0.) tensor(0.6440)\n",
      "h_from_s_denoised max, min, mean tensor(6.1134) tensor(0.) tensor(0.6516)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0002) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2927e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(0.8884) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2945e-12) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2466) tensor(0.) tensor(0.6599)\n",
      "h_from_s max, min, mean tensor(5.1787) tensor(0.) tensor(0.6561)\n",
      "h_from_s_denoised max, min, mean tensor(5.2502) tensor(0.) tensor(0.6604)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1507) tensor(1507)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0002) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6806e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.1077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.8041e-12) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6632) tensor(0.) tensor(0.6547)\n",
      "h_from_s max, min, mean tensor(5.5647) tensor(0.) tensor(0.6457)\n",
      "h_from_s_denoised max, min, mean tensor(5.6673) tensor(0.) tensor(0.6552)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1775) tensor(1775)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1014) tensor(1014)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0004) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2014e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.4371) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0024) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1279e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5799) tensor(0.) tensor(0.6819)\n",
      "h_from_s max, min, mean tensor(5.4872) tensor(0.) tensor(0.6732)\n",
      "h_from_s_denoised max, min, mean tensor(5.5842) tensor(0.) tensor(0.6824)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1873) tensor(1873)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0004) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0555e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.5682) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0027) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2190e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4344) tensor(0.) tensor(0.6876)\n",
      "h_from_s max, min, mean tensor(5.3569) tensor(0.) tensor(0.6843)\n",
      "h_from_s_denoised max, min, mean tensor(5.4377) tensor(0.) tensor(0.6881)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1911) tensor(1911)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0003) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9749e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.3975) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4809e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3827) tensor(0.) tensor(0.6133)\n",
      "h_from_s max, min, mean tensor(5.2950) tensor(0.) tensor(0.6149)\n",
      "h_from_s_denoised max, min, mean tensor(5.3863) tensor(0.) tensor(0.6138)\n",
      "avg nonzero/greaterzero h from book: tensor(990) tensor(990)\n",
      "avg nonzero/greaterzero h from s: tensor(1937) tensor(1937)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0003) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4434e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.4269) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0948e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6356) tensor(0.) tensor(0.6573)\n",
      "h_from_s max, min, mean tensor(5.5294) tensor(0.) tensor(0.6514)\n",
      "h_from_s_denoised max, min, mean tensor(5.6398) tensor(0.) tensor(0.6578)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1796) tensor(1796)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0005) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7923e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.8451) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2415e-11) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:00<00:15, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8337) tensor(0.) tensor(0.6524)\n",
      "h_from_s max, min, mean tensor(5.7698) tensor(0.) tensor(0.6590)\n",
      "h_from_s_denoised max, min, mean tensor(5.8378) tensor(0.) tensor(0.6529)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1961) tensor(1961)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0006) tensor([0.9998])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2108e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.7462) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7072e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0413) tensor(0.) tensor(0.6681)\n",
      "h_from_s max, min, mean tensor(5.5873) tensor(0.) tensor(0.6475)\n",
      "h_from_s_denoised max, min, mean tensor(6.0449) tensor(0.) tensor(0.6685)\n",
      "avg nonzero/greaterzero h from book: tensor(1047) tensor(1047)\n",
      "avg nonzero/greaterzero h from s: tensor(1727) tensor(1727)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1047) tensor(1047)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0082) tensor([0.9989])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6582e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.1125) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0015) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2014e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3403) tensor(0.) tensor(0.6609)\n",
      "h_from_s max, min, mean tensor(5.2558) tensor(0.) tensor(0.6592)\n",
      "h_from_s_denoised max, min, mean tensor(5.3434) tensor(0.) tensor(0.6614)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1978) tensor(1978)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1025) tensor(1025)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0004) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4874e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.8357) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9039e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0675) tensor(0.) tensor(0.6515)\n",
      "h_from_s max, min, mean tensor(5.9463) tensor(0.) tensor(0.6512)\n",
      "h_from_s_denoised max, min, mean tensor(6.0720) tensor(0.) tensor(0.6520)\n",
      "avg nonzero/greaterzero h from book: tensor(968) tensor(968)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(967) tensor(967)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0007) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4184e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.2325) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0772e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7406) tensor(0.) tensor(0.6906)\n",
      "h_from_s max, min, mean tensor(6.5595) tensor(0.) tensor(0.6810)\n",
      "h_from_s_denoised max, min, mean tensor(6.7457) tensor(0.) tensor(0.6910)\n",
      "avg nonzero/greaterzero h from book: tensor(1036) tensor(1036)\n",
      "avg nonzero/greaterzero h from s: tensor(1745) tensor(1745)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1035) tensor(1035)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0011) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4270e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.6271) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0021) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4988e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1579) tensor(0.) tensor(0.6620)\n",
      "h_from_s max, min, mean tensor(5.1013) tensor(0.) tensor(0.6629)\n",
      "h_from_s_denoised max, min, mean tensor(5.1613) tensor(0.) tensor(0.6625)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1854) tensor(1854)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0003) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3408e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.2652) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8226e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9760) tensor(0.) tensor(0.6706)\n",
      "h_from_s max, min, mean tensor(5.8972) tensor(0.) tensor(0.6711)\n",
      "h_from_s_denoised max, min, mean tensor(5.9811) tensor(0.) tensor(0.6711)\n",
      "avg nonzero/greaterzero h from book: tensor(997) tensor(997)\n",
      "avg nonzero/greaterzero h from s: tensor(1858) tensor(1858)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0004) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0789e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.6745) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.1258e-11) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/500 [00:00<00:14, 33.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5824) tensor(0.) tensor(0.6708)\n",
      "h_from_s max, min, mean tensor(6.1921) tensor(0.) tensor(0.6664)\n",
      "h_from_s_denoised max, min, mean tensor(6.5875) tensor(0.) tensor(0.6713)\n",
      "avg nonzero/greaterzero h from book: tensor(1025) tensor(1025)\n",
      "avg nonzero/greaterzero h from s: tensor(1891) tensor(1891)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0059) tensor([0.9987])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4652e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.7452) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0023) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2830e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.9335) tensor(0.) tensor(0.6481)\n",
      "h_from_s max, min, mean tensor(6.8147) tensor(0.) tensor(0.6468)\n",
      "h_from_s_denoised max, min, mean tensor(6.9389) tensor(0.) tensor(0.6486)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1716) tensor(1716)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0007) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9810e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.0404) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.0006e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9950) tensor(0.) tensor(0.6890)\n",
      "h_from_s max, min, mean tensor(5.9004) tensor(0.) tensor(0.6827)\n",
      "h_from_s_denoised max, min, mean tensor(5.9991) tensor(0.) tensor(0.6895)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1764) tensor(1764)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0006) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4355e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.8570) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.2779e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3168) tensor(0.) tensor(0.6290)\n",
      "h_from_s max, min, mean tensor(5.2008) tensor(0.) tensor(0.6369)\n",
      "h_from_s_denoised max, min, mean tensor(5.3200) tensor(0.) tensor(0.6294)\n",
      "avg nonzero/greaterzero h from book: tensor(973) tensor(973)\n",
      "avg nonzero/greaterzero h from s: tensor(1948) tensor(1948)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0014) tensor([0.9996])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7717e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.6975) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6963e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9299) tensor(0.) tensor(0.6580)\n",
      "h_from_s max, min, mean tensor(5.7725) tensor(0.) tensor(0.6434)\n",
      "h_from_s_denoised max, min, mean tensor(5.9339) tensor(0.) tensor(0.6584)\n",
      "avg nonzero/greaterzero h from book: tensor(1010) tensor(1010)\n",
      "avg nonzero/greaterzero h from s: tensor(1678) tensor(1678)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0014) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9352e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.8648) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0022) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3681e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5759) tensor(0.) tensor(0.6719)\n",
      "h_from_s max, min, mean tensor(5.3159) tensor(0.) tensor(0.6630)\n",
      "h_from_s_denoised max, min, mean tensor(5.5805) tensor(0.) tensor(0.6724)\n",
      "avg nonzero/greaterzero h from book: tensor(1028) tensor(1028)\n",
      "avg nonzero/greaterzero h from s: tensor(1856) tensor(1856)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0044) tensor([0.9994])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7450e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.5252) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0029) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3035e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8559) tensor(0.) tensor(0.6432)\n",
      "h_from_s max, min, mean tensor(4.8086) tensor(0.) tensor(0.6463)\n",
      "h_from_s_denoised max, min, mean tensor(4.8581) tensor(0.) tensor(0.6437)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1892) tensor(1892)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0004) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0903e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.5089) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6484e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0245) tensor(0.) tensor(0.6556)\n",
      "h_from_s max, min, mean tensor(5.9414) tensor(0.) tensor(0.6616)\n",
      "h_from_s_denoised max, min, mean tensor(6.0295) tensor(0.) tensor(0.6561)\n",
      "avg nonzero/greaterzero h from book: tensor(1038) tensor(1038)\n",
      "avg nonzero/greaterzero h from s: tensor(1829) tensor(1829)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1037) tensor(1037)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0007) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6978e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.0043) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0068) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4062e-11) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:00<00:13, 34.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3769) tensor(0.) tensor(0.6430)\n",
      "h_from_s max, min, mean tensor(5.1655) tensor(0.) tensor(0.6332)\n",
      "h_from_s_denoised max, min, mean tensor(5.3807) tensor(0.) tensor(0.6434)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(976) tensor(976)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0036) tensor([0.9995])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2044e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.5668) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0022) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2098e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3377) tensor(0.) tensor(0.6884)\n",
      "h_from_s max, min, mean tensor(4.8176) tensor(0.) tensor(0.6772)\n",
      "h_from_s_denoised max, min, mean tensor(5.3406) tensor(0.) tensor(0.6889)\n",
      "avg nonzero/greaterzero h from book: tensor(1031) tensor(1031)\n",
      "avg nonzero/greaterzero h from s: tensor(1642) tensor(1642)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1030) tensor(1030)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0410) tensor([0.9872])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2430e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.2196) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2567e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4478) tensor(0.) tensor(0.6982)\n",
      "h_from_s max, min, mean tensor(5.3377) tensor(0.) tensor(0.6928)\n",
      "h_from_s_denoised max, min, mean tensor(5.4510) tensor(0.) tensor(0.6987)\n",
      "avg nonzero/greaterzero h from book: tensor(1038) tensor(1038)\n",
      "avg nonzero/greaterzero h from s: tensor(1803) tensor(1803)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1038) tensor(1038)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0012) tensor([0.9998])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9536e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.5094) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4434e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4100) tensor(0.) tensor(0.6196)\n",
      "h_from_s max, min, mean tensor(5.2836) tensor(0.) tensor(0.6243)\n",
      "h_from_s_denoised max, min, mean tensor(5.4139) tensor(0.) tensor(0.6200)\n",
      "avg nonzero/greaterzero h from book: tensor(963) tensor(963)\n",
      "avg nonzero/greaterzero h from s: tensor(1895) tensor(1895)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(961) tensor(961)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0007) tensor([0.9998])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4095e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.8701) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0068) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5321e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8128) tensor(0.) tensor(0.6535)\n",
      "h_from_s max, min, mean tensor(5.5212) tensor(0.) tensor(0.6401)\n",
      "h_from_s_denoised max, min, mean tensor(5.8173) tensor(0.) tensor(0.6540)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1816) tensor(1816)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0035) tensor([0.9996])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7862e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.8938) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0022) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4643e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3251) tensor(0.) tensor(0.6623)\n",
      "h_from_s max, min, mean tensor(6.2753) tensor(0.) tensor(0.6713)\n",
      "h_from_s_denoised max, min, mean tensor(6.3294) tensor(0.) tensor(0.6628)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1788) tensor(1788)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0009) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2442e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.2469) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0104) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6422e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0731) tensor(0.) tensor(0.6887)\n",
      "h_from_s max, min, mean tensor(6.0035) tensor(0.) tensor(0.6928)\n",
      "h_from_s_denoised max, min, mean tensor(6.0773) tensor(0.) tensor(0.6892)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1874) tensor(1874)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0003) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0152e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(1.2744) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2385e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3032) tensor(0.) tensor(0.6597)\n",
      "h_from_s max, min, mean tensor(6.1418) tensor(0.) tensor(0.6623)\n",
      "h_from_s_denoised max, min, mean tensor(6.3081) tensor(0.) tensor(0.6602)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1804) tensor(1804)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0018) tensor([0.9995])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6737e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.7403) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.4845e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/500 [00:01<00:13, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.1533) tensor(0.) tensor(0.6474)\n",
      "h_from_s max, min, mean tensor(7.0623) tensor(0.) tensor(0.6464)\n",
      "h_from_s_denoised max, min, mean tensor(7.1585) tensor(0.) tensor(0.6478)\n",
      "avg nonzero/greaterzero h from book: tensor(975) tensor(975)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0005) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6386e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.0175) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3343e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2969) tensor(0.) tensor(0.6913)\n",
      "h_from_s max, min, mean tensor(5.2324) tensor(0.) tensor(0.6961)\n",
      "h_from_s_denoised max, min, mean tensor(5.3011) tensor(0.) tensor(0.6918)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1828) tensor(1828)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0017) tensor([0.9996])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.3053e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.8845) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8984e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3785) tensor(0.) tensor(0.6526)\n",
      "h_from_s max, min, mean tensor(6.1833) tensor(0.) tensor(0.6481)\n",
      "h_from_s_denoised max, min, mean tensor(6.3824) tensor(0.) tensor(0.6531)\n",
      "avg nonzero/greaterzero h from book: tensor(1033) tensor(1033)\n",
      "avg nonzero/greaterzero h from s: tensor(1741) tensor(1741)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1031) tensor(1031)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0017) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1707e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.0318) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5511e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7026) tensor(0.) tensor(0.6530)\n",
      "h_from_s max, min, mean tensor(5.3857) tensor(0.) tensor(0.6501)\n",
      "h_from_s_denoised max, min, mean tensor(5.7063) tensor(0.) tensor(0.6535)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1759) tensor(1759)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0048) tensor([0.9989])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6766e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.1022) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8119e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.8129) tensor(0.) tensor(0.6503)\n",
      "h_from_s max, min, mean tensor(6.6478) tensor(0.) tensor(0.6596)\n",
      "h_from_s_denoised max, min, mean tensor(6.8175) tensor(0.) tensor(0.6508)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1899) tensor(1899)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0010) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5383e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.1796) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.7155e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.4799) tensor(0.) tensor(0.6564)\n",
      "h_from_s max, min, mean tensor(4.4172) tensor(0.) tensor(0.6507)\n",
      "h_from_s_denoised max, min, mean tensor(4.4824) tensor(0.) tensor(0.6569)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1701) tensor(1701)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0010) tensor([0.9998])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9983e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.9131) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5137e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9085) tensor(0.) tensor(0.6932)\n",
      "h_from_s max, min, mean tensor(5.7938) tensor(0.) tensor(0.7103)\n",
      "h_from_s_denoised max, min, mean tensor(5.9126) tensor(0.) tensor(0.6937)\n",
      "avg nonzero/greaterzero h from book: tensor(1037) tensor(1037)\n",
      "avg nonzero/greaterzero h from s: tensor(1832) tensor(1832)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0023) tensor([0.9992])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4040e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.3162) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0195e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9927) tensor(0.) tensor(0.6372)\n",
      "h_from_s max, min, mean tensor(4.8484) tensor(0.) tensor(0.6512)\n",
      "h_from_s_denoised max, min, mean tensor(4.9963) tensor(0.) tensor(0.6377)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1734) tensor(1734)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0037) tensor([0.9986])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8442e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.6138) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6695e-11) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 43/500 [00:01<00:12, 36.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7645) tensor(0.) tensor(0.6664)\n",
      "h_from_s max, min, mean tensor(5.5866) tensor(0.) tensor(0.6646)\n",
      "h_from_s_denoised max, min, mean tensor(5.7687) tensor(0.) tensor(0.6669)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1712) tensor(1712)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0023) tensor([0.9994])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8801e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.4986) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7445e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4964) tensor(0.) tensor(0.6852)\n",
      "h_from_s max, min, mean tensor(5.2424) tensor(0.) tensor(0.6945)\n",
      "h_from_s_denoised max, min, mean tensor(5.4997) tensor(0.) tensor(0.6857)\n",
      "avg nonzero/greaterzero h from book: tensor(1043) tensor(1043)\n",
      "avg nonzero/greaterzero h from s: tensor(1945) tensor(1945)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1042) tensor(1042)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0063) tensor([0.9984])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7687e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.7651) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6565e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6810) tensor(0.) tensor(0.6567)\n",
      "h_from_s max, min, mean tensor(5.3528) tensor(0.) tensor(0.6561)\n",
      "h_from_s_denoised max, min, mean tensor(5.6853) tensor(0.) tensor(0.6571)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1765) tensor(1765)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0059) tensor([0.9985])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1385e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.1047) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0022) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7431e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1770) tensor(0.) tensor(0.6567)\n",
      "h_from_s max, min, mean tensor(4.9571) tensor(0.) tensor(0.6562)\n",
      "h_from_s_denoised max, min, mean tensor(5.1815) tensor(0.) tensor(0.6572)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1723) tensor(1723)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0021) tensor([0.9995])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6276e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.2189) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0914e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4125) tensor(0.) tensor(0.6460)\n",
      "h_from_s max, min, mean tensor(5.2027) tensor(0.) tensor(0.6370)\n",
      "h_from_s_denoised max, min, mean tensor(5.4157) tensor(0.) tensor(0.6464)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1853) tensor(1853)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0051) tensor([0.9992])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2541e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.4571) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0018) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2662e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3670) tensor(0.) tensor(0.6862)\n",
      "h_from_s max, min, mean tensor(5.1813) tensor(0.) tensor(0.6812)\n",
      "h_from_s_denoised max, min, mean tensor(5.3708) tensor(0.) tensor(0.6867)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1791) tensor(1791)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(998) tensor(998)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0046) tensor([0.9991])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.3387e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.5942) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0020) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.4079e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2084) tensor(0.) tensor(0.6882)\n",
      "h_from_s max, min, mean tensor(5.9842) tensor(0.) tensor(0.6805)\n",
      "h_from_s_denoised max, min, mean tensor(6.2121) tensor(0.) tensor(0.6887)\n",
      "avg nonzero/greaterzero h from book: tensor(1062) tensor(1062)\n",
      "avg nonzero/greaterzero h from s: tensor(1706) tensor(1706)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1061) tensor(1061)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0016) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7711e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.6283) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0023) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2600e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5679) tensor(0.) tensor(0.6094)\n",
      "h_from_s max, min, mean tensor(6.2838) tensor(0.) tensor(0.6085)\n",
      "h_from_s_denoised max, min, mean tensor(6.5726) tensor(0.) tensor(0.6098)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1717) tensor(1717)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0034) tensor([0.9991])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3930e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.5399) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0225e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [00:01<00:12, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9892) tensor(0.) tensor(0.6516)\n",
      "h_from_s max, min, mean tensor(5.8376) tensor(0.) tensor(0.6518)\n",
      "h_from_s_denoised max, min, mean tensor(5.9928) tensor(0.) tensor(0.6521)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1795) tensor(1795)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0010) tensor([0.9998])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7645e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.8447) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9590e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2169) tensor(0.) tensor(0.6642)\n",
      "h_from_s max, min, mean tensor(5.1495) tensor(0.) tensor(0.6709)\n",
      "h_from_s_denoised max, min, mean tensor(5.2203) tensor(0.) tensor(0.6646)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1712) tensor(1712)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0010) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1761e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.0302) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3047e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0415) tensor(0.) tensor(0.6677)\n",
      "h_from_s max, min, mean tensor(5.7967) tensor(0.) tensor(0.6578)\n",
      "h_from_s_denoised max, min, mean tensor(6.0455) tensor(0.) tensor(0.6682)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1699) tensor(1699)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1025) tensor(1025)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0022) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8346e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.8399) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0417e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0962) tensor(0.) tensor(0.6668)\n",
      "h_from_s max, min, mean tensor(4.8579) tensor(0.) tensor(0.6742)\n",
      "h_from_s_denoised max, min, mean tensor(5.1000) tensor(0.) tensor(0.6672)\n",
      "avg nonzero/greaterzero h from book: tensor(995) tensor(995)\n",
      "avg nonzero/greaterzero h from s: tensor(1851) tensor(1851)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0076) tensor([0.9980])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7910e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.6600) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4503e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1078) tensor(0.) tensor(0.6482)\n",
      "h_from_s max, min, mean tensor(5.0886) tensor(0.) tensor(0.6342)\n",
      "h_from_s_denoised max, min, mean tensor(5.1121) tensor(0.) tensor(0.6486)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1642) tensor(1642)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0040) tensor([0.9993])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5840e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.8405) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9678e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3618) tensor(0.) tensor(0.6863)\n",
      "h_from_s max, min, mean tensor(6.4196) tensor(0.) tensor(0.6878)\n",
      "h_from_s_denoised max, min, mean tensor(6.3663) tensor(0.) tensor(0.6868)\n",
      "avg nonzero/greaterzero h from book: tensor(1054) tensor(1054)\n",
      "avg nonzero/greaterzero h from s: tensor(1418) tensor(1418)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1053) tensor(1053)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0008) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4820e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.8251) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0076) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7940e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6869) tensor(0.) tensor(0.6698)\n",
      "h_from_s max, min, mean tensor(5.5033) tensor(0.) tensor(0.6615)\n",
      "h_from_s_denoised max, min, mean tensor(5.6905) tensor(0.) tensor(0.6703)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1680) tensor(1680)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(981) tensor(981)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0021) tensor([0.9997])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3406e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.8307) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9392e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0150) tensor(0.) tensor(0.6502)\n",
      "h_from_s max, min, mean tensor(4.7876) tensor(0.) tensor(0.6632)\n",
      "h_from_s_denoised max, min, mean tensor(5.0187) tensor(0.) tensor(0.6506)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1860) tensor(1860)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0066) tensor([0.9980])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7430e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.7316) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.9978e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 59/500 [00:01<00:12, 34.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5861) tensor(0.) tensor(0.6637)\n",
      "h_from_s max, min, mean tensor(5.4110) tensor(0.) tensor(0.6620)\n",
      "h_from_s_denoised max, min, mean tensor(5.5894) tensor(0.) tensor(0.6641)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1804) tensor(1804)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0024) tensor([0.9995])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4864e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.5341) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4164e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5934) tensor(0.) tensor(0.6443)\n",
      "h_from_s max, min, mean tensor(5.3970) tensor(0.) tensor(0.6562)\n",
      "h_from_s_denoised max, min, mean tensor(5.5969) tensor(0.) tensor(0.6447)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1820) tensor(1820)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0036) tensor([0.9988])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8397e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.7234) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.7594e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6298) tensor(0.) tensor(0.6716)\n",
      "h_from_s max, min, mean tensor(5.6132) tensor(0.) tensor(0.6748)\n",
      "h_from_s_denoised max, min, mean tensor(5.6329) tensor(0.) tensor(0.6721)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1688) tensor(1688)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0019) tensor([0.9995])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2127e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.9168) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4032e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0007) tensor(0.) tensor(0.6230)\n",
      "h_from_s max, min, mean tensor(4.7433) tensor(0.) tensor(0.6296)\n",
      "h_from_s_denoised max, min, mean tensor(5.0040) tensor(0.) tensor(0.6234)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1819) tensor(1819)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0065) tensor([0.9981])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7049e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.6614) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3489e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6285) tensor(0.) tensor(0.6656)\n",
      "h_from_s max, min, mean tensor(5.4677) tensor(0.) tensor(0.6726)\n",
      "h_from_s_denoised max, min, mean tensor(5.6325) tensor(0.) tensor(0.6661)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1798) tensor(1798)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0024) tensor([0.9994])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2260e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.1683) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7133e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4473) tensor(0.) tensor(0.6857)\n",
      "h_from_s max, min, mean tensor(5.0387) tensor(0.) tensor(0.6798)\n",
      "h_from_s_denoised max, min, mean tensor(5.4515) tensor(0.) tensor(0.6862)\n",
      "avg nonzero/greaterzero h from book: tensor(1031) tensor(1031)\n",
      "avg nonzero/greaterzero h from s: tensor(1813) tensor(1813)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1031) tensor(1031)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0182) tensor([0.9956])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7652e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.4291) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.7388e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9897) tensor(0.) tensor(0.6256)\n",
      "h_from_s max, min, mean tensor(5.8426) tensor(0.) tensor(0.6264)\n",
      "h_from_s_denoised max, min, mean tensor(5.9938) tensor(0.) tensor(0.6260)\n",
      "avg nonzero/greaterzero h from book: tensor(973) tensor(973)\n",
      "avg nonzero/greaterzero h from s: tensor(1676) tensor(1676)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0014) tensor([0.9996])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8255e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.4240) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0134e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 67/500 [00:01<00:12, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8048) tensor(0.) tensor(0.6700)\n",
      "h_from_s max, min, mean tensor(4.4416) tensor(0.) tensor(0.6668)\n",
      "h_from_s_denoised max, min, mean tensor(4.8093) tensor(0.) tensor(0.6705)\n",
      "avg nonzero/greaterzero h from book: tensor(1039) tensor(1039)\n",
      "avg nonzero/greaterzero h from s: tensor(1728) tensor(1728)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1037) tensor(1037)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0108) tensor([0.9972])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4751e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.5071) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0030) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.8964e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0676) tensor(0.) tensor(0.6224)\n",
      "h_from_s max, min, mean tensor(5.6239) tensor(0.) tensor(0.6337)\n",
      "h_from_s_denoised max, min, mean tensor(6.0723) tensor(0.) tensor(0.6229)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1872) tensor(1872)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0099) tensor([0.9973])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9205e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.9799) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3172e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0324) tensor(0.) tensor(0.6651)\n",
      "h_from_s max, min, mean tensor(5.8276) tensor(0.) tensor(0.6722)\n",
      "h_from_s_denoised max, min, mean tensor(6.0357) tensor(0.) tensor(0.6656)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1742) tensor(1742)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0041) tensor([0.9988])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.3557e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.8585) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0080) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7916e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.8181) tensor(0.) tensor(0.6597)\n",
      "h_from_s max, min, mean tensor(6.5329) tensor(0.) tensor(0.6557)\n",
      "h_from_s_denoised max, min, mean tensor(6.8226) tensor(0.) tensor(0.6602)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1701) tensor(1701)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1015) tensor(1015)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0031) tensor([0.9993])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9277e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.2550) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3248e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2343) tensor(0.) tensor(0.6505)\n",
      "h_from_s max, min, mean tensor(4.9628) tensor(0.) tensor(0.6463)\n",
      "h_from_s_denoised max, min, mean tensor(5.2369) tensor(0.) tensor(0.6510)\n",
      "avg nonzero/greaterzero h from book: tensor(989) tensor(989)\n",
      "avg nonzero/greaterzero h from s: tensor(1710) tensor(1710)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(989) tensor(989)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0069) tensor([0.9984])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4453e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.7340) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1085e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0014) tensor(0.) tensor(0.6365)\n",
      "h_from_s max, min, mean tensor(4.8600) tensor(0.) tensor(0.6352)\n",
      "h_from_s_denoised max, min, mean tensor(5.0040) tensor(0.) tensor(0.6370)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1731) tensor(1731)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0054) tensor([0.9987])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9691e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.4931) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1110e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0597) tensor(0.) tensor(0.6262)\n",
      "h_from_s max, min, mean tensor(5.4697) tensor(0.) tensor(0.6386)\n",
      "h_from_s_denoised max, min, mean tensor(6.0633) tensor(0.) tensor(0.6267)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1885) tensor(1885)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0193) tensor([0.9946])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0444e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.5484) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0024) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3027e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 75/500 [00:02<00:12, 33.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7653) tensor(0.) tensor(0.6666)\n",
      "h_from_s max, min, mean tensor(6.6051) tensor(0.) tensor(0.6587)\n",
      "h_from_s_denoised max, min, mean tensor(6.7704) tensor(0.) tensor(0.6671)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1632) tensor(1632)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0009) tensor([0.9999])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9818e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.4077) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1157e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6856) tensor(0.) tensor(0.6765)\n",
      "h_from_s max, min, mean tensor(5.3221) tensor(0.) tensor(0.6835)\n",
      "h_from_s_denoised max, min, mean tensor(5.6904) tensor(0.) tensor(0.6770)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1843) tensor(1843)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0086) tensor([0.9978])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0948e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.3634) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0072) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5111e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8627) tensor(0.) tensor(0.5966)\n",
      "h_from_s max, min, mean tensor(4.7446) tensor(0.) tensor(0.6151)\n",
      "h_from_s_denoised max, min, mean tensor(4.8659) tensor(0.) tensor(0.5971)\n",
      "avg nonzero/greaterzero h from book: tensor(956) tensor(956)\n",
      "avg nonzero/greaterzero h from s: tensor(1772) tensor(1772)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(953) tensor(953)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0131) tensor([0.9955])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3640e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.8475) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6013e-11) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7477) tensor(0.) tensor(0.6496)\n",
      "h_from_s max, min, mean tensor(6.2389) tensor(0.) tensor(0.6541)\n",
      "h_from_s_denoised max, min, mean tensor(6.7526) tensor(0.) tensor(0.6501)\n",
      "avg nonzero/greaterzero h from book: tensor(1044) tensor(1044)\n",
      "avg nonzero/greaterzero h from s: tensor(1792) tensor(1792)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1043) tensor(1043)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0141) tensor([0.9961])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3410e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.3036) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.8212e-11) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5438) tensor(0.) tensor(0.6440)\n",
      "h_from_s max, min, mean tensor(4.6673) tensor(0.) tensor(0.6327)\n",
      "h_from_s_denoised max, min, mean tensor(5.5482) tensor(0.) tensor(0.6444)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1891) tensor(1891)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0373) tensor([0.9924])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3993e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.5104) tensor([0.9982])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0029) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3788e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4589) tensor(0.) tensor(0.6697)\n",
      "h_from_s max, min, mean tensor(5.0684) tensor(0.) tensor(0.6661)\n",
      "h_from_s_denoised max, min, mean tensor(5.4633) tensor(0.) tensor(0.6702)\n",
      "avg nonzero/greaterzero h from book: tensor(1035) tensor(1035)\n",
      "avg nonzero/greaterzero h from s: tensor(1786) tensor(1786)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0105) tensor([0.9977])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1854e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.4536) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0536e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1692) tensor(0.) tensor(0.6437)\n",
      "h_from_s max, min, mean tensor(5.8482) tensor(0.) tensor(0.6630)\n",
      "h_from_s_denoised max, min, mean tensor(6.1739) tensor(0.) tensor(0.6442)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1821) tensor(1821)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0142) tensor([0.9958])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6982e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.1114) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6468e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 79/500 [00:02<00:13, 30.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1695) tensor(0.) tensor(0.6213)\n",
      "h_from_s max, min, mean tensor(5.8462) tensor(0.) tensor(0.6260)\n",
      "h_from_s_denoised max, min, mean tensor(6.1729) tensor(0.) tensor(0.6218)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1787) tensor(1787)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0091) tensor([0.9975])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9024e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.3640) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1465e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4007) tensor(0.) tensor(0.6687)\n",
      "h_from_s max, min, mean tensor(5.1066) tensor(0.) tensor(0.6629)\n",
      "h_from_s_denoised max, min, mean tensor(5.4036) tensor(0.) tensor(0.6692)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0038) tensor([0.9994])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7819e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.4475) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4767e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.8677) tensor(0.) tensor(0.6493)\n",
      "h_from_s max, min, mean tensor(5.9701) tensor(0.) tensor(0.6435)\n",
      "h_from_s_denoised max, min, mean tensor(6.8725) tensor(0.) tensor(0.6498)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1864) tensor(1864)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0317) tensor([0.9926])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1441e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.8813) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4948e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8147) tensor(0.) tensor(0.6388)\n",
      "h_from_s max, min, mean tensor(5.2412) tensor(0.) tensor(0.6767)\n",
      "h_from_s_denoised max, min, mean tensor(5.8195) tensor(0.) tensor(0.6392)\n",
      "avg nonzero/greaterzero h from book: tensor(967) tensor(967)\n",
      "avg nonzero/greaterzero h from s: tensor(1914) tensor(1914)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(967) tensor(967)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0223) tensor([0.9927])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6405e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.1714) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2647e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2012) tensor(0.) tensor(0.6572)\n",
      "h_from_s max, min, mean tensor(5.5962) tensor(0.) tensor(0.6622)\n",
      "h_from_s_denoised max, min, mean tensor(6.2049) tensor(0.) tensor(0.6577)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1883) tensor(1883)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0152) tensor([0.9963])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9273e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.4117) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0277e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9391) tensor(0.) tensor(0.6279)\n",
      "h_from_s max, min, mean tensor(5.6152) tensor(0.) tensor(0.6261)\n",
      "h_from_s_denoised max, min, mean tensor(5.9434) tensor(0.) tensor(0.6284)\n",
      "avg nonzero/greaterzero h from book: tensor(974) tensor(974)\n",
      "avg nonzero/greaterzero h from s: tensor(1614) tensor(1614)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(973) tensor(973)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0051) tensor([0.9986])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9563e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.2908) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4697e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 87/500 [00:02<00:13, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4121) tensor(0.) tensor(0.6764)\n",
      "h_from_s max, min, mean tensor(4.8488) tensor(0.) tensor(0.6743)\n",
      "h_from_s_denoised max, min, mean tensor(5.4150) tensor(0.) tensor(0.6769)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1838) tensor(1838)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0166) tensor([0.9963])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6049e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.1236) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3100e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2366) tensor(0.) tensor(0.6056)\n",
      "h_from_s max, min, mean tensor(5.0103) tensor(0.) tensor(0.6145)\n",
      "h_from_s_denoised max, min, mean tensor(5.2397) tensor(0.) tensor(0.6061)\n",
      "avg nonzero/greaterzero h from book: tensor(971) tensor(971)\n",
      "avg nonzero/greaterzero h from s: tensor(1706) tensor(1706)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(967) tensor(967)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0038) tensor([0.9987])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7388e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.3761) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7958e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3749) tensor(0.) tensor(0.6695)\n",
      "h_from_s max, min, mean tensor(6.0297) tensor(0.) tensor(0.6779)\n",
      "h_from_s_denoised max, min, mean tensor(6.3798) tensor(0.) tensor(0.6699)\n",
      "avg nonzero/greaterzero h from book: tensor(1029) tensor(1029)\n",
      "avg nonzero/greaterzero h from s: tensor(1809) tensor(1809)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1029) tensor(1029)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0094) tensor([0.9975])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4187e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.6754) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0290e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2852) tensor(0.) tensor(0.6530)\n",
      "h_from_s max, min, mean tensor(4.9650) tensor(0.) tensor(0.6364)\n",
      "h_from_s_denoised max, min, mean tensor(5.2889) tensor(0.) tensor(0.6534)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1720) tensor(1720)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0092) tensor([0.9985])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7766e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.9327) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5914e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6347) tensor(0.) tensor(0.6430)\n",
      "h_from_s max, min, mean tensor(5.1836) tensor(0.) tensor(0.6353)\n",
      "h_from_s_denoised max, min, mean tensor(5.6390) tensor(0.) tensor(0.6434)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1746) tensor(1746)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0093) tensor([0.9982])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4519e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.4553) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2518e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1290) tensor(0.) tensor(0.6218)\n",
      "h_from_s max, min, mean tensor(5.8809) tensor(0.) tensor(0.6255)\n",
      "h_from_s_denoised max, min, mean tensor(6.1335) tensor(0.) tensor(0.6223)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1695) tensor(1695)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0031) tensor([0.9991])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8550e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.5303) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5337e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.8229) tensor(0.) tensor(0.6326)\n",
      "h_from_s max, min, mean tensor(6.1328) tensor(0.) tensor(0.6475)\n",
      "h_from_s_denoised max, min, mean tensor(6.8271) tensor(0.) tensor(0.6330)\n",
      "avg nonzero/greaterzero h from book: tensor(968) tensor(968)\n",
      "avg nonzero/greaterzero h from s: tensor(1811) tensor(1811)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(968) tensor(968)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0175) tensor([0.9949])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2878e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.4558) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.7144e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 95/500 [00:02<00:12, 32.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6348) tensor(0.) tensor(0.6622)\n",
      "h_from_s max, min, mean tensor(5.2161) tensor(0.) tensor(0.6467)\n",
      "h_from_s_denoised max, min, mean tensor(5.6395) tensor(0.) tensor(0.6627)\n",
      "avg nonzero/greaterzero h from book: tensor(1030) tensor(1030)\n",
      "avg nonzero/greaterzero h from s: tensor(1558) tensor(1558)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1030) tensor(1030)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0057) tensor([0.9990])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0310e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.1731) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5193e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0442) tensor(0.) tensor(0.6749)\n",
      "h_from_s max, min, mean tensor(5.6561) tensor(0.) tensor(0.6786)\n",
      "h_from_s_denoised max, min, mean tensor(6.0486) tensor(0.) tensor(0.6754)\n",
      "avg nonzero/greaterzero h from book: tensor(1038) tensor(1038)\n",
      "avg nonzero/greaterzero h from s: tensor(1827) tensor(1827)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1034) tensor(1034)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0055) tensor([0.9987])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0732e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.5969) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4295e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9074) tensor(0.) tensor(0.6013)\n",
      "h_from_s max, min, mean tensor(5.5431) tensor(0.) tensor(0.6057)\n",
      "h_from_s_denoised max, min, mean tensor(5.9122) tensor(0.) tensor(0.6018)\n",
      "avg nonzero/greaterzero h from book: tensor(948) tensor(948)\n",
      "avg nonzero/greaterzero h from s: tensor(1571) tensor(1571)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(947) tensor(947)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0087) tensor([0.9969])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3408e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.8838) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.5207e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9409) tensor(0.) tensor(0.6599)\n",
      "h_from_s max, min, mean tensor(4.8650) tensor(0.) tensor(0.6637)\n",
      "h_from_s_denoised max, min, mean tensor(4.9447) tensor(0.) tensor(0.6604)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1708) tensor(1708)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0069) tensor([0.9980])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4464e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.9718) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5388e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9180) tensor(0.) tensor(0.6488)\n",
      "h_from_s max, min, mean tensor(5.2335) tensor(0.) tensor(0.6167)\n",
      "h_from_s_denoised max, min, mean tensor(5.9221) tensor(0.) tensor(0.6492)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1679) tensor(1679)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0170) tensor([0.9978])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4064e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.1804) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0027) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7478e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1605) tensor(0.) tensor(0.6826)\n",
      "h_from_s max, min, mean tensor(4.7970) tensor(0.) tensor(0.6958)\n",
      "h_from_s_denoised max, min, mean tensor(5.1653) tensor(0.) tensor(0.6831)\n",
      "avg nonzero/greaterzero h from book: tensor(1033) tensor(1033)\n",
      "avg nonzero/greaterzero h from s: tensor(1869) tensor(1869)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1033) tensor(1033)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0085) tensor([0.9977])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2471e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.8845) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2574e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2011) tensor(0.) tensor(0.6428)\n",
      "h_from_s max, min, mean tensor(4.6656) tensor(0.) tensor(0.6559)\n",
      "h_from_s_denoised max, min, mean tensor(5.2044) tensor(0.) tensor(0.6433)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1803) tensor(1803)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0142) tensor([0.9957])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5902e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.6575) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4520e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 99/500 [00:02<00:12, 33.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7842) tensor(0.) tensor(0.6336)\n",
      "h_from_s max, min, mean tensor(5.2932) tensor(0.) tensor(0.6435)\n",
      "h_from_s_denoised max, min, mean tensor(5.7878) tensor(0.) tensor(0.6341)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1745) tensor(1745)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0255) tensor([0.9923])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0165e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.7093) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0085) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5078e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3408) tensor(0.) tensor(0.6605)\n",
      "h_from_s max, min, mean tensor(4.8415) tensor(0.) tensor(0.6775)\n",
      "h_from_s_denoised max, min, mean tensor(5.3442) tensor(0.) tensor(0.6610)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1787) tensor(1787)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0360) tensor([0.9897])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7616e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.5177) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5584e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2998) tensor(0.) tensor(0.6380)\n",
      "h_from_s max, min, mean tensor(4.7602) tensor(0.) tensor(0.6396)\n",
      "h_from_s_denoised max, min, mean tensor(5.3029) tensor(0.) tensor(0.6384)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1786) tensor(1786)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0307) tensor([0.9912])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9908e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.0293) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3110e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5785) tensor(0.) tensor(0.6441)\n",
      "h_from_s max, min, mean tensor(6.8554) tensor(0.) tensor(0.6488)\n",
      "h_from_s_denoised max, min, mean tensor(7.5843) tensor(0.) tensor(0.6446)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1678) tensor(1678)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0257) tensor([0.9923])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7780e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.9214) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5707e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3764) tensor(0.) tensor(0.6553)\n",
      "h_from_s max, min, mean tensor(5.7780) tensor(0.) tensor(0.6396)\n",
      "h_from_s_denoised max, min, mean tensor(6.3812) tensor(0.) tensor(0.6558)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1688) tensor(1688)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0389) tensor([0.9897])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6656e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.8494) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6149e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1025) tensor(0.) tensor(0.6258)\n",
      "h_from_s max, min, mean tensor(4.8150) tensor(0.) tensor(0.6150)\n",
      "h_from_s_denoised max, min, mean tensor(5.1064) tensor(0.) tensor(0.6263)\n",
      "avg nonzero/greaterzero h from book: tensor(980) tensor(980)\n",
      "avg nonzero/greaterzero h from s: tensor(1598) tensor(1598)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0065) tensor([0.9986])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9287e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.1499) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0029) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.1032e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7306) tensor(0.) tensor(0.6533)\n",
      "h_from_s max, min, mean tensor(5.4298) tensor(0.) tensor(0.6598)\n",
      "h_from_s_denoised max, min, mean tensor(5.7356) tensor(0.) tensor(0.6537)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1809) tensor(1809)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1027) tensor(1027)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0083) tensor([0.9977])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2871e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.1336) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4205e-09) tensor([1.])\n",
      "info for each h directly after learning it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 107/500 [00:03<00:11, 34.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h max, min, mean tensor(7.1634) tensor(0.) tensor(0.6178)\n",
      "h_from_s max, min, mean tensor(5.7801) tensor(0.) tensor(0.6248)\n",
      "h_from_s_denoised max, min, mean tensor(7.1690) tensor(0.) tensor(0.6182)\n",
      "avg nonzero/greaterzero h from book: tensor(960) tensor(960)\n",
      "avg nonzero/greaterzero h from s: tensor(1823) tensor(1823)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(958) tensor(958)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0707) tensor([0.9779])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7499e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(15.6667) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0023) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3538e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4528) tensor(0.) tensor(0.6531)\n",
      "h_from_s max, min, mean tensor(4.8309) tensor(0.) tensor(0.6440)\n",
      "h_from_s_denoised max, min, mean tensor(5.4579) tensor(0.) tensor(0.6536)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1689) tensor(1689)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0211) tensor([0.9952])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4539e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.3961) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6079e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.9520) tensor(0.) tensor(0.6614)\n",
      "h_from_s max, min, mean tensor(5.9598) tensor(0.) tensor(0.6410)\n",
      "h_from_s_denoised max, min, mean tensor(6.9567) tensor(0.) tensor(0.6619)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1621) tensor(1621)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0477) tensor([0.9874])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8128e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(25.9909) tensor([0.9959])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0024) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.2926e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.0728) tensor(0.) tensor(0.6535)\n",
      "h_from_s max, min, mean tensor(6.2490) tensor(0.) tensor(0.6772)\n",
      "h_from_s_denoised max, min, mean tensor(7.0780) tensor(0.) tensor(0.6539)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1823) tensor(1823)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0414) tensor([0.9876])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4969e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.3409) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.8478e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9681) tensor(0.) tensor(0.6386)\n",
      "h_from_s max, min, mean tensor(4.5580) tensor(0.) tensor(0.6246)\n",
      "h_from_s_denoised max, min, mean tensor(4.9710) tensor(0.) tensor(0.6391)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1734) tensor(1734)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(980) tensor(980)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0243) tensor([0.9943])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0466e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.2038) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7653e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5512) tensor(0.) tensor(0.6419)\n",
      "h_from_s max, min, mean tensor(5.1380) tensor(0.) tensor(0.6314)\n",
      "h_from_s_denoised max, min, mean tensor(5.5549) tensor(0.) tensor(0.6423)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1731) tensor(1731)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0197) tensor([0.9954])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3431e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.3471) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9213e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4185) tensor(0.) tensor(0.6669)\n",
      "h_from_s max, min, mean tensor(5.3089) tensor(0.) tensor(0.6589)\n",
      "h_from_s_denoised max, min, mean tensor(5.4231) tensor(0.) tensor(0.6674)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1607) tensor(1607)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0029) tensor([0.9994])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1255e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.6714) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8068e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0106) tensor(0.) tensor(0.6788)\n",
      "h_from_s max, min, mean tensor(5.6910) tensor(0.) tensor(0.6766)\n",
      "h_from_s_denoised max, min, mean tensor(6.0156) tensor(0.) tensor(0.6793)\n",
      "avg nonzero/greaterzero h from book: tensor(1034) tensor(1034)\n",
      "avg nonzero/greaterzero h from s: tensor(1571) tensor(1571)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1032) tensor(1032)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0048) tensor([0.9987])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1709e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.5049) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0085e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 115/500 [00:03<00:10, 35.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3269) tensor(0.) tensor(0.6042)\n",
      "h_from_s max, min, mean tensor(5.9066) tensor(0.) tensor(0.5999)\n",
      "h_from_s_denoised max, min, mean tensor(6.3314) tensor(0.) tensor(0.6046)\n",
      "avg nonzero/greaterzero h from book: tensor(965) tensor(965)\n",
      "avg nonzero/greaterzero h from s: tensor(1699) tensor(1699)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(962) tensor(962)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0070) tensor([0.9984])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4970e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.7410) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0922e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1284) tensor(0.) tensor(0.6538)\n",
      "h_from_s max, min, mean tensor(5.8727) tensor(0.) tensor(0.6636)\n",
      "h_from_s_denoised max, min, mean tensor(6.1318) tensor(0.) tensor(0.6543)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1688) tensor(1688)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0044) tensor([0.9986])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5411e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.6643) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0081) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7676e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9238) tensor(0.) tensor(0.6496)\n",
      "h_from_s max, min, mean tensor(4.4599) tensor(0.) tensor(0.6505)\n",
      "h_from_s_denoised max, min, mean tensor(4.9272) tensor(0.) tensor(0.6501)\n",
      "avg nonzero/greaterzero h from book: tensor(960) tensor(960)\n",
      "avg nonzero/greaterzero h from s: tensor(1706) tensor(1706)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(959) tensor(959)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0747) tensor([0.9775])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3552e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.3544) tensor([0.9974])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0022) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.3359e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7546) tensor(0.) tensor(0.6724)\n",
      "h_from_s max, min, mean tensor(5.8817) tensor(0.) tensor(0.6824)\n",
      "h_from_s_denoised max, min, mean tensor(6.7597) tensor(0.) tensor(0.6729)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1754) tensor(1754)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0275) tensor([0.9919])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1200e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.7697) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7940e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0124) tensor(0.) tensor(0.6393)\n",
      "h_from_s max, min, mean tensor(5.6888) tensor(0.) tensor(0.6544)\n",
      "h_from_s_denoised max, min, mean tensor(6.0165) tensor(0.) tensor(0.6398)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1761) tensor(1761)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0050) tensor([0.9983])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3437e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(5.8669) tensor([0.9998])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3693e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3772) tensor(0.) tensor(0.6270)\n",
      "h_from_s max, min, mean tensor(4.9697) tensor(0.) tensor(0.6267)\n",
      "h_from_s_denoised max, min, mean tensor(5.3807) tensor(0.) tensor(0.6275)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1693) tensor(1693)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0295) tensor([0.9911])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9364e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.4863) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.0767e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5823) tensor(0.) tensor(0.6497)\n",
      "h_from_s max, min, mean tensor(4.9764) tensor(0.) tensor(0.6516)\n",
      "h_from_s_denoised max, min, mean tensor(5.5863) tensor(0.) tensor(0.6502)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1889) tensor(1889)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0201) tensor([0.9956])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4837e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.0439) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4521e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5398) tensor(0.) tensor(0.6477)\n",
      "h_from_s max, min, mean tensor(6.3599) tensor(0.) tensor(0.6612)\n",
      "h_from_s_denoised max, min, mean tensor(6.5449) tensor(0.) tensor(0.6482)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1722) tensor(1722)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(993) tensor(993)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0053) tensor([0.9982])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1547e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.7703) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0749e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 123/500 [00:03<00:10, 35.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8958) tensor(0.) tensor(0.6421)\n",
      "h_from_s max, min, mean tensor(5.4814) tensor(0.) tensor(0.6219)\n",
      "h_from_s_denoised max, min, mean tensor(5.9008) tensor(0.) tensor(0.6425)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1551) tensor(1551)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0145) tensor([0.9966])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5957e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.0605) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.9136e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.9249) tensor(0.) tensor(0.6626)\n",
      "h_from_s max, min, mean tensor(6.4463) tensor(0.) tensor(0.6752)\n",
      "h_from_s_denoised max, min, mean tensor(6.9300) tensor(0.) tensor(0.6631)\n",
      "avg nonzero/greaterzero h from book: tensor(1029) tensor(1029)\n",
      "avg nonzero/greaterzero h from s: tensor(1725) tensor(1725)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1029) tensor(1029)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0148) tensor([0.9956])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9697e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.0828) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0080) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1252e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8165) tensor(0.) tensor(0.6474)\n",
      "h_from_s max, min, mean tensor(5.5104) tensor(0.) tensor(0.6509)\n",
      "h_from_s_denoised max, min, mean tensor(5.8212) tensor(0.) tensor(0.6479)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1641) tensor(1641)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0086) tensor([0.9974])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4500e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.4477) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8224e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3973) tensor(0.) tensor(0.6663)\n",
      "h_from_s max, min, mean tensor(5.1892) tensor(0.) tensor(0.6860)\n",
      "h_from_s_denoised max, min, mean tensor(5.4010) tensor(0.) tensor(0.6668)\n",
      "avg nonzero/greaterzero h from book: tensor(1028) tensor(1028)\n",
      "avg nonzero/greaterzero h from s: tensor(1716) tensor(1716)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1028) tensor(1028)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0090) tensor([0.9969])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6232e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.3195) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0074) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9501e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3671) tensor(0.) tensor(0.6391)\n",
      "h_from_s max, min, mean tensor(4.9990) tensor(0.) tensor(0.6372)\n",
      "h_from_s_denoised max, min, mean tensor(5.3709) tensor(0.) tensor(0.6396)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0061) tensor([0.9986])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9395e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(6.2281) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.8100e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7118) tensor(0.) tensor(0.6373)\n",
      "h_from_s max, min, mean tensor(5.3265) tensor(0.) tensor(0.6414)\n",
      "h_from_s_denoised max, min, mean tensor(5.7153) tensor(0.) tensor(0.6377)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1675) tensor(1675)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0249) tensor([0.9927])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4256e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.1886) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5084e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3671) tensor(0.) tensor(0.6289)\n",
      "h_from_s max, min, mean tensor(4.3613) tensor(0.) tensor(0.5780)\n",
      "h_from_s_denoised max, min, mean tensor(5.3714) tensor(0.) tensor(0.6293)\n",
      "avg nonzero/greaterzero h from book: tensor(966) tensor(966)\n",
      "avg nonzero/greaterzero h from s: tensor(1622) tensor(1622)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(965) tensor(965)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0876) tensor([0.9800])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6569e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(36.6693) tensor([0.9933])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0018) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7432e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3921) tensor(0.) tensor(0.6551)\n",
      "h_from_s max, min, mean tensor(5.8571) tensor(0.) tensor(0.6844)\n",
      "h_from_s_denoised max, min, mean tensor(6.3969) tensor(0.) tensor(0.6556)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1815) tensor(1815)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0379) tensor([0.9879])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2860e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.5843) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0723e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 131/500 [00:03<00:10, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2449) tensor(0.) tensor(0.6773)\n",
      "h_from_s max, min, mean tensor(4.8874) tensor(0.) tensor(0.6783)\n",
      "h_from_s_denoised max, min, mean tensor(5.2494) tensor(0.) tensor(0.6778)\n",
      "avg nonzero/greaterzero h from book: tensor(1014) tensor(1014)\n",
      "avg nonzero/greaterzero h from s: tensor(1711) tensor(1711)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0158) tensor([0.9959])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0652e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.6019) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5601e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3722) tensor(0.) tensor(0.6089)\n",
      "h_from_s max, min, mean tensor(4.9919) tensor(0.) tensor(0.5987)\n",
      "h_from_s_denoised max, min, mean tensor(5.3768) tensor(0.) tensor(0.6093)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1760) tensor(1760)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0117) tensor([0.9975])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5253e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.5056) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.1442e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6055) tensor(0.) tensor(0.6436)\n",
      "h_from_s max, min, mean tensor(5.5361) tensor(0.) tensor(0.6646)\n",
      "h_from_s_denoised max, min, mean tensor(6.6110) tensor(0.) tensor(0.6441)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1794) tensor(1794)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0481) tensor([0.9848])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1481e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.6879) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0834e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4334) tensor(0.) tensor(0.6126)\n",
      "h_from_s max, min, mean tensor(5.8557) tensor(0.) tensor(0.6553)\n",
      "h_from_s_denoised max, min, mean tensor(6.4379) tensor(0.) tensor(0.6130)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1847) tensor(1847)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0283) tensor([0.9896])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7999e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.7350) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9207e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3544) tensor(0.) tensor(0.6651)\n",
      "h_from_s max, min, mean tensor(4.9047) tensor(0.) tensor(0.6529)\n",
      "h_from_s_denoised max, min, mean tensor(5.3588) tensor(0.) tensor(0.6655)\n",
      "avg nonzero/greaterzero h from book: tensor(987) tensor(987)\n",
      "avg nonzero/greaterzero h from s: tensor(1711) tensor(1711)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0177) tensor([0.9964])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6138e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.6729) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6754e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2234) tensor(0.) tensor(0.6662)\n",
      "h_from_s max, min, mean tensor(5.3371) tensor(0.) tensor(0.6823)\n",
      "h_from_s_denoised max, min, mean tensor(6.2278) tensor(0.) tensor(0.6667)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1776) tensor(1776)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0305) tensor([0.9911])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8058e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.5179) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9020e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.8801) tensor(0.) tensor(0.6248)\n",
      "h_from_s max, min, mean tensor(5.8259) tensor(0.) tensor(0.6156)\n",
      "h_from_s_denoised max, min, mean tensor(6.8856) tensor(0.) tensor(0.6252)\n",
      "avg nonzero/greaterzero h from book: tensor(950) tensor(950)\n",
      "avg nonzero/greaterzero h from s: tensor(1673) tensor(1673)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(950) tensor(950)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0361) tensor([0.9903])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0653e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.6384) tensor([0.9982])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0026) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.2755e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6636) tensor(0.) tensor(0.6570)\n",
      "h_from_s max, min, mean tensor(4.7182) tensor(0.) tensor(0.6502)\n",
      "h_from_s_denoised max, min, mean tensor(5.6678) tensor(0.) tensor(0.6575)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1688) tensor(1688)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0516) tensor([0.9861])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4814e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.1241) tensor([0.9981])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9531e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 139/500 [00:04<00:09, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1854) tensor(0.) tensor(0.6422)\n",
      "h_from_s max, min, mean tensor(4.9807) tensor(0.) tensor(0.6537)\n",
      "h_from_s_denoised max, min, mean tensor(5.1888) tensor(0.) tensor(0.6427)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1692) tensor(1692)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0067) tensor([0.9979])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1249e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.1253) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.0337e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6463) tensor(0.) tensor(0.6604)\n",
      "h_from_s max, min, mean tensor(5.1414) tensor(0.) tensor(0.6673)\n",
      "h_from_s_denoised max, min, mean tensor(5.6498) tensor(0.) tensor(0.6609)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1817) tensor(1817)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0156) tensor([0.9962])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7389e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.1405) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9236e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5468) tensor(0.) tensor(0.6727)\n",
      "h_from_s max, min, mean tensor(4.9747) tensor(0.) tensor(0.6701)\n",
      "h_from_s_denoised max, min, mean tensor(5.5505) tensor(0.) tensor(0.6732)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1709) tensor(1709)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0209) tensor([0.9947])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9801e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.3789) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0296e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8562) tensor(0.) tensor(0.6316)\n",
      "h_from_s max, min, mean tensor(5.1842) tensor(0.) tensor(0.6825)\n",
      "h_from_s_denoised max, min, mean tensor(5.8602) tensor(0.) tensor(0.6321)\n",
      "avg nonzero/greaterzero h from book: tensor(970) tensor(970)\n",
      "avg nonzero/greaterzero h from s: tensor(1884) tensor(1884)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0414) tensor([0.9857])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0134e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.3776) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4567e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5442) tensor(0.) tensor(0.6282)\n",
      "h_from_s max, min, mean tensor(4.9994) tensor(0.) tensor(0.6320)\n",
      "h_from_s_denoised max, min, mean tensor(5.5478) tensor(0.) tensor(0.6287)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1664) tensor(1664)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0190) tensor([0.9944])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1111e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.3539) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7764e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0873) tensor(0.) tensor(0.6310)\n",
      "h_from_s max, min, mean tensor(4.6433) tensor(0.) tensor(0.6494)\n",
      "h_from_s_denoised max, min, mean tensor(5.0908) tensor(0.) tensor(0.6315)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1839) tensor(1839)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0205) tensor([0.9939])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8904e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.9170) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4613e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5289) tensor(0.) tensor(0.6673)\n",
      "h_from_s max, min, mean tensor(4.8484) tensor(0.) tensor(0.6354)\n",
      "h_from_s_denoised max, min, mean tensor(5.5322) tensor(0.) tensor(0.6678)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1620) tensor(1620)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0225) tensor([0.9958])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5393e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.8967) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0024) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0383e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4887) tensor(0.) tensor(0.6414)\n",
      "h_from_s max, min, mean tensor(5.7707) tensor(0.) tensor(0.6450)\n",
      "h_from_s_denoised max, min, mean tensor(6.4933) tensor(0.) tensor(0.6419)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1849) tensor(1849)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0324) tensor([0.9916])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5071e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.2798) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.9497e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 147/500 [00:04<00:09, 35.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4252) tensor(0.) tensor(0.6371)\n",
      "h_from_s max, min, mean tensor(4.8396) tensor(0.) tensor(0.6306)\n",
      "h_from_s_denoised max, min, mean tensor(5.4294) tensor(0.) tensor(0.6375)\n",
      "avg nonzero/greaterzero h from book: tensor(956) tensor(956)\n",
      "avg nonzero/greaterzero h from s: tensor(1743) tensor(1743)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(954) tensor(954)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0218) tensor([0.9951])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9440e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.8402) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0027) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.8539e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2506) tensor(0.) tensor(0.6427)\n",
      "h_from_s max, min, mean tensor(5.7571) tensor(0.) tensor(0.6516)\n",
      "h_from_s_denoised max, min, mean tensor(6.2555) tensor(0.) tensor(0.6432)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1771) tensor(1771)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0163) tensor([0.9955])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6090e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.9553) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0065) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5354e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0452) tensor(0.) tensor(0.6232)\n",
      "h_from_s max, min, mean tensor(4.7463) tensor(0.) tensor(0.6252)\n",
      "h_from_s_denoised max, min, mean tensor(5.0486) tensor(0.) tensor(0.6236)\n",
      "avg nonzero/greaterzero h from book: tensor(979) tensor(979)\n",
      "avg nonzero/greaterzero h from s: tensor(1674) tensor(1674)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(978) tensor(978)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0146) tensor([0.9957])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5819e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.9983) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6981e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5371) tensor(0.) tensor(0.6613)\n",
      "h_from_s max, min, mean tensor(4.7952) tensor(0.) tensor(0.6917)\n",
      "h_from_s_denoised max, min, mean tensor(5.5417) tensor(0.) tensor(0.6618)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1819) tensor(1819)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(998) tensor(998)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0451) tensor([0.9850])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0705e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.4645) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1720e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6647) tensor(0.) tensor(0.6813)\n",
      "h_from_s max, min, mean tensor(6.0259) tensor(0.) tensor(0.6958)\n",
      "h_from_s_denoised max, min, mean tensor(6.6692) tensor(0.) tensor(0.6818)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1745) tensor(1745)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0230) tensor([0.9936])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.3078e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.5879) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.9905e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9633) tensor(0.) tensor(0.6193)\n",
      "h_from_s max, min, mean tensor(5.2167) tensor(0.) tensor(0.6485)\n",
      "h_from_s_denoised max, min, mean tensor(5.9681) tensor(0.) tensor(0.6197)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1870) tensor(1870)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0379) tensor([0.9874])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6250e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.6935) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7761e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4993) tensor(0.) tensor(0.6385)\n",
      "h_from_s max, min, mean tensor(4.6928) tensor(0.) tensor(0.6112)\n",
      "h_from_s_denoised max, min, mean tensor(5.5043) tensor(0.) tensor(0.6389)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1658) tensor(1658)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0289) tensor([0.9944])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1839e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.0647) tensor([0.9983])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.7690e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 155/500 [00:04<00:10, 34.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0989) tensor(0.) tensor(0.6313)\n",
      "h_from_s max, min, mean tensor(5.4968) tensor(0.) tensor(0.6552)\n",
      "h_from_s_denoised max, min, mean tensor(6.1024) tensor(0.) tensor(0.6317)\n",
      "avg nonzero/greaterzero h from book: tensor(955) tensor(955)\n",
      "avg nonzero/greaterzero h from s: tensor(1818) tensor(1818)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(955) tensor(955)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0251) tensor([0.9922])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9256e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.4959) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0089) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.6557e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8675) tensor(0.) tensor(0.6626)\n",
      "h_from_s max, min, mean tensor(5.4647) tensor(0.) tensor(0.7055)\n",
      "h_from_s_denoised max, min, mean tensor(5.8724) tensor(0.) tensor(0.6630)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1804) tensor(1804)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0278) tensor([0.9908])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8139e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.7549) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7571e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7322) tensor(0.) tensor(0.6617)\n",
      "h_from_s max, min, mean tensor(5.9151) tensor(0.) tensor(0.6938)\n",
      "h_from_s_denoised max, min, mean tensor(6.7368) tensor(0.) tensor(0.6622)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1865) tensor(1865)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0415) tensor([0.9872])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6888e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.6563) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2649e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2646) tensor(0.) tensor(0.6444)\n",
      "h_from_s max, min, mean tensor(4.8928) tensor(0.) tensor(0.6478)\n",
      "h_from_s_denoised max, min, mean tensor(6.2681) tensor(0.) tensor(0.6449)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1775) tensor(1775)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0814) tensor([0.9757])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2396e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.5376) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0025) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1688e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2701) tensor(0.) tensor(0.6231)\n",
      "h_from_s max, min, mean tensor(4.6182) tensor(0.) tensor(0.6204)\n",
      "h_from_s_denoised max, min, mean tensor(5.2747) tensor(0.) tensor(0.6236)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1661) tensor(1661)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(986) tensor(986)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0698) tensor([0.9767])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1740e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.8259) tensor([0.9972])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0030) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.6587e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7314) tensor(0.) tensor(0.6429)\n",
      "h_from_s max, min, mean tensor(4.9171) tensor(0.) tensor(0.6311)\n",
      "h_from_s_denoised max, min, mean tensor(5.7350) tensor(0.) tensor(0.6434)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1695) tensor(1695)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(989) tensor(989)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0291) tensor([0.9932])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0733e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.6920) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6989e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3950) tensor(0.) tensor(0.6640)\n",
      "h_from_s max, min, mean tensor(4.7175) tensor(0.) tensor(0.6954)\n",
      "h_from_s_denoised max, min, mean tensor(5.3989) tensor(0.) tensor(0.6645)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1833) tensor(1833)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0688) tensor([0.9791])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7180e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.9456) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5531e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 163/500 [00:04<00:09, 35.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1180) tensor(0.) tensor(0.6541)\n",
      "h_from_s max, min, mean tensor(4.6505) tensor(0.) tensor(0.6156)\n",
      "h_from_s_denoised max, min, mean tensor(5.1225) tensor(0.) tensor(0.6546)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1590) tensor(1590)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1025) tensor(1025)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0182) tensor([0.9971])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7798e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.6373) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.6655e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2396) tensor(0.) tensor(0.6341)\n",
      "h_from_s max, min, mean tensor(4.5987) tensor(0.) tensor(0.6265)\n",
      "h_from_s_denoised max, min, mean tensor(5.2436) tensor(0.) tensor(0.6346)\n",
      "avg nonzero/greaterzero h from book: tensor(959) tensor(959)\n",
      "avg nonzero/greaterzero h from s: tensor(1697) tensor(1697)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(959) tensor(959)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0351) tensor([0.9911])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9206e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.0635) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0078) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5929e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7437) tensor(0.) tensor(0.6437)\n",
      "h_from_s max, min, mean tensor(5.3965) tensor(0.) tensor(0.6131)\n",
      "h_from_s_denoised max, min, mean tensor(5.7474) tensor(0.) tensor(0.6441)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1520) tensor(1520)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0113) tensor([0.9981])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1404e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.5466) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.5435e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4410) tensor(0.) tensor(0.6346)\n",
      "h_from_s max, min, mean tensor(5.6712) tensor(0.) tensor(0.6188)\n",
      "h_from_s_denoised max, min, mean tensor(6.4454) tensor(0.) tensor(0.6351)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1688) tensor(1688)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0173) tensor([0.9964])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9830e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.9895) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2564e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4190) tensor(0.) tensor(0.6559)\n",
      "h_from_s max, min, mean tensor(4.7249) tensor(0.) tensor(0.6900)\n",
      "h_from_s_denoised max, min, mean tensor(5.4225) tensor(0.) tensor(0.6564)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1797) tensor(1797)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0442) tensor([0.9850])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3140e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.7466) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4702e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6002) tensor(0.) tensor(0.6513)\n",
      "h_from_s max, min, mean tensor(5.7512) tensor(0.) tensor(0.6376)\n",
      "h_from_s_denoised max, min, mean tensor(6.6054) tensor(0.) tensor(0.6517)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1714) tensor(1714)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0223) tensor([0.9951])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5303e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.0456) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0065) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0108e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7333) tensor(0.) tensor(0.6196)\n",
      "h_from_s max, min, mean tensor(5.8663) tensor(0.) tensor(0.6537)\n",
      "h_from_s_denoised max, min, mean tensor(6.7387) tensor(0.) tensor(0.6201)\n",
      "avg nonzero/greaterzero h from book: tensor(973) tensor(973)\n",
      "avg nonzero/greaterzero h from s: tensor(1798) tensor(1798)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0351) tensor([0.9876])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7988e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.3690) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.7879e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5952) tensor(0.) tensor(0.6355)\n",
      "h_from_s max, min, mean tensor(4.7292) tensor(0.) tensor(0.6803)\n",
      "h_from_s_denoised max, min, mean tensor(5.5991) tensor(0.) tensor(0.6360)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1801) tensor(1801)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0481) tensor([0.9837])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5811e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.2666) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.3543e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 171/500 [00:04<00:09, 34.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3754) tensor(0.) tensor(0.6371)\n",
      "h_from_s max, min, mean tensor(4.7175) tensor(0.) tensor(0.6582)\n",
      "h_from_s_denoised max, min, mean tensor(5.3784) tensor(0.) tensor(0.6376)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1767) tensor(1767)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0204) tensor([0.9930])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5987e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.7736) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0625e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3412) tensor(0.) tensor(0.6361)\n",
      "h_from_s max, min, mean tensor(5.3997) tensor(0.) tensor(0.6324)\n",
      "h_from_s_denoised max, min, mean tensor(6.3452) tensor(0.) tensor(0.6366)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1761) tensor(1761)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0485) tensor([0.9863])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0606e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(25.0790) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7223e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0942) tensor(0.) tensor(0.6846)\n",
      "h_from_s max, min, mean tensor(5.3367) tensor(0.) tensor(0.6620)\n",
      "h_from_s_denoised max, min, mean tensor(6.0984) tensor(0.) tensor(0.6851)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1630) tensor(1630)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0467) tensor([0.9894])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2190e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(38.0917) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6597e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1055) tensor(0.) tensor(0.6286)\n",
      "h_from_s max, min, mean tensor(4.1198) tensor(0.) tensor(0.6198)\n",
      "h_from_s_denoised max, min, mean tensor(5.1099) tensor(0.) tensor(0.6290)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1699) tensor(1699)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(978) tensor(978)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0682) tensor([0.9796])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7331e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.1475) tensor([0.9985])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7944e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4180) tensor(0.) tensor(0.6248)\n",
      "h_from_s max, min, mean tensor(4.5799) tensor(0.) tensor(0.6772)\n",
      "h_from_s_denoised max, min, mean tensor(5.4218) tensor(0.) tensor(0.6252)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1955) tensor(1955)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0350) tensor([0.9875])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9277e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(9.5668) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4209e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6709) tensor(0.) tensor(0.6389)\n",
      "h_from_s max, min, mean tensor(4.8504) tensor(0.) tensor(0.6560)\n",
      "h_from_s_denoised max, min, mean tensor(5.6750) tensor(0.) tensor(0.6393)\n",
      "avg nonzero/greaterzero h from book: tensor(973) tensor(973)\n",
      "avg nonzero/greaterzero h from s: tensor(1719) tensor(1719)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0487) tensor([0.9843])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9846e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.1946) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0083) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8406e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8335) tensor(0.) tensor(0.6673)\n",
      "h_from_s max, min, mean tensor(5.0430) tensor(0.) tensor(0.6510)\n",
      "h_from_s_denoised max, min, mean tensor(5.8384) tensor(0.) tensor(0.6677)\n",
      "avg nonzero/greaterzero h from book: tensor(1014) tensor(1014)\n",
      "avg nonzero/greaterzero h from s: tensor(1750) tensor(1750)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0430) tensor([0.9903])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7279e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.2302) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5279e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 175/500 [00:05<00:09, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5153) tensor(0.) tensor(0.6612)\n",
      "h_from_s max, min, mean tensor(4.9075) tensor(0.) tensor(0.6561)\n",
      "h_from_s_denoised max, min, mean tensor(5.5198) tensor(0.) tensor(0.6617)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1741) tensor(1741)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0247) tensor([0.9940])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7349e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.1202) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4727e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5297) tensor(0.) tensor(0.6367)\n",
      "h_from_s max, min, mean tensor(5.0419) tensor(0.) tensor(0.6675)\n",
      "h_from_s_denoised max, min, mean tensor(5.5334) tensor(0.) tensor(0.6372)\n",
      "avg nonzero/greaterzero h from book: tensor(964) tensor(964)\n",
      "avg nonzero/greaterzero h from s: tensor(1767) tensor(1767)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(963) tensor(963)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0299) tensor([0.9901])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1041e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.4460) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.5346e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0130) tensor(0.) tensor(0.6434)\n",
      "h_from_s max, min, mean tensor(5.0778) tensor(0.) tensor(0.6583)\n",
      "h_from_s_denoised max, min, mean tensor(6.0168) tensor(0.) tensor(0.6439)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1770) tensor(1770)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(998) tensor(998)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0493) tensor([0.9844])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3088e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.8168) tensor([0.9974])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.6473e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6058) tensor(0.) tensor(0.6360)\n",
      "h_from_s max, min, mean tensor(5.1643) tensor(0.) tensor(0.6330)\n",
      "h_from_s_denoised max, min, mean tensor(6.6108) tensor(0.) tensor(0.6364)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1825) tensor(1825)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0813) tensor([0.9784])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1287e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.3875) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0027) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2656e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8652) tensor(0.) tensor(0.6512)\n",
      "h_from_s max, min, mean tensor(4.7472) tensor(0.) tensor(0.6676)\n",
      "h_from_s_denoised max, min, mean tensor(5.8688) tensor(0.) tensor(0.6516)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1733) tensor(1733)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0428) tensor([0.9867])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5609e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.6696) tensor([0.9986])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0773e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(8.0145) tensor(0.) tensor(0.6669)\n",
      "h_from_s max, min, mean tensor(6.9339) tensor(0.) tensor(0.7096)\n",
      "h_from_s_denoised max, min, mean tensor(8.0200) tensor(0.) tensor(0.6674)\n",
      "avg nonzero/greaterzero h from book: tensor(1022) tensor(1022)\n",
      "avg nonzero/greaterzero h from s: tensor(1864) tensor(1864)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0413) tensor([0.9869])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0070e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.7850) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4884e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8969) tensor(0.) tensor(0.6145)\n",
      "h_from_s max, min, mean tensor(4.6383) tensor(0.) tensor(0.6990)\n",
      "h_from_s_denoised max, min, mean tensor(5.9017) tensor(0.) tensor(0.6149)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1845) tensor(1845)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1380) tensor([0.9414])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7443e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.6283) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.6343e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6518) tensor(0.) tensor(0.6430)\n",
      "h_from_s max, min, mean tensor(5.2042) tensor(0.) tensor(0.6034)\n",
      "h_from_s_denoised max, min, mean tensor(5.6553) tensor(0.) tensor(0.6435)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1447) tensor(1447)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 183/500 [00:05<00:09, 34.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0117) tensor([0.9985])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0786e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.3177) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0188e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2975) tensor(0.) tensor(0.6441)\n",
      "h_from_s max, min, mean tensor(4.8042) tensor(0.) tensor(0.6439)\n",
      "h_from_s_denoised max, min, mean tensor(5.3015) tensor(0.) tensor(0.6445)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1732) tensor(1732)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(980) tensor(980)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0206) tensor([0.9947])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0318e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.0684) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0097) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.3214e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7789) tensor(0.) tensor(0.6753)\n",
      "h_from_s max, min, mean tensor(5.0870) tensor(0.) tensor(0.6617)\n",
      "h_from_s_denoised max, min, mean tensor(5.7838) tensor(0.) tensor(0.6758)\n",
      "avg nonzero/greaterzero h from book: tensor(1035) tensor(1035)\n",
      "avg nonzero/greaterzero h from s: tensor(1764) tensor(1764)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1034) tensor(1034)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0388) tensor([0.9910])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0841e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.2526) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2771e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0027) tensor(0.) tensor(0.6233)\n",
      "h_from_s max, min, mean tensor(5.5788) tensor(0.) tensor(0.6233)\n",
      "h_from_s_denoised max, min, mean tensor(6.0065) tensor(0.) tensor(0.6237)\n",
      "avg nonzero/greaterzero h from book: tensor(967) tensor(967)\n",
      "avg nonzero/greaterzero h from s: tensor(1677) tensor(1677)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(966) tensor(966)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0169) tensor([0.9954])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0348e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(15.1166) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9179e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(8.0125) tensor(0.) tensor(0.6693)\n",
      "h_from_s max, min, mean tensor(6.8801) tensor(0.) tensor(0.6732)\n",
      "h_from_s_denoised max, min, mean tensor(8.0189) tensor(0.) tensor(0.6697)\n",
      "avg nonzero/greaterzero h from book: tensor(987) tensor(987)\n",
      "avg nonzero/greaterzero h from s: tensor(1714) tensor(1714)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0322) tensor([0.9920])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1432e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(15.7151) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7275e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7303) tensor(0.) tensor(0.6576)\n",
      "h_from_s max, min, mean tensor(4.9176) tensor(0.) tensor(0.6785)\n",
      "h_from_s_denoised max, min, mean tensor(5.7345) tensor(0.) tensor(0.6581)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1765) tensor(1765)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0407) tensor([0.9872])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4284e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.5083) tensor([0.9986])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.1328e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0993) tensor(0.) tensor(0.6561)\n",
      "h_from_s max, min, mean tensor(4.1876) tensor(0.) tensor(0.6880)\n",
      "h_from_s_denoised max, min, mean tensor(5.1023) tensor(0.) tensor(0.6566)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1844) tensor(1844)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1472) tensor([0.9502])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4077e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.7665) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0422e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/500 [00:05<00:09, 33.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3564) tensor(0.) tensor(0.6616)\n",
      "h_from_s max, min, mean tensor(4.8630) tensor(0.) tensor(0.7028)\n",
      "h_from_s_denoised max, min, mean tensor(5.3605) tensor(0.) tensor(0.6621)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1858) tensor(1858)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0316) tensor([0.9894])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6331e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(10.3658) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0062) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7863e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1079) tensor(0.) tensor(0.6395)\n",
      "h_from_s max, min, mean tensor(4.7371) tensor(0.) tensor(0.6436)\n",
      "h_from_s_denoised max, min, mean tensor(5.1116) tensor(0.) tensor(0.6399)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1642) tensor(1642)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(978) tensor(978)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0184) tensor([0.9943])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0632e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(14.6748) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.9743e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6500) tensor(0.) tensor(0.6164)\n",
      "h_from_s max, min, mean tensor(5.1205) tensor(0.) tensor(0.6595)\n",
      "h_from_s_denoised max, min, mean tensor(5.6533) tensor(0.) tensor(0.6168)\n",
      "avg nonzero/greaterzero h from book: tensor(987) tensor(987)\n",
      "avg nonzero/greaterzero h from s: tensor(1867) tensor(1867)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0206) tensor([0.9923])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7917e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.0043) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2859e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4350) tensor(0.) tensor(0.6665)\n",
      "h_from_s max, min, mean tensor(4.6384) tensor(0.) tensor(0.6943)\n",
      "h_from_s_denoised max, min, mean tensor(5.4395) tensor(0.) tensor(0.6670)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1749) tensor(1749)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0470) tensor([0.9844])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2565e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(23.6712) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4556e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3309) tensor(0.) tensor(0.6654)\n",
      "h_from_s max, min, mean tensor(4.8351) tensor(0.) tensor(0.6835)\n",
      "h_from_s_denoised max, min, mean tensor(5.3351) tensor(0.) tensor(0.6659)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1754) tensor(1754)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0232) tensor([0.9934])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9143e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.0365) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.2498e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3098) tensor(0.) tensor(0.6920)\n",
      "h_from_s max, min, mean tensor(4.7042) tensor(0.) tensor(0.7031)\n",
      "h_from_s_denoised max, min, mean tensor(5.3132) tensor(0.) tensor(0.6925)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1747) tensor(1747)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0251) tensor([0.9930])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1227e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.0231) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3387e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1157) tensor(0.) tensor(0.6448)\n",
      "h_from_s max, min, mean tensor(4.0030) tensor(0.) tensor(0.6401)\n",
      "h_from_s_denoised max, min, mean tensor(5.1199) tensor(0.) tensor(0.6453)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1753) tensor(1753)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(986) tensor(986)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1163) tensor([0.9649])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1391e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(26.7603) tensor([0.9971])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.8592e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 199/500 [00:05<00:08, 34.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9051) tensor(0.) tensor(0.6587)\n",
      "h_from_s max, min, mean tensor(4.9869) tensor(0.) tensor(0.6441)\n",
      "h_from_s_denoised max, min, mean tensor(5.9097) tensor(0.) tensor(0.6591)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1676) tensor(1676)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0643) tensor([0.9826])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6692e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(31.3827) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.9436e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2418) tensor(0.) tensor(0.6425)\n",
      "h_from_s max, min, mean tensor(4.5263) tensor(0.) tensor(0.6734)\n",
      "h_from_s_denoised max, min, mean tensor(5.2469) tensor(0.) tensor(0.6430)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1778) tensor(1778)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0351) tensor([0.9884])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3706e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.3753) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8226e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1040) tensor(0.) tensor(0.6534)\n",
      "h_from_s max, min, mean tensor(5.1041) tensor(0.) tensor(0.6732)\n",
      "h_from_s_denoised max, min, mean tensor(6.1089) tensor(0.) tensor(0.6539)\n",
      "avg nonzero/greaterzero h from book: tensor(1025) tensor(1025)\n",
      "avg nonzero/greaterzero h from s: tensor(1772) tensor(1772)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0418) tensor([0.9869])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4212e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.8351) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2081e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1783) tensor(0.) tensor(0.6706)\n",
      "h_from_s max, min, mean tensor(4.3327) tensor(0.) tensor(0.6555)\n",
      "h_from_s_denoised max, min, mean tensor(5.1811) tensor(0.) tensor(0.6711)\n",
      "avg nonzero/greaterzero h from book: tensor(1032) tensor(1032)\n",
      "avg nonzero/greaterzero h from s: tensor(1758) tensor(1758)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1032) tensor(1032)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0758) tensor([0.9800])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0802e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(32.5914) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0151e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5504) tensor(0.) tensor(0.6569)\n",
      "h_from_s max, min, mean tensor(4.7549) tensor(0.) tensor(0.6601)\n",
      "h_from_s_denoised max, min, mean tensor(5.5551) tensor(0.) tensor(0.6573)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1700) tensor(1700)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0286) tensor([0.9921])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4402e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.4517) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.5618e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1827) tensor(0.) tensor(0.6408)\n",
      "h_from_s max, min, mean tensor(4.9912) tensor(0.) tensor(0.6432)\n",
      "h_from_s_denoised max, min, mean tensor(6.1877) tensor(0.) tensor(0.6413)\n",
      "avg nonzero/greaterzero h from book: tensor(982) tensor(982)\n",
      "avg nonzero/greaterzero h from s: tensor(1755) tensor(1755)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0635) tensor([0.9826])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6432e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(21.4136) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.1769e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9146) tensor(0.) tensor(0.6597)\n",
      "h_from_s max, min, mean tensor(5.1979) tensor(0.) tensor(0.6726)\n",
      "h_from_s_denoised max, min, mean tensor(5.9186) tensor(0.) tensor(0.6602)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1707) tensor(1707)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1027) tensor(1027)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0265) tensor([0.9917])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5221e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.2812) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4448e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1821) tensor(0.) tensor(0.6483)\n",
      "h_from_s max, min, mean tensor(4.5178) tensor(0.) tensor(0.6659)\n",
      "h_from_s_denoised max, min, mean tensor(5.1854) tensor(0.) tensor(0.6487)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1777) tensor(1777)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0344) tensor([0.9893])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4568e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(15.3196) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3612e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 207/500 [00:06<00:08, 35.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6474) tensor(0.) tensor(0.6983)\n",
      "h_from_s max, min, mean tensor(4.8922) tensor(0.) tensor(0.7069)\n",
      "h_from_s_denoised max, min, mean tensor(6.6527) tensor(0.) tensor(0.6988)\n",
      "avg nonzero/greaterzero h from book: tensor(1032) tensor(1032)\n",
      "avg nonzero/greaterzero h from s: tensor(1804) tensor(1804)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1031) tensor(1031)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1307) tensor([0.9621])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2827e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.3853) tensor([0.9963])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.6686e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8552) tensor(0.) tensor(0.6426)\n",
      "h_from_s max, min, mean tensor(4.1355) tensor(0.) tensor(0.6491)\n",
      "h_from_s_denoised max, min, mean tensor(5.8593) tensor(0.) tensor(0.6431)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1824) tensor(1824)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1759) tensor([0.9409])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2032e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.4366) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7860e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4784) tensor(0.) tensor(0.6577)\n",
      "h_from_s max, min, mean tensor(4.9708) tensor(0.) tensor(0.6653)\n",
      "h_from_s_denoised max, min, mean tensor(5.4819) tensor(0.) tensor(0.6582)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1670) tensor(1670)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0355) tensor([0.9898])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9762e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(23.8500) tensor([0.9985])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8312e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4823) tensor(0.) tensor(0.6610)\n",
      "h_from_s max, min, mean tensor(4.6040) tensor(0.) tensor(0.6466)\n",
      "h_from_s_denoised max, min, mean tensor(5.4861) tensor(0.) tensor(0.6615)\n",
      "avg nonzero/greaterzero h from book: tensor(1029) tensor(1029)\n",
      "avg nonzero/greaterzero h from s: tensor(1758) tensor(1758)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1029) tensor(1029)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0426) tensor([0.9897])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5185e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.7103) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3157e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2363) tensor(0.) tensor(0.6744)\n",
      "h_from_s max, min, mean tensor(4.3517) tensor(0.) tensor(0.6731)\n",
      "h_from_s_denoised max, min, mean tensor(5.2400) tensor(0.) tensor(0.6748)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1776) tensor(1776)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0601) tensor([0.9840])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8855e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.4327) tensor([0.9986])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4650e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7955) tensor(0.) tensor(0.6648)\n",
      "h_from_s max, min, mean tensor(4.0610) tensor(0.) tensor(0.6363)\n",
      "h_from_s_denoised max, min, mean tensor(5.7996) tensor(0.) tensor(0.6652)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1843) tensor(1843)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1469) tensor([0.9615])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8900e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(23.1184) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0230e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5279) tensor(0.) tensor(0.6504)\n",
      "h_from_s max, min, mean tensor(4.8389) tensor(0.) tensor(0.6128)\n",
      "h_from_s_denoised max, min, mean tensor(5.5325) tensor(0.) tensor(0.6509)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1634) tensor(1634)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0341) tensor([0.9934])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1269e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.3940) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.9494e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3492) tensor(0.) tensor(0.6468)\n",
      "h_from_s max, min, mean tensor(5.0078) tensor(0.) tensor(0.6696)\n",
      "h_from_s_denoised max, min, mean tensor(5.3534) tensor(0.) tensor(0.6473)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1778) tensor(1778)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0299) tensor([0.9904])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3916e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.4521) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4393e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 215/500 [00:06<00:07, 36.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9928) tensor(0.) tensor(0.6503)\n",
      "h_from_s max, min, mean tensor(4.3503) tensor(0.) tensor(0.6704)\n",
      "h_from_s_denoised max, min, mean tensor(5.9976) tensor(0.) tensor(0.6508)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1807) tensor(1807)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1217) tensor([0.9596])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1387e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(28.8695) tensor([0.9973])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5440e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9998) tensor(0.) tensor(0.6464)\n",
      "h_from_s max, min, mean tensor(5.2813) tensor(0.) tensor(0.6485)\n",
      "h_from_s_denoised max, min, mean tensor(6.0043) tensor(0.) tensor(0.6469)\n",
      "avg nonzero/greaterzero h from book: tensor(995) tensor(995)\n",
      "avg nonzero/greaterzero h from s: tensor(1843) tensor(1843)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0331) tensor([0.9922])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6249e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.2679) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9966e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8058) tensor(0.) tensor(0.6644)\n",
      "h_from_s max, min, mean tensor(4.0442) tensor(0.) tensor(0.5905)\n",
      "h_from_s_denoised max, min, mean tensor(4.8096) tensor(0.) tensor(0.6649)\n",
      "avg nonzero/greaterzero h from book: tensor(1042) tensor(1042)\n",
      "avg nonzero/greaterzero h from s: tensor(1563) tensor(1563)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1040) tensor(1040)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0580) tensor([0.9891])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6760e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(39.2378) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4216e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2965) tensor(0.) tensor(0.6264)\n",
      "h_from_s max, min, mean tensor(4.8181) tensor(0.) tensor(0.6945)\n",
      "h_from_s_denoised max, min, mean tensor(6.3005) tensor(0.) tensor(0.6268)\n",
      "avg nonzero/greaterzero h from book: tensor(971) tensor(971)\n",
      "avg nonzero/greaterzero h from s: tensor(1849) tensor(1849)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(970) tensor(970)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1187) tensor([0.9546])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8013e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(21.8268) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5163e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5932) tensor(0.) tensor(0.6696)\n",
      "h_from_s max, min, mean tensor(5.4891) tensor(0.) tensor(0.6913)\n",
      "h_from_s_denoised max, min, mean tensor(6.5985) tensor(0.) tensor(0.6700)\n",
      "avg nonzero/greaterzero h from book: tensor(982) tensor(982)\n",
      "avg nonzero/greaterzero h from s: tensor(1741) tensor(1741)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0672) tensor([0.9803])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8021e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.0443) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0393e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7124) tensor(0.) tensor(0.6486)\n",
      "h_from_s max, min, mean tensor(5.1893) tensor(0.) tensor(0.6667)\n",
      "h_from_s_denoised max, min, mean tensor(5.7171) tensor(0.) tensor(0.6491)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1765) tensor(1765)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0187) tensor([0.9945])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5833e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(11.8340) tensor([0.9996])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.8402e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1590) tensor(0.) tensor(0.6528)\n",
      "h_from_s max, min, mean tensor(4.7979) tensor(0.) tensor(0.6858)\n",
      "h_from_s_denoised max, min, mean tensor(5.1623) tensor(0.) tensor(0.6533)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1746) tensor(1746)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0276) tensor([0.9904])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4188e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(23.0051) tensor([0.9986])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4952e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5470) tensor(0.) tensor(0.6717)\n",
      "h_from_s max, min, mean tensor(4.9062) tensor(0.) tensor(0.6914)\n",
      "h_from_s_denoised max, min, mean tensor(5.5503) tensor(0.) tensor(0.6722)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1783) tensor(1783)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0438) tensor([0.9873])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0865e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.6175) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0075) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7395e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 223/500 [00:06<00:07, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4916) tensor(0.) tensor(0.6646)\n",
      "h_from_s max, min, mean tensor(4.6368) tensor(0.) tensor(0.6669)\n",
      "h_from_s_denoised max, min, mean tensor(5.4959) tensor(0.) tensor(0.6651)\n",
      "avg nonzero/greaterzero h from book: tensor(1015) tensor(1015)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1014) tensor(1014)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0440) tensor([0.9876])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5576e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.9945) tensor([0.9985])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8436e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8645) tensor(0.) tensor(0.6281)\n",
      "h_from_s max, min, mean tensor(4.6047) tensor(0.) tensor(0.6318)\n",
      "h_from_s_denoised max, min, mean tensor(5.8692) tensor(0.) tensor(0.6285)\n",
      "avg nonzero/greaterzero h from book: tensor(969) tensor(969)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(969) tensor(969)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0802) tensor([0.9758])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2056e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(39.9242) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.1400e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4489) tensor(0.) tensor(0.6774)\n",
      "h_from_s max, min, mean tensor(5.6131) tensor(0.) tensor(0.6814)\n",
      "h_from_s_denoised max, min, mean tensor(6.4542) tensor(0.) tensor(0.6779)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1778) tensor(1778)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0402) tensor([0.9895])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7156e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.1186) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3642e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7208) tensor(0.) tensor(0.6689)\n",
      "h_from_s max, min, mean tensor(5.2404) tensor(0.) tensor(0.6845)\n",
      "h_from_s_denoised max, min, mean tensor(5.7255) tensor(0.) tensor(0.6694)\n",
      "avg nonzero/greaterzero h from book: tensor(1036) tensor(1036)\n",
      "avg nonzero/greaterzero h from s: tensor(1686) tensor(1686)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0177) tensor([0.9944])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9004e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.2289) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4398e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4682) tensor(0.) tensor(0.6896)\n",
      "h_from_s max, min, mean tensor(5.2912) tensor(0.) tensor(0.6782)\n",
      "h_from_s_denoised max, min, mean tensor(5.4726) tensor(0.) tensor(0.6901)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1510) tensor(1510)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0071) tensor([0.9984])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.5291e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.0536) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0080) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5256e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3830) tensor(0.) tensor(0.6342)\n",
      "h_from_s max, min, mean tensor(4.6520) tensor(0.) tensor(0.7139)\n",
      "h_from_s_denoised max, min, mean tensor(5.3876) tensor(0.) tensor(0.6346)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1883) tensor(1883)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0597) tensor([0.9777])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1536e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.5772) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6667e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7506) tensor(0.) tensor(0.6600)\n",
      "h_from_s max, min, mean tensor(5.1493) tensor(0.) tensor(0.6638)\n",
      "h_from_s_denoised max, min, mean tensor(5.7560) tensor(0.) tensor(0.6605)\n",
      "avg nonzero/greaterzero h from book: tensor(990) tensor(990)\n",
      "avg nonzero/greaterzero h from s: tensor(1740) tensor(1740)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0328) tensor([0.9910])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9828e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.2184) tensor([0.9993])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3101e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1381) tensor(0.) tensor(0.6423)\n",
      "h_from_s max, min, mean tensor(4.3568) tensor(0.) tensor(0.6468)\n",
      "h_from_s_denoised max, min, mean tensor(5.1424) tensor(0.) tensor(0.6427)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0503) tensor([0.9858])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2968e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.6355) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.7251e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 231/500 [00:06<00:07, 36.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1645) tensor(0.) tensor(0.6730)\n",
      "h_from_s max, min, mean tensor(4.6126) tensor(0.) tensor(0.6917)\n",
      "h_from_s_denoised max, min, mean tensor(5.1685) tensor(0.) tensor(0.6735)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1774) tensor(1774)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0489) tensor([0.9857])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7334e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(19.3058) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4260e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8181) tensor(0.) tensor(0.6578)\n",
      "h_from_s max, min, mean tensor(4.4743) tensor(0.) tensor(0.6996)\n",
      "h_from_s_denoised max, min, mean tensor(4.8231) tensor(0.) tensor(0.6583)\n",
      "avg nonzero/greaterzero h from book: tensor(1010) tensor(1010)\n",
      "avg nonzero/greaterzero h from s: tensor(1840) tensor(1840)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0441) tensor([0.9846])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6484e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.6385) tensor([0.9994])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8636e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9512) tensor(0.) tensor(0.6397)\n",
      "h_from_s max, min, mean tensor(4.8899) tensor(0.) tensor(0.6636)\n",
      "h_from_s_denoised max, min, mean tensor(5.9562) tensor(0.) tensor(0.6402)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1756) tensor(1756)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0674) tensor([0.9775])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0913e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(26.8507) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5093e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8970) tensor(0.) tensor(0.6416)\n",
      "h_from_s max, min, mean tensor(4.8176) tensor(0.) tensor(0.6713)\n",
      "h_from_s_denoised max, min, mean tensor(5.9007) tensor(0.) tensor(0.6421)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1796) tensor(1796)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(976) tensor(976)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0772) tensor([0.9760])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3196e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.6929) tensor([0.9981])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2571e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0046) tensor(0.) tensor(0.6551)\n",
      "h_from_s max, min, mean tensor(4.8460) tensor(0.) tensor(0.6507)\n",
      "h_from_s_denoised max, min, mean tensor(5.0085) tensor(0.) tensor(0.6555)\n",
      "avg nonzero/greaterzero h from book: tensor(1025) tensor(1025)\n",
      "avg nonzero/greaterzero h from s: tensor(1565) tensor(1565)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0243) tensor([0.9924])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2671e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(47.3047) tensor([0.9951])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8622e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1829) tensor(0.) tensor(0.6399)\n",
      "h_from_s max, min, mean tensor(4.9689) tensor(0.) tensor(0.6677)\n",
      "h_from_s_denoised max, min, mean tensor(5.1862) tensor(0.) tensor(0.6404)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1693) tensor(1693)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0279) tensor([0.9901])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3305e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(27.1179) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0090) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0913e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5361) tensor(0.) tensor(0.6796)\n",
      "h_from_s max, min, mean tensor(4.0917) tensor(0.) tensor(0.6512)\n",
      "h_from_s_denoised max, min, mean tensor(5.5409) tensor(0.) tensor(0.6801)\n",
      "avg nonzero/greaterzero h from book: tensor(1035) tensor(1035)\n",
      "avg nonzero/greaterzero h from s: tensor(1737) tensor(1737)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1034) tensor(1034)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1430) tensor([0.9594])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8683e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(61.3876) tensor([0.9944])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2166e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1230) tensor(0.) tensor(0.6432)\n",
      "h_from_s max, min, mean tensor(4.1951) tensor(0.) tensor(0.6390)\n",
      "h_from_s_denoised max, min, mean tensor(5.1274) tensor(0.) tensor(0.6436)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1667) tensor(1667)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1501) tensor([0.9480])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1309e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(55.9294) tensor([0.9943])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0416e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 239/500 [00:06<00:07, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5486) tensor(0.) tensor(0.6509)\n",
      "h_from_s max, min, mean tensor(4.7844) tensor(0.) tensor(0.6105)\n",
      "h_from_s_denoised max, min, mean tensor(5.5531) tensor(0.) tensor(0.6514)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1528) tensor(1528)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0603) tensor([0.9849])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5061e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(48.0537) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4015e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6746) tensor(0.) tensor(0.6480)\n",
      "h_from_s max, min, mean tensor(5.0819) tensor(0.) tensor(0.6610)\n",
      "h_from_s_denoised max, min, mean tensor(5.6800) tensor(0.) tensor(0.6485)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1689) tensor(1689)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0250) tensor([0.9923])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5857e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(18.2064) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3068e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4600) tensor(0.) tensor(0.6568)\n",
      "h_from_s max, min, mean tensor(4.4290) tensor(0.) tensor(0.6397)\n",
      "h_from_s_denoised max, min, mean tensor(5.4638) tensor(0.) tensor(0.6573)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1675) tensor(1675)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0553) tensor([0.9851])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5516e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.9099) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6797e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9724) tensor(0.) tensor(0.6681)\n",
      "h_from_s max, min, mean tensor(5.2849) tensor(0.) tensor(0.6746)\n",
      "h_from_s_denoised max, min, mean tensor(5.9771) tensor(0.) tensor(0.6686)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1607) tensor(1607)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1017) tensor(1017)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0319) tensor([0.9904])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1867e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(43.5155) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4800e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5404) tensor(0.) tensor(0.6764)\n",
      "h_from_s max, min, mean tensor(5.3441) tensor(0.) tensor(0.7138)\n",
      "h_from_s_denoised max, min, mean tensor(5.5439) tensor(0.) tensor(0.6768)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1674) tensor(1674)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0439) tensor([0.9849])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6311e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(42.1241) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0076) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8805e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6250) tensor(0.) tensor(0.6504)\n",
      "h_from_s max, min, mean tensor(5.4291) tensor(0.) tensor(0.6174)\n",
      "h_from_s_denoised max, min, mean tensor(6.6302) tensor(0.) tensor(0.6509)\n",
      "avg nonzero/greaterzero h from book: tensor(965) tensor(965)\n",
      "avg nonzero/greaterzero h from s: tensor(1584) tensor(1584)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(965) tensor(965)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0759) tensor([0.9801])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7098e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(79.9792) tensor([0.9933])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.5657e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1841) tensor(0.) tensor(0.6712)\n",
      "h_from_s max, min, mean tensor(4.8523) tensor(0.) tensor(0.6969)\n",
      "h_from_s_denoised max, min, mean tensor(6.1893) tensor(0.) tensor(0.6717)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1780) tensor(1780)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1160) tensor([0.9624])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6926e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(35.4978) tensor([0.9972])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4275e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4639) tensor(0.) tensor(0.6589)\n",
      "h_from_s max, min, mean tensor(4.8178) tensor(0.) tensor(0.6503)\n",
      "h_from_s_denoised max, min, mean tensor(5.4685) tensor(0.) tensor(0.6594)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1670) tensor(1670)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0398) tensor([0.9896])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7580e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(33.9253) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9277e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 247/500 [00:07<00:06, 36.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5803) tensor(0.) tensor(0.6378)\n",
      "h_from_s max, min, mean tensor(5.4873) tensor(0.) tensor(0.6410)\n",
      "h_from_s_denoised max, min, mean tensor(6.5847) tensor(0.) tensor(0.6383)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1711) tensor(1711)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0713) tensor([0.9771])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0889e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(34.7832) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4646e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6128) tensor(0.) tensor(0.6361)\n",
      "h_from_s max, min, mean tensor(5.0622) tensor(0.) tensor(0.6450)\n",
      "h_from_s_denoised max, min, mean tensor(5.6164) tensor(0.) tensor(0.6366)\n",
      "avg nonzero/greaterzero h from book: tensor(1031) tensor(1031)\n",
      "avg nonzero/greaterzero h from s: tensor(1685) tensor(1685)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1030) tensor(1030)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0174) tensor([0.9940])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0412e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.4092) tensor([0.9991])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0686e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3258) tensor(0.) tensor(0.6513)\n",
      "h_from_s max, min, mean tensor(5.6143) tensor(0.) tensor(0.6393)\n",
      "h_from_s_denoised max, min, mean tensor(6.3295) tensor(0.) tensor(0.6517)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1672) tensor(1672)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0546) tensor([0.9849])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5109e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(42.7468) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0087) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.9823e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5722) tensor(0.) tensor(0.6814)\n",
      "h_from_s max, min, mean tensor(4.4242) tensor(0.) tensor(0.6922)\n",
      "h_from_s_denoised max, min, mean tensor(5.5755) tensor(0.) tensor(0.6818)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1832) tensor(1832)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1066) tensor([0.9707])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0049e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(29.6780) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0076) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8393e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2882) tensor(0.) tensor(0.6397)\n",
      "h_from_s max, min, mean tensor(4.6345) tensor(0.) tensor(0.7397)\n",
      "h_from_s_denoised max, min, mean tensor(5.2916) tensor(0.) tensor(0.6401)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1917) tensor(1917)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0536) tensor([0.9787])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8242e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(12.1995) tensor([0.9995])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0094) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.6373e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0450) tensor(0.) tensor(0.6338)\n",
      "h_from_s max, min, mean tensor(5.2207) tensor(0.) tensor(0.6841)\n",
      "h_from_s_denoised max, min, mean tensor(6.0489) tensor(0.) tensor(0.6343)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1771) tensor(1771)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0668) tensor([0.9757])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9712e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(29.5627) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0410e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4460) tensor(0.) tensor(0.6556)\n",
      "h_from_s max, min, mean tensor(5.9992) tensor(0.) tensor(0.6220)\n",
      "h_from_s_denoised max, min, mean tensor(6.4505) tensor(0.) tensor(0.6560)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1520) tensor(1520)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0285) tensor([0.9934])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3179e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(58.6217) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8575e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4022) tensor(0.) tensor(0.6609)\n",
      "h_from_s max, min, mean tensor(3.9455) tensor(0.) tensor(0.6210)\n",
      "h_from_s_denoised max, min, mean tensor(5.4058) tensor(0.) tensor(0.6614)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1801) tensor(1801)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2072) tensor([0.9389])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7445e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(30.3024) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.4679e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 255/500 [00:07<00:06, 36.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9075) tensor(0.) tensor(0.6714)\n",
      "h_from_s max, min, mean tensor(4.0445) tensor(0.) tensor(0.7145)\n",
      "h_from_s_denoised max, min, mean tensor(4.9107) tensor(0.) tensor(0.6719)\n",
      "avg nonzero/greaterzero h from book: tensor(1052) tensor(1052)\n",
      "avg nonzero/greaterzero h from s: tensor(1780) tensor(1780)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1050) tensor(1050)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1189) tensor([0.9582])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4223e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(32.6813) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0075) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2050e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2661) tensor(0.) tensor(0.6111)\n",
      "h_from_s max, min, mean tensor(4.4483) tensor(0.) tensor(0.6450)\n",
      "h_from_s_denoised max, min, mean tensor(5.2690) tensor(0.) tensor(0.6115)\n",
      "avg nonzero/greaterzero h from book: tensor(964) tensor(964)\n",
      "avg nonzero/greaterzero h from s: tensor(1687) tensor(1687)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(963) tensor(963)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0611) tensor([0.9759])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3004e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(43.9416) tensor([0.9981])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0087) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.7722e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3052) tensor(0.) tensor(0.6406)\n",
      "h_from_s max, min, mean tensor(4.7632) tensor(0.) tensor(0.6297)\n",
      "h_from_s_denoised max, min, mean tensor(5.3091) tensor(0.) tensor(0.6411)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1578) tensor(1578)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0409) tensor([0.9869])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0137e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(31.2643) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0547e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9571) tensor(0.) tensor(0.6701)\n",
      "h_from_s max, min, mean tensor(3.6520) tensor(0.) tensor(0.6914)\n",
      "h_from_s_denoised max, min, mean tensor(5.9612) tensor(0.) tensor(0.6706)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1864) tensor(1864)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2037) tensor([0.9362])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6830e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(31.3432) tensor([0.9974])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4034e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1450) tensor(0.) tensor(0.6528)\n",
      "h_from_s max, min, mean tensor(5.4049) tensor(0.) tensor(0.6721)\n",
      "h_from_s_denoised max, min, mean tensor(6.1495) tensor(0.) tensor(0.6533)\n",
      "avg nonzero/greaterzero h from book: tensor(1010) tensor(1010)\n",
      "avg nonzero/greaterzero h from s: tensor(1776) tensor(1776)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0425) tensor([0.9869])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6571e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(23.7968) tensor([0.9986])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0062) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.7591e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2404) tensor(0.) tensor(0.6441)\n",
      "h_from_s max, min, mean tensor(4.8586) tensor(0.) tensor(0.6740)\n",
      "h_from_s_denoised max, min, mean tensor(5.2448) tensor(0.) tensor(0.6446)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0162) tensor([0.9945])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6197e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(8.9032) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0083e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9626) tensor(0.) tensor(0.6247)\n",
      "h_from_s max, min, mean tensor(5.1484) tensor(0.) tensor(0.6657)\n",
      "h_from_s_denoised max, min, mean tensor(5.9660) tensor(0.) tensor(0.6251)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1674) tensor(1674)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0493) tensor([0.9815])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7007e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(35.8676) tensor([0.9969])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.7081e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4848) tensor(0.) tensor(0.6664)\n",
      "h_from_s max, min, mean tensor(5.4666) tensor(0.) tensor(0.6830)\n",
      "h_from_s_denoised max, min, mean tensor(6.4896) tensor(0.) tensor(0.6669)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1804) tensor(1804)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0682) tensor([0.9805])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5606e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(20.7012) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0086) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2643e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 263/500 [00:07<00:06, 36.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2813) tensor(0.) tensor(0.6838)\n",
      "h_from_s max, min, mean tensor(4.9075) tensor(0.) tensor(0.6792)\n",
      "h_from_s_denoised max, min, mean tensor(6.2858) tensor(0.) tensor(0.6843)\n",
      "avg nonzero/greaterzero h from book: tensor(1015) tensor(1015)\n",
      "avg nonzero/greaterzero h from s: tensor(1782) tensor(1782)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0747) tensor([0.9811])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2167e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(21.9504) tensor([0.9978])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.9855e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4638) tensor(0.) tensor(0.6285)\n",
      "h_from_s max, min, mean tensor(4.5955) tensor(0.) tensor(0.6403)\n",
      "h_from_s_denoised max, min, mean tensor(5.4675) tensor(0.) tensor(0.6290)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1724) tensor(1724)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0930) tensor([0.9687])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8260e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(40.4580) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.5862e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9232) tensor(0.) tensor(0.6678)\n",
      "h_from_s max, min, mean tensor(3.6875) tensor(0.) tensor(0.5873)\n",
      "h_from_s_denoised max, min, mean tensor(5.9271) tensor(0.) tensor(0.6683)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1624) tensor(1624)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1445) tensor([0.9669])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8971e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(64.2366) tensor([0.9921])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3879e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.7609) tensor(0.) tensor(0.6488)\n",
      "h_from_s max, min, mean tensor(4.5625) tensor(0.) tensor(0.6570)\n",
      "h_from_s_denoised max, min, mean tensor(4.7651) tensor(0.) tensor(0.6493)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1699) tensor(1699)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0419) tensor([0.9864])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3718e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(31.7661) tensor([0.9976])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.7815e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2633) tensor(0.) tensor(0.6537)\n",
      "h_from_s max, min, mean tensor(4.7835) tensor(0.) tensor(0.6556)\n",
      "h_from_s_denoised max, min, mean tensor(5.2669) tensor(0.) tensor(0.6541)\n",
      "avg nonzero/greaterzero h from book: tensor(997) tensor(997)\n",
      "avg nonzero/greaterzero h from s: tensor(1671) tensor(1671)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0235) tensor([0.9932])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3189e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(21.7286) tensor([0.9972])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0930e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2106) tensor(0.) tensor(0.6498)\n",
      "h_from_s max, min, mean tensor(4.6611) tensor(0.) tensor(0.6781)\n",
      "h_from_s_denoised max, min, mean tensor(5.2144) tensor(0.) tensor(0.6503)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1851) tensor(1851)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0954) tensor([0.9680])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0294e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.1314) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3057e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9243) tensor(0.) tensor(0.6311)\n",
      "h_from_s max, min, mean tensor(4.6767) tensor(0.) tensor(0.6144)\n",
      "h_from_s_denoised max, min, mean tensor(5.9289) tensor(0.) tensor(0.6316)\n",
      "avg nonzero/greaterzero h from book: tensor(974) tensor(974)\n",
      "avg nonzero/greaterzero h from s: tensor(1609) tensor(1609)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(974) tensor(974)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0444) tensor([0.9881])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4860e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(46.3005) tensor([0.9958])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5179e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2441) tensor(0.) tensor(0.6827)\n",
      "h_from_s max, min, mean tensor(4.1954) tensor(0.) tensor(0.6826)\n",
      "h_from_s_denoised max, min, mean tensor(5.2467) tensor(0.) tensor(0.6832)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1747) tensor(1747)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1020) tensor([0.9701])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8493e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(41.4087) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.8572e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 271/500 [00:07<00:06, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4903) tensor(0.) tensor(0.6242)\n",
      "h_from_s max, min, mean tensor(4.7303) tensor(0.) tensor(0.6468)\n",
      "h_from_s_denoised max, min, mean tensor(5.4943) tensor(0.) tensor(0.6246)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1703) tensor(1703)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0539) tensor([0.9809])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6158e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(44.1550) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.4873e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.7258) tensor(0.) tensor(0.6300)\n",
      "h_from_s max, min, mean tensor(3.9854) tensor(0.) tensor(0.6632)\n",
      "h_from_s_denoised max, min, mean tensor(4.7293) tensor(0.) tensor(0.6305)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1782) tensor(1782)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0683) tensor([0.9754])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9566e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(35.8239) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0090) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6899e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4583) tensor(0.) tensor(0.6506)\n",
      "h_from_s max, min, mean tensor(4.7489) tensor(0.) tensor(0.6899)\n",
      "h_from_s_denoised max, min, mean tensor(5.4618) tensor(0.) tensor(0.6510)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1829) tensor(1829)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0298) tensor([0.9899])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2628e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(17.7258) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0068) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.5931e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7000) tensor(0.) tensor(0.6822)\n",
      "h_from_s max, min, mean tensor(4.5603) tensor(0.) tensor(0.6401)\n",
      "h_from_s_denoised max, min, mean tensor(6.7048) tensor(0.) tensor(0.6827)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1785) tensor(1785)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1489) tensor([0.9652])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1235e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(30.1357) tensor([0.9972])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.1399e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2833) tensor(0.) tensor(0.6678)\n",
      "h_from_s max, min, mean tensor(4.4361) tensor(0.) tensor(0.7083)\n",
      "h_from_s_denoised max, min, mean tensor(5.2874) tensor(0.) tensor(0.6682)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1764) tensor(1764)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0752) tensor([0.9751])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6787e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(34.3982) tensor([0.9971])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1618e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4734) tensor(0.) tensor(0.6110)\n",
      "h_from_s max, min, mean tensor(3.5590) tensor(0.) tensor(0.5147)\n",
      "h_from_s_denoised max, min, mean tensor(5.4768) tensor(0.) tensor(0.6114)\n",
      "avg nonzero/greaterzero h from book: tensor(980) tensor(980)\n",
      "avg nonzero/greaterzero h from s: tensor(1709) tensor(1709)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2327) tensor([0.9382])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5208e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(59.2851) tensor([0.9936])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.3311e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2087) tensor(0.) tensor(0.6367)\n",
      "h_from_s max, min, mean tensor(3.5356) tensor(0.) tensor(0.5429)\n",
      "h_from_s_denoised max, min, mean tensor(5.2124) tensor(0.) tensor(0.6372)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1666) tensor(1666)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3376) tensor([0.8805])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8167e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(65.9367) tensor([0.9837])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1169e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9481) tensor(0.) tensor(0.6581)\n",
      "h_from_s max, min, mean tensor(4.2312) tensor(0.) tensor(0.6816)\n",
      "h_from_s_denoised max, min, mean tensor(5.9527) tensor(0.) tensor(0.6585)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1811) tensor(1811)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1766) tensor([0.9399])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6092e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(39.8921) tensor([0.9963])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5242e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 279/500 [00:07<00:05, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0728) tensor(0.) tensor(0.6668)\n",
      "h_from_s max, min, mean tensor(4.4593) tensor(0.) tensor(0.6885)\n",
      "h_from_s_denoised max, min, mean tensor(5.0757) tensor(0.) tensor(0.6673)\n",
      "avg nonzero/greaterzero h from book: tensor(1015) tensor(1015)\n",
      "avg nonzero/greaterzero h from s: tensor(1847) tensor(1847)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1014) tensor(1014)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0579) tensor([0.9827])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6158e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(16.5832) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8884e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2335) tensor(0.) tensor(0.6619)\n",
      "h_from_s max, min, mean tensor(5.2450) tensor(0.) tensor(0.6424)\n",
      "h_from_s_denoised max, min, mean tensor(6.2378) tensor(0.) tensor(0.6623)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1710) tensor(1710)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0714) tensor([0.9818])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6686e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(44.6631) tensor([0.9969])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.0305e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2019) tensor(0.) tensor(0.6102)\n",
      "h_from_s max, min, mean tensor(4.1044) tensor(0.) tensor(0.6098)\n",
      "h_from_s_denoised max, min, mean tensor(5.2056) tensor(0.) tensor(0.6106)\n",
      "avg nonzero/greaterzero h from book: tensor(995) tensor(995)\n",
      "avg nonzero/greaterzero h from s: tensor(1660) tensor(1660)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0753) tensor([0.9731])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5512e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(61.8696) tensor([0.9948])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9949e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.9210) tensor(0.) tensor(0.6738)\n",
      "h_from_s max, min, mean tensor(5.8535) tensor(0.) tensor(0.6880)\n",
      "h_from_s_denoised max, min, mean tensor(6.9260) tensor(0.) tensor(0.6743)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1717) tensor(1717)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1280) tensor([0.9599])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7127e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(97.2012) tensor([0.9923])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.0454e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0764) tensor(0.) tensor(0.6720)\n",
      "h_from_s max, min, mean tensor(3.2899) tensor(0.) tensor(0.5584)\n",
      "h_from_s_denoised max, min, mean tensor(6.0811) tensor(0.) tensor(0.6724)\n",
      "avg nonzero/greaterzero h from book: tensor(1036) tensor(1036)\n",
      "avg nonzero/greaterzero h from s: tensor(1777) tensor(1777)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1034) tensor(1034)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4065) tensor([0.8757])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9606e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(61.1993) tensor([0.9881])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0031) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.2190e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.6602) tensor(0.) tensor(0.6224)\n",
      "h_from_s max, min, mean tensor(4.2894) tensor(0.) tensor(0.6388)\n",
      "h_from_s_denoised max, min, mean tensor(4.6646) tensor(0.) tensor(0.6229)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1656) tensor(1656)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0245) tensor([0.9908])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7345e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.1764) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0072) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9551e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5071) tensor(0.) tensor(0.6608)\n",
      "h_from_s max, min, mean tensor(4.8501) tensor(0.) tensor(0.6622)\n",
      "h_from_s_denoised max, min, mean tensor(5.5099) tensor(0.) tensor(0.6612)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1649) tensor(1649)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0998) tensor([0.9680])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7014e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(92.0221) tensor([0.9943])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.0333e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0689) tensor(0.) tensor(0.6641)\n",
      "h_from_s max, min, mean tensor(4.4085) tensor(0.) tensor(0.6340)\n",
      "h_from_s_denoised max, min, mean tensor(5.0732) tensor(0.) tensor(0.6646)\n",
      "avg nonzero/greaterzero h from book: tensor(975) tensor(975)\n",
      "avg nonzero/greaterzero h from s: tensor(1643) tensor(1643)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0646) tensor([0.9850])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4511e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(66.6749) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.7469e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 283/500 [00:08<00:05, 37.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3203) tensor(0.) tensor(0.6650)\n",
      "h_from_s max, min, mean tensor(4.2193) tensor(0.) tensor(0.6363)\n",
      "h_from_s_denoised max, min, mean tensor(5.3242) tensor(0.) tensor(0.6654)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1694) tensor(1694)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1224) tensor([0.9653])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4508e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(66.7541) tensor([0.9930])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.8400e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6149) tensor(0.) tensor(0.6328)\n",
      "h_from_s max, min, mean tensor(6.0585) tensor(0.) tensor(0.6453)\n",
      "h_from_s_denoised max, min, mean tensor(6.6194) tensor(0.) tensor(0.6332)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1579) tensor(1579)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(998) tensor(998)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0322) tensor([0.9885])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9070e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(44.4539) tensor([0.9976])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3367e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6067) tensor(0.) tensor(0.6467)\n",
      "h_from_s max, min, mean tensor(4.9964) tensor(0.) tensor(0.6296)\n",
      "h_from_s_denoised max, min, mean tensor(5.6109) tensor(0.) tensor(0.6472)\n",
      "avg nonzero/greaterzero h from book: tensor(987) tensor(987)\n",
      "avg nonzero/greaterzero h from s: tensor(1603) tensor(1603)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0369) tensor([0.9906])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4516e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.2904) tensor([0.9960])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0027) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6458e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4578) tensor(0.) tensor(0.6551)\n",
      "h_from_s max, min, mean tensor(5.1408) tensor(0.) tensor(0.6944)\n",
      "h_from_s_denoised max, min, mean tensor(5.4615) tensor(0.) tensor(0.6556)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1693) tensor(1693)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0412) tensor([0.9852])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6083e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(33.0510) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0081) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.2336e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2054) tensor(0.) tensor(0.6420)\n",
      "h_from_s max, min, mean tensor(4.7822) tensor(0.) tensor(0.6239)\n",
      "h_from_s_denoised max, min, mean tensor(5.2097) tensor(0.) tensor(0.6424)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1613) tensor(1613)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0354) tensor([0.9903])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8743e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(50.6996) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2517e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5519) tensor(0.) tensor(0.6270)\n",
      "h_from_s max, min, mean tensor(3.7286) tensor(0.) tensor(0.6548)\n",
      "h_from_s_denoised max, min, mean tensor(5.5561) tensor(0.) tensor(0.6274)\n",
      "avg nonzero/greaterzero h from book: tensor(987) tensor(987)\n",
      "avg nonzero/greaterzero h from s: tensor(1773) tensor(1773)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(986) tensor(986)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2084) tensor([0.9199])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7539e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(46.2648) tensor([0.9962])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.9881e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 291/500 [00:08<00:06, 34.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7651) tensor(0.) tensor(0.6425)\n",
      "h_from_s max, min, mean tensor(5.2167) tensor(0.) tensor(0.7633)\n",
      "h_from_s_denoised max, min, mean tensor(5.7690) tensor(0.) tensor(0.6430)\n",
      "avg nonzero/greaterzero h from book: tensor(1014) tensor(1014)\n",
      "avg nonzero/greaterzero h from s: tensor(1835) tensor(1835)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1014) tensor(1014)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0873) tensor([0.9659])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1861e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(36.8544) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0871e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0627) tensor(0.) tensor(0.6766)\n",
      "h_from_s max, min, mean tensor(5.3984) tensor(0.) tensor(0.6801)\n",
      "h_from_s_denoised max, min, mean tensor(6.0663) tensor(0.) tensor(0.6771)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1705) tensor(1705)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0567) tensor([0.9837])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9797e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(45.1931) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7497e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3766) tensor(0.) tensor(0.6646)\n",
      "h_from_s max, min, mean tensor(4.7589) tensor(0.) tensor(0.6805)\n",
      "h_from_s_denoised max, min, mean tensor(5.3806) tensor(0.) tensor(0.6650)\n",
      "avg nonzero/greaterzero h from book: tensor(1031) tensor(1031)\n",
      "avg nonzero/greaterzero h from s: tensor(1744) tensor(1744)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1028) tensor(1028)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0605) tensor([0.9808])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5243e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(33.7569) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6332e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1391) tensor(0.) tensor(0.6134)\n",
      "h_from_s max, min, mean tensor(3.2305) tensor(0.) tensor(0.6367)\n",
      "h_from_s_denoised max, min, mean tensor(5.1421) tensor(0.) tensor(0.6138)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1825) tensor(1825)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1627) tensor([0.9334])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4235e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(56.9923) tensor([0.9945])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2222e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9477) tensor(0.) tensor(0.6490)\n",
      "h_from_s max, min, mean tensor(3.4806) tensor(0.) tensor(0.5491)\n",
      "h_from_s_denoised max, min, mean tensor(5.9517) tensor(0.) tensor(0.6495)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1737) tensor(1737)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3149) tensor([0.9049])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0525e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(78.8525) tensor([0.9901])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2992e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5749) tensor(0.) tensor(0.6804)\n",
      "h_from_s max, min, mean tensor(4.0434) tensor(0.) tensor(0.6413)\n",
      "h_from_s_denoised max, min, mean tensor(5.5778) tensor(0.) tensor(0.6809)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1707) tensor(1707)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1553) tensor([0.9598])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8445e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(63.8222) tensor([0.9955])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.2459e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2530) tensor(0.) tensor(0.6571)\n",
      "h_from_s max, min, mean tensor(4.8904) tensor(0.) tensor(0.6443)\n",
      "h_from_s_denoised max, min, mean tensor(6.2574) tensor(0.) tensor(0.6575)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1701) tensor(1701)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1073) tensor([0.9695])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8017e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(62.9937) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.5900e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7596) tensor(0.) tensor(0.6452)\n",
      "h_from_s max, min, mean tensor(4.7860) tensor(0.) tensor(0.6805)\n",
      "h_from_s_denoised max, min, mean tensor(5.7632) tensor(0.) tensor(0.6457)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1802) tensor(1802)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0907) tensor([0.9702])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6084e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(33.2280) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.9801e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 299/500 [00:08<00:05, 35.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5696) tensor(0.) tensor(0.6227)\n",
      "h_from_s max, min, mean tensor(5.1471) tensor(0.) tensor(0.6467)\n",
      "h_from_s_denoised max, min, mean tensor(5.5731) tensor(0.) tensor(0.6231)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1652) tensor(1652)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0215) tensor([0.9919])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4354e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(27.0744) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.8847e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2609) tensor(0.) tensor(0.6622)\n",
      "h_from_s max, min, mean tensor(5.0629) tensor(0.) tensor(0.7024)\n",
      "h_from_s_denoised max, min, mean tensor(6.2655) tensor(0.) tensor(0.6627)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1863) tensor(1863)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1188) tensor([0.9613])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5842e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(27.9903) tensor([0.9983])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.6252e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6166) tensor(0.) tensor(0.6773)\n",
      "h_from_s max, min, mean tensor(4.9105) tensor(0.) tensor(0.6802)\n",
      "h_from_s_denoised max, min, mean tensor(5.6204) tensor(0.) tensor(0.6778)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1665) tensor(1665)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0477) tensor([0.9870])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9709e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.9304) tensor([0.9979])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5640e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6199) tensor(0.) tensor(0.6311)\n",
      "h_from_s max, min, mean tensor(5.0002) tensor(0.) tensor(0.6448)\n",
      "h_from_s_denoised max, min, mean tensor(5.6240) tensor(0.) tensor(0.6316)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1756) tensor(1756)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1093) tensor([0.9609])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8313e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(36.2045) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0065) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.9506e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1056) tensor(0.) tensor(0.6415)\n",
      "h_from_s max, min, mean tensor(4.4943) tensor(0.) tensor(0.7320)\n",
      "h_from_s_denoised max, min, mean tensor(5.1088) tensor(0.) tensor(0.6420)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1748) tensor(1748)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0974) tensor([0.9623])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6372e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.4705) tensor([0.9973])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7909e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6996) tensor(0.) tensor(0.6720)\n",
      "h_from_s max, min, mean tensor(5.0654) tensor(0.) tensor(0.6564)\n",
      "h_from_s_denoised max, min, mean tensor(5.7028) tensor(0.) tensor(0.6724)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1667) tensor(1667)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0604) tensor([0.9845])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5795e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(57.9746) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3180e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9882) tensor(0.) tensor(0.6234)\n",
      "h_from_s max, min, mean tensor(4.3395) tensor(0.) tensor(0.6039)\n",
      "h_from_s_denoised max, min, mean tensor(5.9924) tensor(0.) tensor(0.6238)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1754) tensor(1754)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(981) tensor(981)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1468) tensor([0.9538])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7256e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(52.8900) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.2499e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5332) tensor(0.) tensor(0.6821)\n",
      "h_from_s max, min, mean tensor(4.0793) tensor(0.) tensor(0.6901)\n",
      "h_from_s_denoised max, min, mean tensor(5.5375) tensor(0.) tensor(0.6826)\n",
      "avg nonzero/greaterzero h from book: tensor(1014) tensor(1014)\n",
      "avg nonzero/greaterzero h from s: tensor(1776) tensor(1776)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1705) tensor([0.9440])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7874e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(55.2052) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9769e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 307/500 [00:08<00:05, 36.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0405) tensor(0.) tensor(0.6258)\n",
      "h_from_s max, min, mean tensor(4.7865) tensor(0.) tensor(0.6714)\n",
      "h_from_s_denoised max, min, mean tensor(6.0455) tensor(0.) tensor(0.6262)\n",
      "avg nonzero/greaterzero h from book: tensor(974) tensor(974)\n",
      "avg nonzero/greaterzero h from s: tensor(1719) tensor(1719)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(974) tensor(974)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0987) tensor([0.9631])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7383e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(84.5087) tensor([0.9951])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3486e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4880) tensor(0.) tensor(0.6641)\n",
      "h_from_s max, min, mean tensor(4.9450) tensor(0.) tensor(0.6915)\n",
      "h_from_s_denoised max, min, mean tensor(5.4926) tensor(0.) tensor(0.6646)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1749) tensor(1749)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0873) tensor([0.9716])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1793e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(87.0295) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0109e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8015) tensor(0.) tensor(0.6541)\n",
      "h_from_s max, min, mean tensor(4.3400) tensor(0.) tensor(0.6543)\n",
      "h_from_s_denoised max, min, mean tensor(5.8058) tensor(0.) tensor(0.6545)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1650) tensor(1650)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1278) tensor([0.9585])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4816e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(122.9495) tensor([0.9847])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4026e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2869) tensor(0.) tensor(0.6213)\n",
      "h_from_s max, min, mean tensor(4.1735) tensor(0.) tensor(0.6261)\n",
      "h_from_s_denoised max, min, mean tensor(6.2917) tensor(0.) tensor(0.6218)\n",
      "avg nonzero/greaterzero h from book: tensor(997) tensor(997)\n",
      "avg nonzero/greaterzero h from s: tensor(1725) tensor(1725)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1512) tensor([0.9439])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4894e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(46.4093) tensor([0.9964])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.4629e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7689) tensor(0.) tensor(0.6424)\n",
      "h_from_s max, min, mean tensor(4.7596) tensor(0.) tensor(0.6397)\n",
      "h_from_s_denoised max, min, mean tensor(5.7732) tensor(0.) tensor(0.6429)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1657) tensor(1657)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0562) tensor([0.9824])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3856e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(76.1441) tensor([0.9953])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1049e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2796) tensor(0.) tensor(0.6455)\n",
      "h_from_s max, min, mean tensor(3.8401) tensor(0.) tensor(0.6565)\n",
      "h_from_s_denoised max, min, mean tensor(6.2850) tensor(0.) tensor(0.6460)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1832) tensor(1832)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1691) tensor([0.9446])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2538e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(36.9154) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0062) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.8138e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7682) tensor(0.) tensor(0.6658)\n",
      "h_from_s max, min, mean tensor(4.7739) tensor(0.) tensor(0.6950)\n",
      "h_from_s_denoised max, min, mean tensor(5.7731) tensor(0.) tensor(0.6663)\n",
      "avg nonzero/greaterzero h from book: tensor(974) tensor(974)\n",
      "avg nonzero/greaterzero h from s: tensor(1751) tensor(1751)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(973) tensor(973)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0644) tensor([0.9801])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0791e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(27.4859) tensor([0.9990])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.5059e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1393) tensor(0.) tensor(0.6923)\n",
      "h_from_s max, min, mean tensor(4.1396) tensor(0.) tensor(0.5502)\n",
      "h_from_s_denoised max, min, mean tensor(6.1442) tensor(0.) tensor(0.6928)\n",
      "avg nonzero/greaterzero h from book: tensor(1017) tensor(1017)\n",
      "avg nonzero/greaterzero h from s: tensor(1705) tensor(1705)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1017) tensor(1017)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4014) tensor([0.8839])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0134e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(92.1763) tensor([0.9891])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.8829e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 315/500 [00:08<00:05, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6088) tensor(0.) tensor(0.6072)\n",
      "h_from_s max, min, mean tensor(2.9340) tensor(0.) tensor(0.5766)\n",
      "h_from_s_denoised max, min, mean tensor(5.6125) tensor(0.) tensor(0.6076)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1855) tensor(1855)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2735) tensor([0.9059])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3734e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.0995) tensor([0.9937])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.3664e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1280) tensor(0.) tensor(0.6631)\n",
      "h_from_s max, min, mean tensor(4.0852) tensor(0.) tensor(0.6879)\n",
      "h_from_s_denoised max, min, mean tensor(5.1319) tensor(0.) tensor(0.6636)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1791) tensor(1791)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1409) tensor([0.9541])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9109e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(93.0046) tensor([0.9942])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.1594e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7398) tensor(0.) tensor(0.6318)\n",
      "h_from_s max, min, mean tensor(5.2636) tensor(0.) tensor(0.7008)\n",
      "h_from_s_denoised max, min, mean tensor(5.7430) tensor(0.) tensor(0.6323)\n",
      "avg nonzero/greaterzero h from book: tensor(997) tensor(997)\n",
      "avg nonzero/greaterzero h from s: tensor(1782) tensor(1782)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0520) tensor([0.9803])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0314e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(43.6876) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.9097e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4840) tensor(0.) tensor(0.6779)\n",
      "h_from_s max, min, mean tensor(3.7621) tensor(0.) tensor(0.7299)\n",
      "h_from_s_denoised max, min, mean tensor(5.4874) tensor(0.) tensor(0.6784)\n",
      "avg nonzero/greaterzero h from book: tensor(1040) tensor(1040)\n",
      "avg nonzero/greaterzero h from s: tensor(1845) tensor(1845)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1038) tensor(1038)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2258) tensor([0.9190])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0110e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(35.4836) tensor([0.9971])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0074) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.7001e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9437) tensor(0.) tensor(0.6405)\n",
      "h_from_s max, min, mean tensor(4.2736) tensor(0.) tensor(0.6366)\n",
      "h_from_s_denoised max, min, mean tensor(4.9476) tensor(0.) tensor(0.6410)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1730) tensor(1730)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(970) tensor(970)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0874) tensor([0.9741])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0926e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(51.8175) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.7642e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1970) tensor(0.) tensor(0.6262)\n",
      "h_from_s max, min, mean tensor(3.4034) tensor(0.) tensor(0.6544)\n",
      "h_from_s_denoised max, min, mean tensor(5.2014) tensor(0.) tensor(0.6267)\n",
      "avg nonzero/greaterzero h from book: tensor(990) tensor(990)\n",
      "avg nonzero/greaterzero h from s: tensor(1833) tensor(1833)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2756) tensor([0.8877])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6857e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.9010) tensor([0.9962])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2702e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3041) tensor(0.) tensor(0.6672)\n",
      "h_from_s max, min, mean tensor(5.5479) tensor(0.) tensor(0.6256)\n",
      "h_from_s_denoised max, min, mean tensor(6.3094) tensor(0.) tensor(0.6676)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1525) tensor(1525)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0846) tensor([0.9746])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3831e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(159.5525) tensor([0.9832])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.2707e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5807) tensor(0.) tensor(0.6444)\n",
      "h_from_s max, min, mean tensor(5.4392) tensor(0.) tensor(0.6790)\n",
      "h_from_s_denoised max, min, mean tensor(5.5843) tensor(0.) tensor(0.6448)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1736) tensor(1736)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0719) tensor([0.9743])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0287e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(32.6381) tensor([0.9984])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.9012e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 323/500 [00:09<00:04, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7158) tensor(0.) tensor(0.6626)\n",
      "h_from_s max, min, mean tensor(4.8288) tensor(0.) tensor(0.6752)\n",
      "h_from_s_denoised max, min, mean tensor(5.7193) tensor(0.) tensor(0.6631)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1746) tensor(1746)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0411) tensor([0.9881])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0722e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(26.3311) tensor([0.9981])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1429e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0055) tensor(0.) tensor(0.6714)\n",
      "h_from_s max, min, mean tensor(4.3111) tensor(0.) tensor(0.7158)\n",
      "h_from_s_denoised max, min, mean tensor(6.0092) tensor(0.) tensor(0.6719)\n",
      "avg nonzero/greaterzero h from book: tensor(1038) tensor(1038)\n",
      "avg nonzero/greaterzero h from s: tensor(1826) tensor(1826)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1037) tensor(1037)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1857) tensor([0.9354])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6681e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(39.2866) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1743e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7309) tensor(0.) tensor(0.6335)\n",
      "h_from_s max, min, mean tensor(4.0983) tensor(0.) tensor(0.6405)\n",
      "h_from_s_denoised max, min, mean tensor(5.7349) tensor(0.) tensor(0.6340)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1790) tensor(1790)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1033) tensor([0.9668])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6967e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(49.8639) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.8004e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6598) tensor(0.) tensor(0.6752)\n",
      "h_from_s max, min, mean tensor(4.7510) tensor(0.) tensor(0.6495)\n",
      "h_from_s_denoised max, min, mean tensor(6.6654) tensor(0.) tensor(0.6756)\n",
      "avg nonzero/greaterzero h from book: tensor(1050) tensor(1050)\n",
      "avg nonzero/greaterzero h from s: tensor(1736) tensor(1736)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1048) tensor(1048)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1896) tensor([0.9386])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8033e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.9155) tensor([0.9947])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6141e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4373) tensor(0.) tensor(0.6294)\n",
      "h_from_s max, min, mean tensor(4.4285) tensor(0.) tensor(0.5978)\n",
      "h_from_s_denoised max, min, mean tensor(5.4403) tensor(0.) tensor(0.6298)\n",
      "avg nonzero/greaterzero h from book: tensor(975) tensor(975)\n",
      "avg nonzero/greaterzero h from s: tensor(1543) tensor(1543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(973) tensor(973)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0874) tensor([0.9738])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8906e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(100.9491) tensor([0.9905])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.6164e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4574) tensor(0.) tensor(0.6546)\n",
      "h_from_s max, min, mean tensor(4.5515) tensor(0.) tensor(0.6541)\n",
      "h_from_s_denoised max, min, mean tensor(5.4612) tensor(0.) tensor(0.6551)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1793) tensor(1793)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0479) tensor([0.9871])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7047e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(24.4825) tensor([0.9989])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.8881e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2592) tensor(0.) tensor(0.6604)\n",
      "h_from_s max, min, mean tensor(4.9449) tensor(0.) tensor(0.7205)\n",
      "h_from_s_denoised max, min, mean tensor(5.2625) tensor(0.) tensor(0.6609)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1773) tensor(1773)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1240) tensor([0.9573])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7884e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.5542) tensor([0.9944])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.8360e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1779) tensor(0.) tensor(0.6419)\n",
      "h_from_s max, min, mean tensor(4.7369) tensor(0.) tensor(0.6883)\n",
      "h_from_s_denoised max, min, mean tensor(6.1825) tensor(0.) tensor(0.6423)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1728) tensor(1728)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1024) tensor(1024)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0919) tensor([0.9651])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8609e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(62.2345) tensor([0.9972])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.5847e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 331/500 [00:09<00:04, 36.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7614) tensor(0.) tensor(0.6410)\n",
      "h_from_s max, min, mean tensor(4.3195) tensor(0.) tensor(0.6387)\n",
      "h_from_s_denoised max, min, mean tensor(5.7658) tensor(0.) tensor(0.6414)\n",
      "avg nonzero/greaterzero h from book: tensor(979) tensor(979)\n",
      "avg nonzero/greaterzero h from s: tensor(1634) tensor(1634)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0972) tensor([0.9694])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4637e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(119.0067) tensor([0.9922])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.0334e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5860) tensor(0.) tensor(0.6321)\n",
      "h_from_s max, min, mean tensor(5.4805) tensor(0.) tensor(0.6430)\n",
      "h_from_s_denoised max, min, mean tensor(6.5912) tensor(0.) tensor(0.6325)\n",
      "avg nonzero/greaterzero h from book: tensor(989) tensor(989)\n",
      "avg nonzero/greaterzero h from s: tensor(1660) tensor(1660)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0639) tensor([0.9783])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2021e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(50.5895) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.9609e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5840) tensor(0.) tensor(0.6662)\n",
      "h_from_s max, min, mean tensor(4.1443) tensor(0.) tensor(0.7041)\n",
      "h_from_s_denoised max, min, mean tensor(5.5881) tensor(0.) tensor(0.6666)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1803) tensor(1803)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1465) tensor([0.9526])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0637e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(57.1240) tensor([0.9971])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0080) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.6325e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1679) tensor(0.) tensor(0.6586)\n",
      "h_from_s max, min, mean tensor(4.5263) tensor(0.) tensor(0.6652)\n",
      "h_from_s_denoised max, min, mean tensor(5.1718) tensor(0.) tensor(0.6591)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1732) tensor(1732)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0806) tensor([0.9738])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3265e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(41.5558) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.3260e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9455) tensor(0.) tensor(0.6037)\n",
      "h_from_s max, min, mean tensor(3.9599) tensor(0.) tensor(0.6194)\n",
      "h_from_s_denoised max, min, mean tensor(4.9486) tensor(0.) tensor(0.6041)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1749) tensor(1749)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1114) tensor([0.9580])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3091e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(56.6088) tensor([0.9965])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0084) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5788e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6358) tensor(0.) tensor(0.6612)\n",
      "h_from_s max, min, mean tensor(4.4886) tensor(0.) tensor(0.6787)\n",
      "h_from_s_denoised max, min, mean tensor(5.6404) tensor(0.) tensor(0.6617)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1755) tensor(1755)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1277) tensor([0.9586])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7310e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(64.2738) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4081e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8246) tensor(0.) tensor(0.6546)\n",
      "h_from_s max, min, mean tensor(4.7059) tensor(0.) tensor(0.6531)\n",
      "h_from_s_denoised max, min, mean tensor(5.8286) tensor(0.) tensor(0.6550)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1765) tensor(1765)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0790) tensor([0.9764])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9586e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.3457) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.2046e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6399) tensor(0.) tensor(0.6807)\n",
      "h_from_s max, min, mean tensor(4.8590) tensor(0.) tensor(0.6932)\n",
      "h_from_s_denoised max, min, mean tensor(5.6444) tensor(0.) tensor(0.6812)\n",
      "avg nonzero/greaterzero h from book: tensor(1030) tensor(1030)\n",
      "avg nonzero/greaterzero h from s: tensor(1611) tensor(1611)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1031) tensor(1031)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0814) tensor([0.9732])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2254e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(84.3181) tensor([0.9953])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.5577e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 339/500 [00:09<00:04, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6888) tensor(0.) tensor(0.6504)\n",
      "h_from_s max, min, mean tensor(4.6901) tensor(0.) tensor(0.6362)\n",
      "h_from_s_denoised max, min, mean tensor(5.6930) tensor(0.) tensor(0.6509)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1664) tensor(1664)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(982) tensor(982)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0836) tensor([0.9758])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1509e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(73.8339) tensor([0.9950])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.2927e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0489) tensor(0.) tensor(0.6348)\n",
      "h_from_s max, min, mean tensor(4.0711) tensor(0.) tensor(0.6160)\n",
      "h_from_s_denoised max, min, mean tensor(5.0528) tensor(0.) tensor(0.6352)\n",
      "avg nonzero/greaterzero h from book: tensor(990) tensor(990)\n",
      "avg nonzero/greaterzero h from s: tensor(1724) tensor(1724)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1278) tensor([0.9581])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7123e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(87.3944) tensor([0.9911])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.1632e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7825) tensor(0.) tensor(0.6604)\n",
      "h_from_s max, min, mean tensor(4.4509) tensor(0.) tensor(0.6544)\n",
      "h_from_s_denoised max, min, mean tensor(6.7880) tensor(0.) tensor(0.6608)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1779) tensor(1779)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1848) tensor([0.9403])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5758e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(59.9918) tensor([0.9941])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5089e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1617) tensor(0.) tensor(0.6550)\n",
      "h_from_s max, min, mean tensor(3.9264) tensor(0.) tensor(0.6178)\n",
      "h_from_s_denoised max, min, mean tensor(5.1645) tensor(0.) tensor(0.6554)\n",
      "avg nonzero/greaterzero h from book: tensor(1017) tensor(1017)\n",
      "avg nonzero/greaterzero h from s: tensor(1623) tensor(1623)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1014) tensor(1014)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1637) tensor([0.9503])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2124e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(147.3667) tensor([0.9900])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.0683e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5560) tensor(0.) tensor(0.6568)\n",
      "h_from_s max, min, mean tensor(4.1715) tensor(0.) tensor(0.6482)\n",
      "h_from_s_denoised max, min, mean tensor(5.5603) tensor(0.) tensor(0.6572)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1659) tensor(1659)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(980) tensor(980)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1315) tensor([0.9588])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8387e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(106.0827) tensor([0.9886])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.4853e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8557) tensor(0.) tensor(0.6698)\n",
      "h_from_s max, min, mean tensor(4.9325) tensor(0.) tensor(0.6580)\n",
      "h_from_s_denoised max, min, mean tensor(5.8603) tensor(0.) tensor(0.6703)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1628) tensor(1628)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0693) tensor([0.9796])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7760e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.6917) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7578e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9471) tensor(0.) tensor(0.6299)\n",
      "h_from_s max, min, mean tensor(4.8883) tensor(0.) tensor(0.6490)\n",
      "h_from_s_denoised max, min, mean tensor(5.9515) tensor(0.) tensor(0.6303)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1581) tensor(1581)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1032) tensor([0.9614])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7963e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(111.7314) tensor([0.9914])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3558e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6351) tensor(0.) tensor(0.6688)\n",
      "h_from_s max, min, mean tensor(4.6204) tensor(0.) tensor(0.6176)\n",
      "h_from_s_denoised max, min, mean tensor(5.6403) tensor(0.) tensor(0.6693)\n",
      "avg nonzero/greaterzero h from book: tensor(1028) tensor(1028)\n",
      "avg nonzero/greaterzero h from s: tensor(1671) tensor(1671)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1028) tensor(1028)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0732) tensor([0.9837])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7347e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(50.8916) tensor([0.9980])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3793e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 347/500 [00:09<00:04, 36.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4135) tensor(0.) tensor(0.6197)\n",
      "h_from_s max, min, mean tensor(3.9923) tensor(0.) tensor(0.5803)\n",
      "h_from_s_denoised max, min, mean tensor(5.4183) tensor(0.) tensor(0.6201)\n",
      "avg nonzero/greaterzero h from book: tensor(966) tensor(966)\n",
      "avg nonzero/greaterzero h from s: tensor(1719) tensor(1719)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(964) tensor(964)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1213) tensor([0.9667])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7597e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.8298) tensor([0.9937])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4264e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8942) tensor(0.) tensor(0.6708)\n",
      "h_from_s max, min, mean tensor(3.9017) tensor(0.) tensor(0.7147)\n",
      "h_from_s_denoised max, min, mean tensor(4.8978) tensor(0.) tensor(0.6713)\n",
      "avg nonzero/greaterzero h from book: tensor(1022) tensor(1022)\n",
      "avg nonzero/greaterzero h from s: tensor(1762) tensor(1762)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1593) tensor([0.9438])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9018e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(67.7325) tensor([0.9955])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.0742e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7139) tensor(0.) tensor(0.6503)\n",
      "h_from_s max, min, mean tensor(4.5105) tensor(0.) tensor(0.6596)\n",
      "h_from_s_denoised max, min, mean tensor(5.7181) tensor(0.) tensor(0.6507)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1758) tensor(1758)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1229) tensor([0.9618])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4011e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(54.5165) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0035) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.3892e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.8526) tensor(0.) tensor(0.6402)\n",
      "h_from_s max, min, mean tensor(4.0049) tensor(0.) tensor(0.7071)\n",
      "h_from_s_denoised max, min, mean tensor(4.8558) tensor(0.) tensor(0.6406)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1824) tensor(1824)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2052) tensor([0.9160])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7096e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(55.5414) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0845e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8654) tensor(0.) tensor(0.6392)\n",
      "h_from_s max, min, mean tensor(3.9968) tensor(0.) tensor(0.5552)\n",
      "h_from_s_denoised max, min, mean tensor(5.8687) tensor(0.) tensor(0.6397)\n",
      "avg nonzero/greaterzero h from book: tensor(984) tensor(984)\n",
      "avg nonzero/greaterzero h from s: tensor(1642) tensor(1642)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(984) tensor(984)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2009) tensor([0.9454])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3689e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(116.0844) tensor([0.9910])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.6680e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7365) tensor(0.) tensor(0.6420)\n",
      "h_from_s max, min, mean tensor(4.8290) tensor(0.) tensor(0.6440)\n",
      "h_from_s_denoised max, min, mean tensor(5.7416) tensor(0.) tensor(0.6424)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1675) tensor(1675)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0719) tensor([0.9769])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0496e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(51.6594) tensor([0.9977])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2799e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1597) tensor(0.) tensor(0.6622)\n",
      "h_from_s max, min, mean tensor(4.6530) tensor(0.) tensor(0.8400)\n",
      "h_from_s_denoised max, min, mean tensor(6.1648) tensor(0.) tensor(0.6627)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1930) tensor(1930)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2028) tensor([0.9265])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.3327e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(22.2308) tensor([0.9988])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0081) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.1549e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3832) tensor(0.) tensor(0.6884)\n",
      "h_from_s max, min, mean tensor(4.8223) tensor(0.) tensor(0.6637)\n",
      "h_from_s_denoised max, min, mean tensor(5.3878) tensor(0.) tensor(0.6889)\n",
      "avg nonzero/greaterzero h from book: tensor(1045) tensor(1045)\n",
      "avg nonzero/greaterzero h from s: tensor(1676) tensor(1676)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1043) tensor(1043)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1002) tensor([0.9712])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7743e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(181.3631) tensor([0.9869])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9133e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 355/500 [00:10<00:03, 36.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2349) tensor(0.) tensor(0.6139)\n",
      "h_from_s max, min, mean tensor(4.0002) tensor(0.) tensor(0.6837)\n",
      "h_from_s_denoised max, min, mean tensor(5.2390) tensor(0.) tensor(0.6143)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1795) tensor(1795)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1352) tensor([0.9437])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.3347e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.6530) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0037) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.9964e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2139) tensor(0.) tensor(0.6583)\n",
      "h_from_s max, min, mean tensor(3.3754) tensor(0.) tensor(0.7381)\n",
      "h_from_s_denoised max, min, mean tensor(5.2182) tensor(0.) tensor(0.6587)\n",
      "avg nonzero/greaterzero h from book: tensor(1033) tensor(1033)\n",
      "avg nonzero/greaterzero h from s: tensor(1893) tensor(1893)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1032) tensor(1032)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3559) tensor([0.8574])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7591e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(36.6773) tensor([0.9967])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9697e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9366) tensor(0.) tensor(0.6379)\n",
      "h_from_s max, min, mean tensor(5.7110) tensor(0.) tensor(0.7118)\n",
      "h_from_s_denoised max, min, mean tensor(5.9405) tensor(0.) tensor(0.6383)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1668) tensor(1668)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1106) tensor([0.9571])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9101e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(200.8228) tensor([0.9897])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0078) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0709e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3513) tensor(0.) tensor(0.6539)\n",
      "h_from_s max, min, mean tensor(3.9500) tensor(0.) tensor(0.6815)\n",
      "h_from_s_denoised max, min, mean tensor(5.3550) tensor(0.) tensor(0.6543)\n",
      "avg nonzero/greaterzero h from book: tensor(1010) tensor(1010)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1729) tensor([0.9399])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8201e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(45.9233) tensor([0.9965])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2794e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3618) tensor(0.) tensor(0.6601)\n",
      "h_from_s max, min, mean tensor(3.8190) tensor(0.) tensor(0.6509)\n",
      "h_from_s_denoised max, min, mean tensor(5.3658) tensor(0.) tensor(0.6606)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1711) tensor(1711)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2057) tensor([0.9315])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4816e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(112.2789) tensor([0.9872])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4424e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7783) tensor(0.) tensor(0.6437)\n",
      "h_from_s max, min, mean tensor(4.0573) tensor(0.) tensor(0.6903)\n",
      "h_from_s_denoised max, min, mean tensor(5.7828) tensor(0.) tensor(0.6441)\n",
      "avg nonzero/greaterzero h from book: tensor(979) tensor(979)\n",
      "avg nonzero/greaterzero h from s: tensor(1824) tensor(1824)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(978) tensor(978)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2022) tensor([0.9241])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9367e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(66.5999) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.9381e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4082) tensor(0.) tensor(0.6659)\n",
      "h_from_s max, min, mean tensor(4.7931) tensor(0.) tensor(0.6294)\n",
      "h_from_s_denoised max, min, mean tensor(5.4132) tensor(0.) tensor(0.6663)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1494) tensor(1494)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1082) tensor([0.9677])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7117e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(232.8001) tensor([0.9787])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3077e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9948) tensor(0.) tensor(0.6514)\n",
      "h_from_s max, min, mean tensor(3.5202) tensor(0.) tensor(0.7433)\n",
      "h_from_s_denoised max, min, mean tensor(4.9982) tensor(0.) tensor(0.6519)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1889) tensor(1889)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2820) tensor([0.8881])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0859e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(45.6244) tensor([0.9964])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0543e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 363/500 [00:10<00:03, 36.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2202) tensor(0.) tensor(0.6631)\n",
      "h_from_s max, min, mean tensor(3.7207) tensor(0.) tensor(0.6599)\n",
      "h_from_s_denoised max, min, mean tensor(6.2241) tensor(0.) tensor(0.6636)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1830) tensor(1830)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3044) tensor([0.8958])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8585e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(54.3885) tensor([0.9926])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6618e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3259) tensor(0.) tensor(0.6479)\n",
      "h_from_s max, min, mean tensor(4.6010) tensor(0.) tensor(0.6511)\n",
      "h_from_s_denoised max, min, mean tensor(5.3295) tensor(0.) tensor(0.6483)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1691) tensor(1691)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1440) tensor([0.9514])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3375e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(87.9842) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0096) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4866e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4635) tensor(0.) tensor(0.6106)\n",
      "h_from_s max, min, mean tensor(5.3028) tensor(0.) tensor(0.6480)\n",
      "h_from_s_denoised max, min, mean tensor(5.4676) tensor(0.) tensor(0.6110)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1774) tensor(1774)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(992) tensor(992)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0157) tensor([0.9937])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.4518e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(13.8635) tensor([0.9992])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0074) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1171e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0250) tensor(0.) tensor(0.6517)\n",
      "h_from_s max, min, mean tensor(4.9622) tensor(0.) tensor(0.6426)\n",
      "h_from_s_denoised max, min, mean tensor(6.0297) tensor(0.) tensor(0.6522)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1694) tensor(1694)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1525) tensor([0.9502])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4610e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(105.5307) tensor([0.9939])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0555e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6219) tensor(0.) tensor(0.6209)\n",
      "h_from_s max, min, mean tensor(5.0302) tensor(0.) tensor(0.6648)\n",
      "h_from_s_denoised max, min, mean tensor(6.6271) tensor(0.) tensor(0.6213)\n",
      "avg nonzero/greaterzero h from book: tensor(979) tensor(979)\n",
      "avg nonzero/greaterzero h from s: tensor(1718) tensor(1718)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1467) tensor([0.9462])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8346e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(79.8924) tensor([0.9938])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.1125e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6280) tensor(0.) tensor(0.6748)\n",
      "h_from_s max, min, mean tensor(4.6634) tensor(0.) tensor(0.6716)\n",
      "h_from_s_denoised max, min, mean tensor(6.6329) tensor(0.) tensor(0.6753)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1744) tensor(1744)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2107) tensor([0.9328])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1103e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(124.6031) tensor([0.9886])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4225e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4432) tensor(0.) tensor(0.6496)\n",
      "h_from_s max, min, mean tensor(3.7990) tensor(0.) tensor(0.5868)\n",
      "h_from_s_denoised max, min, mean tensor(5.4482) tensor(0.) tensor(0.6501)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1656) tensor(1656)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1745) tensor([0.9538])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8413e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(154.9449) tensor([0.9822])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0034) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4621e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5248) tensor(0.) tensor(0.6314)\n",
      "h_from_s max, min, mean tensor(4.5943) tensor(0.) tensor(0.6073)\n",
      "h_from_s_denoised max, min, mean tensor(5.5286) tensor(0.) tensor(0.6318)\n",
      "avg nonzero/greaterzero h from book: tensor(958) tensor(958)\n",
      "avg nonzero/greaterzero h from s: tensor(1575) tensor(1575)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(957) tensor(957)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0673) tensor([0.9807])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9301e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(81.2917) tensor([0.9964])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.7041e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 371/500 [00:10<00:03, 36.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1467) tensor(0.) tensor(0.6510)\n",
      "h_from_s max, min, mean tensor(3.1158) tensor(0.) tensor(0.5901)\n",
      "h_from_s_denoised max, min, mean tensor(5.1510) tensor(0.) tensor(0.6515)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1822) tensor(1822)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4646) tensor([0.8191])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2767e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(63.6175) tensor([0.9900])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0021) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2385e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4718) tensor(0.) tensor(0.6345)\n",
      "h_from_s max, min, mean tensor(3.6421) tensor(0.) tensor(0.6736)\n",
      "h_from_s_denoised max, min, mean tensor(5.4752) tensor(0.) tensor(0.6349)\n",
      "avg nonzero/greaterzero h from book: tensor(967) tensor(967)\n",
      "avg nonzero/greaterzero h from s: tensor(1842) tensor(1842)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(965) tensor(965)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1785) tensor([0.9404])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1822e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(57.8732) tensor([0.9976])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.5700e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7824) tensor(0.) tensor(0.6641)\n",
      "h_from_s max, min, mean tensor(4.6163) tensor(0.) tensor(0.6981)\n",
      "h_from_s_denoised max, min, mean tensor(5.7859) tensor(0.) tensor(0.6646)\n",
      "avg nonzero/greaterzero h from book: tensor(1029) tensor(1029)\n",
      "avg nonzero/greaterzero h from s: tensor(1822) tensor(1822)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1028) tensor(1028)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1265) tensor([0.9565])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7197e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(44.2829) tensor([0.9962])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2706e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5163) tensor(0.) tensor(0.6425)\n",
      "h_from_s max, min, mean tensor(4.5287) tensor(0.) tensor(0.6198)\n",
      "h_from_s_denoised max, min, mean tensor(5.5204) tensor(0.) tensor(0.6430)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1678) tensor(1678)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(990) tensor(990)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1596) tensor([0.9499])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5155e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(91.0428) tensor([0.9927])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.6496e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3703) tensor(0.) tensor(0.6414)\n",
      "h_from_s max, min, mean tensor(4.3084) tensor(0.) tensor(0.7336)\n",
      "h_from_s_denoised max, min, mean tensor(5.3745) tensor(0.) tensor(0.6418)\n",
      "avg nonzero/greaterzero h from book: tensor(990) tensor(990)\n",
      "avg nonzero/greaterzero h from s: tensor(1832) tensor(1832)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(989) tensor(989)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1782) tensor([0.9341])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2672e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(67.2145) tensor([0.9932])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9523e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1085) tensor(0.) tensor(0.6718)\n",
      "h_from_s max, min, mean tensor(3.6353) tensor(0.) tensor(0.6432)\n",
      "h_from_s_denoised max, min, mean tensor(5.1121) tensor(0.) tensor(0.6723)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1683) tensor(1683)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2268) tensor([0.9252])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6440e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(143.9808) tensor([0.9907])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.2885e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6921) tensor(0.) tensor(0.6435)\n",
      "h_from_s max, min, mean tensor(4.2823) tensor(0.) tensor(0.6193)\n",
      "h_from_s_denoised max, min, mean tensor(5.6974) tensor(0.) tensor(0.6439)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1722) tensor(1722)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1398) tensor([0.9576])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3876e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(72.0632) tensor([0.9925])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0033) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8532e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.3232) tensor(0.) tensor(0.6303)\n",
      "h_from_s max, min, mean tensor(4.3851) tensor(0.) tensor(0.6275)\n",
      "h_from_s_denoised max, min, mean tensor(7.3278) tensor(0.) tensor(0.6308)\n",
      "avg nonzero/greaterzero h from book: tensor(974) tensor(974)\n",
      "avg nonzero/greaterzero h from s: tensor(1741) tensor(1741)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(973) tensor(973)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1905) tensor([0.9357])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3517e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(125.4129) tensor([0.9896])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0463e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 379/500 [00:10<00:03, 36.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6896) tensor(0.) tensor(0.6758)\n",
      "h_from_s max, min, mean tensor(3.9464) tensor(0.) tensor(0.7892)\n",
      "h_from_s_denoised max, min, mean tensor(5.6942) tensor(0.) tensor(0.6763)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1895) tensor(1895)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2113) tensor([0.9261])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0795e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(60.1337) tensor([0.9966])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.4468e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8589) tensor(0.) tensor(0.6206)\n",
      "h_from_s max, min, mean tensor(4.8259) tensor(0.) tensor(0.6293)\n",
      "h_from_s_denoised max, min, mean tensor(5.8625) tensor(0.) tensor(0.6211)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1717) tensor(1717)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1255) tensor([0.9554])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6961e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(110.6505) tensor([0.9949])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2689e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3790) tensor(0.) tensor(0.6674)\n",
      "h_from_s max, min, mean tensor(4.1022) tensor(0.) tensor(0.6615)\n",
      "h_from_s_denoised max, min, mean tensor(5.3833) tensor(0.) tensor(0.6679)\n",
      "avg nonzero/greaterzero h from book: tensor(989) tensor(989)\n",
      "avg nonzero/greaterzero h from s: tensor(1678) tensor(1678)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1210) tensor([0.9639])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8985e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(184.1951) tensor([0.9844])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0044) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0180e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7424) tensor(0.) tensor(0.6055)\n",
      "h_from_s max, min, mean tensor(4.5816) tensor(0.) tensor(0.6858)\n",
      "h_from_s_denoised max, min, mean tensor(5.7462) tensor(0.) tensor(0.6059)\n",
      "avg nonzero/greaterzero h from book: tensor(969) tensor(969)\n",
      "avg nonzero/greaterzero h from s: tensor(1782) tensor(1782)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(969) tensor(969)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1925) tensor([0.9189])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6071e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(124.9215) tensor([0.9925])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0076) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2757e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4528) tensor(0.) tensor(0.6625)\n",
      "h_from_s max, min, mean tensor(5.1870) tensor(0.) tensor(0.6986)\n",
      "h_from_s_denoised max, min, mean tensor(5.4565) tensor(0.) tensor(0.6630)\n",
      "avg nonzero/greaterzero h from book: tensor(1024) tensor(1024)\n",
      "avg nonzero/greaterzero h from s: tensor(1652) tensor(1652)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0497) tensor([0.9819])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8171e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(108.0548) tensor([0.9938])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0068) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.9757e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4953) tensor(0.) tensor(0.6410)\n",
      "h_from_s max, min, mean tensor(4.6264) tensor(0.) tensor(0.6257)\n",
      "h_from_s_denoised max, min, mean tensor(6.4998) tensor(0.) tensor(0.6414)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1632) tensor(1632)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2055) tensor([0.9280])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4058e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(245.1830) tensor([0.9740])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.0691e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0947) tensor(0.) tensor(0.6281)\n",
      "h_from_s max, min, mean tensor(4.3576) tensor(0.) tensor(0.6656)\n",
      "h_from_s_denoised max, min, mean tensor(5.0987) tensor(0.) tensor(0.6285)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1668) tensor(1668)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0516) tensor([0.9803])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8046e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(66.6337) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2578e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4734) tensor(0.) tensor(0.6576)\n",
      "h_from_s max, min, mean tensor(5.0828) tensor(0.) tensor(0.6223)\n",
      "h_from_s_denoised max, min, mean tensor(6.4779) tensor(0.) tensor(0.6581)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1705) tensor(1705)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1382) tensor([0.9621])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4021e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(87.1082) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.1888e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 387/500 [00:10<00:03, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6079) tensor(0.) tensor(0.6383)\n",
      "h_from_s max, min, mean tensor(4.4673) tensor(0.) tensor(0.7107)\n",
      "h_from_s_denoised max, min, mean tensor(6.6136) tensor(0.) tensor(0.6387)\n",
      "avg nonzero/greaterzero h from book: tensor(961) tensor(961)\n",
      "avg nonzero/greaterzero h from s: tensor(1810) tensor(1810)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(960) tensor(960)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1931) tensor([0.9296])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1188e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(59.3687) tensor([0.9949])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2135e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6028) tensor(0.) tensor(0.6687)\n",
      "h_from_s max, min, mean tensor(3.6347) tensor(0.) tensor(0.6429)\n",
      "h_from_s_denoised max, min, mean tensor(5.6071) tensor(0.) tensor(0.6692)\n",
      "avg nonzero/greaterzero h from book: tensor(1004) tensor(1004)\n",
      "avg nonzero/greaterzero h from s: tensor(1778) tensor(1778)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1003) tensor(1003)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3754) tensor([0.8707])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9691e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(96.6857) tensor([0.9939])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.5961e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4279) tensor(0.) tensor(0.6504)\n",
      "h_from_s max, min, mean tensor(5.0648) tensor(0.) tensor(0.6904)\n",
      "h_from_s_denoised max, min, mean tensor(6.4335) tensor(0.) tensor(0.6508)\n",
      "avg nonzero/greaterzero h from book: tensor(1043) tensor(1043)\n",
      "avg nonzero/greaterzero h from s: tensor(1821) tensor(1821)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1041) tensor(1041)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1113) tensor([0.9598])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6273e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(64.9607) tensor([0.9944])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3080e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.3383) tensor(0.) tensor(0.6097)\n",
      "h_from_s max, min, mean tensor(6.4671) tensor(0.) tensor(0.6732)\n",
      "h_from_s_denoised max, min, mean tensor(7.3430) tensor(0.) tensor(0.6102)\n",
      "avg nonzero/greaterzero h from book: tensor(952) tensor(952)\n",
      "avg nonzero/greaterzero h from s: tensor(1726) tensor(1726)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(951) tensor(951)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0601) tensor([0.9765])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7751e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(47.7628) tensor([0.9983])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0087) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(9.5676e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7311) tensor(0.) tensor(0.6691)\n",
      "h_from_s max, min, mean tensor(5.3029) tensor(0.) tensor(0.7361)\n",
      "h_from_s_denoised max, min, mean tensor(6.7362) tensor(0.) tensor(0.6695)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1781) tensor(1781)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0982) tensor([0.9663])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7415e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(74.5470) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.8425e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6922) tensor(0.) tensor(0.6581)\n",
      "h_from_s max, min, mean tensor(4.2579) tensor(0.) tensor(0.6958)\n",
      "h_from_s_denoised max, min, mean tensor(5.6956) tensor(0.) tensor(0.6586)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1775) tensor(1775)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(986) tensor(986)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1764) tensor([0.9373])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4338e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(60.8123) tensor([0.9951])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.6095e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9948) tensor(0.) tensor(0.6434)\n",
      "h_from_s max, min, mean tensor(4.7657) tensor(0.) tensor(0.5630)\n",
      "h_from_s_denoised max, min, mean tensor(5.9984) tensor(0.) tensor(0.6439)\n",
      "avg nonzero/greaterzero h from book: tensor(1003) tensor(1003)\n",
      "avg nonzero/greaterzero h from s: tensor(1506) tensor(1506)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1185) tensor([0.9717])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6797e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(131.7470) tensor([0.9797])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6250e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0486) tensor(0.) tensor(0.6465)\n",
      "h_from_s max, min, mean tensor(3.7838) tensor(0.) tensor(0.6683)\n",
      "h_from_s_denoised max, min, mean tensor(6.0537) tensor(0.) tensor(0.6469)\n",
      "avg nonzero/greaterzero h from book: tensor(992) tensor(992)\n",
      "avg nonzero/greaterzero h from s: tensor(1809) tensor(1809)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2284) tensor([0.9178])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7026e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(93.4829) tensor([0.9925])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.8349e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 395/500 [00:11<00:02, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4126) tensor(0.) tensor(0.6207)\n",
      "h_from_s max, min, mean tensor(5.6246) tensor(0.) tensor(0.6139)\n",
      "h_from_s_denoised max, min, mean tensor(6.4169) tensor(0.) tensor(0.6211)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1585) tensor(1585)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0701) tensor([0.9760])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.7283e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(94.6733) tensor([0.9943])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6066e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1829) tensor(0.) tensor(0.6705)\n",
      "h_from_s max, min, mean tensor(4.2751) tensor(0.) tensor(0.7456)\n",
      "h_from_s_denoised max, min, mean tensor(5.1860) tensor(0.) tensor(0.6709)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1853) tensor(1853)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1128) tensor([0.9611])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6756e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(27.1767) tensor([0.9987])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5055e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1583) tensor(0.) tensor(0.6229)\n",
      "h_from_s max, min, mean tensor(4.8580) tensor(0.) tensor(0.6425)\n",
      "h_from_s_denoised max, min, mean tensor(6.1624) tensor(0.) tensor(0.6233)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1698) tensor(1698)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0934) tensor([0.9673])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2158e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(109.8977) tensor([0.9934])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.2208e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6067) tensor(0.) tensor(0.6559)\n",
      "h_from_s max, min, mean tensor(4.3459) tensor(0.) tensor(0.6626)\n",
      "h_from_s_denoised max, min, mean tensor(5.6107) tensor(0.) tensor(0.6564)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1695) tensor(1695)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1741) tensor([0.9395])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6113e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(144.1812) tensor([0.9916])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4133e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0136) tensor(0.) tensor(0.6665)\n",
      "h_from_s max, min, mean tensor(3.6931) tensor(0.) tensor(0.5700)\n",
      "h_from_s_denoised max, min, mean tensor(5.0169) tensor(0.) tensor(0.6670)\n",
      "avg nonzero/greaterzero h from book: tensor(1007) tensor(1007)\n",
      "avg nonzero/greaterzero h from s: tensor(1603) tensor(1603)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2170) tensor([0.9441])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9114e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(438.2144) tensor([0.9482])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.6719e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2157) tensor(0.) tensor(0.6301)\n",
      "h_from_s max, min, mean tensor(4.3895) tensor(0.) tensor(0.7255)\n",
      "h_from_s_denoised max, min, mean tensor(6.2207) tensor(0.) tensor(0.6306)\n",
      "avg nonzero/greaterzero h from book: tensor(959) tensor(959)\n",
      "avg nonzero/greaterzero h from s: tensor(1824) tensor(1824)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(959) tensor(959)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1961) tensor([0.9233])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8917e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(69.8194) tensor([0.9957])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8359e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6253) tensor(0.) tensor(0.6605)\n",
      "h_from_s max, min, mean tensor(4.3029) tensor(0.) tensor(0.5972)\n",
      "h_from_s_denoised max, min, mean tensor(5.6297) tensor(0.) tensor(0.6610)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1572) tensor(1572)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1465) tensor([0.9582])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6414e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(133.1110) tensor([0.9846])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4416e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.4557) tensor(0.) tensor(0.6093)\n",
      "h_from_s max, min, mean tensor(4.0183) tensor(0.) tensor(0.5742)\n",
      "h_from_s_denoised max, min, mean tensor(7.4604) tensor(0.) tensor(0.6097)\n",
      "avg nonzero/greaterzero h from book: tensor(959) tensor(959)\n",
      "avg nonzero/greaterzero h from s: tensor(1874) tensor(1874)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(957) tensor(957)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3516) tensor([0.8694])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6566e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(31.7008) tensor([0.9966])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0065) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.8583e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 403/500 [00:11<00:02, 36.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.9523) tensor(0.) tensor(0.6745)\n",
      "h_from_s max, min, mean tensor(3.9766) tensor(0.) tensor(0.5483)\n",
      "h_from_s_denoised max, min, mean tensor(6.6271) tensor(0.) tensor(0.6213)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1774) tensor(1774)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(979) tensor(979)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.6389) tensor([0.7687])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(0.7516) tensor([0.7312])\n",
      "mse/cosinesimilarity s and s from h from s tensor(117.1781) tensor([0.9804])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(5633.7383) tensor([0.3992])\n",
      "mse/cosinesimilarity s and s from h tensor(3.8729e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6983) tensor(0.) tensor(0.6552)\n",
      "h_from_s max, min, mean tensor(5.3160) tensor(0.) tensor(0.7187)\n",
      "h_from_s_denoised max, min, mean tensor(6.7029) tensor(0.) tensor(0.6557)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1672) tensor(1672)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1316) tensor([0.9509])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5732e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(159.6344) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0090) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0955e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7671) tensor(0.) tensor(0.6223)\n",
      "h_from_s max, min, mean tensor(5.8707) tensor(0.) tensor(0.6536)\n",
      "h_from_s_denoised max, min, mean tensor(5.7719) tensor(0.) tensor(0.6227)\n",
      "avg nonzero/greaterzero h from book: tensor(969) tensor(969)\n",
      "avg nonzero/greaterzero h from s: tensor(1550) tensor(1550)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(968) tensor(968)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0220) tensor([0.9911])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6399e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.8874) tensor([0.9959])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0062) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1069e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(4.9355) tensor(0.) tensor(0.6582)\n",
      "h_from_s max, min, mean tensor(3.5290) tensor(0.) tensor(0.6391)\n",
      "h_from_s_denoised max, min, mean tensor(4.9389) tensor(0.) tensor(0.6587)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1774) tensor(1774)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2035) tensor([0.9336])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4676e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(65.1029) tensor([0.9946])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.7831e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0900) tensor(0.) tensor(0.6296)\n",
      "h_from_s max, min, mean tensor(3.9648) tensor(0.) tensor(0.5619)\n",
      "h_from_s_denoised max, min, mean tensor(6.0949) tensor(0.) tensor(0.6301)\n",
      "avg nonzero/greaterzero h from book: tensor(1008) tensor(1008)\n",
      "avg nonzero/greaterzero h from s: tensor(1617) tensor(1617)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1007) tensor(1007)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1952) tensor([0.9381])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9680e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(160.9389) tensor([0.9847])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5559e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3775) tensor(0.) tensor(0.6539)\n",
      "h_from_s max, min, mean tensor(4.4020) tensor(0.) tensor(0.6433)\n",
      "h_from_s_denoised max, min, mean tensor(5.3807) tensor(0.) tensor(0.6543)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1629) tensor(1629)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1647) tensor([0.9468])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7041e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(200.1169) tensor([0.9835])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4901e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8233) tensor(0.) tensor(0.6603)\n",
      "h_from_s max, min, mean tensor(5.2648) tensor(0.) tensor(0.6812)\n",
      "h_from_s_denoised max, min, mean tensor(5.8279) tensor(0.) tensor(0.6608)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1740) tensor(1740)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0650) tensor([0.9784])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8920e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(45.7360) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3233e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6391) tensor(0.) tensor(0.6127)\n",
      "h_from_s max, min, mean tensor(4.2355) tensor(0.) tensor(0.6122)\n",
      "h_from_s_denoised max, min, mean tensor(5.6429) tensor(0.) tensor(0.6132)\n",
      "avg nonzero/greaterzero h from book: tensor(931) tensor(931)\n",
      "avg nonzero/greaterzero h from s: tensor(1620) tensor(1620)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(931) tensor(931)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2178) tensor([0.9175])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6962e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(161.3899) tensor([0.9893])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0072) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.1750e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 411/500 [00:11<00:02, 36.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8045) tensor(0.) tensor(0.6761)\n",
      "h_from_s max, min, mean tensor(3.4820) tensor(0.) tensor(0.6614)\n",
      "h_from_s_denoised max, min, mean tensor(5.8089) tensor(0.) tensor(0.6765)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1791) tensor(1791)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(999) tensor(999)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3018) tensor([0.8981])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6278e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(68.1419) tensor([0.9941])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0028) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.3548e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5455) tensor(0.) tensor(0.6282)\n",
      "h_from_s max, min, mean tensor(3.7695) tensor(0.) tensor(0.6346)\n",
      "h_from_s_denoised max, min, mean tensor(5.5496) tensor(0.) tensor(0.6286)\n",
      "avg nonzero/greaterzero h from book: tensor(973) tensor(973)\n",
      "avg nonzero/greaterzero h from s: tensor(1728) tensor(1728)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2495) tensor([0.9071])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1745e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(107.3652) tensor([0.9909])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0043) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.6504e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1998) tensor(0.) tensor(0.6636)\n",
      "h_from_s max, min, mean tensor(2.9647) tensor(0.) tensor(0.6286)\n",
      "h_from_s_denoised max, min, mean tensor(5.2036) tensor(0.) tensor(0.6641)\n",
      "avg nonzero/greaterzero h from book: tensor(1029) tensor(1029)\n",
      "avg nonzero/greaterzero h from s: tensor(1834) tensor(1834)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1027) tensor(1027)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4062) tensor([0.8438])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7527e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(50.2414) tensor([0.9917])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0039) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6214e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7383) tensor(0.) tensor(0.6293)\n",
      "h_from_s max, min, mean tensor(4.5714) tensor(0.) tensor(0.6991)\n",
      "h_from_s_denoised max, min, mean tensor(5.7424) tensor(0.) tensor(0.6298)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1807) tensor(1807)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1535) tensor([0.9411])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5048e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(65.0724) tensor([0.9948])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(3.9339e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5372) tensor(0.) tensor(0.6459)\n",
      "h_from_s max, min, mean tensor(5.6232) tensor(0.) tensor(0.6507)\n",
      "h_from_s_denoised max, min, mean tensor(6.5414) tensor(0.) tensor(0.6464)\n",
      "avg nonzero/greaterzero h from book: tensor(975) tensor(975)\n",
      "avg nonzero/greaterzero h from s: tensor(1654) tensor(1654)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0425) tensor([0.9882])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3738e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(49.6993) tensor([0.9975])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.5214e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4175) tensor(0.) tensor(0.6710)\n",
      "h_from_s max, min, mean tensor(3.8525) tensor(0.) tensor(0.7073)\n",
      "h_from_s_denoised max, min, mean tensor(5.4210) tensor(0.) tensor(0.6715)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1757) tensor(1757)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2690) tensor([0.9038])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6122e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(107.7799) tensor([0.9915])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0516e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2935) tensor(0.) tensor(0.6374)\n",
      "h_from_s max, min, mean tensor(3.2612) tensor(0.) tensor(0.5500)\n",
      "h_from_s_denoised max, min, mean tensor(5.2972) tensor(0.) tensor(0.6379)\n",
      "avg nonzero/greaterzero h from book: tensor(956) tensor(956)\n",
      "avg nonzero/greaterzero h from s: tensor(1640) tensor(1640)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(955) tensor(955)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2020) tensor([0.9496])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3334e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(103.9153) tensor([0.9812])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0032) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2323e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5638) tensor(0.) tensor(0.6473)\n",
      "h_from_s max, min, mean tensor(5.0956) tensor(0.) tensor(0.6695)\n",
      "h_from_s_denoised max, min, mean tensor(5.5681) tensor(0.) tensor(0.6477)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1627) tensor(1627)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1004) tensor(1004)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2007) tensor([0.9256])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6699e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(196.6238) tensor([0.9804])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0052) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1846e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 419/500 [00:11<00:02, 36.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8241) tensor(0.) tensor(0.6526)\n",
      "h_from_s max, min, mean tensor(4.3793) tensor(0.) tensor(0.6088)\n",
      "h_from_s_denoised max, min, mean tensor(5.8278) tensor(0.) tensor(0.6531)\n",
      "avg nonzero/greaterzero h from book: tensor(993) tensor(993)\n",
      "avg nonzero/greaterzero h from s: tensor(1625) tensor(1625)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(991) tensor(991)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1554) tensor([0.9523])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7160e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(139.0887) tensor([0.9908])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1928e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5020) tensor(0.) tensor(0.6209)\n",
      "h_from_s max, min, mean tensor(5.0069) tensor(0.) tensor(0.6306)\n",
      "h_from_s_denoised max, min, mean tensor(6.5073) tensor(0.) tensor(0.6213)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1654) tensor(1654)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0837) tensor([0.9715])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6435e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(144.6361) tensor([0.9927])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.5023e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8665) tensor(0.) tensor(0.6569)\n",
      "h_from_s max, min, mean tensor(3.8357) tensor(0.) tensor(0.7185)\n",
      "h_from_s_denoised max, min, mean tensor(5.8703) tensor(0.) tensor(0.6574)\n",
      "avg nonzero/greaterzero h from book: tensor(1040) tensor(1040)\n",
      "avg nonzero/greaterzero h from s: tensor(1868) tensor(1868)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1039) tensor(1039)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3270) tensor([0.8733])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7015e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(39.7595) tensor([0.9966])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1777e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1563) tensor(0.) tensor(0.6279)\n",
      "h_from_s max, min, mean tensor(5.2651) tensor(0.) tensor(0.6513)\n",
      "h_from_s_denoised max, min, mean tensor(6.1607) tensor(0.) tensor(0.6283)\n",
      "avg nonzero/greaterzero h from book: tensor(965) tensor(965)\n",
      "avg nonzero/greaterzero h from s: tensor(1652) tensor(1652)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(965) tensor(965)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0577) tensor([0.9801])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8750e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(167.1058) tensor([0.9792])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.6654e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.0812) tensor(0.) tensor(0.6701)\n",
      "h_from_s max, min, mean tensor(4.8805) tensor(0.) tensor(0.6181)\n",
      "h_from_s_denoised max, min, mean tensor(7.0862) tensor(0.) tensor(0.6706)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1698) tensor(1698)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2021) tensor([0.9438])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0163e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(173.7244) tensor([0.9587])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0036) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0567e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.5379) tensor(0.) tensor(0.6610)\n",
      "h_from_s max, min, mean tensor(4.1976) tensor(0.) tensor(0.6111)\n",
      "h_from_s_denoised max, min, mean tensor(6.5433) tensor(0.) tensor(0.6614)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1658) tensor(1658)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1836) tensor([0.9458])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6557e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(100.2224) tensor([0.9919])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.5491e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9531) tensor(0.) tensor(0.6608)\n",
      "h_from_s max, min, mean tensor(3.7698) tensor(0.) tensor(0.6027)\n",
      "h_from_s_denoised max, min, mean tensor(5.9570) tensor(0.) tensor(0.6613)\n",
      "avg nonzero/greaterzero h from book: tensor(1030) tensor(1030)\n",
      "avg nonzero/greaterzero h from s: tensor(1699) tensor(1699)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1030) tensor(1030)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2842) tensor([0.9096])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6684e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(180.3451) tensor([0.9823])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0079) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0243e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8790) tensor(0.) tensor(0.6487)\n",
      "h_from_s max, min, mean tensor(3.8390) tensor(0.) tensor(0.6845)\n",
      "h_from_s_denoised max, min, mean tensor(5.8832) tensor(0.) tensor(0.6492)\n",
      "avg nonzero/greaterzero h from book: tensor(1026) tensor(1026)\n",
      "avg nonzero/greaterzero h from s: tensor(1785) tensor(1785)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1025) tensor(1025)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2227) tensor([0.9153])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3750e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(135.8282) tensor([0.9933])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2098e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 427/500 [00:12<00:02, 36.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8260) tensor(0.) tensor(0.6329)\n",
      "h_from_s max, min, mean tensor(4.4375) tensor(0.) tensor(0.6178)\n",
      "h_from_s_denoised max, min, mean tensor(5.8308) tensor(0.) tensor(0.6334)\n",
      "avg nonzero/greaterzero h from book: tensor(980) tensor(980)\n",
      "avg nonzero/greaterzero h from s: tensor(1696) tensor(1696)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0913) tensor([0.9735])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0236e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(75.6191) tensor([0.9911])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2280e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5916) tensor(0.) tensor(0.6658)\n",
      "h_from_s max, min, mean tensor(3.2479) tensor(0.) tensor(0.6584)\n",
      "h_from_s_denoised max, min, mean tensor(5.5952) tensor(0.) tensor(0.6663)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1836) tensor(1836)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4235) tensor([0.8507])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8927e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.2692) tensor([0.9935])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0062) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.0086e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9604) tensor(0.) tensor(0.6549)\n",
      "h_from_s max, min, mean tensor(5.0005) tensor(0.) tensor(0.6973)\n",
      "h_from_s_denoised max, min, mean tensor(5.9636) tensor(0.) tensor(0.6553)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1725) tensor(1725)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0548) tensor([0.9813])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5611e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(85.0331) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0079) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.2949e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9569) tensor(0.) tensor(0.6503)\n",
      "h_from_s max, min, mean tensor(4.5869) tensor(0.) tensor(0.6353)\n",
      "h_from_s_denoised max, min, mean tensor(5.9606) tensor(0.) tensor(0.6507)\n",
      "avg nonzero/greaterzero h from book: tensor(1006) tensor(1006)\n",
      "avg nonzero/greaterzero h from s: tensor(1735) tensor(1735)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1005) tensor(1005)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1452) tensor([0.9551])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3435e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(64.7952) tensor([0.9955])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0081) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.5572e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1621) tensor(0.) tensor(0.6853)\n",
      "h_from_s max, min, mean tensor(5.0595) tensor(0.) tensor(0.7717)\n",
      "h_from_s_denoised max, min, mean tensor(6.1664) tensor(0.) tensor(0.6858)\n",
      "avg nonzero/greaterzero h from book: tensor(1042) tensor(1042)\n",
      "avg nonzero/greaterzero h from s: tensor(1844) tensor(1844)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1042) tensor(1042)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0885) tensor([0.9691])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0404e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(40.2929) tensor([0.9982])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0087) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.5863e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3020) tensor(0.) tensor(0.6486)\n",
      "h_from_s max, min, mean tensor(4.9565) tensor(0.) tensor(0.7109)\n",
      "h_from_s_denoised max, min, mean tensor(6.3063) tensor(0.) tensor(0.6491)\n",
      "avg nonzero/greaterzero h from book: tensor(959) tensor(959)\n",
      "avg nonzero/greaterzero h from s: tensor(1801) tensor(1801)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(958) tensor(958)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1489) tensor([0.9470])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5144e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(51.7299) tensor([0.9985])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0112) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3076e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5307) tensor(0.) tensor(0.6593)\n",
      "h_from_s max, min, mean tensor(3.8381) tensor(0.) tensor(0.7534)\n",
      "h_from_s_denoised max, min, mean tensor(5.5339) tensor(0.) tensor(0.6598)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1794) tensor(1794)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1015) tensor(1015)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4311) tensor([0.8240])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3077e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(173.5314) tensor([0.9860])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0073) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.1733e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9045) tensor(0.) tensor(0.6136)\n",
      "h_from_s max, min, mean tensor(4.4879) tensor(0.) tensor(0.6527)\n",
      "h_from_s_denoised max, min, mean tensor(5.9088) tensor(0.) tensor(0.6140)\n",
      "avg nonzero/greaterzero h from book: tensor(975) tensor(975)\n",
      "avg nonzero/greaterzero h from s: tensor(1739) tensor(1739)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(974) tensor(974)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1270) tensor([0.9512])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.6363e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(81.7771) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0110) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8471e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 435/500 [00:12<00:01, 36.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4180) tensor(0.) tensor(0.6554)\n",
      "h_from_s max, min, mean tensor(4.3178) tensor(0.) tensor(0.6333)\n",
      "h_from_s_denoised max, min, mean tensor(6.4227) tensor(0.) tensor(0.6559)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1651) tensor(1651)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1019) tensor(1019)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2261) tensor([0.9195])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6448e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(260.0552) tensor([0.9753])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0041) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.9559e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6152) tensor(0.) tensor(0.6749)\n",
      "h_from_s max, min, mean tensor(3.6873) tensor(0.) tensor(0.7747)\n",
      "h_from_s_denoised max, min, mean tensor(5.6198) tensor(0.) tensor(0.6754)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1862) tensor(1862)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3113) tensor([0.8867])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0745e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(44.5772) tensor([0.9971])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0038) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.7633e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1553) tensor(0.) tensor(0.6354)\n",
      "h_from_s max, min, mean tensor(4.3592) tensor(0.) tensor(0.6059)\n",
      "h_from_s_denoised max, min, mean tensor(5.1599) tensor(0.) tensor(0.6358)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1507) tensor(1507)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(972) tensor(972)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0430) tensor([0.9890])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2957e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(84.1376) tensor([0.9940])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9690e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0923) tensor(0.) tensor(0.6432)\n",
      "h_from_s max, min, mean tensor(3.7681) tensor(0.) tensor(0.6627)\n",
      "h_from_s_denoised max, min, mean tensor(5.0960) tensor(0.) tensor(0.6436)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1747) tensor(1747)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1683) tensor([0.9396])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7197e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(107.9818) tensor([0.9929])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0075) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.4231e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5440) tensor(0.) tensor(0.6375)\n",
      "h_from_s max, min, mean tensor(5.1768) tensor(0.) tensor(0.6318)\n",
      "h_from_s_denoised max, min, mean tensor(5.5472) tensor(0.) tensor(0.6380)\n",
      "avg nonzero/greaterzero h from book: tensor(1002) tensor(1002)\n",
      "avg nonzero/greaterzero h from s: tensor(1573) tensor(1573)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1000) tensor(1000)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0703) tensor([0.9765])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1086e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(107.7060) tensor([0.9877])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0048) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.7281e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8816) tensor(0.) tensor(0.6567)\n",
      "h_from_s max, min, mean tensor(5.1482) tensor(0.) tensor(0.6647)\n",
      "h_from_s_denoised max, min, mean tensor(5.8851) tensor(0.) tensor(0.6571)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1593) tensor(1593)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0798) tensor([0.9728])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2648e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(76.9821) tensor([0.9963])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0099) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1082e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0471) tensor(0.) tensor(0.6781)\n",
      "h_from_s max, min, mean tensor(3.3929) tensor(0.) tensor(0.5943)\n",
      "h_from_s_denoised max, min, mean tensor(6.0517) tensor(0.) tensor(0.6786)\n",
      "avg nonzero/greaterzero h from book: tensor(1037) tensor(1037)\n",
      "avg nonzero/greaterzero h from s: tensor(1660) tensor(1660)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2896) tensor([0.9104])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7751e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(128.7931) tensor([0.9822])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0051) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.6384e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1130) tensor(0.) tensor(0.6353)\n",
      "h_from_s max, min, mean tensor(5.0243) tensor(0.) tensor(0.6804)\n",
      "h_from_s_denoised max, min, mean tensor(6.1171) tensor(0.) tensor(0.6358)\n",
      "avg nonzero/greaterzero h from book: tensor(956) tensor(956)\n",
      "avg nonzero/greaterzero h from s: tensor(1701) tensor(1701)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(954) tensor(954)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1882) tensor([0.9300])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2739e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(190.6801) tensor([0.9807])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0060) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4437e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 443/500 [00:12<00:01, 36.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7795) tensor(0.) tensor(0.6617)\n",
      "h_from_s max, min, mean tensor(3.5364) tensor(0.) tensor(0.6446)\n",
      "h_from_s_denoised max, min, mean tensor(5.7840) tensor(0.) tensor(0.6621)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1823) tensor(1823)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1018) tensor(1018)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2966) tensor([0.8974])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5142e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(50.1092) tensor([0.9970])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1802e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7132) tensor(0.) tensor(0.6453)\n",
      "h_from_s max, min, mean tensor(3.9567) tensor(0.) tensor(0.7252)\n",
      "h_from_s_denoised max, min, mean tensor(5.7168) tensor(0.) tensor(0.6458)\n",
      "avg nonzero/greaterzero h from book: tensor(971) tensor(971)\n",
      "avg nonzero/greaterzero h from s: tensor(1809) tensor(1809)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(970) tensor(970)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2463) tensor([0.9053])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2151e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(100.0878) tensor([0.9938])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(7.0276e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2579) tensor(0.) tensor(0.6705)\n",
      "h_from_s max, min, mean tensor(4.9069) tensor(0.) tensor(0.6966)\n",
      "h_from_s_denoised max, min, mean tensor(6.2623) tensor(0.) tensor(0.6710)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1739) tensor(1739)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1026) tensor(1026)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0740) tensor([0.9766])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8236e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(92.0306) tensor([0.9963])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0089) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.5618e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1788) tensor(0.) tensor(0.6498)\n",
      "h_from_s max, min, mean tensor(3.2818) tensor(0.) tensor(0.6359)\n",
      "h_from_s_denoised max, min, mean tensor(5.1822) tensor(0.) tensor(0.6502)\n",
      "avg nonzero/greaterzero h from book: tensor(1020) tensor(1020)\n",
      "avg nonzero/greaterzero h from s: tensor(1767) tensor(1767)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1020) tensor(1020)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3300) tensor([0.8743])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2244e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(103.6399) tensor([0.9897])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0059) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.9141e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3449) tensor(0.) tensor(0.6201)\n",
      "h_from_s max, min, mean tensor(3.5936) tensor(0.) tensor(0.6057)\n",
      "h_from_s_denoised max, min, mean tensor(5.3501) tensor(0.) tensor(0.6205)\n",
      "avg nonzero/greaterzero h from book: tensor(971) tensor(971)\n",
      "avg nonzero/greaterzero h from s: tensor(1744) tensor(1744)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(966) tensor(966)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2775) tensor([0.8951])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8972e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(114.6572) tensor([0.9875])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.2841e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2960) tensor(0.) tensor(0.6552)\n",
      "h_from_s max, min, mean tensor(3.7708) tensor(0.) tensor(0.5700)\n",
      "h_from_s_denoised max, min, mean tensor(6.2999) tensor(0.) tensor(0.6556)\n",
      "avg nonzero/greaterzero h from book: tensor(994) tensor(994)\n",
      "avg nonzero/greaterzero h from s: tensor(1676) tensor(1676)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3706) tensor([0.8810])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6967e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(131.6884) tensor([0.9867])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0079) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.3452e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.4670) tensor(0.) tensor(0.6429)\n",
      "h_from_s max, min, mean tensor(5.9030) tensor(0.) tensor(0.6262)\n",
      "h_from_s_denoised max, min, mean tensor(6.4718) tensor(0.) tensor(0.6433)\n",
      "avg nonzero/greaterzero h from book: tensor(986) tensor(986)\n",
      "avg nonzero/greaterzero h from s: tensor(1619) tensor(1619)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(987) tensor(987)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0836) tensor([0.9739])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2895e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(97.5096) tensor([0.9883])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3403e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6233) tensor(0.) tensor(0.6555)\n",
      "h_from_s max, min, mean tensor(4.0429) tensor(0.) tensor(0.6829)\n",
      "h_from_s_denoised max, min, mean tensor(5.6276) tensor(0.) tensor(0.6560)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1642) tensor(1642)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1027) tensor(1027)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1820) tensor([0.9291])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3920e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(204.6510) tensor([0.9886])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0464e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [00:12<00:01, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4626) tensor(0.) tensor(0.6809)\n",
      "h_from_s max, min, mean tensor(3.7902) tensor(0.) tensor(0.6388)\n",
      "h_from_s_denoised max, min, mean tensor(5.4674) tensor(0.) tensor(0.6814)\n",
      "avg nonzero/greaterzero h from book: tensor(1034) tensor(1034)\n",
      "avg nonzero/greaterzero h from s: tensor(1562) tensor(1562)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1034) tensor(1034)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2146) tensor([0.9280])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.8484e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(465.5938) tensor([0.9641])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0042) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(7.5915e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1506) tensor(0.) tensor(0.6340)\n",
      "h_from_s max, min, mean tensor(2.7237) tensor(0.) tensor(0.5857)\n",
      "h_from_s_denoised max, min, mean tensor(6.1548) tensor(0.) tensor(0.6345)\n",
      "avg nonzero/greaterzero h from book: tensor(966) tensor(966)\n",
      "avg nonzero/greaterzero h from s: tensor(1913) tensor(1913)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(965) tensor(965)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.5023) tensor([0.8229])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5364e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(37.2028) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0055) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.8693e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4518) tensor(0.) tensor(0.6562)\n",
      "h_from_s max, min, mean tensor(4.4405) tensor(0.) tensor(0.7028)\n",
      "h_from_s_denoised max, min, mean tensor(5.4555) tensor(0.) tensor(0.6567)\n",
      "avg nonzero/greaterzero h from book: tensor(1011) tensor(1011)\n",
      "avg nonzero/greaterzero h from s: tensor(1806) tensor(1806)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0668) tensor([0.9764])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2654e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(33.2436) tensor([0.9982])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0056) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9895e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7556) tensor(0.) tensor(0.6251)\n",
      "h_from_s max, min, mean tensor(5.2642) tensor(0.) tensor(0.7036)\n",
      "h_from_s_denoised max, min, mean tensor(5.7591) tensor(0.) tensor(0.6255)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1697) tensor(1697)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1777) tensor([0.9272])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.5902e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(169.2632) tensor([0.9897])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0053) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2004e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3493) tensor(0.) tensor(0.6687)\n",
      "h_from_s max, min, mean tensor(2.6874) tensor(0.) tensor(0.6524)\n",
      "h_from_s_denoised max, min, mean tensor(5.3525) tensor(0.) tensor(0.6692)\n",
      "avg nonzero/greaterzero h from book: tensor(1005) tensor(1005)\n",
      "avg nonzero/greaterzero h from s: tensor(1896) tensor(1896)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1002) tensor(1002)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4102) tensor([0.8547])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7399e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(48.6242) tensor([0.9942])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3980e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3647) tensor(0.) tensor(0.6792)\n",
      "h_from_s max, min, mean tensor(4.6488) tensor(0.) tensor(0.6917)\n",
      "h_from_s_denoised max, min, mean tensor(5.3686) tensor(0.) tensor(0.6797)\n",
      "avg nonzero/greaterzero h from book: tensor(1017) tensor(1017)\n",
      "avg nonzero/greaterzero h from s: tensor(1765) tensor(1765)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1017) tensor(1017)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0475) tensor([0.9863])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.0497e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.7304) tensor([0.9976])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.4294e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7824) tensor(0.) tensor(0.6478)\n",
      "h_from_s max, min, mean tensor(4.2657) tensor(0.) tensor(0.6357)\n",
      "h_from_s_denoised max, min, mean tensor(5.7872) tensor(0.) tensor(0.6483)\n",
      "avg nonzero/greaterzero h from book: tensor(1012) tensor(1012)\n",
      "avg nonzero/greaterzero h from s: tensor(1725) tensor(1725)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1010) tensor(1010)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1279) tensor([0.9616])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5942e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(68.6481) tensor([0.9964])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0092) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6810e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0738) tensor(0.) tensor(0.6514)\n",
      "h_from_s max, min, mean tensor(4.5456) tensor(0.) tensor(0.6567)\n",
      "h_from_s_denoised max, min, mean tensor(6.0781) tensor(0.) tensor(0.6519)\n",
      "avg nonzero/greaterzero h from book: tensor(997) tensor(997)\n",
      "avg nonzero/greaterzero h from s: tensor(1701) tensor(1701)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1205) tensor([0.9599])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7262e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(105.9506) tensor([0.9939])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0979e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 459/500 [00:12<00:01, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9099) tensor(0.) tensor(0.6293)\n",
      "h_from_s max, min, mean tensor(2.9936) tensor(0.) tensor(0.5843)\n",
      "h_from_s_denoised max, min, mean tensor(5.9140) tensor(0.) tensor(0.6297)\n",
      "avg nonzero/greaterzero h from book: tensor(978) tensor(978)\n",
      "avg nonzero/greaterzero h from s: tensor(1832) tensor(1832)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4513) tensor([0.8205])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0594e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(80.0847) tensor([0.9828])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3127e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5479) tensor(0.) tensor(0.6506)\n",
      "h_from_s max, min, mean tensor(3.7165) tensor(0.) tensor(0.6180)\n",
      "h_from_s_denoised max, min, mean tensor(5.5518) tensor(0.) tensor(0.6511)\n",
      "avg nonzero/greaterzero h from book: tensor(998) tensor(998)\n",
      "avg nonzero/greaterzero h from s: tensor(1834) tensor(1834)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(996) tensor(996)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3195) tensor([0.8933])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2556e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.0512) tensor([0.9942])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.5256e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0410) tensor(0.) tensor(0.6772)\n",
      "h_from_s max, min, mean tensor(4.2726) tensor(0.) tensor(0.6750)\n",
      "h_from_s_denoised max, min, mean tensor(5.0438) tensor(0.) tensor(0.6777)\n",
      "avg nonzero/greaterzero h from book: tensor(1034) tensor(1034)\n",
      "avg nonzero/greaterzero h from s: tensor(1616) tensor(1616)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1033) tensor(1033)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1552) tensor([0.9481])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7127e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(219.5109) tensor([0.9790])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0099e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3373) tensor(0.) tensor(0.6311)\n",
      "h_from_s max, min, mean tensor(4.0869) tensor(0.) tensor(0.6522)\n",
      "h_from_s_denoised max, min, mean tensor(5.3412) tensor(0.) tensor(0.6315)\n",
      "avg nonzero/greaterzero h from book: tensor(988) tensor(988)\n",
      "avg nonzero/greaterzero h from s: tensor(1672) tensor(1672)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1695) tensor([0.9332])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1138e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(185.5093) tensor([0.9881])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(6.4703e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0326) tensor(0.) tensor(0.6565)\n",
      "h_from_s max, min, mean tensor(4.5340) tensor(0.) tensor(0.6178)\n",
      "h_from_s_denoised max, min, mean tensor(5.0362) tensor(0.) tensor(0.6569)\n",
      "avg nonzero/greaterzero h from book: tensor(1022) tensor(1022)\n",
      "avg nonzero/greaterzero h from s: tensor(1686) tensor(1686)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1022) tensor(1022)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1747) tensor([0.9437])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3306e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(179.8919) tensor([0.9938])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0108) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.5720e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8507) tensor(0.) tensor(0.6346)\n",
      "h_from_s max, min, mean tensor(4.6548) tensor(0.) tensor(0.6578)\n",
      "h_from_s_denoised max, min, mean tensor(5.8542) tensor(0.) tensor(0.6351)\n",
      "avg nonzero/greaterzero h from book: tensor(976) tensor(976)\n",
      "avg nonzero/greaterzero h from s: tensor(1728) tensor(1728)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1322) tensor([0.9565])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1856e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(80.4229) tensor([0.9947])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0068) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2410e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6601) tensor(0.) tensor(0.6700)\n",
      "h_from_s max, min, mean tensor(4.0746) tensor(0.) tensor(0.6566)\n",
      "h_from_s_denoised max, min, mean tensor(5.6650) tensor(0.) tensor(0.6705)\n",
      "avg nonzero/greaterzero h from book: tensor(1037) tensor(1037)\n",
      "avg nonzero/greaterzero h from s: tensor(1691) tensor(1691)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1739) tensor([0.9430])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7704e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(215.0166) tensor([0.9808])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0045) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.3807e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6254) tensor(0.) tensor(0.6528)\n",
      "h_from_s max, min, mean tensor(4.5916) tensor(0.) tensor(0.6288)\n",
      "h_from_s_denoised max, min, mean tensor(6.6299) tensor(0.) tensor(0.6532)\n",
      "avg nonzero/greaterzero h from book: tensor(999) tensor(999)\n",
      "avg nonzero/greaterzero h from s: tensor(1691) tensor(1691)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(998) tensor(998)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1965) tensor([0.9352])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3260e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(154.8280) tensor([0.9893])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0040) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(8.9838e-10) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 467/500 [00:13<00:00, 36.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2446) tensor(0.) tensor(0.6355)\n",
      "h_from_s max, min, mean tensor(5.0030) tensor(0.) tensor(0.7308)\n",
      "h_from_s_denoised max, min, mean tensor(5.2479) tensor(0.) tensor(0.6359)\n",
      "avg nonzero/greaterzero h from book: tensor(995) tensor(995)\n",
      "avg nonzero/greaterzero h from s: tensor(1732) tensor(1732)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0956) tensor([0.9624])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.9354e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(80.8323) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0122) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.7857e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4866) tensor(0.) tensor(0.6622)\n",
      "h_from_s max, min, mean tensor(4.1338) tensor(0.) tensor(0.6420)\n",
      "h_from_s_denoised max, min, mean tensor(5.4900) tensor(0.) tensor(0.6627)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1711) tensor(1711)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1009) tensor(1009)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2066) tensor([0.9315])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6107e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(133.7448) tensor([0.9826])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6979e-08) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4570) tensor(0.) tensor(0.6532)\n",
      "h_from_s max, min, mean tensor(4.5204) tensor(0.) tensor(0.6754)\n",
      "h_from_s_denoised max, min, mean tensor(5.4607) tensor(0.) tensor(0.6537)\n",
      "avg nonzero/greaterzero h from book: tensor(983) tensor(983)\n",
      "avg nonzero/greaterzero h from s: tensor(1722) tensor(1722)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(983) tensor(983)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1097) tensor([0.9640])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4265e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(133.9859) tensor([0.9961])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(5.6748e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8500) tensor(0.) tensor(0.6505)\n",
      "h_from_s max, min, mean tensor(5.1725) tensor(0.) tensor(0.6377)\n",
      "h_from_s_denoised max, min, mean tensor(5.8546) tensor(0.) tensor(0.6509)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1590) tensor(1590)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1017) tensor([0.9648])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3130e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(230.1296) tensor([0.9868])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0086) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.8139e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2117) tensor(0.) tensor(0.6610)\n",
      "h_from_s max, min, mean tensor(2.8118) tensor(0.) tensor(0.6336)\n",
      "h_from_s_denoised max, min, mean tensor(6.2162) tensor(0.) tensor(0.6615)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1862) tensor(1862)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1013) tensor(1013)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4309) tensor([0.8364])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7255e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(82.2525) tensor([0.9840])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.5818e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1446) tensor(0.) tensor(0.6403)\n",
      "h_from_s max, min, mean tensor(4.9608) tensor(0.) tensor(0.6880)\n",
      "h_from_s_denoised max, min, mean tensor(6.1496) tensor(0.) tensor(0.6407)\n",
      "avg nonzero/greaterzero h from book: tensor(970) tensor(970)\n",
      "avg nonzero/greaterzero h from s: tensor(1728) tensor(1728)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(963) tensor(963)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1462) tensor([0.9488])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5580e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(101.5869) tensor([0.9935])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0093) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.8743e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.3842) tensor(0.) tensor(0.6572)\n",
      "h_from_s max, min, mean tensor(4.6430) tensor(0.) tensor(0.6089)\n",
      "h_from_s_denoised max, min, mean tensor(5.3874) tensor(0.) tensor(0.6577)\n",
      "avg nonzero/greaterzero h from book: tensor(1018) tensor(1018)\n",
      "avg nonzero/greaterzero h from s: tensor(1515) tensor(1515)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0522) tensor([0.9870])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3624e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(144.9222) tensor([0.9802])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0050) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(4.6836e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.1461) tensor(0.) tensor(0.6248)\n",
      "h_from_s max, min, mean tensor(4.2988) tensor(0.) tensor(0.6914)\n",
      "h_from_s_denoised max, min, mean tensor(5.1506) tensor(0.) tensor(0.6253)\n",
      "avg nonzero/greaterzero h from book: tensor(985) tensor(985)\n",
      "avg nonzero/greaterzero h from s: tensor(1721) tensor(1721)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(985) tensor(985)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0920) tensor([0.9633])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(7.8261e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(118.6711) tensor([0.9932])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0079) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9206e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 475/500 [00:13<00:00, 36.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6938) tensor(0.) tensor(0.6644)\n",
      "h_from_s max, min, mean tensor(3.9863) tensor(0.) tensor(0.6285)\n",
      "h_from_s_denoised max, min, mean tensor(5.6973) tensor(0.) tensor(0.6649)\n",
      "avg nonzero/greaterzero h from book: tensor(1045) tensor(1045)\n",
      "avg nonzero/greaterzero h from s: tensor(1648) tensor(1648)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1045) tensor(1045)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2624) tensor([0.9102])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7044e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(162.8358) tensor([0.9792])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.0393e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8639) tensor(0.) tensor(0.6823)\n",
      "h_from_s max, min, mean tensor(3.7683) tensor(0.) tensor(0.6853)\n",
      "h_from_s_denoised max, min, mean tensor(5.8688) tensor(0.) tensor(0.6828)\n",
      "avg nonzero/greaterzero h from book: tensor(1017) tensor(1017)\n",
      "avg nonzero/greaterzero h from s: tensor(1803) tensor(1803)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1015) tensor(1015)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3342) tensor([0.8872])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1358e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(102.7826) tensor([0.9930])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0064) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.6449e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7022) tensor(0.) tensor(0.6431)\n",
      "h_from_s max, min, mean tensor(4.8804) tensor(0.) tensor(0.6773)\n",
      "h_from_s_denoised max, min, mean tensor(5.7068) tensor(0.) tensor(0.6436)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1676) tensor(1676)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(977) tensor(977)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1674) tensor([0.9393])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5033e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(213.9903) tensor([0.9731])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1632e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2278) tensor(0.) tensor(0.6494)\n",
      "h_from_s max, min, mean tensor(4.4753) tensor(0.) tensor(0.6503)\n",
      "h_from_s_denoised max, min, mean tensor(5.2308) tensor(0.) tensor(0.6499)\n",
      "avg nonzero/greaterzero h from book: tensor(989) tensor(989)\n",
      "avg nonzero/greaterzero h from s: tensor(1618) tensor(1618)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(988) tensor(988)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0771) tensor([0.9748])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6356e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(113.0539) tensor([0.9941])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0082) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1523e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.9567) tensor(0.) tensor(0.6394)\n",
      "h_from_s max, min, mean tensor(4.9829) tensor(0.) tensor(0.6014)\n",
      "h_from_s_denoised max, min, mean tensor(5.9612) tensor(0.) tensor(0.6398)\n",
      "avg nonzero/greaterzero h from book: tensor(996) tensor(996)\n",
      "avg nonzero/greaterzero h from s: tensor(1553) tensor(1553)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(994) tensor(994)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0947) tensor([0.9719])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0825e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(163.2246) tensor([0.9865])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0057) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.4173e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2753) tensor(0.) tensor(0.6606)\n",
      "h_from_s max, min, mean tensor(3.1215) tensor(0.) tensor(0.5788)\n",
      "h_from_s_denoised max, min, mean tensor(5.2790) tensor(0.) tensor(0.6611)\n",
      "avg nonzero/greaterzero h from book: tensor(1023) tensor(1023)\n",
      "avg nonzero/greaterzero h from s: tensor(1690) tensor(1690)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1023) tensor(1023)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3249) tensor([0.8922])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3793e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(343.4964) tensor([0.9548])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0067) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.9090e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.4363) tensor(0.) tensor(0.6916)\n",
      "h_from_s max, min, mean tensor(4.4628) tensor(0.) tensor(0.6872)\n",
      "h_from_s_denoised max, min, mean tensor(5.4403) tensor(0.) tensor(0.6921)\n",
      "avg nonzero/greaterzero h from book: tensor(1049) tensor(1049)\n",
      "avg nonzero/greaterzero h from s: tensor(1646) tensor(1646)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1047) tensor(1047)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0973) tensor([0.9701])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9069e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(160.0181) tensor([0.9824])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0049) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1095e-08) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.0197) tensor(0.) tensor(0.6239)\n",
      "h_from_s max, min, mean tensor(4.6858) tensor(0.) tensor(0.6439)\n",
      "h_from_s_denoised max, min, mean tensor(6.0238) tensor(0.) tensor(0.6243)\n",
      "avg nonzero/greaterzero h from book: tensor(981) tensor(981)\n",
      "avg nonzero/greaterzero h from s: tensor(1710) tensor(1710)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(981) tensor(981)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1464) tensor([0.9453])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1457e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(217.2888) tensor([0.9906])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0108) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(5.1275e-09) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 483/500 [00:13<00:00, 35.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7061) tensor(0.) tensor(0.6355)\n",
      "h_from_s max, min, mean tensor(4.5657) tensor(0.) tensor(0.8101)\n",
      "h_from_s_denoised max, min, mean tensor(5.7099) tensor(0.) tensor(0.6360)\n",
      "avg nonzero/greaterzero h from book: tensor(1016) tensor(1016)\n",
      "avg nonzero/greaterzero h from s: tensor(1866) tensor(1866)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2894) tensor([0.8816])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3425e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(53.9397) tensor([0.9968])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0080) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.1961e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5137) tensor(0.) tensor(0.6341)\n",
      "h_from_s max, min, mean tensor(4.0986) tensor(0.) tensor(0.6351)\n",
      "h_from_s_denoised max, min, mean tensor(5.5174) tensor(0.) tensor(0.6345)\n",
      "avg nonzero/greaterzero h from book: tensor(967) tensor(967)\n",
      "avg nonzero/greaterzero h from s: tensor(1749) tensor(1749)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(966) tensor(966)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2205) tensor([0.9223])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0854e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(133.2180) tensor([0.9924])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0094) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1254e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.6553) tensor(0.) tensor(0.6738)\n",
      "h_from_s max, min, mean tensor(5.3080) tensor(0.) tensor(0.7640)\n",
      "h_from_s_denoised max, min, mean tensor(6.6601) tensor(0.) tensor(0.6743)\n",
      "avg nonzero/greaterzero h from book: tensor(1056) tensor(1056)\n",
      "avg nonzero/greaterzero h from s: tensor(1779) tensor(1779)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1055) tensor(1055)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1990) tensor([0.9262])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1268e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(152.9397) tensor([0.9921])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0066) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3183e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7939) tensor(0.) tensor(0.6496)\n",
      "h_from_s max, min, mean tensor(4.4255) tensor(0.) tensor(0.6896)\n",
      "h_from_s_denoised max, min, mean tensor(5.7976) tensor(0.) tensor(0.6501)\n",
      "avg nonzero/greaterzero h from book: tensor(962) tensor(962)\n",
      "avg nonzero/greaterzero h from s: tensor(1660) tensor(1660)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(962) tensor(962)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1690) tensor([0.9372])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3373e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(342.1500) tensor([0.9703])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.3229e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8076) tensor(0.) tensor(0.6555)\n",
      "h_from_s max, min, mean tensor(3.6442) tensor(0.) tensor(0.6740)\n",
      "h_from_s_denoised max, min, mean tensor(5.8121) tensor(0.) tensor(0.6560)\n",
      "avg nonzero/greaterzero h from book: tensor(972) tensor(972)\n",
      "avg nonzero/greaterzero h from s: tensor(1761) tensor(1761)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(971) tensor(971)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.3196) tensor([0.8875])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6382e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(88.2946) tensor([0.9921])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0054) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6167e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5532) tensor(0.) tensor(0.6657)\n",
      "h_from_s max, min, mean tensor(4.7751) tensor(0.) tensor(0.6719)\n",
      "h_from_s_denoised max, min, mean tensor(5.5581) tensor(0.) tensor(0.6661)\n",
      "avg nonzero/greaterzero h from book: tensor(1038) tensor(1038)\n",
      "avg nonzero/greaterzero h from s: tensor(1667) tensor(1667)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1040) tensor(1040)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0509) tensor([0.9837])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4640e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(71.0030) tensor([0.9956])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0075) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.2822e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1343) tensor(0.) tensor(0.6654)\n",
      "h_from_s max, min, mean tensor(2.9385) tensor(0.) tensor(0.6055)\n",
      "h_from_s_denoised max, min, mean tensor(6.1376) tensor(0.) tensor(0.6658)\n",
      "avg nonzero/greaterzero h from book: tensor(1022) tensor(1022)\n",
      "avg nonzero/greaterzero h from s: tensor(1727) tensor(1727)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.4381) tensor([0.8377])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.3834e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(157.8800) tensor([0.9709])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0047) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6537e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 491/500 [00:13<00:00, 35.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h max, min, mean tensor(5.8652) tensor(0.) tensor(0.6660)\n",
      "h_from_s max, min, mean tensor(4.7457) tensor(0.) tensor(0.7057)\n",
      "h_from_s_denoised max, min, mean tensor(5.8700) tensor(0.) tensor(0.6664)\n",
      "avg nonzero/greaterzero h from book: tensor(1000) tensor(1000)\n",
      "avg nonzero/greaterzero h from s: tensor(1730) tensor(1730)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(997) tensor(997)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0901) tensor([0.9697])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.1445e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(72.7573) tensor([0.9953])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0086) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0128e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0923) tensor(0.) tensor(0.6248)\n",
      "h_from_s max, min, mean tensor(3.9527) tensor(0.) tensor(0.6288)\n",
      "h_from_s_denoised max, min, mean tensor(5.0962) tensor(0.) tensor(0.6253)\n",
      "avg nonzero/greaterzero h from book: tensor(995) tensor(995)\n",
      "avg nonzero/greaterzero h from s: tensor(1646) tensor(1646)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(995) tensor(995)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1600) tensor([0.9404])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.0368e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(195.3578) tensor([0.9879])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(6.9206e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8821) tensor(0.) tensor(0.6718)\n",
      "h_from_s max, min, mean tensor(4.5813) tensor(0.) tensor(0.6558)\n",
      "h_from_s_denoised max, min, mean tensor(5.8852) tensor(0.) tensor(0.6723)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1729) tensor(1729)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1008) tensor(1008)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1118) tensor([0.9706])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.9499e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(77.6755) tensor([0.9935])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0063) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0510e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7053) tensor(0.) tensor(0.6821)\n",
      "h_from_s max, min, mean tensor(4.7643) tensor(0.) tensor(0.7512)\n",
      "h_from_s_denoised max, min, mean tensor(5.7088) tensor(0.) tensor(0.6826)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1802) tensor(1802)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1012) tensor(1012)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1395) tensor([0.9520])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5799e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(70.4194) tensor([0.9958])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0086) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.3422e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.1290) tensor(0.) tensor(0.6513)\n",
      "h_from_s max, min, mean tensor(4.7018) tensor(0.) tensor(0.6920)\n",
      "h_from_s_denoised max, min, mean tensor(6.1330) tensor(0.) tensor(0.6518)\n",
      "avg nonzero/greaterzero h from book: tensor(991) tensor(991)\n",
      "avg nonzero/greaterzero h from s: tensor(1689) tensor(1689)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(989) tensor(989)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1396) tensor([0.9475])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.1583e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(328.1893) tensor([0.9761])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0061) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(9.2877e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.3322) tensor(0.) tensor(0.6892)\n",
      "h_from_s max, min, mean tensor(4.6091) tensor(0.) tensor(0.6559)\n",
      "h_from_s_denoised max, min, mean tensor(6.3365) tensor(0.) tensor(0.6897)\n",
      "avg nonzero/greaterzero h from book: tensor(1009) tensor(1009)\n",
      "avg nonzero/greaterzero h from s: tensor(1637) tensor(1637)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1006) tensor(1006)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1990) tensor([0.9410])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.4238e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(142.7258) tensor([0.9913])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0070) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2123e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.7778) tensor(0.) tensor(0.6697)\n",
      "h_from_s max, min, mean tensor(4.5218) tensor(0.) tensor(0.6241)\n",
      "h_from_s_denoised max, min, mean tensor(5.7823) tensor(0.) tensor(0.6702)\n",
      "avg nonzero/greaterzero h from book: tensor(969) tensor(969)\n",
      "avg nonzero/greaterzero h from s: tensor(1522) tensor(1522)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(968) tensor(968)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1790) tensor([0.9443])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.7297e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(347.3126) tensor([0.9622])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0077) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1524e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6575) tensor(0.) tensor(0.6407)\n",
      "h_from_s max, min, mean tensor(4.0721) tensor(0.) tensor(0.6397)\n",
      "h_from_s_denoised max, min, mean tensor(5.6613) tensor(0.) tensor(0.6412)\n",
      "avg nonzero/greaterzero h from book: tensor(1013) tensor(1013)\n",
      "avg nonzero/greaterzero h from s: tensor(1787) tensor(1787)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1011) tensor(1011)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2886) tensor([0.8905])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2761e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(96.4095) tensor([0.9919])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0058) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1401e-09) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:14<00:00, 35.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.2595) tensor(0.) tensor(0.6596)\n",
      "h_from_s max, min, mean tensor(3.9730) tensor(0.) tensor(0.6397)\n",
      "h_from_s_denoised max, min, mean tensor(5.2636) tensor(0.) tensor(0.6600)\n",
      "avg nonzero/greaterzero h from book: tensor(1001) tensor(1001)\n",
      "avg nonzero/greaterzero h from s: tensor(1576) tensor(1576)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1001) tensor(1001)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1274) tensor([0.9597])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.4594e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(266.1549) tensor([0.9813])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0095) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.0342e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.5372) tensor(0.) tensor(0.6530)\n",
      "h_from_s max, min, mean tensor(4.1909) tensor(0.) tensor(0.6177)\n",
      "h_from_s_denoised max, min, mean tensor(5.5417) tensor(0.) tensor(0.6535)\n",
      "avg nonzero/greaterzero h from book: tensor(977) tensor(977)\n",
      "avg nonzero/greaterzero h from s: tensor(1565) tensor(1565)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(975) tensor(975)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1271) tensor([0.9618])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2984e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(244.6133) tensor([0.9855])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0072) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2099e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.2002) tensor(0.) tensor(0.6713)\n",
      "h_from_s max, min, mean tensor(5.0712) tensor(0.) tensor(0.7495)\n",
      "h_from_s_denoised max, min, mean tensor(6.2046) tensor(0.) tensor(0.6718)\n",
      "avg nonzero/greaterzero h from book: tensor(1036) tensor(1036)\n",
      "avg nonzero/greaterzero h from s: tensor(1799) tensor(1799)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1036) tensor(1036)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1233) tensor([0.9565])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(9.2078e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(64.6563) tensor([0.9969])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0113) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2434e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.2645) tensor(0.) tensor(0.6571)\n",
      "h_from_s max, min, mean tensor(4.7049) tensor(0.) tensor(0.6650)\n",
      "h_from_s_denoised max, min, mean tensor(7.2691) tensor(0.) tensor(0.6575)\n",
      "avg nonzero/greaterzero h from book: tensor(1021) tensor(1021)\n",
      "avg nonzero/greaterzero h from s: tensor(1738) tensor(1738)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1021) tensor(1021)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.2403) tensor([0.9116])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.2761e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(206.7692) tensor([0.9867])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0084) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(8.7336e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.0311) tensor(0.) tensor(0.6529)\n",
      "h_from_s max, min, mean tensor(4.0571) tensor(0.) tensor(0.6958)\n",
      "h_from_s_denoised max, min, mean tensor(5.0344) tensor(0.) tensor(0.6533)\n",
      "avg nonzero/greaterzero h from book: tensor(950) tensor(950)\n",
      "avg nonzero/greaterzero h from s: tensor(1624) tensor(1624)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(950) tensor(950)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1192) tensor([0.9568])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.6046e-07) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s tensor(162.6692) tensor([0.9855])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0071) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.2280e-09) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.8599) tensor(0.) tensor(0.6491)\n",
      "h_from_s max, min, mean tensor(4.1481) tensor(0.) tensor(0.6712)\n",
      "h_from_s_denoised max, min, mean tensor(5.8646) tensor(0.) tensor(0.6496)\n",
      "avg nonzero/greaterzero h from book: tensor(1019) tensor(1019)\n",
      "avg nonzero/greaterzero h from s: tensor(1689) tensor(1689)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1016) tensor(1016)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.1991) tensor([0.9269])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5430e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(285.0980) tensor([0.9710])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0046) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.1224e-09) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(5.6491) tensor(0.) tensor(0.6706)\n",
      "h_from_s max, min, mean tensor(4.8815) tensor(0.) tensor(0.6808)\n",
      "h_from_s_denoised max, min, mean tensor(5.6518) tensor(0.) tensor(0.6711)\n",
      "avg nonzero/greaterzero h from book: tensor(1027) tensor(1027)\n",
      "avg nonzero/greaterzero h from s: tensor(1710) tensor(1710)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(1027) tensor(1027)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0997) tensor([0.9696])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(8.5309e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s tensor(108.6080) tensor([0.9936])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0074) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(1.2930e-09) tensor([1.0000])\n",
      "Unique Gs seen while learning: 500\n",
      "Unique Hs seen while learning: 500\n",
      "Unique Hs seen while recalling: 0\n",
      "Unique Gs seen while recalling (right after learning): 0\n",
      "Unique Gs seen while recalling (right after learning, after denoising): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gs seen while learning (after denoising): 500\n",
      "Unique Hs seen while recalling: 500\n",
      "Unique Gs seen while recalling (before denoising): 500\n",
      "Unique Gs seen while recalling (after denoising): 495\n",
      "Unique Hs seen while recalling (after denoising): 495\n",
      "avg nonzero H: 1727.8900146484375\n",
      "avg nonzero H_denoised: 1000.3679809570312\n",
      "tensor(161.9607)\n",
      "tensor(0.9884)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1850x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1850x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vectorhash_functions import spacefillingcurve\n",
    "from data_utils import prepare_data, load_mnist_dataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_mnist_dataset()\n",
    "data, noisy_data = prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=num_imgs,\n",
    "    preprocess_sensory=False,\n",
    "    noise_level=\"none\",\n",
    "    across_dataset=True,\n",
    ")\n",
    "\n",
    "# REMOVE THESE LINES\n",
    "# data = data.float() / 255.0\n",
    "# noisy_data = noisy_data.float() / 255.0\n",
    "\n",
    "# data, noisy_data = prepare_data_random(noise_scale=0)\n",
    "v = spacefillingcurve(shapes)\n",
    "\n",
    "g_positions, g_positions2, g_points, g_points_2 = GS.learn_path(\n",
    "    observations=data, velocities=v[: len(data)]\n",
    ")\n",
    "recalled_imgs = GS.recall(noisy_data)\n",
    "similarity = torch.cosine_similarity(data, recalled_imgs, dim=1)\n",
    "mse = torch.nn.functional.mse_loss(data, recalled_imgs, reduction=\"none\")\n",
    "print(mse.mean())\n",
    "print(similarity.mean())\n",
    "for i in range(min(num_imgs, 5)):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    im1 = ax[0].imshow(data[(-i)].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[0].set_title(\"Original\")\n",
    "    im2 = ax[1].imshow((recalled_imgs[(-i)]).reshape(28, 28), cmap=\"gray\")\n",
    "    title = f\"Recalled similarity: {similarity[(-i)].item()}\"\n",
    "    ax[1].set_title(title)\n",
    "\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# BARCHART\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "# put legend outside of the plot\n",
    "labels = dataset.train_labels[:num_imgs]\n",
    "unique_labels = np.unique(labels)\n",
    "similarity_per_label = []\n",
    "for label in unique_labels:\n",
    "    idx = labels == label\n",
    "    similarity_per_label.append(similarity[idx].mean())\n",
    "# make bars not overlap\n",
    "label = f\"percent_nonzero_relu={percent_nonzero_relu} sparsity={sparse_initialization}\"\n",
    "ax.bar(unique_labels, similarity_per_label, label=label)\n",
    "ax.set_title(\"Similarity per label\")\n",
    "ax.set_xlabel(\"Label\")\n",
    "ax.set_ylabel(\"Similarity\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# LINEPLOT\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "\n",
    "label = f\"percent_nonzero_relu={percent_nonzero_relu} sparsity={sparse_initialization}\"\n",
    "ax.plot(similarity, label=label)\n",
    "ax.set_title(\"Similarity per image\")\n",
    "ax.set_xlabel(\"Image\")\n",
    "ax.set_ylabel(\"Similarity\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.1762)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.mean(dim=0).reshape(28, 28), cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "print(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorhash_functions import *\n",
    "\n",
    "mod_n_positions = []\n",
    "mod_n_positions_2 = []\n",
    "mod_n_states = []\n",
    "mod_n_states_2 = []\n",
    "\n",
    "# assume shapes are squares\n",
    "\n",
    "for _ in lambdas:\n",
    "    mod_n_positions.append(list())\n",
    "    mod_n_positions_2.append(list())\n",
    "    mod_n_states.append(list())\n",
    "    mod_n_states_2.append(list())\n",
    "\n",
    "for g in g_positions:\n",
    "    pos = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        mod_n = g[pos : pos + l**2]\n",
    "        mod_n_positions[i].append(ConvertToXYNew(mod_n, (l, l)))\n",
    "        pos += l**2\n",
    "\n",
    "for g in g_positions2:\n",
    "    pos = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        mod_n = g[pos : pos + l**2]\n",
    "        mod_n_positions_2[i].append(ConvertToXYNew(mod_n, (l, l)))\n",
    "        pos += l**2\n",
    "\n",
    "for g in g_points:\n",
    "    pos = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        mod_n = g[pos : pos + l**2]\n",
    "        mod_n_states[i].append(ConvertToXYNew(mod_n, (l, l)))\n",
    "        pos += l**2\n",
    "\n",
    "for g in g_points_2:\n",
    "    pos = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        mod_n = g[pos : pos + l**2]\n",
    "        mod_n_states_2[i].append(ConvertToXYNew(mod_n, (l, l)))\n",
    "        pos += l**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "499\n",
      "500\n",
      "499\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "499\n",
      "500\n",
      "499\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "499\n",
      "500\n",
      "499\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, l in enumerate(lambdas):\n",
    "    GraphGrids(\n",
    "        shapes_lists=[(l, l), (l, l), (l, l), (l, l)],\n",
    "        points_lists=[\n",
    "            mod_n_positions[i],\n",
    "            mod_n_positions_2[i],\n",
    "            mod_n_states[i],\n",
    "            mod_n_states_2[i],\n",
    "        ],\n",
    "        first_points=[\n",
    "            mod_n_positions[i][0],\n",
    "            mod_n_positions_2[i][0],\n",
    "            mod_n_states[i][0],\n",
    "            mod_n_states_2[i][0],\n",
    "        ],\n",
    "        titles=[\n",
    "            f\"estimated grid position of first image\",\n",
    "            f\"estimated grid position of second image\",\n",
    "            f\"denoised grid state of first image\",\n",
    "            f\"denoised grid state of second image\",\n",
    "        ],\n",
    "        main_title=f\"estimated grid positions and denoised grid states of first and second images as the number of images learned increases. \\n{l}x{l} module, N_h={GS.N_h}, sparsity={round(sparse_initialization, 2)}, relu_theta={round(relu_theta, 2)}, W_hg_mean={round(W_hg_mean, 2)}, W_hg_std={W_hg_std} shapes={shapes}, num_imgs={num_imgs}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1571837118.py, line 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 96\u001b[0;36m\u001b[0m\n\u001b[0;31m    fig.colorbar(im1, ax=ax[0])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from vectorhash_functions import spacefillingcurve\n",
    "from data_utils import prepare_data, load_mnist_dataset\n",
    "import torch\n",
    "from graph_utils import print_imgs_side_by_side_on_top\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "num_imgs = 201\n",
    "data, noisy_data = prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=num_imgs,\n",
    "    preprocess_sensory=True,\n",
    "    noise_level=\"none\",\n",
    "    use_fix=True,\n",
    ")\n",
    "LAST_N_IMGS = 10\n",
    "# data, noisy_data = prepare_data_random(noise_scale=0) \n",
    "params = [0.01, 0.001, 0.0001, 0.01, 0.1, 1]\n",
    "sims = []\n",
    "fixed = []\n",
    "v = spacefillingcurve(shapes)\n",
    "\n",
    "lambdas = [3, 4, 5]\n",
    "shapes = [(i, i) for i in lambdas]\n",
    "for i in params:\n",
    "    percent_nonzero_relu = 0.02\n",
    "    W_gh_var = 1\n",
    "    sparse_initialization = 0.8\n",
    "    T = i\n",
    "    W_hg_std = math.sqrt(W_gh_var)\n",
    "    W_hg_mean = -W_hg_std * norm.ppf(1 - percent_nonzero_relu) / math.sqrt(len(lambdas))\n",
    "    h_normal_mean = len(lambdas) * W_hg_mean\n",
    "    h_normal_std = math.sqrt(len(lambdas)) * W_hg_std\n",
    "    relu_theta = math.sqrt((1 - sparse_initialization) * len(lambdas)) * norm.ppf(\n",
    "        1 - percent_nonzero_relu\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        percent_nonzero_relu,\n",
    "        W_hg_mean,\n",
    "        W_hg_std,\n",
    "        h_normal_mean,\n",
    "        h_normal_std,\n",
    "        relu_theta,\n",
    "    )\n",
    "\n",
    "    GS = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=1700,\n",
    "        input_size=784,\n",
    "        h_normal_mean=h_normal_mean,\n",
    "        h_normal_std=h_normal_std,\n",
    "        device=None,\n",
    "        sparse_matrix_initializer=SparseMatrixBySparsityInitializer(\n",
    "            sparsity=sparse_initialization, device=\"cpu\"\n",
    "        ),\n",
    "        relu_theta=relu_theta,  ######\n",
    "        from_checkpoint=False,\n",
    "        T=T,\n",
    "        ratshift=False,\n",
    "        pseudo_inverse=False,\n",
    "        use_h_fix=False,\n",
    "        learned_pseudo=False,\n",
    "        epsilon=0.01,\n",
    "        calculate_update_scaling_method=\"norm\",\n",
    "        sanity_check=False,\n",
    "        calculate_g_method=\"fast\",\n",
    "        scaling_updates=True,\n",
    "        dream_fix=10,\n",
    "        slumber=False,\n",
    "    )\n",
    "    g_positions, g_positions2, g_points, g_points_2, imgs_fixed = GS.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    recalled_imgs = GS.recall(noisy_data)\n",
    "    similarity = torch.cosine_similarity(data, recalled_imgs, dim=1)\n",
    "    sims.append(similarity)\n",
    "    human_render = []\n",
    "    for o in range(LAST_N_IMGS):\n",
    "        a = []\n",
    "        a.append(data[-(o+1)].reshape(28, 28))\n",
    "        a.append(recalled_imgs[-(o+1)].reshape(28, 28))\n",
    "        human_render.append(a)\n",
    "    fixed.append(imgs_fixed)\n",
    "\n",
    "    imgname = \"images_graphs/TEMP_CHECK\" + str(params.index(i)) + \".png\"\n",
    "    print_imgs_side_by_side_on_top(human_render, out=imgname, captions=[\"Original\", \"Recalled\"], title=\"TEMP \" + str(i))\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# BARCHART\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "# put legend outside of the plot\n",
    "for i in range(len(sims)):\n",
    "    similarity = sims[i]\n",
    "    percent_nonzero_relu, sparse_initialization = params[i]\n",
    "\n",
    "    labels = dataset.train_labels[:len(data)]\n",
    "    unique_labels = np.unique(labels)\n",
    "    similarity_per_label = []\n",
    "    for label in unique_labels:\n",
    "        idx = labels == label\n",
    "        similarity_per_label.append(similarity[idx].mean())\n",
    "    # make bars not overlap\n",
    "    ax.bar(unique_labels, similarity_per_label, label=\"TEMP \" + str(params[i]))\n",
    "    ax.set_title(\"Similarity per label\")\n",
    "    ax.set_xlabel(\"Label\")\n",
    "    ax.set_ylabel(\"Similarity\")\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"images_graphs/SLUMBER_LABELS.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# LINEPLOT\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "for i in range(len(sims)):\n",
    "    similarity = sims[i]\n",
    "    percent_nonzero_relu, sparse_initialization = params[i]\n",
    "    label = (\n",
    "        f\"percent_nonzero_relu={percent_nonzero_relu} sparsity={sparse_initialization}\"\n",
    "    )\n",
    "    ax.plot(similarity, label=label)\n",
    "    ax.set_title(\"Similarity per image\")\n",
    "    ax.set_xlabel(\"Image\")\n",
    "    ax.set_ylabel(\"Similarity\")\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"images_graphs/SLUMBER_SIMS.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# LINEPLOT number of images fixed every 10 images\n",
    "for i in range(len(fixed)):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "    ax.plot(fixed[i], label=\"TEMP \" + str(params[i]))\n",
    "    ax.set_title(\"Number of images fixed\")\n",
    "    ax.set_xlabel(\"DREAM SEQUENCE NUMBER\")\n",
    "    ax.set_ylabel(\"Fixed\")\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.savefig(\"images_graphs/SLUMBER_FIXED\" + str(params[i]) + \".png\")\n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_positions_n = []\n",
    "point_states_n = []\n",
    "for l in lambdas:\n",
    "    point_positions_n.append([])\n",
    "    point_states_n.append([])\n",
    "\n",
    "for img in data:\n",
    "    pos = GS.estimate_position(img)\n",
    "    state = GS.denoise(\n",
    "        GS.grid_from_hippocampal(GS.hippocampal_from_sensory(img))\n",
    "    ).flatten()\n",
    "\n",
    "    p = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        point_positions_n[i].append(ConvertToXYNew(pos[p : p + l**2], (l, l)))\n",
    "        point_states_n[i].append(ConvertToXYNew(state[p : p + l**2], (l, l)))\n",
    "        p += l**2\n",
    "\n",
    "for i, l in enumerate(lambdas):\n",
    "    GraphGrids(\n",
    "        shapes_lists=[(l, l), (l, l)],\n",
    "        points_lists=[point_positions_n[i], point_states_n[i]],\n",
    "        first_points=[point_positions_n[i][0], point_states_n[i][0]],\n",
    "        titles=[\n",
    "            f\"estimated {l}x{l} grid position of each image.\",\n",
    "            f\"denoised {l}x{l} grid state of each image.\",\n",
    "        ],\n",
    "        main_title=f\"estimated positions and denoised grid states of each image.\\n {l}x{l} module, N_h={GS.N_h}, sparsity={round(sparse_initialization, 2)}, relu_theta={round(relu_theta,2 )}, W_hg_mean={round(W_hg_mean, 2)}, W_hg_std={W_hg_std}\\n shapes={shapes}, num_imgs={num_imgs}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[0]\n",
    "recalled = GS.recall(img)\n",
    "print(torch.cosine_similarity(img, recalled).mean())\n",
    "\n",
    "plt.imshow(img.reshape(28, 28))\n",
    "print(img.mean())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow((recalled).reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    GS.sensory_from_hippocampal(GS.hippocampal_from_grid(GS.G[3200])).reshape(28, 28)\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_indices = (dataset.train_labels == 0).nonzero().flatten()\n",
    "\n",
    "data_by_class = dataset.data[zero_indices][:200].reshape(200, 784)\n",
    "data_by_class = torch.tensor(data).float().to(\"cpu\")\n",
    "data_by_class = (data - data.mean(dim=0)) / (data.std(dim=0) + 1e-8)\n",
    "\n",
    "plt.imshow(data_by_class[0].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(data_by_class[1].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(data_by_class.mean(dim=0).reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "point_positions_n = []\n",
    "point_states_n = []\n",
    "for l in lambdas:\n",
    "    point_positions_n.append([])\n",
    "    point_states_n.append([])\n",
    "\n",
    "for img in data_by_class:\n",
    "    pos = GS.estimate_position(img)\n",
    "    state = GS.denoise(\n",
    "        GS.grid_from_hippocampal(GS.hippocampal_from_sensory(img))\n",
    "    ).flatten()\n",
    "\n",
    "    p = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        point_positions_n[i].append(ConvertToXYNew(pos[p : p + l**2], (l, l)))\n",
    "        point_states_n[i].append(ConvertToXYNew(state[p : p + l**2], (l, l)))\n",
    "        p += l**2\n",
    "\n",
    "for i, l in enumerate(lambdas):\n",
    "    GraphGrids(\n",
    "        shapes_lists=[(l, l), (l, l)],\n",
    "        points_lists=[point_positions_n[i], point_states_n[i]],\n",
    "        first_points=[point_positions_n[i][0], point_states_n[i][0]],\n",
    "        titles=[\n",
    "            f\"estimated {l}x{l} grid position of each image.\",\n",
    "            f\"denoised {l}x{l} grid state of each image.\",\n",
    "        ],\n",
    "        main_title=f\"estimated positions and denoised grid states of each image.\\n {l}x{l} module, N_h={GS.N_h}, sparsity={round(sparse_initialization, 2)}, relu_theta={round(relu_theta,2 )}, W_hg_mean={round(W_hg_mean, 2)}, W_hg_std={W_hg_std}\\n shapes={shapes}, num_imgs={num_imgs}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
