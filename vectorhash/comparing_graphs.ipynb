{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=10,\n",
    "    preprocess_sensory=True,\n",
    "    noise_level=\"medium\",\n",
    "):\n",
    "    import torch\n",
    "    import random\n",
    "\n",
    "    data = dataset.data\n",
    "    # print(num_imgs)\n",
    "    # print(data.shape)\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    # print(data.shape)\n",
    "    data = torch.tensor(data[:num_imgs]).float().to(device)\n",
    "    # print(data.shape)\n",
    "\n",
    "    # data = random.sample(dataset.data.flatten(1).float().to(\"cpu\"), num_imgs)\n",
    "    if preprocess_sensory:\n",
    "        data = (data - data.mean()) / data.std()\n",
    "        # print(mnist_data[0])\n",
    "\n",
    "    # noissing the data\n",
    "    if noise_level == \"none\":\n",
    "        return data, data\n",
    "    elif noise_level == \"low\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1, 1)\n",
    "    elif noise_level == \"medium\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.25, 1.25)\n",
    "    elif noise_level == \"high\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.5, 1.5)\n",
    "    noisy_data = data + random_noise\n",
    "    # TODO: DO WE PREPROCESS NOISY IMAGES?\n",
    "    # if preprocess_sensory:\n",
    "    #     noisy_mnist = (noisy_mnist - noisy_mnist.mean()) / noisy_mnist.std()\n",
    "\n",
    "    return data, noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from nd_scaffold import GridScaffold, SparseMatrixBySparsityInitializer\n",
    "from graph_utils import graph_scaffold, print_imgs_side_by_side\n",
    "from matrix_initializers import SparseMatrixByScalingInitializer\n",
    "from vectorhash_functions import solve_mean, spacefillingcurve\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def test_memory_capacity(\n",
    "    data,\n",
    "    noisy_data,\n",
    "    shapes=[(3, 3, 5), (4, 4, 7)],\n",
    "    N_h=1000,\n",
    "    initalization_method=\"by_scaling\",\n",
    "    percent_nonzero_relu=0.01,\n",
    "    W_gh_var=1.0,\n",
    "    sparse_initialization=0.1,\n",
    "    T=0.01,\n",
    "    **vectorhash_kwargs,\n",
    "):\n",
    "    assert initalization_method in [\"by_scaling\", \"by_sparsity\"]\n",
    " \n",
    "    if initalization_method == \"by_scaling\":\n",
    "        W_hg_mean = -W_hg_std * norm.ppf(1-percent_nonzero_relu) / math.sqrt(len(shapes))\n",
    "        W_hg_std = math.sqrt(W_gh_var)\n",
    "        h_normal_mean=len(shapes)*W_hg_mean\n",
    "        h_normal_std=math.sqrt(len(shapes))*W_hg_std\n",
    "        relu_theta = 0\n",
    "    elif initalization_method == \"by_sparsity\":\n",
    "        gamma = 1- sparse_initialization\n",
    "        relu_theta = math.sqrt(gamma * len(shapes)) * norm.ppf(1-percent_nonzero_relu)\n",
    "        W_hg_mean = 0\n",
    "        W_hg_std = math.sqrt(gamma * len(shapes))\n",
    "        h_normal_mean = -relu_theta\n",
    "        h_normal_std = (1-sparse_initialization) * len(shapes)\n",
    "\n",
    "\n",
    "    GS = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=device,\n",
    "        h_normal_mean=h_normal_mean,\n",
    "        h_normal_std=h_normal_std,\n",
    "        sparse_matrix_initializer=(\n",
    "            SparseMatrixByScalingInitializer(\n",
    "                mean=W_hg_mean,\n",
    "                scale=W_hg_std,\n",
    "                device=device\n",
    "            )\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else SparseMatrixBySparsityInitializer(sparsity=sparse_initialization, device=device)\n",
    "        ),\n",
    "        relu_theta=relu_theta,\n",
    "        T=T,\n",
    "        **vectorhash_kwargs,\n",
    "    )\n",
    "\n",
    "    # learn over all images\n",
    "    v = spacefillingcurve(shapes)\n",
    "\n",
    "    GS.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    print(len(v[: len(data)]))\n",
    "    recalled_imgs = GS.recall(noisy_data)\n",
    "\n",
    "    # for i in range(min(5, len(data))):\n",
    "    #     original_img = data[i].reshape(28, 28).cpu().numpy()\n",
    "    #     noisy_img = noisy_data[i].reshape(28, 28).cpu().numpy()\n",
    "    #     recalled_img = recalled_imgs[i].reshape(28, 28).cpu().numpy()\n",
    "    #     print_imgs_side_by_side(\n",
    "    #         original_img,\n",
    "    #         noisy_img,\n",
    "    #         recalled_img, \n",
    "    #         captions=[\"Original\", \"Noisy\", \"Recalled\"],\n",
    "    #         out=f\"g1/{len(data)}_{percent_nonzero_relu}_imgs_{i}_{vectorhash_kwargs}.png\")\n",
    "\n",
    "    print(recalled_imgs)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(data, recalled_imgs)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating Capacity Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 32, 48, 58, 64]\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11816/2224200746.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data[:num_imgs]).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gs seen while learning: 22\n",
      "Unique Hs seen while learning: 22\n",
      "22\n",
      "Unique Hs seen while recalling: 22\n",
      "Unique Gs seen while recalling (before denoising): 22\n",
      "Unique Gs seen while recalling (after denoising): 8\n",
      "Unique Hs seen while recalling (after denoising): 8\n",
      "avg nonzero H: 179.9545440673828\n",
      "avg nonzero H_denoised: 20.5\n",
      "tensor([[-2.7006, -2.7006, -2.7006,  ..., -2.7006, -2.7006, -2.7006],\n",
      "        [-2.7006, -2.7006, -2.7006,  ..., -2.7006, -2.7006, -2.7006],\n",
      "        [-1.7388, -1.7388, -1.7388,  ..., -1.7388, -1.7388, -1.7388],\n",
      "        ...,\n",
      "        [-2.5576, -2.5576, -2.5576,  ..., -2.5576, -2.5576, -2.5576],\n",
      "        [-2.7006, -2.7006, -2.7006,  ..., -2.7006, -2.7006, -2.7006],\n",
      "        [-2.7006, -2.7006, -2.7006,  ..., -2.7006, -2.7006, -2.7006]],\n",
      "       device='cuda:0')\n",
      "Cosine Similarity 0.5466322898864746\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 32\n",
      "Unique Hs seen while learning: 32\n",
      "32\n",
      "Unique Hs seen while recalling: 32\n",
      "Unique Gs seen while recalling (before denoising): 32\n",
      "Unique Gs seen while recalling (after denoising): 5\n",
      "Unique Hs seen while recalling (after denoising): 5\n",
      "avg nonzero H: 166.4375\n",
      "avg nonzero H_denoised: 16.5625\n",
      "tensor([[-3.3509, -3.3509, -3.3509,  ..., -3.3509, -3.3509, -3.3509],\n",
      "        [-2.3078, -2.3078, -2.3078,  ..., -2.3078, -2.3078, -2.3078],\n",
      "        [-2.3890, -2.3890, -2.3890,  ..., -2.3890, -2.3890, -2.3890],\n",
      "        ...,\n",
      "        [-3.3509, -3.3509, -3.3509,  ..., -3.3509, -3.3509, -3.3509],\n",
      "        [-2.5697, -2.5697, -2.5697,  ..., -2.5697, -2.5697, -2.5697],\n",
      "        [-3.3509, -3.3509, -3.3509,  ..., -3.3509, -3.3509, -3.3509]],\n",
      "       device='cuda:0')\n",
      "Cosine Similarity 0.5927959084510803\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 48\n",
      "Unique Hs seen while learning: 48\n",
      "48\n",
      "Unique Hs seen while recalling: 48\n",
      "Unique Gs seen while recalling (before denoising): 48\n",
      "Unique Gs seen while recalling (after denoising): 4\n",
      "Unique Hs seen while recalling (after denoising): 4\n",
      "avg nonzero H: 167.875\n",
      "avg nonzero H_denoised: 18.5\n",
      "tensor([[-5.2998, -5.2998, -5.2998,  ..., -5.2998, -5.2998, -5.2998],\n",
      "        [-6.0231, -6.0231, -6.0231,  ..., -6.0231, -6.0231, -6.0231],\n",
      "        [-5.7544, -5.7544, -5.7544,  ..., -5.7544, -5.7544, -5.7544],\n",
      "        ...,\n",
      "        [-5.2998, -5.2998, -5.2998,  ..., -5.2998, -5.2998, -5.2998],\n",
      "        [-5.2998, -5.2998, -5.2998,  ..., -5.2998, -5.2998, -5.2998],\n",
      "        [-5.2998, -5.2998, -5.2998,  ..., -5.2998, -5.2998, -5.2998]],\n",
      "       device='cuda:0')\n",
      "Cosine Similarity 0.5676674842834473\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 58\n",
      "Unique Hs seen while learning: 58\n",
      "58\n",
      "Unique Hs seen while recalling: 58\n",
      "Unique Gs seen while recalling (before denoising): 58\n",
      "Unique Gs seen while recalling (after denoising): 5\n",
      "Unique Hs seen while recalling (after denoising): 5\n",
      "avg nonzero H: 189.84483337402344\n",
      "avg nonzero H_denoised: 22.913793563842773\n",
      "tensor([[-4.8243, -4.8243, -4.8243,  ..., -4.8243, -4.8243, -4.8243],\n",
      "        [-4.9013, -4.9013, -4.9013,  ..., -4.9013, -4.9013, -4.9013],\n",
      "        [-4.7461, -4.7461, -4.7461,  ..., -4.7461, -4.7461, -4.7461],\n",
      "        ...,\n",
      "        [-4.9013, -4.9013, -4.9013,  ..., -4.9013, -4.9013, -4.9013],\n",
      "        [-6.3964, -6.3964, -6.3964,  ..., -6.3964, -6.3964, -6.3964],\n",
      "        [-4.8243, -4.8243, -4.8243,  ..., -4.8243, -4.8243, -4.8243]],\n",
      "       device='cuda:0')\n",
      "Cosine Similarity 0.581619381904602\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 64\n",
      "Unique Hs seen while learning: 64\n",
      "64\n",
      "Unique Hs seen while recalling: 64\n",
      "Unique Gs seen while recalling (before denoising): 64\n",
      "Unique Gs seen while recalling (after denoising): 3\n",
      "Unique Hs seen while recalling (after denoising): 3\n",
      "avg nonzero H: 220.828125\n",
      "avg nonzero H_denoised: 11.984375\n",
      "tensor([[-7.4554, -7.4554, -7.4554,  ..., -7.4554, -7.4554, -7.4554],\n",
      "        [-7.4554, -7.4554, -7.4554,  ..., -7.4554, -7.4554, -7.4554],\n",
      "        [-5.7174, -5.7174, -5.7174,  ..., -5.7174, -5.7174, -5.7174],\n",
      "        ...,\n",
      "        [-6.7150, -6.7150, -6.7150,  ..., -6.7150, -6.7150, -6.7150],\n",
      "        [-6.7150, -6.7150, -6.7150,  ..., -6.7150, -6.7150, -6.7150],\n",
      "        [-7.4554, -7.4554, -7.4554,  ..., -7.4554, -7.4554, -7.4554]],\n",
      "       device='cuda:0')\n",
      "Cosine Similarity 0.5583508014678955\n"
     ]
    }
   ],
   "source": [
    "# Memory Capacity Tests\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "shapes = [(3, 3), (4, 4), (5, 5)]\n",
    "# shapes = [(5, 5), (9, 9), (11, 11)]\n",
    "\n",
    "N_h = 1000\n",
    "\n",
    "N_g = 0\n",
    "for shape in shapes:\n",
    "    l = torch.prod(torch.tensor(shape)).item()\n",
    "    N_g += l\n",
    "# print(\"N_g\", N_g)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# dataset = torchvision.datasets.FashionMNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# dataset = torchvision.datasets.CIFAR100(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "input_size = 1\n",
    "for shape in dataset.data[0].shape:\n",
    "    input_size *= shape\n",
    "\n",
    "theoretical_capacity = N_g * N_h / input_size  # 784 is the size of the input for MNIST\n",
    "\n",
    "percents = [\n",
    "    # 0.01,  # 1\n",
    "    # 0.03,  # 2\n",
    "    # 0.1,  # 3\n",
    "    # 0.2,  # 4\n",
    "    0.33,  # 5\n",
    "    0.5,  # 6\n",
    "    0.75,  # 7\n",
    "    0.9,  # 8\n",
    "    1.0,  # 9\n",
    "    # 1.1,  # 10\n",
    "    # 1.5,  # 11\n",
    "    # 2.0,  # 12\n",
    "    # 3.0,  # 13\n",
    "    # 10.0,  # 14\n",
    "]\n",
    "\n",
    "num_images = [theoretical_capacity * p for p in percents]\n",
    "num_images = [math.ceil(n) for n in num_images]\n",
    "print(num_images)\n",
    "\n",
    "preprocess_sensory = True\n",
    "noise_level = \"medium\"\n",
    "\n",
    "# TODO: Need a hyperparam N_p for dimension of the projection from grid cells to place cells\n",
    "similarities = []\n",
    "for num_imgs in num_images:\n",
    "    print(\"==========================================\")\n",
    "    data, noisy_data = prepare_data(\n",
    "        dataset,\n",
    "        num_imgs=num_imgs,\n",
    "        preprocess_sensory=preprocess_sensory,\n",
    "        noise_level=noise_level,\n",
    "    )\n",
    "    similarity = test_memory_capacity(\n",
    "        data,\n",
    "        noisy_data,\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        initalization_method=\"by_sparsity\",\n",
    "        percent_nonzero_relu=10 / N_h,\n",
    "        W_gh_var=1.0,\n",
    "        sparse_initialization=0.6,\n",
    "        T=0.01,\n",
    "        continualupdate=False,\n",
    "        ratshift=False,\n",
    "        initialize_W_gh_with_zeroes=False,\n",
    "        pseudo_inverse=False,\n",
    "        learned_pseudo=False,\n",
    "    )\n",
    "    print(\"Cosine Similarity\", torch.mean(similarity).item())\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing initialization techniques (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare continual learning vs learning once at start (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparam tuning for number active hippocampal cells after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we losing grid states? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test effect of using h fix or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Capacity Tests\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from matrix_initializers import ConstantInitializer, SparseMatrixByScalingInitializer\n",
    "from vectorhash_functions import solve_mean, spacefillingcurve\n",
    "from nd_scaffold import GridScaffold\n",
    "from graph_utils import print_imgs_side_by_side\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "shapes = [(3, 3), (4, 4), (5, 5)]\n",
    "device = \"cuda\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "input_size = 1\n",
    "for shape in dataset.data[0].shape:\n",
    "    input_size *= shape\n",
    "\n",
    "theoretical_capacity = 3600 // 10\n",
    "\n",
    "N_h = 1000\n",
    "target_N_hs = [10, 100, 300, 500]\n",
    "percents = [0.01, 0.03, 0.1, 0.33, 0.5, 0.75, 0.9, 1.0]\n",
    "num_images = [theoretical_capacity * p for p in percents]\n",
    "num_images = [math.ceil(n) for n in num_images]\n",
    "print(num_images)\n",
    "\n",
    "preprocess_sensory = True\n",
    "noise_level = \"none\"\n",
    "\n",
    "# TODO: Need a hyperparam N_p for dimension of the projection from grid cells to place cells\n",
    "\n",
    "results_no_fix = np.zeros((len(target_N_hs), len(percents)))\n",
    "results_fix = np.zeros((len(target_N_hs), len(percents)))\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def test_h_fix(\n",
    "    data,\n",
    "    noisy_data,\n",
    "    shapes=[(3, 3, 5), (4, 4, 7)],\n",
    "    N_h=1000,\n",
    "    percent_nonzero_relu=0.01,\n",
    "    W_hg_std=1.0,\n",
    "    T=0.01,\n",
    "    **vectorhash_kwargs,\n",
    "):\n",
    "    W_hg_mean = -W_hg_std * norm.ppf(1-percent_nonzero_relu) / math.sqrt(len(shapes))\n",
    "    h_normal_mean=len(shapes)*W_hg_mean\n",
    "    h_normal_std=math.sqrt(len(shapes))*W_hg_std\n",
    "    print(\"normal_mean\", W_hg_mean)\n",
    "    GS_no_fix = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=device,\n",
    "        h_normal_mean=h_normal_mean,\n",
    "        h_normal_std=h_normal_std,\n",
    "        sparse_matrix_initializer=(\n",
    "            SparseMatrixByScalingInitializer(\n",
    "                mean=W_hg_mean,\n",
    "                scale=W_hg_std,\n",
    "                device=device,\n",
    "            )\n",
    "        ),\n",
    "        relu_theta=0,\n",
    "        T=T,\n",
    "        **vectorhash_kwargs,\n",
    "        use_h_fix=False,\n",
    "    )\n",
    "    GS_fix = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=device,\n",
    "        h_normal_mean=h_normal_mean,\n",
    "        h_normal_std=h_normal_std,\n",
    "        sparse_matrix_initializer=ConstantInitializer(value=GS_no_fix.W_hg),\n",
    "        relu_theta=0,\n",
    "        T=T,\n",
    "        **vectorhash_kwargs,\n",
    "        use_h_fix=True,\n",
    "    )\n",
    "\n",
    "    # learn over all images\n",
    "    v = spacefillingcurve(shapes)\n",
    "\n",
    "    GS_no_fix.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    GS_fix.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    print(len(v[: len(data)]))\n",
    "    recalled_imgs_no_fix = GS_no_fix.recall(noisy_data)\n",
    "    recalled_imgs_fix = GS_fix.recall(noisy_data)\n",
    "\n",
    "    # os.makedirs(f\"g1/num_imgs_{len(data)}_target_{target_N_h}\", exist_ok=True)\n",
    "    # dir = f\"g1/num_imgs_{len(data)}_target_{target_N_h}\"\n",
    "    # for i in range(min(5, len(data))):\n",
    "    #     original_img = data[i].reshape(28, 28).cpu().numpy()\n",
    "    #     noisy_img = noisy_data[i].reshape(28, 28).cpu().numpy()\n",
    "    #     recalled_img_no_fix = recalled_imgs_no_fix[i].reshape(28, 28).cpu().numpy()\n",
    "    #     recalled_img_fix = recalled_imgs_fix[i].reshape(28, 28).cpu().numpy()\n",
    "    #     print_imgs_side_by_side(\n",
    "    #         original_img,\n",
    "    #         noisy_img,\n",
    "    #         recalled_img_no_fix,\n",
    "    #         recalled_img_fix,\n",
    "    #         captions=[\"Original\", \"Noisy\", \"Recalled No Fix\", \"Recalled Fix\"],\n",
    "    #         out=f\"{dir}/imgs_{i}.png\",\n",
    "    #     )\n",
    "    #     plt.close('all')\n",
    "\n",
    "\n",
    "    similarity_no_fix = torch.nn.functional.cosine_similarity(data, recalled_imgs_no_fix)\n",
    "    similarity_fix = torch.nn.functional.cosine_similarity(data, recalled_imgs_fix)\n",
    "    return similarity_no_fix, similarity_fix\n",
    "\n",
    "\n",
    "for i, target_N_h in enumerate(target_N_hs):\n",
    "    vectorhash_kwargs = dict(\n",
    "        continualupdate=False,\n",
    "        ratshift=False,\n",
    "        initialize_W_gh_with_zeroes=False,\n",
    "        pseudo_inverse=False,\n",
    "        learned_pseudo=False,\n",
    "        calculate_update_scaling_method=\"norm\",\n",
    "    )\n",
    "\n",
    "    for j, num_imgs in enumerate(num_images):\n",
    "        data, noisy_data = prepare_data(\n",
    "            dataset,\n",
    "            num_imgs=num_imgs,\n",
    "            preprocess_sensory=preprocess_sensory,\n",
    "            noise_level=noise_level,\n",
    "        )\n",
    "        similarity_no_fix, similarity_fix = test_h_fix(\n",
    "            data,\n",
    "            noisy_data,\n",
    "            shapes=shapes,\n",
    "            N_h=1000,\n",
    "            percent_nonzero_relu=target_N_h / N_h,\n",
    "            W_hg_std=1.0,\n",
    "            T=0.01,\n",
    "            **vectorhash_kwargs,\n",
    "        )\n",
    "        results_no_fix[i, j] = torch.mean(similarity_no_fix).item()\n",
    "        results_fix[i, j] = torch.mean(similarity_fix).item()\n",
    "        print(\"Cosine Similarity no fix\", torch.mean(similarity_no_fix).item())\n",
    "        print(\"Cosine Similarity    fix\", torch.mean(similarity_fix).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_theme(\"paper\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "for i, target_N_h in enumerate(target_N_hs):\n",
    "\n",
    "    ax.plot([p* 0.1 for p in percents], results_no_fix[i], label=f\"no fix {target_N_h}\")\n",
    "    ax.plot([p* 0.1 for p in percents], results_fix[i], label=f\"fix {target_N_h}\")\n",
    "\n",
    "ax.set_xlabel(\"Percent of Theoretical Capacity\")\n",
    "ax.set_ylabel(\"Cosine Similarity\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
