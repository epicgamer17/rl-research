{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=10,\n",
    "    preprocess_sensory=True,\n",
    "    noise_level=\"medium\",\n",
    "):\n",
    "    import torch\n",
    "    import random\n",
    "\n",
    "    data = dataset.data\n",
    "    # print(num_imgs)\n",
    "    # print(data.shape)\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    # print(data.shape)\n",
    "    data = torch.tensor(data[:num_imgs]).float().to(\"cpu\")\n",
    "    # print(data.shape)\n",
    "\n",
    "    # data = random.sample(dataset.data.flatten(1).float().to(\"cpu\"), num_imgs)\n",
    "    if preprocess_sensory:\n",
    "        data = (data - data.mean()) / data.std()\n",
    "        # print(mnist_data[0])\n",
    "\n",
    "    # noissing the data\n",
    "    if noise_level == \"none\":\n",
    "        return data, data\n",
    "    elif noise_level == \"low\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1, 1)\n",
    "    elif noise_level == \"medium\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.25, 1.25)\n",
    "    elif noise_level == \"high\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.5, 1.5)\n",
    "    noisy_data = data + random_noise\n",
    "    # TODO: DO WE PREPROCESS NOISY IMAGES?\n",
    "    # if preprocess_sensory:\n",
    "    #     noisy_mnist = (noisy_mnist - noisy_mnist.mean()) / noisy_mnist.std()\n",
    "\n",
    "    return data, noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from nd_scaffold import GridScaffold, SparseMatrixBySparsityInitializer\n",
    "from graph_utils import graph_scaffold, print_imgs_side_by_side\n",
    "from matrix_initializers import SparseMatrixByScalingInitializer\n",
    "from vectorhash_functions import solve_mean, spacefillingcurve\n",
    "import math\n",
    "\n",
    "\n",
    "def test_memory_capacity(\n",
    "    data,\n",
    "    noisy_data,\n",
    "    shapes=[(3, 3, 5), (4, 4, 7)],\n",
    "    N_h=1000,\n",
    "    initalization_method=\"by_scaling\",\n",
    "    percent_nonzero_relu=0.01,\n",
    "    var=1.0,\n",
    "    sparse_initialization=0.1,\n",
    "    T=0.01,\n",
    "):\n",
    "\n",
    "    GS = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=\"cpu\",\n",
    "        sparse_matrix_initializer=(\n",
    "            SparseMatrixByScalingInitializer(\n",
    "                mean=solve_mean(p=percent_nonzero_relu, var=(len(shapes) * var))\n",
    "                / len(shapes),\n",
    "                scale=math.sqrt(var),\n",
    "            )\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else SparseMatrixBySparsityInitializer(sparsity=sparse_initialization)\n",
    "        ),\n",
    "        relu_theta=(\n",
    "            0.0\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else solve_mean(\n",
    "                p=percent_nonzero_relu, var=len(shapes) * (1 - sparse_initialization)\n",
    "            )\n",
    "        ),\n",
    "        T=T,\n",
    "        continualupdate=True,\n",
    "        ratshift=False,\n",
    "        initialize_W_gh_with_zeroes=True,\n",
    "    )\n",
    "\n",
    "    # learn over all images\n",
    "    v = spacefillingcurve(shapes)\n",
    "\n",
    "    GS.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    print(len(v[: len(data)]))\n",
    "    recalled_imgs = GS.recall(noisy_data)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(data, recalled_imgs)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating Capacity Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 8, 15, 25, 37, 56, 67, 74, 82, 111, 148, 222, 739]\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 1\n",
      "1\n",
      "G not denoised\n",
      "avg nonzero H: 9.0\n",
      "avg nonzero H_denoised: 9.0\n",
      "Unique Gs seen while recalling: 1\n",
      "tensor(1.0000)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 3\n",
      "3\n",
      "G not denoised\n",
      "avg nonzero H: 36.0\n",
      "avg nonzero H_denoised: 12.0\n",
      "Unique Gs seen while recalling: 3\n",
      "tensor(1.0000)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 8\n",
      "8\n",
      "G not denoised\n",
      "avg nonzero H: 39.125\n",
      "avg nonzero H_denoised: 8.0\n",
      "Unique Gs seen while recalling: 8\n",
      "tensor(0.9402)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 15\n",
      "15\n",
      "G not denoised\n",
      "avg nonzero H: 87.73332977294922\n",
      "avg nonzero H_denoised: 10.733333587646484\n",
      "Unique Gs seen while recalling: 15\n",
      "tensor(0.9666)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 25\n",
      "25\n",
      "G not denoised\n",
      "avg nonzero H: 110.91999816894531\n",
      "avg nonzero H_denoised: 9.600000381469727\n",
      "Unique Gs seen while recalling: 24\n",
      "tensor(0.7916)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 37\n",
      "37\n",
      "G not denoised\n",
      "avg nonzero H: 145.8918914794922\n",
      "avg nonzero H_denoised: 9.972972869873047\n",
      "Unique Gs seen while recalling: 22\n",
      "tensor(0.3814)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Unique Gs seen while learning: 56\n",
      "56\n",
      "G not denoised\n",
      "avg nonzero H: 158.92857360839844\n",
      "avg nonzero H_denoised: 8.660714149475098\n",
      "Unique Gs seen while recalling: 37\n",
      "tensor(0.4926)\n",
      "==========================================\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n"
     ]
    }
   ],
   "source": [
    "# Memory Capacity Tests\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "shapes = [(5, 5), (9, 9), (11, 11)]\n",
    "N_h = 1000\n",
    "\n",
    "N_g = 0\n",
    "for shape in shapes:\n",
    "    l = torch.prod(torch.tensor(shape)).item()\n",
    "    N_g += l\n",
    "# print(\"N_g\", N_g)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "# dataset = torchvision.datasets.MNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# dataset = torchvision.datasets.FashionMNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR100(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "input_size = 1\n",
    "for shape in dataset.data[0].shape:\n",
    "    input_size *= shape\n",
    "\n",
    "theoretical_capacity = N_g * N_h / input_size  # 784 is the size of the input for MNIST\n",
    "\n",
    "percents = [\n",
    "    0.01,\n",
    "    0.03,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.33,\n",
    "    0.5,\n",
    "    0.75,\n",
    "    0.9,\n",
    "    1.0,\n",
    "    1.1,\n",
    "    1.5,\n",
    "    2.0,\n",
    "    3.0,\n",
    "    10.0,\n",
    "]\n",
    "\n",
    "num_images = [theoretical_capacity * p for p in percents]\n",
    "num_images = [math.ceil(n) for n in num_images]\n",
    "print(num_images)\n",
    "\n",
    "preprocess_sensory = True\n",
    "noise_level = \"medium\"\n",
    "\n",
    "# TODO: Need a hyperparam N_p for dimension of the projection from grid cells to place cells\n",
    "similarities = []\n",
    "for num_imgs in num_images:\n",
    "    print(\"==========================================\")\n",
    "    data, noisy_data = prepare_data(\n",
    "        dataset,\n",
    "        num_imgs=num_imgs,\n",
    "        preprocess_sensory=preprocess_sensory,\n",
    "        noise_level=noise_level,\n",
    "    )\n",
    "    similarity = test_memory_capacity(\n",
    "        data,\n",
    "        noisy_data,\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        initalization_method=\"by_scaling\",\n",
    "        percent_nonzero_relu=10 / N_h,\n",
    "        var=1.0,\n",
    "        sparse_initialization=0.0,\n",
    "    )\n",
    "    print(\"Cosine Similarity\", torch.mean(similarity).item())\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing initialization techniques (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare continual learning vs learning once at start (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparam tuning for number active hippocampal cells after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we losing grid states? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
