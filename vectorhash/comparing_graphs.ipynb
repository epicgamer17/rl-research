{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=10,\n",
    "    preprocess_sensory=True,\n",
    "    noise_level=\"medium\",\n",
    "):\n",
    "    import torch\n",
    "    import random\n",
    "\n",
    "    data = dataset.data\n",
    "    # print(num_imgs)\n",
    "    # print(data.shape)\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    # print(data.shape)\n",
    "    data = torch.tensor(data[:num_imgs]).float().to(\"cpu\")\n",
    "    # print(data.shape)\n",
    "\n",
    "    # data = random.sample(dataset.data.flatten(1).float().to(\"cpu\"), num_imgs)\n",
    "    if preprocess_sensory:\n",
    "        data = (data - data.mean()) / data.std()\n",
    "        # print(mnist_data[0])\n",
    "\n",
    "    # noissing the data\n",
    "    if noise_level == \"none\":\n",
    "        return data, data\n",
    "    elif noise_level == \"low\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1, 1)\n",
    "    elif noise_level == \"medium\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.25, 1.25)\n",
    "    elif noise_level == \"high\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.5, 1.5)\n",
    "    noisy_data = data + random_noise\n",
    "    # TODO: DO WE PREPROCESS NOISY IMAGES?\n",
    "    # if preprocess_sensory:\n",
    "    #     noisy_mnist = (noisy_mnist - noisy_mnist.mean()) / noisy_mnist.std()\n",
    "\n",
    "    return data, noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from nd_scaffold import GridScaffold, SparseMatrixBySparsityInitializer\n",
    "from graph_utils import graph_scaffold, print_imgs_side_by_side\n",
    "from matrix_initializers import SparseMatrixByScalingInitializer\n",
    "from vectorhash_functions import solve_mean, spacefillingcurve\n",
    "import math\n",
    "\n",
    "\n",
    "def test_memory_capacity(\n",
    "    data,\n",
    "    noisy_data,\n",
    "    shapes=[(3, 3, 5), (4, 4, 7)],\n",
    "    N_h=1000,\n",
    "    initalization_method=\"by_scaling\",\n",
    "    percent_nonzero_relu=0.01,\n",
    "    var=1.0,\n",
    "    sparse_initialization=0.1,\n",
    "    T=0.01,\n",
    "):\n",
    "\n",
    "    GS = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=\"cpu\",\n",
    "        sparse_matrix_initializer=(\n",
    "            SparseMatrixByScalingInitializer(\n",
    "                mean=solve_mean(p=percent_nonzero_relu, var=(len(shapes) * var))\n",
    "                / len(shapes),\n",
    "                # TODO: this calculates the mean of the sum of distributions, but we want the mean of just one of the distributions so we should divide my M right?\n",
    "                scale=math.sqrt(var),\n",
    "            )\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else SparseMatrixBySparsityInitializer(sparsity=sparse_initialization)\n",
    "        ),\n",
    "        relu_theta=(\n",
    "            0.0\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else solve_mean(\n",
    "                p=percent_nonzero_relu, var=len(shapes) * (1 - sparse_initialization)\n",
    "            )\n",
    "        ),\n",
    "        T=T,\n",
    "        continualupdate=True,\n",
    "        ratshift=False,\n",
    "        initialize_W_gh_with_zeroes=True,\n",
    "    )\n",
    "\n",
    "    # learn over all images\n",
    "    v = spacefillingcurve(shapes)\n",
    "\n",
    "    GS.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    print(len(v[: len(data)]))\n",
    "    recalled_imgs = GS.recall(noisy_data)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(data, recalled_imgs)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 8, 15, 25, 37, 56, 67, 74, 82, 111, 148, 222, 739]\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "1\n",
      "G not denoised\n",
      "avg nonzero H: 10.0\n",
      "avg nonzero H_denoised: 10.0\n",
      "Unique Gs: 1\n",
      "tensor(1.0000)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "3\n",
      "G not denoised\n",
      "avg nonzero H: 25.0\n",
      "avg nonzero H_denoised: 8.666666984558105\n",
      "Unique Gs: 3\n",
      "tensor(0.9998)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "8\n",
      "G not denoised\n",
      "avg nonzero H: 47.125\n",
      "avg nonzero H_denoised: 9.875\n",
      "Unique Gs: 8\n",
      "tensor(0.9577)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "15\n",
      "G not denoised\n",
      "avg nonzero H: 69.66666412353516\n",
      "avg nonzero H_denoised: 8.533333778381348\n",
      "Unique Gs: 14\n",
      "tensor(0.8815)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "25\n",
      "G not denoised\n",
      "avg nonzero H: 117.27999877929688\n",
      "avg nonzero H_denoised: 10.359999656677246\n",
      "Unique Gs: 21\n",
      "tensor(0.7901)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "37\n",
      "G not denoised\n",
      "avg nonzero H: 139.9729766845703\n",
      "avg nonzero H_denoised: 8.432432174682617\n",
      "Unique Gs: 24\n",
      "tensor(0.6360)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Seen tensor([  1,  26, 108]) count: 1\n",
      "Seen tensor([  2,  27, 109]) count: 1\n",
      "Seen tensor([  3,  28, 110]) count: 1\n",
      "Seen tensor([  4,  29, 111]) count: 1\n",
      "Seen tensor([  0,  30, 112]) count: 1\n",
      "Seen tensor([  1,  31, 113]) count: 1\n",
      "Seen tensor([  2,  32, 114]) count: 1\n",
      "Seen tensor([  3,  33, 115]) count: 1\n",
      "Seen tensor([  4,  25, 116]) count: 1\n",
      "Seen tensor([  0,  26, 106]) count: 1\n",
      "Seen tensor([  1,  27, 107]) count: 1\n",
      "56\n",
      "G not denoised\n",
      "avg nonzero H: 175.5357208251953\n",
      "avg nonzero H_denoised: 10.732142448425293\n",
      "Unique Gs: 37\n",
      "tensor(0.4978)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Seen tensor([  1,  26, 108]) count: 1\n",
      "Seen tensor([  2,  27, 109]) count: 1\n",
      "Seen tensor([  3,  28, 110]) count: 1\n",
      "Seen tensor([  4,  29, 111]) count: 1\n",
      "Seen tensor([  0,  30, 112]) count: 1\n",
      "Seen tensor([  1,  31, 113]) count: 1\n",
      "Seen tensor([  2,  32, 114]) count: 1\n",
      "Seen tensor([  3,  33, 115]) count: 1\n",
      "Seen tensor([  4,  25, 116]) count: 1\n",
      "Seen tensor([  0,  26, 106]) count: 1\n",
      "Seen tensor([  1,  27, 107]) count: 1\n",
      "Seen tensor([  2,  28, 108]) count: 1\n",
      "Seen tensor([  3,  29, 109]) count: 1\n",
      "Seen tensor([  4,  30, 110]) count: 1\n",
      "Seen tensor([  0,  31, 111]) count: 1\n",
      "Seen tensor([  1,  32, 112]) count: 1\n",
      "Seen tensor([  2,  33, 113]) count: 1\n",
      "Seen tensor([  3,  25, 114]) count: 1\n",
      "Seen tensor([  4,  26, 115]) count: 1\n",
      "Seen tensor([  0,  27, 116]) count: 1\n",
      "Seen tensor([  1,  28, 106]) count: 1\n",
      "Seen tensor([  2,  29, 107]) count: 1\n",
      "67\n",
      "G not denoised\n",
      "avg nonzero H: 184.9253692626953\n",
      "avg nonzero H_denoised: 10.447761535644531\n",
      "Unique Gs: 36\n",
      "tensor(0.5543)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Seen tensor([  1,  26, 108]) count: 1\n",
      "Seen tensor([  2,  27, 109]) count: 1\n",
      "Seen tensor([  3,  28, 110]) count: 1\n",
      "Seen tensor([  4,  29, 111]) count: 1\n",
      "Seen tensor([  0,  30, 112]) count: 1\n",
      "Seen tensor([  1,  31, 113]) count: 1\n",
      "Seen tensor([  2,  32, 114]) count: 1\n",
      "Seen tensor([  3,  33, 115]) count: 1\n",
      "Seen tensor([  4,  25, 116]) count: 1\n",
      "Seen tensor([  0,  26, 106]) count: 1\n",
      "Seen tensor([  1,  27, 107]) count: 1\n",
      "Seen tensor([  2,  28, 108]) count: 1\n",
      "Seen tensor([  3,  29, 109]) count: 1\n",
      "Seen tensor([  4,  30, 110]) count: 1\n",
      "Seen tensor([  0,  31, 111]) count: 1\n",
      "Seen tensor([  1,  32, 112]) count: 1\n",
      "Seen tensor([  2,  33, 113]) count: 1\n",
      "Seen tensor([  3,  25, 114]) count: 1\n",
      "Seen tensor([  4,  26, 115]) count: 1\n",
      "Seen tensor([  0,  27, 116]) count: 1\n",
      "Seen tensor([  1,  28, 106]) count: 1\n",
      "Seen tensor([  2,  29, 107]) count: 1\n",
      "Seen tensor([  3,  30, 108]) count: 1\n",
      "Seen tensor([  4,  31, 109]) count: 1\n",
      "Seen tensor([  0,  32, 110]) count: 1\n",
      "Seen tensor([  1,  33, 111]) count: 1\n",
      "Seen tensor([  2,  25, 112]) count: 1\n",
      "Seen tensor([  3,  26, 113]) count: 1\n",
      "Seen tensor([  4,  27, 114]) count: 1\n",
      "74\n",
      "G not denoised\n",
      "avg nonzero H: 195.5270233154297\n",
      "avg nonzero H_denoised: 11.36486530303955\n",
      "Unique Gs: 48\n",
      "tensor(0.4423)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n",
      "Seen tensor([  1,  26, 108]) count: 1\n",
      "Seen tensor([  2,  27, 109]) count: 1\n",
      "Seen tensor([  3,  28, 110]) count: 1\n",
      "Seen tensor([  4,  29, 111]) count: 1\n",
      "Seen tensor([  0,  30, 112]) count: 1\n",
      "Seen tensor([  1,  31, 113]) count: 1\n",
      "Seen tensor([  2,  32, 114]) count: 1\n",
      "Seen tensor([  3,  33, 115]) count: 1\n",
      "Seen tensor([  4,  25, 116]) count: 1\n",
      "Seen tensor([  0,  26, 106]) count: 1\n",
      "Seen tensor([  1,  27, 107]) count: 1\n",
      "Seen tensor([  2,  28, 108]) count: 1\n",
      "Seen tensor([  3,  29, 109]) count: 1\n",
      "Seen tensor([  4,  30, 110]) count: 1\n",
      "Seen tensor([  0,  31, 111]) count: 1\n",
      "Seen tensor([  1,  32, 112]) count: 1\n",
      "Seen tensor([  2,  33, 113]) count: 1\n",
      "Seen tensor([  3,  25, 114]) count: 1\n",
      "Seen tensor([  4,  26, 115]) count: 1\n",
      "Seen tensor([  0,  27, 116]) count: 1\n",
      "Seen tensor([  1,  28, 106]) count: 1\n",
      "Seen tensor([  2,  29, 107]) count: 1\n",
      "Seen tensor([  3,  30, 108]) count: 1\n",
      "Seen tensor([  4,  31, 109]) count: 1\n",
      "Seen tensor([  0,  32, 110]) count: 1\n",
      "Seen tensor([  1,  33, 111]) count: 1\n",
      "Seen tensor([  2,  25, 112]) count: 1\n",
      "Seen tensor([  3,  26, 113]) count: 1\n",
      "Seen tensor([  4,  27, 114]) count: 1\n",
      "Seen tensor([  0,  28, 115]) count: 1\n",
      "Seen tensor([  1,  29, 116]) count: 1\n",
      "Seen tensor([  2,  30, 106]) count: 1\n",
      "Seen tensor([  3,  31, 107]) count: 1\n",
      "Seen tensor([  4,  32, 108]) count: 1\n",
      "Seen tensor([  0,  33, 109]) count: 1\n",
      "Seen tensor([  1,  25, 110]) count: 1\n",
      "Seen tensor([  2,  26, 111]) count: 1\n",
      "82\n",
      "G not denoised\n",
      "avg nonzero H: 199.2073211669922\n",
      "avg nonzero H_denoised: 9.390243530273438\n",
      "Unique Gs: 44\n",
      "tensor(0.3743)\n",
      "module shapes:  [(5, 5), (9, 9), (11, 11)]\n",
      "N_g     :  227\n",
      "N_patts :  245025\n",
      "N_h     :  1000\n"
     ]
    }
   ],
   "source": [
    "# Memory Capacity Tests\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "shapes = [(5, 5), (9, 9), (11, 11)]\n",
    "N_h = 1000\n",
    "\n",
    "N_g = 0\n",
    "for shape in shapes:\n",
    "    l = torch.prod(torch.tensor(shape)).item()\n",
    "    N_g += l\n",
    "# print(\"N_g\", N_g)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "# dataset = torchvision.datasets.MNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# dataset = torchvision.datasets.FashionMNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR100(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "input_size = 1\n",
    "for shape in dataset.data[0].shape:\n",
    "    input_size *= shape\n",
    "\n",
    "theoretical_capacity = N_g * N_h / input_size  # 784 is the size of the input for MNIST\n",
    "\n",
    "percents = [\n",
    "    0.01,\n",
    "    0.03,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.33,\n",
    "    0.5,\n",
    "    0.75,\n",
    "    0.9,\n",
    "    1.0,\n",
    "    1.1,\n",
    "    1.5,\n",
    "    2.0,\n",
    "    3.0,\n",
    "    10.0,\n",
    "]\n",
    "\n",
    "num_images = [theoretical_capacity * p for p in percents]\n",
    "num_images = [math.ceil(n) for n in num_images]\n",
    "print(num_images)\n",
    "\n",
    "preprocess_sensory = True\n",
    "noise_level = \"medium\"\n",
    "\n",
    "# TODO: Need a hyperparam N_p for dimension of the projection from grid cells to place cells\n",
    "similarities = []\n",
    "for num_imgs in num_images:\n",
    "    print(\"==========================================\")\n",
    "    data, noisy_data = prepare_data(\n",
    "        dataset,\n",
    "        num_imgs=num_imgs,\n",
    "        preprocess_sensory=preprocess_sensory,\n",
    "        noise_level=noise_level,\n",
    "    )\n",
    "    similarity = test_memory_capacity(\n",
    "        data,\n",
    "        noisy_data,\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        initalization_method=\"by_scaling\",\n",
    "        percent_nonzero_relu=10 / N_h,\n",
    "        var=1.0,\n",
    "        sparse_initialization=0.0,\n",
    "    )\n",
    "    print(torch.mean(similarity))\n",
    "    similarities.append(similarity)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(percents * 100, similarities)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of Images\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.title(\"Memory Capacity\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
