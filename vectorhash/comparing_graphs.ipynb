{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    dataset,\n",
    "    num_imgs=10,\n",
    "    preprocess_sensory=True,\n",
    "    noise_level=\"medium\",\n",
    "):\n",
    "    import torch\n",
    "    import random\n",
    "\n",
    "    data = dataset.data\n",
    "    # print(num_imgs)\n",
    "    # print(data.shape)\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    # print(data.shape)\n",
    "    data = torch.tensor(data[:num_imgs]).float().to(\"cpu\")\n",
    "    # print(data.shape)\n",
    "\n",
    "    # data = random.sample(dataset.data.flatten(1).float().to(\"cpu\"), num_imgs)\n",
    "    if preprocess_sensory:\n",
    "        data = (data - data.mean()) / data.std()\n",
    "        # print(mnist_data[0])\n",
    "\n",
    "    # noissing the data\n",
    "    if noise_level == \"none\":\n",
    "        return data, data\n",
    "    elif noise_level == \"low\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1, 1)\n",
    "    elif noise_level == \"medium\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.25, 1.25)\n",
    "    elif noise_level == \"high\":\n",
    "        random_noise = torch.zeros_like(data).uniform_(-1.5, 1.5)\n",
    "    noisy_data = data + random_noise\n",
    "    # TODO: DO WE PREPROCESS NOISY IMAGES?\n",
    "    # if preprocess_sensory:\n",
    "    #     noisy_mnist = (noisy_mnist - noisy_mnist.mean()) / noisy_mnist.std()\n",
    "\n",
    "    return data, noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from nd_scaffold import GridScaffold, SparseMatrixBySparsityInitializer\n",
    "from graph_utils import graph_scaffold, print_imgs_side_by_side\n",
    "from matrix_initializers import SparseMatrixByScalingInitializer\n",
    "from vectorhash_functions import solve_mean, spacefillingcurve\n",
    "import math\n",
    "\n",
    "\n",
    "def test_memory_capacity(\n",
    "    data,\n",
    "    noisy_data,\n",
    "    shapes=[(3, 3, 5), (4, 4, 7)],\n",
    "    N_h=1000,\n",
    "    initalization_method=\"by_scaling\",\n",
    "    percent_nonzero_relu=0.01,\n",
    "    var=1.0,\n",
    "    sparse_initialization=0.1,\n",
    "    T=0.01,\n",
    "    continualupdate=False,\n",
    "    ratshift=False,\n",
    "    initialize_W_gh_with_zeroes=False,\n",
    "    pseudo_inverse=False,\n",
    "    learned_pseudo=True,\n",
    "):\n",
    "\n",
    "    GS = GridScaffold(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=data.shape[1],\n",
    "        device=\"cpu\",\n",
    "        sparse_matrix_initializer=(\n",
    "            SparseMatrixByScalingInitializer(\n",
    "                mean=solve_mean(p=percent_nonzero_relu, var=(len(shapes) * var))\n",
    "                / len(shapes),\n",
    "                scale=math.sqrt(var),\n",
    "            )\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else SparseMatrixBySparsityInitializer(sparsity=sparse_initialization)\n",
    "        ),\n",
    "        relu_theta=(\n",
    "            0.0\n",
    "            if initalization_method == \"by_scaling\"\n",
    "            else -solve_mean(\n",
    "                p=percent_nonzero_relu, var=len(shapes) * (1 - sparse_initialization)\n",
    "            )\n",
    "        ),\n",
    "        T=T,\n",
    "        continualupdate=continualupdate,\n",
    "        ratshift=ratshift,\n",
    "        initialize_W_gh_with_zeroes=initialize_W_gh_with_zeroes,\n",
    "        pseudo_inverse=pseudo_inverse,\n",
    "        learned_pseudo=learned_pseudo,\n",
    "    )\n",
    "\n",
    "    # learn over all images\n",
    "    v = spacefillingcurve(shapes)\n",
    "\n",
    "    GS.learn_path(observations=data, velocities=v[: len(data)])\n",
    "    print(len(v[: len(data)]))\n",
    "    recalled_imgs = GS.recall(noisy_data)\n",
    "    print(recalled_imgs)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(data, recalled_imgs)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating Capacity Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 9, 13, 15, 17, 18, 25, 33, 49, 163]\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 2\n",
      "Unique Hs seen while learning: 2\n",
      "2\n",
      "Unique Hs seen while recalling: 2\n",
      "Unique Gs seen while recalling (before denoising): 2\n",
      "Unique Gs seen while recalling (after denoising): 2\n",
      "Unique Hs seen while recalling (after denoising): 2\n",
      "avg nonzero H: 13.0\n",
      "avg nonzero H_denoised: 12.5\n",
      "tensor([[ 0.0105,  0.0105,  0.0105,  ..., -0.0031,  0.0010, -0.0100],\n",
      "        [ 0.0114,  0.0114,  0.0114,  ...,  0.0112,  0.0112,  0.0111]])\n",
      "Cosine Similarity 0.9996100068092346\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlamontange-kratz/Documents/GitHub/rl-stuff/vectorhash/nd_scaffold.py:433: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3729.)\n",
      "  b_k_hs = (input.T @ self.inhibition_matrix_hs.T) / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 4\n",
      "Unique Hs seen while learning: 4\n",
      "4\n",
      "Unique Hs seen while recalling: 4\n",
      "Unique Gs seen while recalling (before denoising): 4\n",
      "Unique Gs seen while recalling (after denoising): 2\n",
      "Unique Hs seen while recalling (after denoising): 2\n",
      "avg nonzero H: 29.25\n",
      "avg nonzero H_denoised: 13.5\n",
      "tensor([[-0.0005,  0.0014,  0.0022,  ...,  0.0022,  0.0020,  0.0016],\n",
      "        [ 0.0080,  0.0080,  0.0080,  ..., -0.0025,  0.0007, -0.0077],\n",
      "        [ 0.0080,  0.0080,  0.0080,  ..., -0.0025,  0.0007, -0.0077],\n",
      "        [-0.0005,  0.0014,  0.0022,  ...,  0.0022,  0.0020,  0.0016]])\n",
      "Cosine Similarity 0.4064047336578369\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 6\n",
      "Unique Hs seen while learning: 6\n",
      "6\n",
      "Unique Hs seen while recalling: 6\n",
      "Unique Gs seen while recalling (before denoising): 6\n",
      "Unique Gs seen while recalling (after denoising): 3\n",
      "Unique Hs seen while recalling (after denoising): 3\n",
      "avg nonzero H: 25.16666603088379\n",
      "avg nonzero H_denoised: 10.666666984558105\n",
      "tensor([[ 0.0068,  0.0046,  0.0007,  ...,  0.0094,  0.0104,  0.0075],\n",
      "        [ 0.0065,  0.0065,  0.0064,  ..., -0.0007,  0.0015, -0.0043],\n",
      "        [ 0.0065,  0.0065,  0.0064,  ..., -0.0007,  0.0015, -0.0043],\n",
      "        [ 0.0065,  0.0065,  0.0064,  ..., -0.0007,  0.0015, -0.0043],\n",
      "        [ 0.0034,  0.0013, -0.0024,  ...,  0.0091,  0.0091,  0.0091],\n",
      "        [ 0.0034,  0.0013, -0.0024,  ...,  0.0091,  0.0091,  0.0091]])\n",
      "Cosine Similarity 0.3252648711204529\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 9\n",
      "Unique Hs seen while learning: 9\n",
      "9\n",
      "Unique Hs seen while recalling: 9\n",
      "Unique Gs seen while recalling (before denoising): 9\n",
      "Unique Gs seen while recalling (after denoising): 2\n",
      "Unique Hs seen while recalling (after denoising): 2\n",
      "avg nonzero H: 42.0\n",
      "avg nonzero H_denoised: 12.333333015441895\n",
      "tensor([[-0.0053,  0.0020,  0.0071,  ..., -0.0227, -0.0223, -0.0226],\n",
      "        [ 0.0227,  0.0212,  0.0184,  ...,  0.0018,  0.0094, -0.0118],\n",
      "        [ 0.0227,  0.0212,  0.0184,  ...,  0.0018,  0.0094, -0.0118],\n",
      "        ...,\n",
      "        [-0.0053,  0.0020,  0.0071,  ..., -0.0227, -0.0223, -0.0226],\n",
      "        [ 0.0227,  0.0212,  0.0184,  ...,  0.0018,  0.0094, -0.0118],\n",
      "        [-0.0053,  0.0020,  0.0071,  ..., -0.0227, -0.0223, -0.0226]])\n",
      "Cosine Similarity 0.17309576272964478\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 13\n",
      "Unique Hs seen while learning: 13\n",
      "13\n",
      "Unique Hs seen while recalling: 13\n",
      "Unique Gs seen while recalling (before denoising): 13\n",
      "Unique Gs seen while recalling (after denoising): 13\n",
      "Unique Hs seen while recalling (after denoising): 13\n",
      "avg nonzero H: 1000.0\n",
      "avg nonzero H_denoised: 1000.0\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "Cosine Similarity nan\n",
      "==========================================\n",
      "module shapes:  [(3, 3), (4, 4), (5, 5)]\n",
      "N_g     :  50\n",
      "N_patts :  3600\n",
      "N_h     :  1000\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "learned pseudo\n",
      "Unique Gs seen while learning: 15\n",
      "Unique Hs seen while learning: 15\n",
      "15\n",
      "Unique Hs seen while recalling: 15\n",
      "Unique Gs seen while recalling (before denoising): 15\n",
      "Unique Gs seen while recalling (after denoising): 15\n",
      "Unique Hs seen while recalling (after denoising): 15\n",
      "avg nonzero H: 1000.0\n",
      "avg nonzero H_denoised: 1000.0\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "Cosine Similarity nan\n",
      "==========================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_imgs \u001b[38;5;129;01min\u001b[39;00m num_images:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m     data, noisy_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_imgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_imgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_sensory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_sensory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m test_memory_capacity(\n\u001b[1;32m     74\u001b[0m         data,\n\u001b[1;32m     75\u001b[0m         noisy_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m         learned_pseudo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine Similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mmean(similarity)\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(dataset, num_imgs, preprocess_sensory, noise_level)\u001b[0m\n\u001b[1;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(num_imgs)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(data.shape)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(data.shape)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[:num_imgs])\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Memory Capacity Tests\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "shapes = [(3, 3), (4, 4), (5, 5)]\n",
    "# shapes = [(5, 5), (9, 9), (11, 11)]\n",
    "\n",
    "N_h = 1000\n",
    "\n",
    "N_g = 0\n",
    "for shape in shapes:\n",
    "    l = torch.prod(torch.tensor(shape)).item()\n",
    "    N_g += l\n",
    "# print(\"N_g\", N_g)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.flatten())]\n",
    ")\n",
    "# dataset = torchvision.datasets.MNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# dataset = torchvision.datasets.FashionMNIST(\n",
    "#     root=\"data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR100(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "input_size = 1\n",
    "for shape in dataset.data[0].shape:\n",
    "    input_size *= shape\n",
    "\n",
    "theoretical_capacity = N_g * N_h / input_size  # 784 is the size of the input for MNIST\n",
    "\n",
    "percents = [\n",
    "    # 0.01,  # 1\n",
    "    # 0.03,  # 2\n",
    "    # 0.1,  # 3\n",
    "    # 0.2,  # 4\n",
    "    0.33,  # 5\n",
    "    0.5,  # 6\n",
    "    0.75,  # 7\n",
    "    0.9,  # 8\n",
    "    1.0,  # 9\n",
    "    1.1,  # 10\n",
    "    1.5,  # 11\n",
    "    2.0,  # 12\n",
    "    3.0,  # 13\n",
    "    10.0,  # 14\n",
    "]\n",
    "\n",
    "num_images = [theoretical_capacity * p for p in percents]\n",
    "num_images = [math.ceil(n) for n in num_images]\n",
    "print(num_images)\n",
    "\n",
    "preprocess_sensory = True\n",
    "noise_level = \"medium\"\n",
    "\n",
    "# TODO: Need a hyperparam N_p for dimension of the projection from grid cells to place cells\n",
    "similarities = []\n",
    "for num_imgs in num_images:\n",
    "    print(\"==========================================\")\n",
    "    data, noisy_data = prepare_data(\n",
    "        dataset,\n",
    "        num_imgs=num_imgs,\n",
    "        preprocess_sensory=preprocess_sensory,\n",
    "        noise_level=noise_level,\n",
    "    )\n",
    "    similarity = test_memory_capacity(\n",
    "        data,\n",
    "        noisy_data,\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        initalization_method=\"hawk tuah\",\n",
    "        percent_nonzero_relu=10 / N_h,\n",
    "        var=1.0,\n",
    "        sparse_initialization=0.1,\n",
    "        T=0.01,\n",
    "        continualupdate=False,\n",
    "        ratshift=False,\n",
    "        initialize_W_gh_with_zeroes=False,\n",
    "        pseudo_inverse=False,\n",
    "        learned_pseudo=True,\n",
    "    )\n",
    "    print(\"Cosine Similarity\", torch.mean(similarity).item())\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing initialization techniques (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare continual learning vs learning once at start (at 10%, 50%, 100%, 150% capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparam tuning for number active hippocampal cells after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we losing grid states? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
