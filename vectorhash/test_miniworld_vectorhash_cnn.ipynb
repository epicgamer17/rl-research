{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniWorld VectorHash + CNN Performance Tests\n",
    "\n",
    "This notebook runs a grid of VectorHash localization tests on the\n",
    "MiniWorld-Maze environment, comparing raw-flattened pixels against a\n",
    "ResNet-18 pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:4: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  from scipy.stats import norm\n"
     ]
    }
   ],
   "source": [
    "# ── Imports, device, reproducibility ──\n",
    "import os, itertools, pickle\n",
    "import torch, numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from miniworld.params import DEFAULT_PARAMS\n",
    "from preprocessing_cnn import PreprocessingCNN\n",
    "from vectorhash import build_vectorhash_architecture\n",
    "from miniworld_agent import MiniworldVectorhashAgent\n",
    "from agent import kidnapping_test\n",
    "from smoothing import (\n",
    "    IdentitySmoothing,\n",
    "    PolynomialSmoothing,\n",
    "    SoftmaxSmoothing,\n",
    "    RatSLAMSmoothing,\n",
    ")\n",
    "from shifts import RatShift\n",
    "\n",
    "# fix seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Env builder, shapes & limits ──\n",
    "\n",
    "shapes = [(3, 3, 4), (4, 4, 5)]\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    params = DEFAULT_PARAMS.copy().no_random()\n",
    "    env = gym.make(\n",
    "        \"MiniWorld-Maze-v0\", max_episode_steps=-1, params=params, domain_rand=False\n",
    "    )\n",
    "    # compute limits from the wrapper attrs\n",
    "    min_x = env.get_wrapper_attr(\"min_x\")\n",
    "    max_x = env.get_wrapper_attr(\"max_x\")\n",
    "    min_z = env.get_wrapper_attr(\"min_z\")\n",
    "    max_z = env.get_wrapper_attr(\"max_z\")\n",
    "    limits = torch.tensor(\n",
    "        [max_x - min_x, max_z - min_z, 2 * np.pi], device=device\n",
    "    ).float()\n",
    "    return env, limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezrahuang/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ezrahuang/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ── CNN Preprocessor & Hyperparams ──\n",
    "\n",
    "# 1) CNN encoder (ResNet-18 adapter)\n",
    "cnn_preproc = PreprocessingCNN(\n",
    "    device=device,\n",
    "    latent_dim=128,\n",
    "    input_channels=3,\n",
    "    target_size=(224, 224),\n",
    "    model_path=\"resnet18_adapter.pth\",\n",
    ")\n",
    "\n",
    "# 2) Hyperparameter grid\n",
    "store_opts = [True, False]  # True=\"Always\", False=\"When New\"\n",
    "shift_opts = [\"additive\", \"multiplicative\"]\n",
    "hard_opts = [True, False]  # True=\"Hard\", False=\"Soft\"\n",
    "smooth_opts = [\n",
    "    IdentitySmoothing(),\n",
    "    PolynomialSmoothing(k=1.0),\n",
    "    PolynomialSmoothing(k=1.5),\n",
    "    SoftmaxSmoothing(T=0.1),\n",
    "    RatSLAMSmoothing(device=device),\n",
    "]\n",
    "\n",
    "# 3) Output folder\n",
    "basedir = \"miniworld_cnn_tests\"\n",
    "os.makedirs(basedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path length: 40\n",
      "Visibles length: 40\n"
     ]
    }
   ],
   "source": [
    "# ─── 1) Motion primitives (90° turns) ───\n",
    "# MiniWorld-Maze: 0=turn left 90°, 1=turn right 90°, 2=move forward\n",
    "forward_10 = [2] * 10  # forward ×10\n",
    "forward_3 = [2] * 3  # forward ×3\n",
    "turn_r = [1]  # one 90° right turn\n",
    "turn_l = [0]  # one 90° left turn\n",
    "\n",
    "# ─── 2) Build path ───\n",
    "# Sequence: F10 → R → F3 → R → F10 → L → F3 → L → F10\n",
    "path = (\n",
    "    forward_10\n",
    "    + turn_r\n",
    "    + forward_3\n",
    "    + turn_r\n",
    "    + forward_10\n",
    "    + turn_l\n",
    "    + forward_3\n",
    "    + turn_l\n",
    "    + forward_10\n",
    ")\n",
    "\n",
    "# Check length\n",
    "print(\"Path length:\", len(path))  # should be 10+1+3+1+10+1+3+1+10 = 40\n",
    "\n",
    "# ─── 3) Visibility flags ───\n",
    "# Make a visibility segment for each chunk\n",
    "visible_10 = [True] * 10\n",
    "visible_3 = [True] * 3\n",
    "visible_1 = [True] * 1\n",
    "not_visible_1 = [False] * 1\n",
    "\n",
    "# Now concatenate in the same order as `path`\n",
    "visibles = (\n",
    "    visible_10\n",
    "    + visible_1  # turn_r\n",
    "    + visible_3\n",
    "    + visible_1  # turn_r\n",
    "    + visible_10\n",
    "    + visible_1  # turn_l\n",
    "    + visible_3\n",
    "    + visible_1  # turn_l\n",
    "    + visible_10\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "print(\"Visibles length:\", len(visibles))  # → 40\n",
    "\n",
    "# ─── 4) Noise list ───\n",
    "# Here we leave each step noise-free\n",
    "noise_list = [[] for _ in path]\n",
    "\n",
    "# Final sanity check\n",
    "assert len(path) == len(visibles) == len(noise_list), \"Lengths must match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cnn__Always__additive__Hard__Identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_sparsity\n",
      "module shapes:  [(3, 3, 4), (4, 4, 5)]\n",
      "N_g     :  116\n",
      "N_patts :  2880\n",
      "N_h     :  600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezrahuang/Projects/rl-research/vectorhash/hippocampal_sensory_layers.py:110: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  1 + input.T @ self.inhibition_matrix_hs @ input\n",
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:102: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s),\n",
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:109: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s_denoised),\n",
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:125: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s),\n",
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:132: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s_denoised),\n",
      "/home/ezrahuang/Projects/rl-research/vectorhash/vectorhash.py:139: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5059) tensor(0.) tensor(1.8728)\n",
      "h_from_s max, min, mean tensor(7.5042) tensor(0.) tensor(1.8723)\n",
      "h_from_s_denoised max, min, mean tensor(1235.1213) tensor(0.) tensor(166.9337)\n",
      "avg nonzero/greaterzero h from book: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(2.5040e-07) tensor([1.])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(80210.3828) tensor([0.5578])\n",
      "mse/cosinesimilarity s and s from h from s tensor(7.0211e-10) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0265) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(4.8451e-10) tensor([1.0000])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5059) tensor(0.) tensor(1.8728)\n",
      "h_from_s max, min, mean tensor(7.5041) tensor(0.) tensor(1.8723)\n",
      "h_from_s_denoised max, min, mean tensor(1235.0974) tensor(0.) tensor(166.9305)\n",
      "avg nonzero/greaterzero h from book: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(2.9658e-07) tensor([1.])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(80207.2500) tensor([0.5578])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.6139e-10) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0132) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.4260e-10) tensor([1.])\n",
      "new positions: tensor([ 0.0267, 25.7306,  6.2832])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(6.7676) tensor(0.) tensor(1.8489)\n",
      "h_from_s max, min, mean tensor(6.8333) tensor(0.) tensor(1.8504)\n",
      "h_from_s_denoised max, min, mean tensor(1220.7577) tensor(0.) tensor(164.9585)\n",
      "avg nonzero/greaterzero h from book: tensor(552) tensor(552)\n",
      "avg nonzero/greaterzero h from s: tensor(553) tensor(553)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(0.0002) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(78365.2812) tensor([0.5692])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.0289e-05) tensor([0.9999])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0127) tensor([0.9997])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0511e-08) tensor([1.0000])\n",
      "new positions: tensor([ 0.0535, 25.7113,  6.2832])\n",
      "new positions: tensor([ 0.0802, 25.6919,  6.2832])\n",
      "new positions: tensor([ 0.1069, 25.6725,  6.2832])\n",
      "new positions: tensor([ 0.1336, 25.6532,  6.2832])\n",
      "new positions: tensor([ 0.1604, 25.6338,  6.2832])\n",
      "new positions: tensor([ 0.1871, 25.6144,  6.2832])\n",
      "new positions: tensor([ 0.2138, 25.5951,  6.2832])\n",
      "new positions: tensor([ 0.2405, 25.5757,  6.2832])\n",
      "new positions: tensor([ 0.2673, 25.5563,  6.2832])\n",
      "new positions: tensor([ 0.2673, 25.5563,  5.9892])\n",
      "new positions: tensor([ 0.2968, 25.5445,  5.9892])\n",
      "new positions: tensor([ 0.3262, 25.5326,  5.9892])\n",
      "new positions: tensor([ 0.3557, 25.5207,  5.9892])\n",
      "new positions: tensor([ 0.3557, 25.5207,  5.6951])\n",
      "new positions: tensor([ 0.3864, 25.5180,  5.6951])\n",
      "new positions: tensor([ 0.4170, 25.5152,  5.6951])\n",
      "new positions: tensor([ 0.4477, 25.5125,  5.6951])\n",
      "new positions: tensor([ 0.4783, 25.5098,  5.6951])\n",
      "new positions: tensor([ 0.5089, 25.5071,  5.6951])\n",
      "new positions: tensor([ 0.5396, 25.5043,  5.6951])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(3.0261) tensor(0.4302) tensor(1.7309)\n",
      "h_from_s max, min, mean tensor(3.0221) tensor(0.4324) tensor(1.7307)\n",
      "h_from_s_denoised max, min, mean tensor(1144.3301) tensor(0.) tensor(153.2796)\n",
      "avg nonzero/greaterzero h from book: tensor(600) tensor(600)\n",
      "avg nonzero/greaterzero h from s: tensor(600) tensor(600)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(320) tensor(320)\n",
      "mse/cosinesimilarity h from book and h from s tensor(4.2801e-06) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(68263.6406) tensor([0.6547])\n",
      "mse/cosinesimilarity s and s from h from s tensor(2.0824e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0111) tensor([0.9465])\n",
      "mse/cosinesimilarity s and s from h tensor(1.6701e-09) tensor([1.0000])\n",
      "new positions: tensor([ 0.5702, 25.5016,  5.6951])\n",
      "new positions: tensor([ 0.6009, 25.4989,  5.6951])\n",
      "new positions: tensor([ 0.6315, 25.4961,  5.6951])\n",
      "new positions: tensor([ 0.6621, 25.4934,  5.6951])\n",
      "new positions: tensor([ 0.6621, 25.4934,  5.9892])\n",
      "new positions: tensor([ 0.6916, 25.4815,  5.9892])\n",
      "new positions: tensor([ 0.7211, 25.4696,  5.9892])\n",
      "new positions: tensor([ 0.7506, 25.4578,  5.9892])\n",
      "new positions: tensor([ 0.7506, 25.4578,  6.2832])\n",
      "new positions: tensor([ 0.7773, 25.4384,  6.2832])\n",
      "new positions: tensor([ 0.8041, 25.4190,  6.2832])\n",
      "new positions: tensor([ 0.8308, 25.3997,  6.2832])\n",
      "new positions: tensor([ 0.8575, 25.3803,  6.2832])\n",
      "new positions: tensor([ 0.8843, 25.3609,  6.2832])\n",
      "new positions: tensor([ 0.9110, 25.3416,  6.2832])\n",
      "new positions: tensor([ 0.9377, 25.3222,  6.2832])\n",
      "new positions: tensor([ 0.9644, 25.3028,  6.2832])\n",
      "new positions: tensor([ 0.9644, 25.3029,  6.2832])\n",
      "new positions: tensor([ 0.9644, 25.3028,  6.2832])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorhashAgentKidnappedHistory' object has no attribute 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 4b) plot error curve\u001b[39;00m\n\u001b[1;32m     54\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 55\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m, label\u001b[38;5;241m=\u001b[39mrun_name)\n\u001b[1;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(run_name)\n\u001b[1;32m     57\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestep\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorhashAgentKidnappedHistory' object has no attribute 'errors'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Run CNN‐only kidnapping tests ──\n",
    "\n",
    "for store_new, shift_m, hard_store, smooth in itertools.product(\n",
    "    store_opts, shift_opts, hard_opts, smooth_opts\n",
    "):\n",
    "    # descriptive run name\n",
    "    sm_str = (\n",
    "        \"Identity\"\n",
    "        if isinstance(smooth, IdentitySmoothing)\n",
    "        else (\n",
    "            f\"Poly(k={smooth.k})\"\n",
    "            if hasattr(smooth, \"k\")\n",
    "            else f\"Softmax(T={smooth.T})\" if hasattr(smooth, \"T\") else \"RatSLAM\"\n",
    "        )\n",
    "    )\n",
    "    run_name = (\n",
    "        f\"cnn__{'Always' if store_new else 'WhenNew'}\"\n",
    "        f\"__{shift_m}__{'Hard' if hard_store else 'Soft'}__{sm_str}\"\n",
    "    )\n",
    "    print(\"Running\", run_name)\n",
    "\n",
    "    # 1) make env & limits\n",
    "    env, limits = make_env()\n",
    "\n",
    "    # 2) build VectorHash + agent\n",
    "    vh = build_vectorhash_architecture(\n",
    "        shapes=shapes,\n",
    "        N_h=600,\n",
    "        input_size=128,  # CNN latent size\n",
    "        initalization_method=\"by_sparsity\",\n",
    "        limits=limits,\n",
    "        device=device,\n",
    "        shift=RatShift(device=device),\n",
    "        smoothing=smooth,\n",
    "    )\n",
    "    agent = MiniworldVectorhashAgent(\n",
    "        vectorhash=vh,\n",
    "        env=env,\n",
    "        hard_store=hard_store,\n",
    "        store_new=store_new,\n",
    "        shift_method=shift_m,\n",
    "        preprocessor=cnn_preproc,\n",
    "    )\n",
    "\n",
    "    # 3) kidnapping history\n",
    "    # signature: kidnapping_test(agent, path, visibles, limits, noise_dist=None)\n",
    "    hist = kidnapping_test(agent, path, visibles, limits / 10)\n",
    "\n",
    "    # 4a) save history\n",
    "    with open(f\"{basedir}/{run_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hist, f)\n",
    "\n",
    "    # 4b) plot error curve\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(hist.errors, label=run_name)\n",
    "    plt.title(run_name)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Position error\")\n",
    "    plt.legend(fontsize=\"x-small\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{basedir}/{run_name}_error.png\", dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
