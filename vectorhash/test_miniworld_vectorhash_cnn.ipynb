{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniWorld VectorHash + CNN Performance Tests\n",
    "\n",
    "This notebook runs a grid of VectorHash localization tests on the\n",
    "MiniWorld-Maze environment, comparing raw-flattened pixels against a\n",
    "ResNet-18 pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 14:27:46.190 Python[8639:508622] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/zz/_8nvyjvj4jd9v1rfts46s0ph0000gn/T/com.apple.python3.savedState\n"
     ]
    }
   ],
   "source": [
    "# ── Imports, device, reproducibility ──\n",
    "import os, itertools, pickle\n",
    "import torch, numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from miniworld.params import DEFAULT_PARAMS\n",
    "from preprocessing_cnn import PreprocessingCNN\n",
    "from vectorhash import build_vectorhash_architecture\n",
    "from miniworld_agent import MiniworldVectorhashAgent\n",
    "from agent import kidnapping_test\n",
    "from smoothing import (\n",
    "    IdentitySmoothing,\n",
    "    PolynomialSmoothing,\n",
    "    SoftmaxSmoothing,\n",
    "    RatSLAMSmoothing,\n",
    ")\n",
    "from shifts import RatShift\n",
    "\n",
    "# fix seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Env builder, shapes & limits ──\n",
    "\n",
    "shapes = [(3, 3, 4), (4, 4, 5)]\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    params = DEFAULT_PARAMS.copy().no_random()\n",
    "    env = gym.make(\n",
    "        \"MiniWorld-Maze-v0\", max_episode_steps=-1, params=params, domain_rand=False\n",
    "    )\n",
    "    # compute limits from the wrapper attrs\n",
    "    min_x = env.get_wrapper_attr(\"min_x\")\n",
    "    max_x = env.get_wrapper_attr(\"max_x\")\n",
    "    min_z = env.get_wrapper_attr(\"min_z\")\n",
    "    max_z = env.get_wrapper_attr(\"max_z\")\n",
    "    limits = torch.tensor(\n",
    "        [max_x - min_x, max_z - min_z, 2 * np.pi], device=device\n",
    "    ).float()\n",
    "    return env, limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ── CNN Preprocessor & Hyperparams ──\n",
    "\n",
    "# 1) CNN encoder (ResNet-18 adapter)\n",
    "cnn_preproc = PreprocessingCNN(\n",
    "    device=device,\n",
    "    latent_dim=128,\n",
    "    input_channels=3,\n",
    "    target_size=(224, 224),\n",
    "    model_path=\"resnet18_adapter.pth\",\n",
    ")\n",
    "\n",
    "# 2) Hyperparameter grid\n",
    "store_opts = [True, False]  # True=\"Always\", False=\"When New\"\n",
    "shift_opts = [\"additive\", \"multiplicative\"]\n",
    "hard_opts = [True, False]  # True=\"Hard\", False=\"Soft\"\n",
    "smooth_opts = [\n",
    "    IdentitySmoothing(),\n",
    "    PolynomialSmoothing(k=1.0),\n",
    "    PolynomialSmoothing(k=1.5),\n",
    "    SoftmaxSmoothing(T=0.1),\n",
    "    RatSLAMSmoothing(device=device),\n",
    "]\n",
    "\n",
    "# 3) Output folder\n",
    "basedir = \"miniworld_cnn_tests\"\n",
    "os.makedirs(basedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path length: 40\n",
      "Visibles length: 40\n"
     ]
    }
   ],
   "source": [
    "# ─── 1) Motion primitives (90° turns) ───\n",
    "# MiniWorld-Maze: 0=turn left 90°, 1=turn right 90°, 2=move forward\n",
    "forward_10 = [2] * 10  # forward ×10\n",
    "forward_3 = [2] * 3  # forward ×3\n",
    "turn_r = [1]  # one 90° right turn\n",
    "turn_l = [0]  # one 90° left turn\n",
    "\n",
    "# ─── 2) Build path ───\n",
    "# Sequence: F10 → R → F3 → R → F10 → L → F3 → L → F10\n",
    "path = (\n",
    "    forward_10\n",
    "    + turn_r\n",
    "    + forward_3\n",
    "    + turn_r\n",
    "    + forward_10\n",
    "    + turn_l\n",
    "    + forward_3\n",
    "    + turn_l\n",
    "    + forward_10\n",
    ")\n",
    "\n",
    "# Check length\n",
    "print(\"Path length:\", len(path))  # should be 10+1+3+1+10+1+3+1+10 = 40\n",
    "\n",
    "# ─── 3) Visibility flags ───\n",
    "# Make a visibility segment for each chunk\n",
    "visible_10 = [True] * 10\n",
    "visible_3 = [True] * 3\n",
    "visible_1 = [True] * 1\n",
    "not_visible_1 = [False] * 1\n",
    "\n",
    "# Now concatenate in the same order as `path`\n",
    "visibles = (\n",
    "    visible_10\n",
    "    + visible_1  # turn_r\n",
    "    + visible_3\n",
    "    + visible_1  # turn_r\n",
    "    + visible_10\n",
    "    + visible_1  # turn_l\n",
    "    + visible_3\n",
    "    + visible_1  # turn_l\n",
    "    + visible_10\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "print(\"Visibles length:\", len(visibles))  # → 40\n",
    "\n",
    "# ─── 4) Noise list ───\n",
    "# Here we leave each step noise-free\n",
    "noise_list = [[] for _ in path]\n",
    "\n",
    "# Final sanity check\n",
    "assert len(path) == len(visibles) == len(noise_list), \"Lengths must match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cnn__Always__additive__Hard__Identity\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n",
      "by_sparsity\n",
      "module shapes:  [(3, 3, 4), (4, 4, 5)]\n",
      "N_g     :  116\n",
      "N_patts :  2880\n",
      "N_h     :  600\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5059) tensor(0.) tensor(1.8728)\n",
      "h_from_s max, min, mean tensor(7.5040) tensor(0.) tensor(1.8723)\n",
      "h_from_s_denoised max, min, mean tensor(1235.0868) tensor(0.) tensor(166.9291)\n",
      "avg nonzero/greaterzero h from book: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(3.1806e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(80205.8750) tensor([0.5578])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.0940e-10) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0112) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0464e-10) tensor([1.])\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5059) tensor(0.) tensor(1.8728)\n",
      "h_from_s max, min, mean tensor(7.5041) tensor(0.) tensor(1.8723)\n",
      "h_from_s_denoised max, min, mean tensor(1235.1036) tensor(0.) tensor(166.9313)\n",
      "avg nonzero/greaterzero h from book: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(2.8416e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(80208.0547) tensor([0.5578])\n",
      "mse/cosinesimilarity s and s from h from s tensor(4.4709e-10) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0166) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h tensor(3.0191e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/hippocampal_sensory_layers.py:110: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:4416.)\n",
      "  1 + input.T @ self.inhibition_matrix_hs @ input\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:102: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:109: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s_denoised),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:125: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:132: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s_denoised),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:139: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h),\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for dimension 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     33\u001b[0m agent \u001b[38;5;241m=\u001b[39m MiniworldVectorhashAgent(\n\u001b[1;32m     34\u001b[0m     vectorhash\u001b[38;5;241m=\u001b[39mvh,\n\u001b[1;32m     35\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     preprocessor\u001b[38;5;241m=\u001b[39mcnn_preproc\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 3) kidnapping history\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# signature: kidnapping_test(agent, path, visibles, limits, noise_dist=None)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mkidnapping_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisibles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 4a) save history\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasedir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/rl-research/vectorhash/agent.py:287\u001b[0m, in \u001b[0;36mkidnapping_test\u001b[0;34m(agent, path, visibles, limits, noise_dist)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m## initial history store\u001b[39;00m\n\u001b[1;32m    286\u001b[0m est_img \u001b[38;5;241m=\u001b[39m s_from_h_from_g(agent\u001b[38;5;241m.\u001b[39mvectorhash\u001b[38;5;241m.\u001b[39mscaffold\u001b[38;5;241m.\u001b[39mg)\n\u001b[0;32m--> 287\u001b[0m certainty_o \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorhash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaffold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_certainty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorhash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaffold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m certainty_s \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mvectorhash\u001b[38;5;241m.\u001b[39mscaffold\u001b[38;5;241m.\u001b[39mestimate_certainty(\n\u001b[1;32m    291\u001b[0m     limits, g\u001b[38;5;241m=\u001b[39mg_from_h_from_s(agent\u001b[38;5;241m.\u001b[39mpreprocessor\u001b[38;5;241m.\u001b[39mencode(start_img))\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    293\u001b[0m history\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    294\u001b[0m     true_image\u001b[38;5;241m=\u001b[39mstart_img,\n\u001b[1;32m    295\u001b[0m     estimated_image\u001b[38;5;241m=\u001b[39mest_img,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     seen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    305\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/rl-research/vectorhash/clean_scaffold.py:407\u001b[0m, in \u001b[0;36mGridHippocampalScaffold.estimate_certainty\u001b[0;34m(self, limits, g)\u001b[0m\n\u001b[1;32m    405\u001b[0m     high \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloor(mean \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_factor[dim] \u001b[38;5;241m*\u001b[39m limits[dim])\n\u001b[1;32m    406\u001b[0m     indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(low, high \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m--> 407\u001b[0m     sums[dim] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sums\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for dimension 0 with size 12"
     ]
    }
   ],
   "source": [
    "# ── Run CNN‐only kidnapping tests ──\n",
    "\n",
    "for store_new, shift_m, hard_store, smooth in itertools.product(\n",
    "    store_opts, shift_opts, hard_opts, smooth_opts\n",
    "):\n",
    "    # descriptive run name\n",
    "    sm_str = (\n",
    "        \"Identity\"\n",
    "        if isinstance(smooth, IdentitySmoothing)\n",
    "        else (\n",
    "            f\"Poly(k={smooth.k})\"\n",
    "            if hasattr(smooth, \"k\")\n",
    "            else f\"Softmax(T={smooth.T})\" if hasattr(smooth, \"T\") else \"RatSLAM\"\n",
    "        )\n",
    "    )\n",
    "    run_name = (\n",
    "        f\"cnn__{'Always' if store_new else 'WhenNew'}\"\n",
    "        f\"__{shift_m}__{'Hard' if hard_store else 'Soft'}__{sm_str}\"\n",
    "    )\n",
    "    print(\"Running\", run_name)\n",
    "\n",
    "    # 1) make env & limits\n",
    "    env, limits = make_env()\n",
    "\n",
    "    # 2) build VectorHash + agent\n",
    "    vh = build_vectorhash_architecture(\n",
    "        shapes=shapes,\n",
    "        N_h=600,\n",
    "        input_size=128,  # CNN latent size\n",
    "        initalization_method=\"by_sparsity\",\n",
    "        limits=limits,\n",
    "        device=device,\n",
    "        shift=RatShift(device=device),\n",
    "        smoothing=smooth,\n",
    "    )\n",
    "    agent = MiniworldVectorhashAgent(\n",
    "        vectorhash=vh,\n",
    "        env=env,\n",
    "        hard_store=hard_store,\n",
    "        store_new=store_new,\n",
    "        shift_method=shift_m,\n",
    "        preprocessor=cnn_preproc,\n",
    "    )\n",
    "\n",
    "    # 3) kidnapping history\n",
    "    # signature: kidnapping_test(agent, path, visibles, limits, noise_dist=None)\n",
    "    hist = kidnapping_test(agent, path, visibles, limits)\n",
    "\n",
    "    # 4a) save history\n",
    "    with open(f\"{basedir}/{run_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hist, f)\n",
    "\n",
    "    # 4b) plot error curve\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(hist.errors, label=run_name)\n",
    "    plt.title(run_name)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Position error\")\n",
    "    plt.legend(fontsize=\"x-small\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{basedir}/{run_name}_error.png\", dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
