{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniWorld VectorHash + CNN Performance Tests\n",
    "\n",
    "This notebook runs a grid of VectorHash localization tests on the\n",
    "MiniWorld-Maze environment, comparing raw-flattened pixels against a\n",
    "ResNet-18 pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 17:44:13.544 Python[52628:3106088] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/zz/_8nvyjvj4jd9v1rfts46s0ph0000gn/T/com.apple.python3.savedState\n"
     ]
    }
   ],
   "source": [
    "# ── Imports & reproducibility ──\n",
    "import os, itertools, pickle\n",
    "import torch, numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from miniworld.params import DEFAULT_PARAMS\n",
    "from preprocessing_cnn import PreprocessingCNN\n",
    "from vectorhash import build_vectorhash_architecture\n",
    "from agent import VectorhashAgent\n",
    "from agent_history import VectorhashAgentKidnappedHistory\n",
    "from smoothing import IdentitySmoothing, PolynomialSmoothing, SoftmaxSmoothing\n",
    "\n",
    "# fix seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Helpers: build_env & build_model ──\n",
    "\n",
    "def build_env():\n",
    "    \"\"\"Return a new MiniWorld-Maze-v0 gym env with no randomness.\"\"\"\n",
    "    params = DEFAULT_PARAMS.copy().no_random()\n",
    "    return gym.make(\n",
    "        \"MiniWorld-Maze-v0\",\n",
    "        max_episode_steps=-1,\n",
    "        params=params,\n",
    "        domain_rand=False\n",
    "    )\n",
    "\n",
    "def build_model(\n",
    "    smoothing,\n",
    "    shift=None,\n",
    "    shapes=[(5,5,5),(8,8,8)],\n",
    "    N_h=600,\n",
    "    latent_dim=128,\n",
    "    device=torch.device(\"cpu\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (vh, preproc) tuple:\n",
    "      - vh: VectorHaSH expecting inputs of size `latent_dim`.\n",
    "      - preproc: CNN encoder mapping images → R^latent_dim.\n",
    "    \"\"\"\n",
    "    # 1) CNN preprocessor (ResNet-18 adapter)\n",
    "    preproc = PreprocessingCNN(\n",
    "        device=torch.device(\"cpu\"),\n",
    "        latent_dim=latent_dim,\n",
    "        input_channels=3,\n",
    "        target_size=(224,224),\n",
    "        model_path=\"resnet18_adapter.pth\"\n",
    "    )\n",
    "\n",
    "    # 2) VectorHaSH scaffold\n",
    "    #    input_size = latent_dim because agent feeds vh the CNN output\n",
    "    vh = build_vectorhash_architecture(\n",
    "        shapes=shapes,\n",
    "        N_h=N_h,\n",
    "        input_size=latent_dim,\n",
    "        smoothing=smoothing,\n",
    "        shift=shift,\n",
    "        limits=(2*np.pi, 2*np.pi, 2*np.pi), \n",
    "        relu=True,\n",
    "        percent_nonzero_relu=0.2,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return vh, preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_opts   = [True, False]   # True=\"Always\", False=\"When New\"\n",
    "shift_opts   = [\"additive\", \"multiplicative\"]\n",
    "hard_opts    = [True, False]   # True=\"Hard\", False=\"Soft\"\n",
    "smooth_opts  = [\n",
    "    IdentitySmoothing(),\n",
    "    PolynomialSmoothing(k=1.0),\n",
    "    PolynomialSmoothing(k=1.5),\n",
    "    SoftmaxSmoothing(T=0.1),\n",
    "]\n",
    "\n",
    "basedir = \"miniworld_cnn_tests\"\n",
    "os.makedirs(basedir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cnn__Always__additive__Hard__Identity\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_scaling\n",
      "module shapes:  [(5, 5, 5), (8, 8, 8)]\n",
      "N_g     :  637\n",
      "N_patts :  64000\n",
      "N_h     :  600\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m env \u001b[38;5;241m=\u001b[39m build_env()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 2) build model + preprocessor\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#shift_inst = RatShiftWithCompetitiveAttractorDynamics(\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#    sigma_xy=0.3, sigma_theta=0.3,\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#    inhibition_constant=0.004, delta_gamma=1,\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#    device=torch.device(\"cpu\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m vh, preproc \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 3) agent\u001b[39;00m\n\u001b[1;32m     31\u001b[0m agent \u001b[38;5;241m=\u001b[39m VectorhashAgent(\n\u001b[1;32m     32\u001b[0m     vectorhash\u001b[38;5;241m=\u001b[39mvh,\n\u001b[1;32m     33\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     preprocessor\u001b[38;5;241m=\u001b[39mpreproc\n\u001b[1;32m     38\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(smoothing, shift, shapes, N_h, latent_dim, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m preproc \u001b[38;5;241m=\u001b[39m PreprocessingCNN(\n\u001b[1;32m     28\u001b[0m     device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     29\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet18_adapter.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 2) VectorHaSH scaffold\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#    input_size = latent_dim because agent feeds vh the CNN output\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m vh \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vectorhash_architecture\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if you want env‐specific, recompute\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpercent_nonzero_relu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vh, preproc\n",
      "File \u001b[0;32m~/Desktop/rl-research/vectorhash/vectorhash.py:526\u001b[0m, in \u001b[0;36mbuild_vectorhash_architecture\u001b[0;34m(shapes, N_h, input_size, initalization_method, W_gh_var, percent_nonzero_relu, sparse_initialization, device, hippocampal_sensory_layer_type, hidden_layer_factor, stationary, epsilon_hs, epsilon_sh, relu, shift, smoothing, limits, sanity_check)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mprint\u001b[39m(initalization_method)\n\u001b[1;32m    512\u001b[0m scaffold, mean_h \u001b[38;5;241m=\u001b[39m build_scaffold(\n\u001b[1;32m    513\u001b[0m     shapes,\n\u001b[1;32m    514\u001b[0m     N_h,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m     sanity_check\u001b[38;5;241m=\u001b[39msanity_check,\n\u001b[1;32m    525\u001b[0m )\n\u001b[0;32m--> 526\u001b[0m \u001b[43mshift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hippocampal_sensory_layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact_pseudoinverse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    529\u001b[0m     hippocampal_sensory_layer \u001b[38;5;241m=\u001b[39m ExactPseudoInverseHippocampalSensoryLayer(\n\u001b[1;32m    530\u001b[0m         input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[1;32m    531\u001b[0m         N_h\u001b[38;5;241m=\u001b[39mN_h,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    534\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    535\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "\n",
    "for store_new, shift_m, hard_store, smooth in itertools.product(\n",
    "        store_opts, shift_opts, hard_opts, smooth_opts\n",
    "    ):\n",
    "\n",
    "    sm_str = (\n",
    "        \"Identity\" if isinstance(smooth, IdentitySmoothing) else\n",
    "        f\"Poly(k={smooth.k})\" if hasattr(smooth, \"k\") else\n",
    "        f\"Softmax(T={smooth.T})\"\n",
    "    )\n",
    "    run_name = (\n",
    "        f\"cnn__{'Always' if store_new else 'WhenNew'}\"\n",
    "        f\"__{shift_m}__{'Hard' if hard_store else 'Soft'}__{sm_str}\"\n",
    "    )\n",
    "    print(\"Running\", run_name)\n",
    "\n",
    "    env = build_env()\n",
    "\n",
    "    #shift_inst = RatShiftWithCompetitiveAttractorDynamics(\n",
    "    #    sigma_xy=0.3, sigma_theta=0.3,\n",
    "    #    inhibition_constant=0.004, delta_gamma=1,\n",
    "    #    device=torch.device(\"cpu\")\n",
    "    #)\n",
    "    vh, preproc = build_model(smoothing=smooth)\n",
    "\n",
    "    agent = VectorhashAgent(\n",
    "        vectorhash=vh,\n",
    "        env=env,\n",
    "        hard_store=hard_store,\n",
    "        store_new=store_new,\n",
    "        shift_method=shift_m,\n",
    "        preprocessor=preproc\n",
    "    )\n",
    "\n",
    "    hist = VectorhashAgentKidnappedHistory(\n",
    "        agent=agent,\n",
    "        n_steps=500,\n",
    "        kidnapping_step=200,\n",
    "        smoothing=smooth\n",
    "    )\n",
    "    hist.run()\n",
    "\n",
    "    with open(f\"{basedir}/{run_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hist, f)\n",
    "\n",
    "    # plot error curve\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(hist.errors, label=run_name)\n",
    "    plt.title(run_name)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Position error\")\n",
    "    plt.legend(fontsize=\"x-small\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{basedir}/{run_name}_error.png\", dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
