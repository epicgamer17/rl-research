{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniWorld VectorHash + CNN Performance Tests\n",
    "\n",
    "This notebook runs a grid of VectorHash localization tests on the\n",
    "MiniWorld-Maze environment, comparing raw-flattened pixels against a\n",
    "ResNet-18 pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 18:45:39.201 Python[53374:3141943] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/zz/_8nvyjvj4jd9v1rfts46s0ph0000gn/T/com.apple.python3.savedState\n"
     ]
    }
   ],
   "source": [
    "# ── Imports, device, reproducibility ──\n",
    "import os, itertools, pickle\n",
    "import torch, numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from miniworld.params import DEFAULT_PARAMS\n",
    "from preprocessing_cnn import PreprocessingCNN\n",
    "from vectorhash import build_vectorhash_architecture\n",
    "from miniworld_agent import MiniworldVectorhashAgent\n",
    "from agent_history import VectorhashAgentKidnappedHistory\n",
    "from smoothing import IdentitySmoothing, PolynomialSmoothing, SoftmaxSmoothing, RatSLAMSmoothing\n",
    "from shifts import RatShift\n",
    "\n",
    "# fix seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Env builder, shapes & limits ──\n",
    "\n",
    "shapes = [(3, 3, 4), (4, 4, 5)]\n",
    "\n",
    "def make_env():\n",
    "    params = DEFAULT_PARAMS.copy().no_random()\n",
    "    env = gym.make(\n",
    "        \"MiniWorld-Maze-v0\",\n",
    "        max_episode_steps=-1,\n",
    "        params=params,\n",
    "        domain_rand=False\n",
    "    )\n",
    "    # compute limits from the wrapper attrs\n",
    "    min_x = env.get_wrapper_attr(\"min_x\")\n",
    "    max_x = env.get_wrapper_attr(\"max_x\")\n",
    "    min_z = env.get_wrapper_attr(\"min_z\")\n",
    "    max_z = env.get_wrapper_attr(\"max_z\")\n",
    "    limits = torch.tensor([max_x-min_x, max_z-min_z, 2*np.pi], device=device).float()\n",
    "    return env, limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ── CNN Preprocessor & Hyperparams ──\n",
    "\n",
    "# 1) CNN encoder (ResNet-18 adapter)\n",
    "cnn_preproc = PreprocessingCNN(\n",
    "    device=device,\n",
    "    latent_dim=128,\n",
    "    input_channels=3,\n",
    "    target_size=(224, 224),\n",
    "    model_path=\"resnet18_adapter.pth\"\n",
    ")\n",
    "\n",
    "# 2) Hyperparameter grid\n",
    "store_opts  = [True, False]   # True=\"Always\", False=\"When New\"\n",
    "shift_opts  = [\"additive\", \"multiplicative\"]\n",
    "hard_opts   = [True, False]   # True=\"Hard\", False=\"Soft\"\n",
    "smooth_opts = [\n",
    "    IdentitySmoothing(),\n",
    "    PolynomialSmoothing(k=1.0),\n",
    "    PolynomialSmoothing(k=1.5),\n",
    "    SoftmaxSmoothing(T=0.1),\n",
    "    RatSLAMSmoothing(device=device)\n",
    "]\n",
    "\n",
    "# 3) Output folder\n",
    "basedir = \"miniworld_cnn_tests\"\n",
    "os.makedirs(basedir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cnn__Always__additive__Hard__Identity\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n",
      "Falling back to num_samples=4\n",
      "Falling back to non-multisampled frame buffer\n",
      "by_sparsity\n",
      "module shapes:  [(3, 3, 4), (4, 4, 5)]\n",
      "N_g     :  116\n",
      "N_patts :  2880\n",
      "N_h     :  600\n",
      "info for each h directly after learning it\n",
      "h max, min, mean tensor(7.5059) tensor(0.) tensor(1.8728)\n",
      "h_from_s max, min, mean tensor(7.5040) tensor(0.) tensor(1.8723)\n",
      "h_from_s_denoised max, min, mean tensor(1235.0868) tensor(0.) tensor(166.9291)\n",
      "avg nonzero/greaterzero h from book: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s: tensor(543) tensor(543)\n",
      "avg nonzero/greaterzero h from s denoised: tensor(323) tensor(323)\n",
      "mse/cosinesimilarity h from book and h from s tensor(3.1810e-07) tensor([1.0000])\n",
      "mse/cosinesimilarity h from book and h from s denoised tensor(80205.8672) tensor([0.5578])\n",
      "mse/cosinesimilarity s and s from h from s tensor(3.1657e-10) tensor([1.])\n",
      "mse/cosinesimilarity s and s from h from s denoised tensor(0.0115) tensor([1.0000])\n",
      "mse/cosinesimilarity s and s from h tensor(2.0950e-10) tensor([1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/hippocampal_sensory_layers.py:110: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:4416.)\n",
      "  1 + input.T @ self.inhibition_matrix_hs @ input\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:102: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:109: UserWarning: Using a target size (torch.Size([1, 600])) that is different to the input size (torch.Size([600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(h, h_from_s_denoised),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:125: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:132: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h_from_s_denoised),\n",
      "/Users/awalnoorsinghbajaj/Desktop/rl-research/vectorhash/vectorhash.py:139: UserWarning: Using a target size (torch.Size([1, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  torch.nn.functional.mse_loss(s, s_from_h),\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     33\u001b[0m agent \u001b[38;5;241m=\u001b[39m MiniworldVectorhashAgent(\n\u001b[1;32m     34\u001b[0m     vectorhash\u001b[38;5;241m=\u001b[39mvh,\n\u001b[1;32m     35\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     preprocessor\u001b[38;5;241m=\u001b[39mcnn_preproc\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 3) kidnapping history\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m### error in history \u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mVectorhashAgentKidnappedHistory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkidnapping_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmooth\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m hist\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 4a) save history\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'agent'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ── Run CNN‐only kidnapping tests ──\n",
    "\n",
    "for store_new, shift_m, hard_store, smooth in itertools.product(\n",
    "    store_opts, shift_opts, hard_opts, smooth_opts\n",
    "):\n",
    "    # descriptive name\n",
    "    sm_str = (\n",
    "        \"Identity\" if isinstance(smooth, IdentitySmoothing) else\n",
    "        f\"Poly(k={smooth.k})\" if hasattr(smooth, \"k\") else\n",
    "        f\"Softmax(T={smooth.T})\" if hasattr(smooth, \"T\") else\n",
    "        \"RatSLAM\"\n",
    "    )\n",
    "    run_name = (\n",
    "        f\"cnn__{'Always' if store_new else 'WhenNew'}\"\n",
    "        f\"__{shift_m}__{'Hard' if hard_store else 'Soft'}__{sm_str}\"\n",
    "    )\n",
    "    print(\"Running\", run_name)\n",
    "\n",
    "    # 1) make env\n",
    "    env, limits = make_env()\n",
    "\n",
    "    # 2) build VectorHash + agent\n",
    "    vh = build_vectorhash_architecture(\n",
    "        shapes=shapes,\n",
    "        N_h=600,\n",
    "        input_size=128,          # CNN latent size\n",
    "        initalization_method=\"by_sparsity\",\n",
    "        limits=limits,\n",
    "        device=device,\n",
    "        shift=RatShift(device=device),\n",
    "        smoothing=smooth,\n",
    "    )\n",
    "    agent = MiniworldVectorhashAgent(\n",
    "        vectorhash=vh,\n",
    "        env=env,\n",
    "        hard_store=hard_store,\n",
    "        store_new=store_new,\n",
    "        shift_method=shift_m,\n",
    "        preprocessor=cnn_preproc\n",
    "    )\n",
    "\n",
    "    # 3) kidnapping history\n",
    "    ### error in history \n",
    "    hist = kidnapping_test(agent, path, noise_list, visibles)\n",
    "    hist.run()\n",
    "\n",
    "    # 4a) save history\n",
    "    with open(f\"{basedir}/{run_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hist, f)\n",
    "\n",
    "    # 4b) plot error\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(hist.errors, label=run_name)\n",
    "    plt.title(run_name)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Position error\")\n",
    "    plt.legend(fontsize=\"x-small\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{basedir}/{run_name}_error.png\", dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
